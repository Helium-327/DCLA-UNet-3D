[0;32m2025-05-15 17:44:50,888  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 17:44:52,389  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 17:44:52,395  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 17:44:52,395  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 17:44:52,395  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 17:44:52,395  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 17:44:52,395  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 17:44:52,403  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 17:44:52,403  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 17:44:52,403  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 17:44:52,405  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA_UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA_UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA_UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA_UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA_UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA_UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.65 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 17:44:52,872  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 17:44:52,872  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 17:47:33,057  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 17:47:33,058  - INFO - - Train mean loss: 0.8566
- ET loss: 0.6492
- TC loss: 0.9768
- WT loss: 0.9439
- Cost time: 2.67mins â±ï¸
[0m
[0;32m2025-05-15 17:47:33,058  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 17:47:53,047  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:19.9877s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.258 â”‚ 0.662 â”‚ 0.031 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.192 â”‚ 0.519 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.232 â”‚ 0.638 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.908 â”‚ 0.742 â”‚ 0.983 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7472, ET: 0.3528, TC: 0.9686, WT: 0.9202
[0m
[0;32m2025-05-15 17:47:53,390  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA_UNet/results/DCLA_UNet_v2_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7472_dice0.2578_20250515174753.pth;             Size 8.29 MB[0m
[0;32m2025-05-15 17:47:53,390  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 18:23:47,997  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 18:23:49,780  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 18:23:49,787  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 18:23:49,787  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:23:49,787  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:23:49,787  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:23:49,787  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 18:23:49,794  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 18:23:49,794  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 18:23:49,794  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 18:23:49,797  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA_UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA_UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA_UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA_UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA_UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA_UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.65 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 18:23:50,266  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 18:23:50,266  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 18:25:06,844  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 18:25:08,555  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 18:25:08,556  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 18:25:08,556  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:25:08,556  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:25:08,557  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:25:08,557  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 18:25:08,561  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-15 18:25:08,561  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-15 18:25:08,561  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-15 18:25:08,563  - INFO - ğŸ§  é¡¹ç›®åï¼š0515_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA_UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA_UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA_UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0515_DCLA_UNet_v2                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA_UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA_UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA_UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.65 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 18:25:11,097  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 18:25:11,097  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 18:27:40,546  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 18:27:42,399  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 18:27:42,401  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 18:27:42,402  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:27:42,402  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:27:42,402  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 18:27:42,402  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 18:27:42,407  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-15 18:27:42,407  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-15 18:27:42,407  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-15 18:27:42,409  - INFO - ğŸ§  é¡¹ç›®åï¼š0515_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0515_DCLA_UNet_v2                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.65 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 18:27:44,652  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 18:27:44,652  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 19:12:19,496  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 19:12:21,431  - INFO - Total number of parameters: 0.70 M[0m
[0;32m2025-05-15 19:12:21,437  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 19:12:21,437  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:12:21,437  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:12:21,437  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:12:21,437  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 19:12:21,451  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 19:12:21,451  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 19:12:21,451  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 19:12:21,454  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.70 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 19:12:21,802  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:12:21,802  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:15:33,643  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:15:33,644  - INFO - - Train mean loss: 0.6509
- ET loss: 0.6540
- TC loss: 0.7319
- WT loss: 0.5668
- Cost time: 3.20mins â±ï¸
[0m
[0;32m2025-05-15 19:15:33,644  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:15:59,196  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:25.5510s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.627 â”‚ 0.625 â”‚ 0.496 â”‚ 0.759 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.493 â”‚ 0.482 â”‚ 0.357 â”‚ 0.639 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.611 â”‚ 0.585 â”‚ 0.397 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.775 â”‚ 0.737 â”‚ 0.868 â”‚ 0.72  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3791, ET: 0.3852, TC: 0.5084, WT: 0.2438
[0m
[0;32m2025-05-15 19:15:59,293  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3791_dice0.6267_20250515191559.pth;             Size 8.86 MB[0m
[0;32m2025-05-15 19:15:59,294  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:16:36,932  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 19:16:38,848  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 19:16:38,850  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 19:16:38,850  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:16:38,850  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:16:38,850  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:16:38,850  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 19:16:38,855  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 19:16:38,855  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 19:16:38,855  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 19:16:38,858  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 19:16:39,219  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:16:39,219  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:19:40,664  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:19:40,664  - INFO - - Train mean loss: 0.7285
- ET loss: 0.8120
- TC loss: 0.7506
- WT loss: 0.6230
- Cost time: 3.02mins â±ï¸
[0m
[0;32m2025-05-15 19:19:40,664  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:20:05,058  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.3930s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.592 â”‚ 0.499 â”‚ 0.555 â”‚ 0.722 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.456 â”‚ 0.353 â”‚ 0.416 â”‚ 0.598 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.406 â”‚ 0.487 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.744 â”‚ 0.773 â”‚ 0.816 â”‚ 0.645 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4120, ET: 0.5086, TC: 0.4505, WT: 0.2768
[0m
[0;32m2025-05-15 19:20:05,164  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4120_dice0.5922_20250515192005.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 19:20:05,164  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 19:23:04,684  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 19:23:04,684  - INFO - - Train mean loss: 0.4839
- ET loss: 0.5692
- TC loss: 0.5375
- WT loss: 0.3450
- Cost time: 2.99mins â±ï¸
[0m
[0;32m2025-05-15 19:23:04,684  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:23:29,481  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.7965s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.68  â”‚ 0.62  â”‚ 0.647 â”‚ 0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.473 â”‚ 0.512 â”‚ 0.654 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.72  â”‚ 0.574 â”‚ 0.711 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.711 â”‚ 0.743 â”‚ 0.664 â”‚ 0.726 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3285, ET: 0.3906, TC: 0.3643, WT: 0.2305
[0m
[1;31m2025-05-15 19:23:29,482  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.4120_dice0.5922_20250515192005.pth[0m
[0;32m2025-05-15 19:23:29,580  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3285_dice0.6798_20250515192329.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 19:23:29,581  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 19:27:13,584  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 19:27:15,497  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-15 19:27:15,498  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 19:27:15,498  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:27:15,498  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:27:15,498  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:27:15,498  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 19:27:15,503  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 19:27:15,503  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 19:27:15,503  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 19:27:15,506  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.64 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 19:27:15,877  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:27:15,877  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:30:15,022  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:30:15,023  - INFO - - Train mean loss: 0.6804
- ET loss: 0.7841
- TC loss: 0.7089
- WT loss: 0.5482
- Cost time: 2.99mins â±ï¸
[0m
[0;32m2025-05-15 19:30:15,023  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:30:39,299  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.2754s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.57  â”‚ 0.417 â”‚ 0.555 â”‚ 0.737 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.439 â”‚ 0.284 â”‚ 0.419 â”‚ 0.615 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.574 â”‚ 0.316 â”‚ 0.48  â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.767 â”‚ 0.825 â”‚ 0.839 â”‚ 0.638 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4343, ET: 0.5868, TC: 0.4502, WT: 0.2660
[0m
[1;31m2025-05-15 19:30:39,301  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3285_dice0.6798_20250515192329.pth[0m
[0;32m2025-05-15 19:30:39,396  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4343_dice0.5696_20250515193039.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:30:39,396  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 19:33:36,435  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 19:33:36,436  - INFO - - Train mean loss: 0.5199
- ET loss: 0.6505
- TC loss: 0.5474
- WT loss: 0.3617
- Cost time: 2.95mins â±ï¸
[0m
[0;32m2025-05-15 19:33:36,436  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:34:00,537  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.1006s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.584 â”‚ 0.424 â”‚ 0.576 â”‚ 0.753 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.454 â”‚ 0.291 â”‚ 0.44  â”‚ 0.631 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.575 â”‚ 0.314 â”‚ 0.486 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.795 â”‚ 0.854 â”‚ 0.874 â”‚ 0.657 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4183, ET: 0.5777, TC: 0.4285, WT: 0.2488
[0m
[1;31m2025-05-15 19:34:00,539  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.4343_dice0.5696_20250515193039.pth[0m
[0;32m2025-05-15 19:34:00,628  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4183_dice0.5844_20250515193400.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:34:00,628  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-15 19:36:58,217  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-15 19:36:58,218  - INFO - - Train mean loss: 0.4852
- ET loss: 0.6111
- TC loss: 0.5023
- WT loss: 0.3421
- Cost time: 2.96mins â±ï¸
[0m
[0;32m2025-05-15 19:36:58,218  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 19:37:22,471  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:24.2527s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.589 â”‚ 0.422 â”‚ 0.572 â”‚ 0.772 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.46  â”‚ 0.289 â”‚ 0.438 â”‚ 0.654 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.565 â”‚ 0.307 â”‚ 0.471 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.822 â”‚ 0.879 â”‚ 0.898 â”‚ 0.689 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4135, ET: 0.5802, TC: 0.4309, WT: 0.2295
[0m
[1;31m2025-05-15 19:37:22,472  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4183_dice0.5844_20250515193400.pth[0m
[0;32m2025-05-15 19:37:22,560  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.4135_dice0.5886_20250515193722.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:37:22,560  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;32m2025-05-15 19:39:33,167  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 19:39:35,066  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-15 19:39:35,068  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 19:39:35,068  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:39:35,068  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:39:35,068  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:39:35,068  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 19:39:35,073  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 19:39:35,073  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 19:39:35,073  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 19:39:35,076  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.64 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 19:39:35,426  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:39:35,426  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:42:35,196  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:42:35,196  - INFO - - Train mean loss: 0.8548
- ET loss: 0.6814
- TC loss: 0.9645
- WT loss: 0.9184
- Cost time: 3.00mins â±ï¸
[0m
[0;32m2025-05-15 19:42:35,196  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:42:59,671  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.4739s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.254 â”‚ 0.619 â”‚ 0.041 â”‚ 0.102 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.183 â”‚ 0.472 â”‚ 0.021 â”‚ 0.055 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.205 â”‚ 0.538 â”‚ 0.021 â”‚ 0.055 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.925 â”‚ 0.791 â”‚ 0.983 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7541, ET: 0.4053, TC: 0.9591, WT: 0.8980
[0m
[1;31m2025-05-15 19:42:59,672  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.4135_dice0.5886_20250515193722.pth[0m
[0;32m2025-05-15 19:42:59,776  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7541_dice0.2540_20250515194259.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:42:59,776  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 19:45:57,975  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 19:45:57,975  - INFO - - Train mean loss: 0.7838
- ET loss: 0.5014
- TC loss: 0.9559
- WT loss: 0.8942
- Cost time: 2.97mins â±ï¸
[0m
[0;32m2025-05-15 19:45:57,976  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:46:22,309  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.3333s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.291 â”‚ 0.69  â”‚ 0.053 â”‚ 0.13  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.218 â”‚ 0.554 â”‚ 0.028 â”‚ 0.072 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.256 â”‚ 0.669 â”‚ 0.028 â”‚ 0.072 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.758 â”‚ 0.981 â”‚ 0.991 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7143, ET: 0.3262, TC: 0.9467, WT: 0.8701
[0m
[1;31m2025-05-15 19:46:22,311  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.7541_dice0.2540_20250515194259.pth[0m
[0;32m2025-05-15 19:46:22,398  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.7143_dice0.2909_20250515194622.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:46:22,399  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 19:46:33,363  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 19:46:35,493  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 19:46:35,494  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 19:46:35,494  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:46:35,494  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:46:35,494  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:46:35,494  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 19:46:35,502  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 19:46:35,502  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 19:46:35,502  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 19:46:35,505  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 19:46:35,867  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:46:35,867  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:49:36,282  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:49:36,283  - INFO - - Train mean loss: 0.8387
- ET loss: 0.5975
- TC loss: 0.9768
- WT loss: 0.9418
- Cost time: 3.01mins â±ï¸
[0m
[0;32m2025-05-15 19:49:36,283  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:50:01,138  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.8539s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.272 â”‚ 0.704 â”‚ 0.031 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.21  â”‚ 0.573 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.262 â”‚ 0.729 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.735 â”‚ 0.983 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7286, ET: 0.2972, TC: 0.9685, WT: 0.9200
[0m
[1;31m2025-05-15 19:50:01,139  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.7143_dice0.2909_20250515194622.pth[0m
[0;32m2025-05-15 19:50:01,243  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7286_dice0.2719_20250515195001.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 19:50:01,243  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:56:01,982  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 19:56:03,959  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-15 19:56:03,960  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 19:56:03,960  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:56:03,960  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:56:03,961  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 19:56:03,961  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 19:56:03,965  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 19:56:03,965  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 19:56:03,965  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 19:56:03,968  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.64 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 19:56:04,335  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:56:04,336  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:59:07,367  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:59:07,368  - INFO - - Train mean loss: 0.8565
- ET loss: 0.6874
- TC loss: 0.9640
- WT loss: 0.9180
- Cost time: 3.05mins â±ï¸
[0m
[0;32m2025-05-15 19:59:07,368  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:59:32,018  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.6496s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.258 â”‚ 0.629 â”‚ 0.042 â”‚ 0.104 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.187 â”‚ 0.483 â”‚ 0.022 â”‚ 0.056 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.211 â”‚ 0.556 â”‚ 0.022 â”‚ 0.056 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.922 â”‚ 0.782 â”‚ 0.983 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7493, ET: 0.3929, TC: 0.9584, WT: 0.8966
[0m
[1;31m2025-05-15 19:59:32,020  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.7286_dice0.2719_20250515195001.pth[0m
[0;32m2025-05-15 19:59:32,119  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7493_dice0.2579_20250515195932.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:59:32,119  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 20:02:31,396  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 20:02:31,396  - INFO - - Train mean loss: 0.7694
- ET loss: 0.5031
- TC loss: 0.9377
- WT loss: 0.8674
- Cost time: 2.99mins â±ï¸
[0m
[0;32m2025-05-15 20:02:31,396  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 20:02:55,726  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.3292s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.546 â”‚ 0.598 â”‚ 0.465 â”‚ 0.576 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.413 â”‚ 0.465 â”‚ 0.333 â”‚ 0.442 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.612 â”‚ 0.663 â”‚ 0.426 â”‚ 0.747 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.634 â”‚ 0.652 â”‚ 0.731 â”‚ 0.518 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4588, ET: 0.4103, TC: 0.5399, WT: 0.4261
[0m
[1;31m2025-05-15 20:02:55,727  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.7493_dice0.2579_20250515195932.pth[0m
[0;32m2025-05-15 20:02:55,819  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4588_dice0.5463_20250515200255.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 20:02:55,819  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-15 20:05:53,401  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-15 20:05:53,401  - INFO - - Train mean loss: 0.4644
- ET loss: 0.4611
- TC loss: 0.5625
- WT loss: 0.3696
- Cost time: 2.96mins â±ï¸
[0m
[0;32m2025-05-15 20:05:53,401  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 20:06:17,672  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:24.2704s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.652 â”‚ 0.677 â”‚ 0.483 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.522 â”‚ 0.539 â”‚ 0.348 â”‚ 0.679 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.591 â”‚ 0.601 â”‚ 0.365 â”‚ 0.805 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.856 â”‚ 0.821 â”‚ 0.934 â”‚ 0.813 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3554, ET: 0.3344, TC: 0.5213, WT: 0.2104
[0m
[1;31m2025-05-15 20:06:17,673  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4588_dice0.5463_20250515200255.pth[0m
[0;32m2025-05-15 20:06:17,768  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3554_dice0.6521_20250515200617.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 20:06:17,768  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-15 20:09:15,642  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-15 20:09:15,643  - INFO - - Train mean loss: 0.4435
- ET loss: 0.4466
- TC loss: 0.5513
- WT loss: 0.3326
- Cost time: 2.96mins â±ï¸
[0m
[0;32m2025-05-15 20:09:15,643  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-15 20:09:39,954  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:24.3105s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.669 â”‚ 0.708 â”‚ 0.487 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.581 â”‚ 0.352 â”‚ 0.7   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.648 â”‚ 0.745 â”‚ 0.37  â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.822 â”‚ 0.712 â”‚ 0.933 â”‚ 0.821 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3362, ET: 0.2991, TC: 0.5157, WT: 0.1939
[0m
[1;31m2025-05-15 20:09:39,955  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3554_dice0.6521_20250515200617.pth[0m
[0;32m2025-05-15 20:09:40,050  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.3362_dice0.6688_20250515200939.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 20:09:40,050  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;32m2025-05-15 20:14:54,180  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 20:14:56,094  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 20:14:56,096  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 20:14:56,096  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 20:14:56,096  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 20:14:56,096  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 20:14:56,096  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 20:14:56,100  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-15 20:14:56,100  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-15 20:14:56,101  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-15 20:14:56,103  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 20:14:56,428  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 20:14:56,428  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 20:17:54,629  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 20:17:54,630  - INFO - - Train mean loss: 0.6699
- ET loss: 1.0000
- TC loss: 0.5798
- WT loss: 0.4299
- Cost time: 2.97mins â±ï¸
[0m
[0;32m2025-05-15 20:17:54,630  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 20:18:19,043  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.4118s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.501 â”‚    0 â”‚ 0.702 â”‚ 0.8   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.418 â”‚    0 â”‚ 0.569 â”‚ 0.686 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.496 â”‚    0 â”‚ 0.653 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.54  â”‚    0 â”‚ 0.831 â”‚ 0.789 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5036, ET: 1.0000, TC: 0.3071, WT: 0.2038
[0m
[1;31m2025-05-15 20:18:19,045  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.3362_dice0.6688_20250515200939.pth[0m
[0;32m2025-05-15 20:18:19,143  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5036_dice0.5007_20250515201819.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 20:18:19,143  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 20:21:15,622  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 20:21:15,623  - INFO - - Train mean loss: 0.5875
- ET loss: 1.0000
- TC loss: 0.4553
- WT loss: 0.3073
- Cost time: 2.94mins â±ï¸
[0m
[0;32m2025-05-15 20:21:15,623  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 20:21:39,621  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:23.9979s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.505 â”‚    0 â”‚ 0.718 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.423 â”‚    0 â”‚ 0.59  â”‚ 0.68  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.464 â”‚    0 â”‚ 0.649 â”‚ 0.743 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.581 â”‚    0 â”‚ 0.86  â”‚ 0.882 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5002, ET: 1.0000, TC: 0.2914, WT: 0.2093
[0m
[1;31m2025-05-15 20:21:39,622  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.5036_dice0.5007_20250515201819.pth[0m
[0;32m2025-05-15 20:21:39,720  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5002_dice0.5049_20250515202139.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 20:21:39,721  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-15 20:24:36,983  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-15 20:24:36,983  - INFO - - Train mean loss: 0.5656
- ET loss: 1.0000
- TC loss: 0.4110
- WT loss: 0.2857
- Cost time: 2.95mins â±ï¸
[0m
[0;32m2025-05-15 20:24:36,983  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 20:25:01,606  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:24.6217s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.495 â”‚    0 â”‚ 0.673 â”‚ 0.812 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.413 â”‚    0 â”‚ 0.539 â”‚ 0.699 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.445 â”‚    0 â”‚ 0.564 â”‚ 0.771 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.595 â”‚    0 â”‚ 0.906 â”‚ 0.878 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5095, ET: 1.0000, TC: 0.3349, WT: 0.1936
[0m
[0;33m2025-05-15 20:25:01,606  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-15 20:25:01,606  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;32m2025-05-15 20:25:30,024  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 20:25:31,967  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 20:25:31,969  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 20:25:31,969  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 20:25:31,969  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 20:25:31,969  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 20:25:31,969  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 20:25:31,975  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-15 20:25:31,975  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-15 20:25:31,975  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-15 20:25:31,978  - INFO - ğŸ§  é¡¹ç›®åï¼š0515_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0515_DCLA_UNet_v2                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 20:25:34,770  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 20:25:34,770  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-15 20:37:57,702  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-15 20:37:57,704  - INFO - - Train mean loss: 0.5939
- ET loss: 1.0000
- TC loss: 0.4670
- WT loss: 0.3145
- Cost time: 12.38mins â±ï¸
[0m
[0;32m2025-05-15 20:37:57,704  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 20:39:36,650  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:98.9445s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.511 â”‚    0 â”‚ 0.708 â”‚ 0.827 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.441 â”‚    0 â”‚ 0.595 â”‚ 0.729 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.553 â”‚    0 â”‚ 0.797 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.512 â”‚    0 â”‚ 0.714 â”‚ 0.822 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4919, ET: 1.0000, TC: 0.2976, WT: 0.1782
[0m
[0;32m2025-05-15 20:39:36,760  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.4919_dice0.5115_20250515203936.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 20:39:36,760  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;32m2025-05-15 21:47:46,040  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 21:47:48,084  - INFO - Total number of parameters: 3.03 M[0m
[0;32m2025-05-15 21:47:48,091  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 21:47:48,091  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 21:47:48,091  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 21:47:48,091  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 21:47:48,091  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 21:47:48,101  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-15 21:47:48,101  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-15 21:47:48,101  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-15 21:47:48,103  - INFO - ğŸ§  é¡¹ç›®åï¼š0515_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ Mamba3d                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0515_DCLA_UNet_v2                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 3.03 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 21:47:51,171  - INFO - 
model: Mamba3d
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 21:47:51,172  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-15 21:51:35,037  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-15 21:51:35,038  - INFO - - Train mean loss: 0.8887
- ET loss: 0.8723
- TC loss: 0.8631
- WT loss: 0.9306
- Cost time: 3.73mins â±ï¸
[0m
[0;32m2025-05-15 21:51:35,038  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 21:52:22,606  - INFO - === [Epoch 1/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:47.5668s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.401 â”‚ 0.477 â”‚ 0.636 â”‚ 0.089 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.296 â”‚ 0.338 â”‚ 0.502 â”‚ 0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.334 â”‚ 0.371 â”‚ 0.584 â”‚ 0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.873 â”‚ 0.807 â”‚ 0.825 â”‚ 0.987 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6357, ET: 0.5547, TC: 0.4416, WT: 0.9108
[0m
[0;32m2025-05-15 21:52:22,756  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.6357_dice0.4006_20250515215222.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 21:52:22,756  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;32m2025-05-15 21:52:40,998  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-15 21:52:43,169  - INFO - Total number of parameters: 3.03 M[0m
[0;32m2025-05-15 21:52:43,170  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-15 21:52:43,170  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-15 21:52:43,170  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 21:52:43,170  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-15 21:52:43,171  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-15 21:52:43,175  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-15 21:52:43,175  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-15 21:52:43,175  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-15 21:52:43,178  - INFO - ğŸ§  é¡¹ç›®åï¼š0515_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ Mamba3d                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0515_DCLA_UNet_v2                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 3.03 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-15 21:52:45,440  - INFO - 
model: Mamba3d
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 21:52:45,441  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-15 21:56:29,381  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-15 21:56:29,382  - INFO - - Train mean loss: 0.8894
- ET loss: 0.8738
- TC loss: 0.8638
- WT loss: 0.9305
- Cost time: 3.73mins â±ï¸
[0m
[0;32m2025-05-15 21:56:29,382  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 21:56:55,664  - INFO - === [Epoch 1/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:26.2805s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.413 â”‚ 0.495 â”‚ 0.657 â”‚ 0.087 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.307 â”‚ 0.354 â”‚ 0.522 â”‚ 0.046 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.361 â”‚ 0.402 â”‚ 0.635 â”‚ 0.046 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.848 â”‚ 0.768 â”‚ 0.792 â”‚ 0.985 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6299, ET: 0.5451, TC: 0.4331, WT: 0.9116
[0m
[0;32m2025-05-15 21:56:55,732  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.6299_dice0.4128_20250515215655.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 21:56:55,732  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-15 22:00:39,953  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-15 22:00:39,954  - INFO - - Train mean loss: 0.6518
- ET loss: 0.5535
- TC loss: 0.4614
- WT loss: 0.9406
- Cost time: 3.74mins â±ï¸
[0m
[0;32m2025-05-15 22:00:39,954  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-15 22:01:07,600  - INFO - === [Epoch 2/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:27.6457s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.451 â”‚ 0.559 â”‚ 0.704 â”‚ 0.089 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.349 â”‚ 0.417 â”‚ 0.581 â”‚ 0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.443 â”‚ 0.506 â”‚ 0.777 â”‚ 0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.801 â”‚ 0.697 â”‚ 0.708 â”‚ 0.999 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5526, ET: 0.4443, TC: 0.3021, WT: 0.9114
[0m
[1;31m2025-05-15 22:01:07,604  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.6299_dice0.4128_20250515215655.pth[0m
[0;32m2025-05-15 22:01:07,677  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.5526_dice0.4508_20250515220107.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:01:07,677  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-15 22:01:09,201  - WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /api/house/metrics[0m
[0;33m2025-05-15 22:05:00,765  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-15 22:05:00,766  - INFO - - Train mean loss: 0.6187
- ET loss: 0.5139
- TC loss: 0.4058
- WT loss: 0.9364
- Cost time: 3.88mins â±ï¸
[0m
[0;32m2025-05-15 22:05:00,766  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-15 22:05:29,717  - INFO - === [Epoch 3/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:28.9499s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.471 â”‚ 0.571 â”‚ 0.748 â”‚ 0.095 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.37  â”‚ 0.429 â”‚ 0.632 â”‚ 0.051 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.417 â”‚ 0.471 â”‚ 0.729 â”‚ 0.051 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.811 â”‚ 0.83  â”‚ 0.968 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5302, ET: 0.4307, TC: 0.2548, WT: 0.9051
[0m
[1;31m2025-05-15 22:05:29,721  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5526_dice0.4508_20250515220107.pth[0m
[0;32m2025-05-15 22:05:29,811  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.5302_dice0.4713_20250515220529.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:05:29,811  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-15 22:09:33,015  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-15 22:09:33,016  - INFO - - Train mean loss: 0.5713
- ET loss: 0.4993
- TC loss: 0.3887
- WT loss: 0.8260
- Cost time: 4.05mins â±ï¸
[0m
[0;32m2025-05-15 22:09:33,016  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-15 22:10:01,696  - INFO - === [Epoch 4/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:28.6792s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.642 â”‚ 0.536 â”‚ 0.711 â”‚ 0.678 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.505 â”‚ 0.395 â”‚ 0.589 â”‚ 0.531 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.573 â”‚ 0.412 â”‚ 0.639 â”‚ 0.668 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.84  â”‚ 0.878 â”‚ 0.889 â”‚ 0.751 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3882, ET: 0.4680, TC: 0.2957, WT: 0.4009
[0m
[1;31m2025-05-15 22:10:01,699  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.5302_dice0.4713_20250515220529.pth[0m
[0;32m2025-05-15 22:10:01,779  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.3882_dice0.6415_20250515221001.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:10:01,779  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-15 22:14:02,227  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-15 22:14:02,227  - INFO - - Train mean loss: 0.4383
- ET loss: 0.5097
- TC loss: 0.4058
- WT loss: 0.3993
- Cost time: 4.01mins â±ï¸
[0m
[0;32m2025-05-15 22:14:02,227  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-15 22:14:30,191  - INFO - === [Epoch 5/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:27.9633s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.707 â”‚ 0.595 â”‚ 0.76  â”‚ 0.765 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.58  â”‚ 0.455 â”‚ 0.649 â”‚ 0.635 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.672 â”‚ 0.499 â”‚ 0.753 â”‚ 0.764 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.807 â”‚ 0.813 â”‚ 0.816 â”‚ 0.793 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3004, ET: 0.4082, TC: 0.2451, WT: 0.2478
[0m
[1;31m2025-05-15 22:14:30,194  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.3882_dice0.6415_20250515221001.pth[0m
[0;32m2025-05-15 22:14:30,265  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.3004_dice0.7069_20250515221430.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:14:30,265  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-15 22:18:33,685  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-15 22:18:33,685  - INFO - - Train mean loss: 0.4027
- ET loss: 0.4959
- TC loss: 0.3888
- WT loss: 0.3233
- Cost time: 4.06mins â±ï¸
[0m
[0;32m2025-05-15 22:18:33,685  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-15 22:19:01,774  - INFO - === [Epoch 6/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:28.0882s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.718 â”‚ 0.61  â”‚ 0.76  â”‚ 0.783 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.593 â”‚ 0.47  â”‚ 0.652 â”‚ 0.657 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.714 â”‚ 0.533 â”‚ 0.794 â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.773 â”‚ 0.774 â”‚ 0.773 â”‚ 0.773 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2865, ET: 0.3919, TC: 0.2429, WT: 0.2247
[0m
[1;31m2025-05-15 22:19:01,778  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.3004_dice0.7069_20250515221430.pth[0m
[0;32m2025-05-15 22:19:01,847  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.2865_dice0.7177_20250515221901.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:19:01,848  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-15 22:22:45,032  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-15 22:22:45,033  - INFO - - Train mean loss: 0.3837
- ET loss: 0.4813
- TC loss: 0.3678
- WT loss: 0.3018
- Cost time: 3.72mins â±ï¸
[0m
[0;32m2025-05-15 22:22:45,033  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-15 22:23:10,309  - INFO - === [Epoch 7/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:25.2755s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.72  â”‚ 0.601 â”‚ 0.761 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.597 â”‚ 0.461 â”‚ 0.65  â”‚ 0.678 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.68  â”‚ 0.496 â”‚ 0.747 â”‚ 0.798 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.824 â”‚ 0.828 â”‚ 0.825 â”‚ 0.817 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2846, ET: 0.4018, TC: 0.2428, WT: 0.2092
[0m
[1;31m2025-05-15 22:23:10,312  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.2865_dice0.7177_20250515221901.pth[0m
[0;32m2025-05-15 22:23:10,374  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.2846_dice0.7196_20250515222310.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:23:10,374  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-15 22:26:44,774  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-15 22:26:44,774  - INFO - - Train mean loss: 0.3710
- ET loss: 0.4717
- TC loss: 0.3578
- WT loss: 0.2834
- Cost time: 3.57mins â±ï¸
[0m
[0;32m2025-05-15 22:26:44,775  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-15 22:27:09,958  - INFO - === [Epoch 8/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:25.1824s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.696 â”‚ 0.574 â”‚ 0.751 â”‚ 0.764 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.57  â”‚ 0.432 â”‚ 0.638 â”‚ 0.64  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.604 â”‚ 0.45  â”‚ 0.685 â”‚ 0.678 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.888 â”‚ 0.895 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3067, ET: 0.4280, TC: 0.2522, WT: 0.2397
[0m
[0;33m2025-05-15 22:27:09,958  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-15 22:27:09,958  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-15 22:30:44,231  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-15 22:30:44,232  - INFO - - Train mean loss: 0.3640
- ET loss: 0.4673
- TC loss: 0.3495
- WT loss: 0.2752
- Cost time: 3.57mins â±ï¸
[0m
[0;32m2025-05-15 22:30:44,232  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-15 22:31:09,658  - INFO - === [Epoch 9/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:25.4251s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.737 â”‚ 0.631 â”‚ 0.764 â”‚ 0.818 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.62  â”‚ 0.491 â”‚ 0.662 â”‚ 0.707 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.737 â”‚ 0.568 â”‚ 0.834 â”‚ 0.808 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.789 â”‚ 0.765 â”‚ 0.753 â”‚ 0.85  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2658, ET: 0.3712, TC: 0.2391, WT: 0.1871
[0m
[1;31m2025-05-15 22:31:09,661  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.2846_dice0.7196_20250515222310.pth[0m
[0;32m2025-05-15 22:31:09,726  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.2658_dice0.7375_20250515223109.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:31:09,726  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-15 22:34:43,995  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-15 22:34:43,995  - INFO - - Train mean loss: 0.3468
- ET loss: 0.4473
- TC loss: 0.3328
- WT loss: 0.2605
- Cost time: 3.57mins â±ï¸
[0m
[0;32m2025-05-15 22:34:43,995  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-15 22:35:09,206  - INFO - === [Epoch 10/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:25.2100s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.742 â”‚ 0.626 â”‚ 0.766 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.627 â”‚ 0.488 â”‚ 0.666 â”‚ 0.728 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.74  â”‚ 0.562 â”‚ 0.826 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.791 â”‚ 0.764 â”‚ 0.756 â”‚ 0.854 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2619, ET: 0.3760, TC: 0.2366, WT: 0.1731
[0m
[1;31m2025-05-15 22:35:09,209  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.2658_dice0.7375_20250515223109.pth[0m
[0;32m2025-05-15 22:35:09,279  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.2619_dice0.7417_20250515223509.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:35:09,279  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-15 22:38:57,482  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-15 22:38:57,482  - INFO - - Train mean loss: 0.3387
- ET loss: 0.4452
- TC loss: 0.3281
- WT loss: 0.2428
- Cost time: 3.80mins â±ï¸
[0m
[0;32m2025-05-15 22:38:57,483  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-15 22:39:24,710  - INFO - === [Epoch 11/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:27.2270s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.752 â”‚ 0.631 â”‚ 0.795 â”‚ 0.83  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.64  â”‚ 0.496 â”‚ 0.701 â”‚ 0.724 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.722 â”‚ 0.546 â”‚ 0.824 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.836 â”‚ 0.808 â”‚ 0.81  â”‚ 0.89  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2513, ET: 0.3712, TC: 0.2080, WT: 0.1748
[0m
[1;31m2025-05-15 22:39:24,714  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.2619_dice0.7417_20250515223509.pth[0m
[0;32m2025-05-15 22:39:24,782  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.2513_dice0.7519_20250515223924.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:39:24,782  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-15 22:43:15,779  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-15 22:43:15,779  - INFO - - Train mean loss: 0.3319
- ET loss: 0.4381
- TC loss: 0.3230
- WT loss: 0.2344
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 22:43:15,779  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-15 22:43:43,176  - INFO - === [Epoch 12/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:27.3962s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.763 â”‚ 0.647 â”‚ 0.793 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.655 â”‚ 0.511 â”‚ 0.703 â”‚ 0.751 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.753 â”‚ 0.566 â”‚ 0.835 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.822 â”‚ 0.811 â”‚ 0.799 â”‚ 0.856 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2409, ET: 0.3557, TC: 0.2099, WT: 0.1569
[0m
[1;31m2025-05-15 22:43:43,180  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.2513_dice0.7519_20250515223924.pth[0m
[0;32m2025-05-15 22:43:43,312  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.2409_dice0.7628_20250515224343.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:43:43,313  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-15 22:47:34,131  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-15 22:47:34,131  - INFO - - Train mean loss: 0.3289
- ET loss: 0.4349
- TC loss: 0.3218
- WT loss: 0.2299
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 22:47:34,131  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-15 22:48:01,398  - INFO - === [Epoch 13/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:27.2658s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.764 â”‚ 0.648 â”‚ 0.792 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.658 â”‚ 0.513 â”‚ 0.702 â”‚ 0.757 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.744 â”‚ 0.565 â”‚ 0.826 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.836 â”‚ 0.823 â”‚ 0.805 â”‚ 0.88  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2394, ET: 0.3545, TC: 0.2108, WT: 0.1529
[0m
[1;31m2025-05-15 22:48:01,401  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.2409_dice0.7628_20250515224343.pth[0m
[0;32m2025-05-15 22:48:01,468  - INFO - âœ¨ Saved checkpoint (epoch 13) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.2394_dice0.7640_20250515224801.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:48:01,468  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-15 22:51:51,460  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-15 22:51:51,461  - INFO - - Train mean loss: 0.3141
- ET loss: 0.4223
- TC loss: 0.3078
- WT loss: 0.2123
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-15 22:51:51,461  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-15 22:52:18,571  - INFO - === [Epoch 14/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:27.1092s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.767 â”‚ 0.647 â”‚ 0.797 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.66  â”‚ 0.512 â”‚ 0.705 â”‚ 0.765 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.769 â”‚ 0.586 â”‚ 0.87  â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.813 â”‚ 0.783 â”‚ 0.775 â”‚ 0.881 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2362, ET: 0.3551, TC: 0.2059, WT: 0.1478
[0m
[1;31m2025-05-15 22:52:18,574  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch13_loss0.2394_dice0.7640_20250515224801.pth[0m
[0;32m2025-05-15 22:52:18,647  - INFO - âœ¨ Saved checkpoint (epoch 14) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch14_loss0.2362_dice0.7674_20250515225218.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:52:18,647  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-15 22:56:08,475  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-15 22:56:08,476  - INFO - - Train mean loss: 0.3305
- ET loss: 0.4366
- TC loss: 0.3267
- WT loss: 0.2282
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-15 22:56:08,476  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-15 22:56:35,631  - INFO - === [Epoch 15/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:27.1548s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.764 â”‚ 0.635 â”‚ 0.803 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.658 â”‚ 0.501 â”‚ 0.714 â”‚ 0.758 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.734 â”‚ 0.544 â”‚ 0.809 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.847 â”‚ 0.836 â”‚ 0.833 â”‚ 0.872 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2399, ET: 0.3665, TC: 0.2002, WT: 0.1530
[0m
[0;33m2025-05-15 22:56:35,631  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-15 22:56:35,631  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-15 23:00:24,997  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-15 23:00:24,997  - INFO - - Train mean loss: 0.3045
- ET loss: 0.4119
- TC loss: 0.2981
- WT loss: 0.2035
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-15 23:00:24,997  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-15 23:00:52,067  - INFO - === [Epoch 16/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:27.0694s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.757 â”‚ 0.632 â”‚ 0.801 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.649 â”‚ 0.499 â”‚ 0.712 â”‚ 0.737 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.715 â”‚ 0.547 â”‚ 0.814 â”‚ 0.784 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.835 â”‚ 0.83  â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2461, ET: 0.3699, TC: 0.2017, WT: 0.1668
[0m
[0;33m2025-05-15 23:00:52,068  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-15 23:00:52,068  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-15 23:04:41,617  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-15 23:04:41,618  - INFO - - Train mean loss: 0.3124
- ET loss: 0.4230
- TC loss: 0.3108
- WT loss: 0.2035
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-15 23:04:41,618  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-15 23:05:08,794  - INFO - === [Epoch 17/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:27.1757s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.779 â”‚ 0.661 â”‚ 0.802 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.674 â”‚ 0.527 â”‚ 0.708 â”‚ 0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.781 â”‚ 0.603 â”‚ 0.88  â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.819 â”‚ 0.788 â”‚ 0.77  â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2247, ET: 0.3410, TC: 0.2012, WT: 0.1317
[0m
[1;31m2025-05-15 23:05:08,797  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch14_loss0.2362_dice0.7674_20250515225218.pth[0m
[0;32m2025-05-15 23:05:08,860  - INFO - âœ¨ Saved checkpoint (epoch 17) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch17_loss0.2247_dice0.7787_20250515230508.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:05:08,860  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-15 23:08:59,175  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-15 23:08:59,175  - INFO - - Train mean loss: 0.3068
- ET loss: 0.4088
- TC loss: 0.3059
- WT loss: 0.2056
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-15 23:08:59,176  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-15 23:09:26,723  - INFO - === [Epoch 18/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:27.5465s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.782 â”‚ 0.661 â”‚ 0.814 â”‚ 0.872 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.683 â”‚ 0.529 â”‚ 0.73  â”‚ 0.788 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.775 â”‚ 0.574 â”‚ 0.846 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.836 â”‚ 0.834 â”‚ 0.82  â”‚ 0.856 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2209, ET: 0.3418, TC: 0.1891, WT: 0.1317
[0m
[1;31m2025-05-15 23:09:26,726  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch17_loss0.2247_dice0.7787_20250515230508.pth[0m
[0;32m2025-05-15 23:09:26,798  - INFO - âœ¨ Saved checkpoint (epoch 18) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch18_loss0.2209_dice0.7821_20250515230926.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:09:26,798  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-15 23:13:16,823  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-15 23:13:16,823  - INFO - - Train mean loss: 0.3010
- ET loss: 0.4098
- TC loss: 0.2944
- WT loss: 0.1988
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-15 23:13:16,824  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-15 23:13:44,092  - INFO - === [Epoch 19/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:27.2678s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.788 â”‚ 0.662 â”‚ 0.826 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.69  â”‚ 0.532 â”‚ 0.745 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.762 â”‚ 0.574 â”‚ 0.839 â”‚ 0.872 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.871 â”‚ 0.863 â”‚ 0.851 â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2147, ET: 0.3401, TC: 0.1770, WT: 0.1269
[0m
[1;31m2025-05-15 23:13:44,095  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch18_loss0.2209_dice0.7821_20250515230926.pth[0m
[0;32m2025-05-15 23:13:44,156  - INFO - âœ¨ Saved checkpoint (epoch 19) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch19_loss0.2147_dice0.7882_20250515231344.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:13:44,157  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-15 23:17:35,038  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-15 23:17:35,039  - INFO - - Train mean loss: 0.2914
- ET loss: 0.4025
- TC loss: 0.2829
- WT loss: 0.1889
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 23:17:35,039  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-15 23:18:02,399  - INFO - === [Epoch 20/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:27.3588s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.791 â”‚ 0.658 â”‚ 0.838 â”‚ 0.878 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.694 â”‚ 0.528 â”‚ 0.758 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.763 â”‚ 0.573 â”‚ 0.849 â”‚ 0.868 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.861 â”‚ 0.863 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2114, ET: 0.3435, TC: 0.1649, WT: 0.1258
[0m
[1;31m2025-05-15 23:18:02,403  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch19_loss0.2147_dice0.7882_20250515231344.pth[0m
[0;32m2025-05-15 23:18:02,469  - INFO - âœ¨ Saved checkpoint (epoch 20) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch20_loss0.2114_dice0.7914_20250515231802.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:18:02,470  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-15 23:21:53,443  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-15 23:21:53,444  - INFO - - Train mean loss: 0.2913
- ET loss: 0.4003
- TC loss: 0.2794
- WT loss: 0.1941
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 23:21:53,444  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-15 23:22:20,550  - INFO - === [Epoch 21/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:27.1057s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.792 â”‚ 0.661 â”‚ 0.841 â”‚ 0.875 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.695 â”‚ 0.53  â”‚ 0.761 â”‚ 0.793 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.765 â”‚ 0.577 â”‚ 0.859 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.858 â”‚ 0.861 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2104, ET: 0.3409, TC: 0.1619, WT: 0.1283
[0m
[1;31m2025-05-15 23:22:20,553  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch20_loss0.2114_dice0.7914_20250515231802.pth[0m
[0;32m2025-05-15 23:22:20,616  - INFO - âœ¨ Saved checkpoint (epoch 21) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.2104_dice0.7924_20250515232220.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:22:20,616  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-15 23:26:11,627  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-15 23:26:11,628  - INFO - - Train mean loss: 0.2910
- ET loss: 0.4040
- TC loss: 0.2844
- WT loss: 0.1846
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 23:26:11,628  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-15 23:26:38,801  - INFO - === [Epoch 22/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:27.1723s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.79  â”‚ 0.657 â”‚ 0.836 â”‚ 0.878 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.693 â”‚ 0.527 â”‚ 0.757 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.748 â”‚ 0.557 â”‚ 0.829 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.886 â”‚ 0.884 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2123, ET: 0.3448, TC: 0.1664, WT: 0.1256
[0m
[0;33m2025-05-15 23:26:38,801  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-15 23:26:38,801  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-15 23:30:29,117  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-15 23:30:29,118  - INFO - - Train mean loss: 0.2912
- ET loss: 0.4017
- TC loss: 0.2805
- WT loss: 0.1913
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-15 23:30:29,118  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-15 23:30:56,391  - INFO - === [Epoch 23/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:27.2726s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.796 â”‚ 0.669 â”‚ 0.837 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.702 â”‚ 0.542 â”‚ 0.759 â”‚ 0.805 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.787 â”‚ 0.588 â”‚ 0.864 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.85  â”‚ 0.841 â”‚ 0.836 â”‚ 0.872 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2058, ET: 0.3325, TC: 0.1654, WT: 0.1194
[0m
[1;31m2025-05-15 23:30:56,394  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch21_loss0.2104_dice0.7924_20250515232220.pth[0m
[0;32m2025-05-15 23:30:56,470  - INFO - âœ¨ Saved checkpoint (epoch 23) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch23_loss0.2058_dice0.7964_20250515233056.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:30:56,470  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-15 23:34:47,218  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-15 23:34:47,218  - INFO - - Train mean loss: 0.2848
- ET loss: 0.3938
- TC loss: 0.2761
- WT loss: 0.1844
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 23:34:47,218  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-15 23:35:14,367  - INFO - === [Epoch 24/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:27.1482s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.8   â”‚ 0.676 â”‚ 0.837 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.705 â”‚ 0.548 â”‚ 0.759 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.786 â”‚ 0.595 â”‚ 0.873 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.857 â”‚ 0.842 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2022, ET: 0.3250, TC: 0.1653, WT: 0.1161
[0m
[1;31m2025-05-15 23:35:14,370  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch23_loss0.2058_dice0.7964_20250515233056.pth[0m
[0;32m2025-05-15 23:35:14,431  - INFO - âœ¨ Saved checkpoint (epoch 24) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch24_loss0.2022_dice0.8001_20250515233514.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:35:14,431  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-15 23:39:05,018  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-15 23:39:05,019  - INFO - - Train mean loss: 0.2843
- ET loss: 0.3924
- TC loss: 0.2750
- WT loss: 0.1854
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-15 23:39:05,019  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-15 23:39:32,316  - INFO - === [Epoch 25/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:27.2970s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.796 â”‚ 0.662 â”‚ 0.844 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.701 â”‚ 0.533 â”‚ 0.768 â”‚ 0.802 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.758 â”‚ 0.565 â”‚ 0.839 â”‚ 0.87  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.885 â”‚ 0.887 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2061, ET: 0.3393, TC: 0.1578, WT: 0.1211
[0m
[0;33m2025-05-15 23:39:32,317  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-15 23:39:32,317  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-15 23:43:23,380  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-15 23:43:23,381  - INFO - - Train mean loss: 0.2829
- ET loss: 0.3905
- TC loss: 0.2773
- WT loss: 0.1808
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 23:43:23,381  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-15 23:43:50,688  - INFO - === [Epoch 26/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:27.3066s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.801 â”‚ 0.664 â”‚ 0.85  â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.707 â”‚ 0.536 â”‚ 0.774 â”‚ 0.81  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.767 â”‚ 0.57  â”‚ 0.847 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.879 â”‚ 0.884 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2012, ET: 0.3370, TC: 0.1516, WT: 0.1151
[0m
[1;31m2025-05-15 23:43:50,692  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch24_loss0.2022_dice0.8001_20250515233514.pth[0m
[0;32m2025-05-15 23:43:50,764  - INFO - âœ¨ Saved checkpoint (epoch 26) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch26_loss0.2012_dice0.8008_20250515234350.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:43:50,765  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-15 23:47:41,183  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-15 23:47:41,183  - INFO - - Train mean loss: 0.2872
- ET loss: 0.3960
- TC loss: 0.2780
- WT loss: 0.1876
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-15 23:47:41,183  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-15 23:48:08,259  - INFO - === [Epoch 27/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:27.0752s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.804 â”‚ 0.673 â”‚ 0.849 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.71  â”‚ 0.545 â”‚ 0.773 â”‚ 0.813 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.783 â”‚ 0.579 â”‚ 0.853 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.879 â”‚ 0.874 â”‚ 0.877 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1979, ET: 0.3282, TC: 0.1531, WT: 0.1123
[0m
[1;31m2025-05-15 23:48:08,263  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch26_loss0.2012_dice0.8008_20250515234350.pth[0m
[0;32m2025-05-15 23:48:08,331  - INFO - âœ¨ Saved checkpoint (epoch 27) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch27_loss0.1979_dice0.8041_20250515234808.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:48:08,331  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-15 23:51:59,094  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-15 23:51:59,095  - INFO - - Train mean loss: 0.2804
- ET loss: 0.3966
- TC loss: 0.2681
- WT loss: 0.1763
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-15 23:51:59,095  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-15 23:52:26,168  - INFO - === [Epoch 28/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:27.0723s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.802 â”‚ 0.667 â”‚ 0.851 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.709 â”‚ 0.539 â”‚ 0.776 â”‚ 0.812 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.769 â”‚ 0.572 â”‚ 0.845 â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.886 â”‚ 0.891 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1993, ET: 0.3343, TC: 0.1510, WT: 0.1128
[0m
[0;33m2025-05-15 23:52:26,168  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-15 23:52:26,168  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-15 23:56:16,846  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-15 23:56:16,847  - INFO - - Train mean loss: 0.2769
- ET loss: 0.3846
- TC loss: 0.2699
- WT loss: 0.1762
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-15 23:56:16,847  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-15 23:56:43,993  - INFO - === [Epoch 29/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:27.1456s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.805 â”‚ 0.679 â”‚ 0.845 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.713 â”‚ 0.553 â”‚ 0.77  â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.796 â”‚ 0.6   â”‚ 0.881 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.86  â”‚ 0.847 â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1962, ET: 0.3216, TC: 0.1569, WT: 0.1102
[0m
[1;31m2025-05-15 23:56:43,996  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch27_loss0.1979_dice0.8041_20250515234808.pth[0m
[0;32m2025-05-15 23:56:44,080  - INFO - âœ¨ Saved checkpoint (epoch 29) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch29_loss0.1962_dice0.8054_20250515235643.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:56:44,080  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-16 00:00:34,598  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-16 00:00:34,599  - INFO - - Train mean loss: 0.2782
- ET loss: 0.3851
- TC loss: 0.2698
- WT loss: 0.1797
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 00:00:34,599  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-16 00:01:01,709  - INFO - === [Epoch 30/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:27.1093s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.803 â”‚ 0.672 â”‚ 0.845 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.71  â”‚ 0.546 â”‚ 0.767 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.785 â”‚ 0.59  â”‚ 0.864 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.868 â”‚ 0.861 â”‚ 0.897 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1987, ET: 0.3290, TC: 0.1565, WT: 0.1107
[0m
[0;33m2025-05-16 00:01:01,709  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:01:01,709  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-16 00:04:52,100  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-16 00:04:52,101  - INFO - - Train mean loss: 0.2863
- ET loss: 0.3970
- TC loss: 0.2811
- WT loss: 0.1808
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 00:04:52,101  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-16 00:05:19,229  - INFO - === [Epoch 31/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:27.1275s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.808 â”‚ 0.675 â”‚ 0.854 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.716 â”‚ 0.547 â”‚ 0.781 â”‚ 0.82  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.801 â”‚ 0.594 â”‚ 0.876 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.863 â”‚ 0.858 â”‚ 0.86  â”‚ 0.872 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1934, ET: 0.3256, TC: 0.1472, WT: 0.1074
[0m
[1;31m2025-05-16 00:05:19,232  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch29_loss0.1962_dice0.8054_20250515235643.pth[0m
[0;32m2025-05-16 00:05:19,306  - INFO - âœ¨ Saved checkpoint (epoch 31) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch31_loss0.1934_dice0.8081_20250516000519.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:05:19,306  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-16 00:09:09,112  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-16 00:09:09,113  - INFO - - Train mean loss: 0.2773
- ET loss: 0.3870
- TC loss: 0.2679
- WT loss: 0.1770
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 00:09:09,113  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-16 00:09:36,341  - INFO - === [Epoch 32/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:27.2268s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.803 â”‚ 0.689 â”‚ 0.835 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.707 â”‚ 0.56  â”‚ 0.754 â”‚ 0.807 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.775 â”‚ 0.597 â”‚ 0.855 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.875 â”‚ 0.844 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1985, ET: 0.3112, TC: 0.1670, WT: 0.1173
[0m
[0;33m2025-05-16 00:09:36,341  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:09:36,341  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-16 00:13:25,769  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-16 00:13:25,770  - INFO - - Train mean loss: 0.2647
- ET loss: 0.3744
- TC loss: 0.2576
- WT loss: 0.1621
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-16 00:13:25,770  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-16 00:13:53,111  - INFO - === [Epoch 33/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:27.3402s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.808 â”‚ 0.675 â”‚ 0.852 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.716 â”‚ 0.546 â”‚ 0.779 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.777 â”‚ 0.572 â”‚ 0.843 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.893 â”‚ 0.888 â”‚ 0.888 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1937, ET: 0.3259, TC: 0.1498, WT: 0.1056
[0m
[0;33m2025-05-16 00:13:53,111  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 00:13:53,111  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-16 00:17:43,831  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-16 00:17:43,831  - INFO - - Train mean loss: 0.2668
- ET loss: 0.3816
- TC loss: 0.2493
- WT loss: 0.1695
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 00:17:43,831  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-16 00:18:11,134  - INFO - === [Epoch 34/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:27.3024s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.812 â”‚ 0.694 â”‚ 0.845 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.719 â”‚ 0.565 â”‚ 0.77  â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.612 â”‚ 0.879 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.869 â”‚ 0.86  â”‚ 0.841 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1897, ET: 0.3068, TC: 0.1561, WT: 0.1064
[0m
[1;31m2025-05-16 00:18:11,137  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch31_loss0.1934_dice0.8081_20250516000519.pth[0m
[0;32m2025-05-16 00:18:11,202  - INFO - âœ¨ Saved checkpoint (epoch 34) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch34_loss0.1897_dice0.8117_20250516001811.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:18:11,203  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-16 00:22:02,040  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-16 00:22:02,041  - INFO - - Train mean loss: 0.2771
- ET loss: 0.3831
- TC loss: 0.2674
- WT loss: 0.1809
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 00:22:02,041  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-16 00:22:29,348  - INFO - === [Epoch 35/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:27.3062s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.806 â”‚ 0.684 â”‚ 0.851 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.713 â”‚ 0.556 â”‚ 0.779 â”‚ 0.803 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.773 â”‚ 0.595 â”‚ 0.868 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.879 â”‚ 0.868 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1952, ET: 0.3170, TC: 0.1503, WT: 0.1181
[0m
[0;33m2025-05-16 00:22:29,348  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:22:29,348  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-16 00:26:19,699  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-16 00:26:19,699  - INFO - - Train mean loss: 0.2726
- ET loss: 0.3844
- TC loss: 0.2640
- WT loss: 0.1694
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 00:26:19,699  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-16 00:26:46,863  - INFO - === [Epoch 36/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:27.1626s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.812 â”‚ 0.688 â”‚ 0.851 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.72  â”‚ 0.561 â”‚ 0.777 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.61  â”‚ 0.888 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.858 â”‚ 0.845 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1896, ET: 0.3126, TC: 0.1511, WT: 0.1053
[0m
[1;31m2025-05-16 00:26:46,871  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch34_loss0.1897_dice0.8117_20250516001811.pth[0m
[0;32m2025-05-16 00:26:46,934  - INFO - âœ¨ Saved checkpoint (epoch 36) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch36_loss0.1896_dice0.8119_20250516002646.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:26:46,934  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-16 00:30:37,644  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-16 00:30:37,645  - INFO - - Train mean loss: 0.2715
- ET loss: 0.3817
- TC loss: 0.2580
- WT loss: 0.1748
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 00:30:37,645  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-16 00:31:04,927  - INFO - === [Epoch 37/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:27.2815s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.81  â”‚ 0.681 â”‚ 0.858 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.719 â”‚ 0.556 â”‚ 0.786 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.604 â”‚ 0.89  â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.866 â”‚ 0.861 â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1912, ET: 0.3197, TC: 0.1432, WT: 0.1108
[0m
[0;33m2025-05-16 00:31:04,927  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:31:04,927  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-16 00:34:55,569  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-16 00:34:55,570  - INFO - - Train mean loss: 0.2624
- ET loss: 0.3725
- TC loss: 0.2472
- WT loss: 0.1675
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 00:34:55,570  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-16 00:35:22,857  - INFO - === [Epoch 38/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:27.2866s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.807 â”‚ 0.67  â”‚ 0.855 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.715 â”‚ 0.543 â”‚ 0.781 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.772 â”‚ 0.573 â”‚ 0.845 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.9   â”‚ 0.901 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1943, ET: 0.3302, TC: 0.1464, WT: 0.1062
[0m
[0;33m2025-05-16 00:35:22,857  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 00:35:22,857  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-16 00:39:12,836  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-16 00:39:12,836  - INFO - - Train mean loss: 0.2734
- ET loss: 0.3908
- TC loss: 0.2595
- WT loss: 0.1699
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 00:39:12,836  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-16 00:39:39,901  - INFO - === [Epoch 39/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:27.0637s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.814 â”‚ 0.679 â”‚ 0.866 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.724 â”‚ 0.553 â”‚ 0.794 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.782 â”‚ 0.588 â”‚ 0.864 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.887 â”‚ 0.894 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1871, ET: 0.3215, TC: 0.1351, WT: 0.1048
[0m
[1;31m2025-05-16 00:39:39,904  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch36_loss0.1896_dice0.8119_20250516002646.pth[0m
[0;32m2025-05-16 00:39:39,965  - INFO - âœ¨ Saved checkpoint (epoch 39) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch39_loss0.1871_dice0.8143_20250516003939.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:39:39,965  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-16 00:43:29,749  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-16 00:43:29,749  - INFO - - Train mean loss: 0.2639
- ET loss: 0.3699
- TC loss: 0.2513
- WT loss: 0.1704
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 00:43:29,749  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-16 00:43:57,023  - INFO - === [Epoch 40/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:27.2732s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.814 â”‚ 0.684 â”‚ 0.858 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.723 â”‚ 0.557 â”‚ 0.787 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.785 â”‚ 0.59  â”‚ 0.869 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.885 â”‚ 0.877 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1876, ET: 0.3163, TC: 0.1432, WT: 0.1034
[0m
[0;33m2025-05-16 00:43:57,023  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:43:57,023  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-16 00:47:47,856  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-16 00:47:47,856  - INFO - - Train mean loss: 0.2639
- ET loss: 0.3799
- TC loss: 0.2463
- WT loss: 0.1656
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 00:47:47,856  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-16 00:48:15,082  - INFO - === [Epoch 41/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:27.2253s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.812 â”‚ 0.675 â”‚ 0.861 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.722 â”‚ 0.549 â”‚ 0.792 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.783 â”‚ 0.584 â”‚ 0.858 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.883 â”‚ 0.892 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1896, ET: 0.3255, TC: 0.1398, WT: 0.1033
[0m
[0;33m2025-05-16 00:48:15,082  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 00:48:15,082  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-16 00:52:05,739  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-16 00:52:05,739  - INFO - - Train mean loss: 0.2593
- ET loss: 0.3749
- TC loss: 0.2408
- WT loss: 0.1623
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 00:52:05,739  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-16 00:52:33,111  - INFO - === [Epoch 42/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:27.3712s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.811 â”‚ 0.68  â”‚ 0.857 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.721 â”‚ 0.553 â”‚ 0.786 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.782 â”‚ 0.59  â”‚ 0.865 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.881 â”‚ 0.879 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1903, ET: 0.3210, TC: 0.1442, WT: 0.1058
[0m
[0;33m2025-05-16 00:52:33,111  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 00:52:33,111  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-16 00:56:23,908  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-16 00:56:23,908  - INFO - - Train mean loss: 0.2688
- ET loss: 0.3815
- TC loss: 0.2583
- WT loss: 0.1666
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 00:56:23,908  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-16 00:56:51,338  - INFO - === [Epoch 43/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:27.4292s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.814 â”‚ 0.691 â”‚ 0.855 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.723 â”‚ 0.564 â”‚ 0.783 â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.787 â”‚ 0.602 â”‚ 0.875 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.881 â”‚ 0.865 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1879, ET: 0.3100, TC: 0.1466, WT: 0.1071
[0m
[0;33m2025-05-16 00:56:51,338  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-16 00:56:51,338  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-16 01:00:41,485  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-16 01:00:41,486  - INFO - - Train mean loss: 0.2647
- ET loss: 0.3770
- TC loss: 0.2469
- WT loss: 0.1702
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:00:41,486  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-16 01:01:08,581  - INFO - === [Epoch 44/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:27.0951s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.813 â”‚ 0.685 â”‚ 0.856 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.723 â”‚ 0.56  â”‚ 0.783 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.784 â”‚ 0.59  â”‚ 0.863 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.887 â”‚ 0.877 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1885, ET: 0.3161, TC: 0.1450, WT: 0.1045
[0m
[0;33m2025-05-16 01:01:08,582  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-16 01:01:08,582  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-16 01:04:58,839  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-16 01:04:58,840  - INFO - - Train mean loss: 0.2723
- ET loss: 0.3878
- TC loss: 0.2584
- WT loss: 0.1707
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:04:58,840  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-16 01:05:26,144  - INFO - === [Epoch 45/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:27.3035s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.811 â”‚ 0.682 â”‚ 0.859 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.721 â”‚ 0.557 â”‚ 0.786 â”‚ 0.819 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.793 â”‚ 0.59  â”‚ 0.865 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.885 â”‚ 0.883 â”‚ 0.873 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1902, ET: 0.3186, TC: 0.1420, WT: 0.1100
[0m
[0;33m2025-05-16 01:05:26,144  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-16 01:05:26,144  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-16 01:09:16,428  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-16 01:09:16,429  - INFO - - Train mean loss: 0.2729
- ET loss: 0.3907
- TC loss: 0.2632
- WT loss: 0.1647
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:09:16,429  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-16 01:09:43,885  - INFO - === [Epoch 46/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:27.4555s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.805 â”‚ 0.665 â”‚ 0.854 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.714 â”‚ 0.538 â”‚ 0.779 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.758 â”‚ 0.559 â”‚ 0.822 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.918 â”‚ 0.917 â”‚ 0.924 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1960, ET: 0.3355, TC: 0.1468, WT: 0.1058
[0m
[0;33m2025-05-16 01:09:43,885  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-16 01:09:43,885  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-16 01:13:34,857  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-16 01:13:34,858  - INFO - - Train mean loss: 0.2577
- ET loss: 0.3766
- TC loss: 0.2375
- WT loss: 0.1591
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 01:13:34,858  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-16 01:14:02,082  - INFO - === [Epoch 47/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:27.2237s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.813 â”‚ 0.681 â”‚ 0.858 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.725 â”‚ 0.558 â”‚ 0.787 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.81  â”‚ 0.615 â”‚ 0.896 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.849 â”‚ 0.855 â”‚ 0.889 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1884, ET: 0.3195, TC: 0.1432, WT: 0.1025
[0m
[0;33m2025-05-16 01:14:02,083  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-16 01:14:02,083  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-16 01:17:52,603  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-16 01:17:52,604  - INFO - - Train mean loss: 0.2673
- ET loss: 0.3822
- TC loss: 0.2545
- WT loss: 0.1651
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:17:52,604  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-16 01:18:19,675  - INFO - === [Epoch 48/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:27.0702s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.818 â”‚ 0.686 â”‚ 0.867 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.73  â”‚ 0.56  â”‚ 0.798 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.602 â”‚ 0.882 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.874 â”‚ 0.879 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1829, ET: 0.3147, TC: 0.1342, WT: 0.0997
[0m
[1;31m2025-05-16 01:18:19,678  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch39_loss0.1871_dice0.8143_20250516003939.pth[0m
[0;32m2025-05-16 01:18:19,749  - INFO - âœ¨ Saved checkpoint (epoch 48) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch48_loss0.1829_dice0.8183_20250516011819.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:18:19,749  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-16 01:22:09,724  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-16 01:22:09,724  - INFO - - Train mean loss: 0.2634
- ET loss: 0.3809
- TC loss: 0.2457
- WT loss: 0.1637
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 01:22:09,724  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-16 01:22:37,028  - INFO - === [Epoch 49/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:27.3031s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.816 â”‚ 0.68  â”‚ 0.869 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.727 â”‚ 0.555 â”‚ 0.799 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.787 â”‚ 0.59  â”‚ 0.866 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.89  â”‚ 0.9   â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1849, ET: 0.3210, TC: 0.1320, WT: 0.1018
[0m
[0;33m2025-05-16 01:22:37,028  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 01:22:37,028  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-16 01:26:27,729  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-16 01:26:27,730  - INFO - - Train mean loss: 0.2610
- ET loss: 0.3730
- TC loss: 0.2435
- WT loss: 0.1665
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 01:26:27,730  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-16 01:26:54,923  - INFO - === [Epoch 50/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:27.1926s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.818 â”‚ 0.687 â”‚ 0.868 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.728 â”‚ 0.561 â”‚ 0.797 â”‚ 0.827 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.801 â”‚ 0.602 â”‚ 0.886 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.876 â”‚ 0.877 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1831, ET: 0.3139, TC: 0.1331, WT: 0.1022
[0m
[0;33m2025-05-16 01:26:54,923  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 01:26:54,923  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-16 01:30:45,788  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-16 01:30:45,788  - INFO - - Train mean loss: 0.2652
- ET loss: 0.3773
- TC loss: 0.2517
- WT loss: 0.1666
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 01:30:45,788  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-16 01:31:13,002  - INFO - === [Epoch 51/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:27.2126s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.815 â”‚ 0.688 â”‚ 0.856 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.726 â”‚ 0.563 â”‚ 0.786 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.608 â”‚ 0.888 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.865 â”‚ 0.857 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1864, ET: 0.3121, TC: 0.1449, WT: 0.1023
[0m
[0;33m2025-05-16 01:31:13,002  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 01:31:13,002  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-16 01:35:03,806  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-16 01:35:03,807  - INFO - - Train mean loss: 0.2649
- ET loss: 0.3786
- TC loss: 0.2475
- WT loss: 0.1686
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 01:35:03,807  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-16 01:35:31,033  - INFO - === [Epoch 52/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:27.2255s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.817 â”‚ 0.685 â”‚ 0.869 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.728 â”‚ 0.559 â”‚ 0.8   â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.786 â”‚ 0.594 â”‚ 0.874 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.888 â”‚ 0.892 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1838, ET: 0.3159, TC: 0.1323, WT: 0.1031
[0m
[0;33m2025-05-16 01:35:31,033  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-16 01:35:31,034  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-16 01:39:22,055  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-16 01:39:22,055  - INFO - - Train mean loss: 0.2638
- ET loss: 0.3786
- TC loss: 0.2546
- WT loss: 0.1582
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 01:39:22,055  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-16 01:39:49,147  - INFO - === [Epoch 53/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:27.0917s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.821 â”‚ 0.687 â”‚ 0.872 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.732 â”‚ 0.561 â”‚ 0.8   â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.793 â”‚ 0.592 â”‚ 0.872 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.894 â”‚ 0.896 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1801, ET: 0.3137, TC: 0.1293, WT: 0.0975
[0m
[1;31m2025-05-16 01:39:49,151  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch48_loss0.1829_dice0.8183_20250516011819.pth[0m
[0;32m2025-05-16 01:39:49,220  - INFO - âœ¨ Saved checkpoint (epoch 53) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch53_loss0.1801_dice0.8209_20250516013949.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:39:49,220  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-16 01:43:39,758  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-16 01:43:39,758  - INFO - - Train mean loss: 0.2651
- ET loss: 0.3834
- TC loss: 0.2497
- WT loss: 0.1623
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:43:39,758  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-16 01:44:07,002  - INFO - === [Epoch 54/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:27.2432s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.822 â”‚ 0.69  â”‚ 0.871 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.733 â”‚ 0.565 â”‚ 0.8   â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.601 â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.886 â”‚ 0.885 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1792, ET: 0.3102, TC: 0.1299, WT: 0.0975
[0m
[1;31m2025-05-16 01:44:07,005  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch53_loss0.1801_dice0.8209_20250516013949.pth[0m
[0;32m2025-05-16 01:44:07,062  - INFO - âœ¨ Saved checkpoint (epoch 54) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch54_loss0.1792_dice0.8218_20250516014407.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:44:07,062  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-16 01:47:57,692  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-16 01:47:57,693  - INFO - - Train mean loss: 0.2514
- ET loss: 0.3672
- TC loss: 0.2321
- WT loss: 0.1550
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:47:57,693  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-16 01:48:25,174  - INFO - === [Epoch 55/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:27.4804s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.815 â”‚ 0.68  â”‚ 0.871 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.723 â”‚ 0.554 â”‚ 0.799 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.764 â”‚ 0.578 â”‚ 0.849 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.922 â”‚ 0.909 â”‚ 0.918 â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1859, ET: 0.3200, TC: 0.1296, WT: 0.1082
[0m
[0;33m2025-05-16 01:48:25,174  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 01:48:25,174  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-16 01:52:15,741  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-16 01:52:15,742  - INFO - - Train mean loss: 0.2462
- ET loss: 0.3583
- TC loss: 0.2269
- WT loss: 0.1534
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 01:52:15,742  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-16 01:52:43,046  - INFO - === [Epoch 56/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:27.3039s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.822 â”‚ 0.689 â”‚ 0.875 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.733 â”‚ 0.563 â”‚ 0.804 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.793 â”‚ 0.596 â”‚ 0.879 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.892 â”‚ 0.892 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1792, ET: 0.3117, TC: 0.1260, WT: 0.0997
[0m
[1;31m2025-05-16 01:52:43,049  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch54_loss0.1792_dice0.8218_20250516014407.pth[0m
[0;32m2025-05-16 01:52:43,125  - INFO - âœ¨ Saved checkpoint (epoch 56) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch56_loss0.1792_dice0.8218_20250516015243.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:52:43,126  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-16 01:56:33,949  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-16 01:56:33,950  - INFO - - Train mean loss: 0.2606
- ET loss: 0.3762
- TC loss: 0.2449
- WT loss: 0.1606
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 01:56:33,950  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-16 01:57:01,237  - INFO - === [Epoch 57/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:27.2864s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.822 â”‚ 0.688 â”‚ 0.875 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.734 â”‚ 0.563 â”‚ 0.805 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.796 â”‚ 0.597 â”‚ 0.877 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.891 â”‚ 0.896 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1789, ET: 0.3126, TC: 0.1262, WT: 0.0978
[0m
[1;31m2025-05-16 01:57:01,240  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch56_loss0.1792_dice0.8218_20250516015243.pth[0m
[0;32m2025-05-16 01:57:01,304  - INFO - âœ¨ Saved checkpoint (epoch 57) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch57_loss0.1789_dice0.8220_20250516015701.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:57:01,304  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-16 02:00:51,654  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-16 02:00:51,654  - INFO - - Train mean loss: 0.2513
- ET loss: 0.3657
- TC loss: 0.2326
- WT loss: 0.1555
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 02:00:51,654  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-16 02:01:18,804  - INFO - === [Epoch 58/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:27.1488s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.819 â”‚ 0.681 â”‚ 0.873 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.731 â”‚ 0.556 â”‚ 0.804 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.782 â”‚ 0.587 â”‚ 0.862 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.908 â”‚ 0.897 â”‚ 0.909 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1823, ET: 0.3196, TC: 0.1281, WT: 0.0992
[0m
[0;33m2025-05-16 02:01:18,804  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:01:18,804  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-16 02:05:08,696  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-16 02:05:08,697  - INFO - - Train mean loss: 0.2679
- ET loss: 0.3867
- TC loss: 0.2507
- WT loss: 0.1664
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:05:08,697  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-16 02:05:35,904  - INFO - === [Epoch 59/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:27.2065s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.82  â”‚ 0.685 â”‚ 0.873 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.732 â”‚ 0.561 â”‚ 0.803 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.602 â”‚ 0.883 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.876 â”‚ 0.884 â”‚ 0.894 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1810, ET: 0.3151, TC: 0.1281, WT: 0.0999
[0m
[0;33m2025-05-16 02:05:35,904  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:05:35,904  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-16 02:09:25,675  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-16 02:09:25,676  - INFO - - Train mean loss: 0.2574
- ET loss: 0.3773
- TC loss: 0.2354
- WT loss: 0.1594
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:09:25,676  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-16 02:09:52,875  - INFO - === [Epoch 60/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:27.1987s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.818 â”‚ 0.682 â”‚ 0.873 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.729 â”‚ 0.557 â”‚ 0.803 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.782 â”‚ 0.586 â”‚ 0.865 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.898 â”‚ 0.905 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1833, ET: 0.3181, TC: 0.1283, WT: 0.1037
[0m
[0;33m2025-05-16 02:09:52,875  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 02:09:52,875  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-16 02:13:42,226  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-16 02:13:42,226  - INFO - - Train mean loss: 0.2468
- ET loss: 0.3589
- TC loss: 0.2245
- WT loss: 0.1571
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-16 02:13:42,226  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-16 02:14:09,522  - INFO - === [Epoch 61/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:27.2955s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.823 â”‚ 0.69  â”‚ 0.877 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.737 â”‚ 0.566 â”‚ 0.809 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.805 â”‚ 0.605 â”‚ 0.885 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.885 â”‚ 0.893 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1774, ET: 0.3109, TC: 0.1237, WT: 0.0978
[0m
[1;31m2025-05-16 02:14:09,526  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch57_loss0.1789_dice0.8220_20250516015701.pth[0m
[0;32m2025-05-16 02:14:09,590  - INFO - âœ¨ Saved checkpoint (epoch 61) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch61_loss0.1774_dice0.8235_20250516021409.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 02:14:09,590  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-16 02:17:59,032  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-16 02:17:59,033  - INFO - - Train mean loss: 0.2431
- ET loss: 0.3570
- TC loss: 0.2215
- WT loss: 0.1508
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-16 02:17:59,033  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-16 02:18:26,359  - INFO - === [Epoch 62/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:27.3253s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.821 â”‚ 0.696 â”‚ 0.863 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.734 â”‚ 0.571 â”‚ 0.794 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.81  â”‚ 0.614 â”‚ 0.895 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.874 â”‚ 0.865 â”‚ 0.898 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1795, ET: 0.3041, TC: 0.1375, WT: 0.0969
[0m
[0;33m2025-05-16 02:18:26,359  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:18:26,359  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-16 02:22:16,117  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-16 02:22:16,117  - INFO - - Train mean loss: 0.2457
- ET loss: 0.3586
- TC loss: 0.2262
- WT loss: 0.1522
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:22:16,117  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-16 02:22:43,408  - INFO - === [Epoch 63/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:27.2905s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.823 â”‚ 0.687 â”‚ 0.877 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.735 â”‚ 0.562 â”‚ 0.808 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.79  â”‚ 0.592 â”‚ 0.87  â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.899 â”‚ 0.906 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1779, ET: 0.3131, TC: 0.1241, WT: 0.0963
[0m
[0;33m2025-05-16 02:22:43,409  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:22:43,409  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-16 02:26:32,839  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-16 02:26:32,840  - INFO - - Train mean loss: 0.2457
- ET loss: 0.3597
- TC loss: 0.2224
- WT loss: 0.1551
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-16 02:26:32,840  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-16 02:26:59,817  - INFO - === [Epoch 64/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:26.9763s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.694 â”‚ 0.877 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.738 â”‚ 0.57  â”‚ 0.808 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.809 â”‚ 0.612 â”‚ 0.898 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.876 â”‚ 0.877 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1752, ET: 0.3065, TC: 0.1237, WT: 0.0955
[0m
[1;31m2025-05-16 02:26:59,820  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch61_loss0.1774_dice0.8235_20250516021409.pth[0m
[0;32m2025-05-16 02:26:59,882  - INFO - âœ¨ Saved checkpoint (epoch 64) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch64_loss0.1752_dice0.8257_20250516022659.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 02:26:59,882  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-16 02:30:49,981  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-16 02:30:49,982  - INFO - - Train mean loss: 0.2399
- ET loss: 0.3549
- TC loss: 0.2191
- WT loss: 0.1458
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:30:49,982  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-16 02:31:17,196  - INFO - === [Epoch 65/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:27.2132s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.823 â”‚ 0.697 â”‚ 0.866 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.734 â”‚ 0.57  â”‚ 0.798 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.796 â”‚ 0.601 â”‚ 0.877 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.896 â”‚ 0.883 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1782, ET: 0.3035, TC: 0.1349, WT: 0.0961
[0m
[0;33m2025-05-16 02:31:17,196  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:31:17,196  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-16 02:35:07,236  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-16 02:35:07,237  - INFO - - Train mean loss: 0.2480
- ET loss: 0.3626
- TC loss: 0.2285
- WT loss: 0.1530
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:35:07,237  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-16 02:35:34,491  - INFO - === [Epoch 66/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:27.2531s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.823 â”‚ 0.69  â”‚ 0.877 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.736 â”‚ 0.566 â”‚ 0.808 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.602 â”‚ 0.884 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.888 â”‚ 0.892 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1777, ET: 0.3103, TC: 0.1244, WT: 0.0984
[0m
[0;33m2025-05-16 02:35:34,491  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:35:34,491  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-16 02:39:24,280  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-16 02:39:24,281  - INFO - - Train mean loss: 0.2673
- ET loss: 0.3828
- TC loss: 0.2534
- WT loss: 0.1658
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:39:24,281  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-16 02:39:51,430  - INFO - === [Epoch 67/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:27.1493s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.825 â”‚ 0.693 â”‚ 0.876 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.737 â”‚ 0.569 â”‚ 0.807 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.604 â”‚ 0.885 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.89  â”‚ 0.891 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1763, ET: 0.3074, TC: 0.1248, WT: 0.0968
[0m
[0;33m2025-05-16 02:39:51,431  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 02:39:51,431  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-16 02:43:41,288  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-16 02:43:41,289  - INFO - - Train mean loss: 0.2528
- ET loss: 0.3679
- TC loss: 0.2337
- WT loss: 0.1567
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:43:41,289  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-16 02:44:08,626  - INFO - === [Epoch 68/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:27.3371s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.825 â”‚ 0.693 â”‚ 0.876 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.737 â”‚ 0.568 â”‚ 0.807 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.603 â”‚ 0.888 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.888 â”‚ 0.888 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1759, ET: 0.3072, TC: 0.1245, WT: 0.0960
[0m
[0;33m2025-05-16 02:44:08,627  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-16 02:44:08,627  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-16 02:47:58,418  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-16 02:47:58,418  - INFO - - Train mean loss: 0.2619
- ET loss: 0.3778
- TC loss: 0.2414
- WT loss: 0.1665
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:47:58,419  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-16 02:48:25,799  - INFO - === [Epoch 69/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:27.3804s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.692 â”‚ 0.88  â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.739 â”‚ 0.567 â”‚ 0.812 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.601 â”‚ 0.883 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.891 â”‚ 0.898 â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1749, ET: 0.3087, TC: 0.1207, WT: 0.0954
[0m
[1;31m2025-05-16 02:48:25,802  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch64_loss0.1752_dice0.8257_20250516022659.pth[0m
[0;32m2025-05-16 02:48:25,863  - INFO - âœ¨ Saved checkpoint (epoch 69) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch69_loss0.1749_dice0.8259_20250516024825.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 02:48:25,863  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-16 02:52:15,777  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-16 02:52:15,778  - INFO - - Train mean loss: 0.2403
- ET loss: 0.3547
- TC loss: 0.2183
- WT loss: 0.1479
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 02:52:15,778  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-16 02:52:42,906  - INFO - === [Epoch 70/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:27.1279s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.82  â”‚ 0.683 â”‚ 0.875 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.732 â”‚ 0.557 â”‚ 0.806 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.777 â”‚ 0.582 â”‚ 0.858 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.918 â”‚ 0.91  â”‚ 0.918 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1809, ET: 0.3179, TC: 0.1255, WT: 0.0995
[0m
[0;33m2025-05-16 02:52:42,906  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:52:42,906  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-16 02:56:32,371  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-16 02:56:32,372  - INFO - - Train mean loss: 0.2412
- ET loss: 0.3550
- TC loss: 0.2203
- WT loss: 0.1482
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-16 02:56:32,372  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-16 02:56:59,473  - INFO - === [Epoch 71/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:27.1001s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.823 â”‚ 0.688 â”‚ 0.878 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.735 â”‚ 0.563 â”‚ 0.81  â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.788 â”‚ 0.592 â”‚ 0.871 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.908 â”‚ 0.9   â”‚ 0.908 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1777, ET: 0.3124, TC: 0.1224, WT: 0.0983
[0m
[0;33m2025-05-16 02:56:59,473  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:56:59,473  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-16 03:00:49,191  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-16 03:00:49,191  - INFO - - Train mean loss: 0.2496
- ET loss: 0.3652
- TC loss: 0.2340
- WT loss: 0.1497
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:00:49,192  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-16 03:01:16,439  - INFO - === [Epoch 72/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:27.2466s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.824 â”‚ 0.689 â”‚ 0.88  â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.738 â”‚ 0.565 â”‚ 0.813 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.601 â”‚ 0.884 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.889 â”‚ 0.899 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1766, ET: 0.3117, TC: 0.1208, WT: 0.0972
[0m
[0;33m2025-05-16 03:01:16,439  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 03:01:16,439  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-16 03:05:06,358  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-16 03:05:06,359  - INFO - - Train mean loss: 0.2443
- ET loss: 0.3607
- TC loss: 0.2246
- WT loss: 0.1475
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:05:06,359  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-16 03:05:33,816  - INFO - === [Epoch 73/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:27.4562s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.825 â”‚ 0.692 â”‚ 0.878 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.738 â”‚ 0.568 â”‚ 0.81  â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.801 â”‚ 0.603 â”‚ 0.888 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.889 â”‚ 0.89  â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1757, ET: 0.3081, TC: 0.1232, WT: 0.0957
[0m
[0;33m2025-05-16 03:05:33,816  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-16 03:05:33,816  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-16 03:09:24,448  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-16 03:09:24,448  - INFO - - Train mean loss: 0.2546
- ET loss: 0.3723
- TC loss: 0.2374
- WT loss: 0.1540
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 03:09:24,449  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-16 03:09:51,762  - INFO - === [Epoch 74/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:27.3125s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.824 â”‚ 0.693 â”‚ 0.873 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.738 â”‚ 0.569 â”‚ 0.807 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.804 â”‚ 0.605 â”‚ 0.891 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.888 â”‚ 0.884 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1770, ET: 0.3071, TC: 0.1282, WT: 0.0956
[0m
[0;33m2025-05-16 03:09:51,762  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-16 03:09:51,762  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-16 03:13:42,604  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-16 03:13:42,605  - INFO - - Train mean loss: 0.2410
- ET loss: 0.3584
- TC loss: 0.2215
- WT loss: 0.1432
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 03:13:42,605  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-16 03:14:09,927  - INFO - === [Epoch 75/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:27.3218s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.822 â”‚ 0.685 â”‚ 0.877 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.735 â”‚ 0.56  â”‚ 0.809 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.788 â”‚ 0.586 â”‚ 0.864 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.909 â”‚ 0.905 â”‚ 0.914 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1788, ET: 0.3157, TC: 0.1239, WT: 0.0968
[0m
[0;33m2025-05-16 03:14:09,927  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-16 03:14:09,927  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-16 03:18:00,312  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-16 03:18:00,312  - INFO - - Train mean loss: 0.2395
- ET loss: 0.3540
- TC loss: 0.2154
- WT loss: 0.1491
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 03:18:00,312  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-16 03:18:27,498  - INFO - === [Epoch 76/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:27.1847s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.691 â”‚ 0.88  â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.739 â”‚ 0.566 â”‚ 0.813 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.6   â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.894 â”‚ 0.899 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1750, ET: 0.3099, TC: 0.1206, WT: 0.0945
[0m
[0;33m2025-05-16 03:18:27,498  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-16 03:18:27,498  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-16 03:22:17,004  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-16 03:22:17,005  - INFO - - Train mean loss: 0.2476
- ET loss: 0.3619
- TC loss: 0.2292
- WT loss: 0.1518
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:22:17,005  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-16 03:22:44,385  - INFO - === [Epoch 77/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:27.3798s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.823 â”‚ 0.692 â”‚ 0.873 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.737 â”‚ 0.567 â”‚ 0.807 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.599 â”‚ 0.882 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.895 â”‚ 0.893 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1774, ET: 0.3083, TC: 0.1281, WT: 0.0957
[0m
[0;33m2025-05-16 03:22:44,386  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-16 03:22:44,386  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-16 03:26:34,446  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-16 03:26:34,446  - INFO - - Train mean loss: 0.2304
- ET loss: 0.3480
- TC loss: 0.2068
- WT loss: 0.1364
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:26:34,446  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-16 03:27:01,822  - INFO - === [Epoch 78/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:27.3758s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.824 â”‚ 0.691 â”‚ 0.877 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.738 â”‚ 0.567 â”‚ 0.811 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.796 â”‚ 0.599 â”‚ 0.884 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.895 â”‚ 0.897 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1764, ET: 0.3093, TC: 0.1236, WT: 0.0964
[0m
[0;33m2025-05-16 03:27:01,822  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-16 03:27:01,823  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-16 03:30:52,256  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-16 03:30:52,256  - INFO - - Train mean loss: 0.2640
- ET loss: 0.3873
- TC loss: 0.2502
- WT loss: 0.1546
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 03:30:52,256  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-16 03:31:19,424  - INFO - === [Epoch 79/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:27.1668s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.692 â”‚ 0.88  â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.568 â”‚ 0.814 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.804 â”‚ 0.603 â”‚ 0.889 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.89  â”‚ 0.895 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1745, ET: 0.3088, TC: 0.1207, WT: 0.0939
[0m
[1;31m2025-05-16 03:31:19,427  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch69_loss0.1749_dice0.8259_20250516024825.pth[0m
[0;32m2025-05-16 03:31:19,491  - INFO - âœ¨ Saved checkpoint (epoch 79) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch79_loss0.1745_dice0.8264_20250516033119.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:31:19,491  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-16 03:35:09,216  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-16 03:35:09,216  - INFO - - Train mean loss: 0.2409
- ET loss: 0.3584
- TC loss: 0.2178
- WT loss: 0.1464
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:35:09,217  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-16 03:35:36,392  - INFO - === [Epoch 80/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:27.1751s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.881 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.567 â”‚ 0.813 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.601 â”‚ 0.884 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.891 â”‚ 0.898 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1743, ET: 0.3088, TC: 0.1200, WT: 0.0940
[0m
[1;31m2025-05-16 03:35:36,395  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch79_loss0.1745_dice0.8264_20250516033119.pth[0m
[0;32m2025-05-16 03:35:36,456  - INFO - âœ¨ Saved checkpoint (epoch 80) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch80_loss0.1743_dice0.8266_20250516033536.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:35:36,457  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-16 03:39:26,491  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-16 03:39:26,492  - INFO - - Train mean loss: 0.2400
- ET loss: 0.3593
- TC loss: 0.2212
- WT loss: 0.1396
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:39:26,492  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-16 03:39:53,889  - INFO - === [Epoch 81/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:27.3967s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.695 â”‚ 0.879 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.57  â”‚ 0.812 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.809 â”‚ 0.61  â”‚ 0.899 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.884 â”‚ 0.884 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1740, ET: 0.3060, TC: 0.1221, WT: 0.0939
[0m
[1;31m2025-05-16 03:39:53,892  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch80_loss0.1743_dice0.8266_20250516033536.pth[0m
[0;32m2025-05-16 03:39:53,955  - INFO - âœ¨ Saved checkpoint (epoch 81) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch81_loss0.1740_dice0.8269_20250516033953.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:39:53,956  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-16 03:43:44,724  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-16 03:43:44,724  - INFO - - Train mean loss: 0.2444
- ET loss: 0.3641
- TC loss: 0.2263
- WT loss: 0.1428
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 03:43:44,724  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-16 03:44:12,080  - INFO - === [Epoch 82/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:27.3548s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.69  â”‚ 0.881 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.566 â”‚ 0.815 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.798 â”‚ 0.599 â”‚ 0.881 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.895 â”‚ 0.904 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1747, ET: 0.3105, TC: 0.1194, WT: 0.0942
[0m
[0;33m2025-05-16 03:44:12,080  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 03:44:12,080  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-16 03:48:02,723  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-16 03:48:02,724  - INFO - - Train mean loss: 0.2564
- ET loss: 0.3742
- TC loss: 0.2346
- WT loss: 0.1603
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 03:48:02,724  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-16 03:48:30,062  - INFO - === [Epoch 83/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:27.3381s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.694 â”‚ 0.88  â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.569 â”‚ 0.812 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.603 â”‚ 0.888 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.891 â”‚ 0.893 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1739, ET: 0.3066, TC: 0.1210, WT: 0.0940
[0m
[1;31m2025-05-16 03:48:30,066  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch81_loss0.1740_dice0.8269_20250516033953.pth[0m
[0;32m2025-05-16 03:48:30,128  - INFO - âœ¨ Saved checkpoint (epoch 83) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch83_loss0.1739_dice0.8270_20250516034830.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:48:30,129  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-16 03:52:20,720  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-16 03:52:20,721  - INFO - - Train mean loss: 0.2529
- ET loss: 0.3728
- TC loss: 0.2335
- WT loss: 0.1523
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 03:52:20,721  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-16 03:52:48,055  - INFO - === [Epoch 84/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:27.3340s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.567 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.802 â”‚ 0.602 â”‚ 0.887 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.891 â”‚ 0.899 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3088, TC: 0.1181, WT: 0.0938
[0m
[1;31m2025-05-16 03:52:48,059  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch83_loss0.1739_dice0.8270_20250516034830.pth[0m
[0;32m2025-05-16 03:52:48,122  - INFO - âœ¨ Saved checkpoint (epoch 84) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch84_loss0.1736_dice0.8272_20250516035248.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:52:48,122  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-16 03:56:38,098  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-16 03:56:38,098  - INFO - - Train mean loss: 0.2416
- ET loss: 0.3554
- TC loss: 0.2150
- WT loss: 0.1543
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 03:56:38,098  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-16 03:57:05,511  - INFO - === [Epoch 85/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:27.4119s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.69  â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.566 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.598 â”‚ 0.88  â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.896 â”‚ 0.906 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1742, ET: 0.3101, TC: 0.1181, WT: 0.0945
[0m
[0;33m2025-05-16 03:57:05,511  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 03:57:05,511  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-16 04:00:56,171  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-16 04:00:56,172  - INFO - - Train mean loss: 0.2587
- ET loss: 0.3763
- TC loss: 0.2385
- WT loss: 0.1614
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 04:00:56,172  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-16 04:01:23,417  - INFO - === [Epoch 86/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:27.2451s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.803 â”‚ 0.605 â”‚ 0.889 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.89  â”‚ 0.897 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3084, TC: 0.1182, WT: 0.0942
[0m
[0;33m2025-05-16 04:01:23,417  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 04:01:23,417  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-16 04:05:13,284  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-16 04:05:13,284  - INFO - - Train mean loss: 0.2475
- ET loss: 0.3676
- TC loss: 0.2260
- WT loss: 0.1488
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 04:05:13,284  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-16 04:05:40,453  - INFO - === [Epoch 87/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:27.1684s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.693 â”‚ 0.882 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.569 â”‚ 0.814 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.602 â”‚ 0.887 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.892 â”‚ 0.897 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1734, ET: 0.3074, TC: 0.1190, WT: 0.0938
[0m
[1;31m2025-05-16 04:05:40,456  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch84_loss0.1736_dice0.8272_20250516035248.pth[0m
[0;32m2025-05-16 04:05:40,520  - INFO - âœ¨ Saved checkpoint (epoch 87) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch87_loss0.1734_dice0.8274_20250516040540.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 04:05:40,520  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-16 04:09:30,732  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-16 04:09:30,733  - INFO - - Train mean loss: 0.2527
- ET loss: 0.3707
- TC loss: 0.2315
- WT loss: 0.1558
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 04:09:30,733  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-16 04:09:58,115  - INFO - === [Epoch 88/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:27.3814s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.828 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.602 â”‚ 0.885 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.894 â”‚ 0.901 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1732, ET: 0.3081, TC: 0.1178, WT: 0.0937
[0m
[1;31m2025-05-16 04:09:58,118  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch87_loss0.1734_dice0.8274_20250516040540.pth[0m
[0;32m2025-05-16 04:09:58,179  - INFO - âœ¨ Saved checkpoint (epoch 88) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch88_loss0.1732_dice0.8276_20250516040958.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 04:09:58,179  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-16 04:13:49,041  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-16 04:13:49,042  - INFO - - Train mean loss: 0.2505
- ET loss: 0.3666
- TC loss: 0.2294
- WT loss: 0.1554
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 04:13:49,042  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-16 04:14:16,345  - INFO - === [Epoch 89/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:27.3030s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.828 â”‚ 0.693 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.569 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.803 â”‚ 0.606 â”‚ 0.89  â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.889 â”‚ 0.896 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1732, ET: 0.3077, TC: 0.1180, WT: 0.0940
[0m
[0;33m2025-05-16 04:14:16,345  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 04:14:16,346  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-16 04:18:07,135  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-16 04:18:07,136  - INFO - - Train mean loss: 0.2514
- ET loss: 0.3701
- TC loss: 0.2299
- WT loss: 0.1543
- Cost time: 3.85mins â±ï¸
[0m
[0;32m2025-05-16 04:18:07,136  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-16 04:18:34,317  - INFO - === [Epoch 90/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:27.1810s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.691 â”‚ 0.882 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.567 â”‚ 0.815 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.797 â”‚ 0.6   â”‚ 0.882 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.904 â”‚ 0.895 â”‚ 0.904 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1741, ET: 0.3091, TC: 0.1185, WT: 0.0945
[0m
[0;33m2025-05-16 04:18:34,317  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 04:18:34,317  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-16 04:22:24,635  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-16 04:22:24,636  - INFO - - Train mean loss: 0.2513
- ET loss: 0.3703
- TC loss: 0.2301
- WT loss: 0.1535
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 04:22:24,636  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-16 04:22:52,008  - INFO - === [Epoch 91/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:27.3718s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.602 â”‚ 0.885 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.893 â”‚ 0.901 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1735, ET: 0.3083, TC: 0.1181, WT: 0.0940
[0m
[0;33m2025-05-16 04:22:52,008  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 04:22:52,008  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-16 04:26:41,718  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-16 04:26:41,719  - INFO - - Train mean loss: 0.2527
- ET loss: 0.3691
- TC loss: 0.2334
- WT loss: 0.1556
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 04:26:41,719  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-16 04:27:08,946  - INFO - === [Epoch 92/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:27.2267s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.882 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.74  â”‚ 0.567 â”‚ 0.815 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.6   â”‚ 0.882 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.894 â”‚ 0.904 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1738, ET: 0.3089, TC: 0.1186, WT: 0.0940
[0m
[0;33m2025-05-16 04:27:08,946  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-16 04:27:08,946  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-16 04:30:58,781  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-16 04:30:58,782  - INFO - - Train mean loss: 0.2458
- ET loss: 0.3649
- TC loss: 0.2258
- WT loss: 0.1466
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 04:30:58,782  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-16 04:31:26,383  - INFO - === [Epoch 93/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:27.6005s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.603 â”‚ 0.885 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.893 â”‚ 0.902 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3082, TC: 0.1181, WT: 0.0946
[0m
[0;33m2025-05-16 04:31:26,383  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-16 04:31:26,383  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-16 04:35:15,874  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-16 04:35:15,874  - INFO - - Train mean loss: 0.2488
- ET loss: 0.3656
- TC loss: 0.2319
- WT loss: 0.1490
- Cost time: 3.82mins â±ï¸
[0m
[0;32m2025-05-16 04:35:15,874  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-16 04:35:43,104  - INFO - === [Epoch 94/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:27.2294s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.601 â”‚ 0.883 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.894 â”‚ 0.903 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3085, TC: 0.1182, WT: 0.0941
[0m
[0;33m2025-05-16 04:35:43,104  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-16 04:35:43,104  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-16 04:39:32,783  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-16 04:39:32,784  - INFO - - Train mean loss: 0.2570
- ET loss: 0.3744
- TC loss: 0.2367
- WT loss: 0.1599
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 04:39:32,784  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-16 04:39:59,915  - INFO - === [Epoch 95/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:27.1305s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.693 â”‚ 0.882 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.569 â”‚ 0.815 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.801 â”‚ 0.605 â”‚ 0.889 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.89  â”‚ 0.897 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3073, TC: 0.1184, WT: 0.0950
[0m
[0;33m2025-05-16 04:39:59,915  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-16 04:39:59,915  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-16 04:43:49,583  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-16 04:43:49,584  - INFO - - Train mean loss: 0.2346
- ET loss: 0.3502
- TC loss: 0.2126
- WT loss: 0.1411
- Cost time: 3.83mins â±ï¸
[0m
[0;32m2025-05-16 04:43:49,584  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-16 04:44:16,800  - INFO - === [Epoch 96/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:27.2159s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.602 â”‚ 0.885 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.893 â”‚ 0.9   â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3082, TC: 0.1183, WT: 0.0944
[0m
[0;33m2025-05-16 04:44:16,800  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-16 04:44:16,800  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-16 04:48:07,111  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-16 04:48:07,111  - INFO - - Train mean loss: 0.2407
- ET loss: 0.3566
- TC loss: 0.2176
- WT loss: 0.1478
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 04:48:07,111  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-16 04:48:34,630  - INFO - === [Epoch 97/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:27.5182s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.601 â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.894 â”‚ 0.903 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1738, ET: 0.3089, TC: 0.1181, WT: 0.0944
[0m
[0;33m2025-05-16 04:48:34,630  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-16 04:48:34,630  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-16 04:52:24,900  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-16 04:52:24,901  - INFO - - Train mean loss: 0.2463
- ET loss: 0.3633
- TC loss: 0.2206
- WT loss: 0.1552
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 04:52:24,901  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-16 04:52:52,230  - INFO - === [Epoch 98/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:27.3288s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.601 â”‚ 0.884 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.894 â”‚ 0.903 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1738, ET: 0.3088, TC: 0.1181, WT: 0.0943
[0m
[0;33m2025-05-16 04:52:52,230  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-16 04:52:52,231  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-16 04:56:42,928  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-16 04:56:42,929  - INFO - - Train mean loss: 0.2532
- ET loss: 0.3702
- TC loss: 0.2351
- WT loss: 0.1543
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 04:56:42,929  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-16 04:57:10,335  - INFO - === [Epoch 99/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:27.4049s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.602 â”‚ 0.885 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.893 â”‚ 0.901 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1737, ET: 0.3083, TC: 0.1184, WT: 0.0943
[0m
[0;33m2025-05-16 04:57:10,335  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-16 04:57:10,335  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-16 05:01:00,875  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-16 05:01:00,875  - INFO - - Train mean loss: 0.2498
- ET loss: 0.3636
- TC loss: 0.2275
- WT loss: 0.1583
- Cost time: 3.84mins â±ï¸
[0m
[0;32m2025-05-16 05:01:00,875  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-16 05:01:28,170  - INFO - === [Epoch 100/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:27.2947s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.827 â”‚ 0.692 â”‚ 0.883 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.741 â”‚ 0.568 â”‚ 0.816 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.601 â”‚ 0.884 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.894 â”‚ 0.902 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1736, ET: 0.3085, TC: 0.1182, WT: 0.0942
[0m
[0;33m2025-05-16 05:01:28,170  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[1;31m2025-05-16 05:01:29,783  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1732 at epoch 88[0m
[0;32m2025-05-16 05:01:29,783  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-16 05:01:29,800  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/Mamba3d_final_model.pth[0m
[1;31m2025-05-16 05:01:29,800  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-16 05:01:29,800  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-16 05:04:06,052  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.811 â”‚  0.674 â”‚ 0.865 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.723 â”‚  0.553 â”‚ 0.796 â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.789 â”‚  0.592 â”‚ 0.878 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚  0.89  â”‚ 0.873 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  7.731 â”‚ 11.096 â”‚ 6.902 â”‚ 5.196 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1896;ET: 0.3262;ET: 0.3262;TC: 0.1355;WT: 0.1071
[0m
[0;32m2025-05-16 05:04:06,052  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-16 05:04:06,052  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-15.log[0m
[0;32m2025-05-16 05:04:14,323  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 05:04:16,619  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-16 05:04:16,623  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 05:04:16,623  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 05:04:16,623  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 05:04:16,623  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 05:04:16,623  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 05:04:16,629  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-16 05:04:16,629  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-16 05:04:16,629  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-16 05:04:16,632  - INFO - ğŸ§  é¡¹ç›®åï¼š0515_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0515_DCLA_UNet_v2                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 05:04:19,904  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-16 05:04:19,905  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-16 06:41:21,655  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-16 06:41:21,656  - INFO - - Train mean loss: 0.8200
- ET loss: 0.5384
- TC loss: 0.9783
- WT loss: 0.9432
- Cost time: 97.03mins â±ï¸
[0m
[0;32m2025-05-16 06:41:21,656  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-16 06:44:59,875  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:218.2176s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.261 â”‚ 0.665 â”‚ 0.033 â”‚ 0.086 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.201 â”‚ 0.54  â”‚ 0.017 â”‚ 0.046 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.243 â”‚ 0.666 â”‚ 0.017 â”‚ 0.046 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.718 â”‚ 0.996 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7422, ET: 0.3450, TC: 0.9672, WT: 0.9142
[0m
[0;32m2025-05-16 06:44:59,961  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.7422_dice0.2612_20250516064459.pth;             Size 8.73 MB[0m
[0;32m2025-05-16 06:44:59,961  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-16 08:23:33,786  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-16 08:23:33,787  - INFO - - Train mean loss: 0.7776
- ET loss: 0.4122
- TC loss: 0.9785
- WT loss: 0.9423
- Cost time: 98.56mins â±ï¸
[0m
[0;32m2025-05-16 08:23:33,787  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-16 08:27:17,608  - INFO - === [Epoch 2/100] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:223.8199s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.273 â”‚ 0.699 â”‚ 0.033 â”‚ 0.086 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.215 â”‚ 0.582 â”‚ 0.017 â”‚ 0.046 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.273 â”‚ 0.757 â”‚ 0.017 â”‚ 0.046 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.693 â”‚ 0.996 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7295, ET: 0.3071, TC: 0.9672, WT: 0.9142
[0m
[0;32m2025-05-16 08:27:17,684  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.7295_dice0.2726_20250516082717.pth;             Size 8.73 MB[0m
[0;32m2025-05-16 08:27:17,684  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;32m2025-05-16 10:55:21,090  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 10:55:24,507  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 10:55:24,513  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 10:55:24,513  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 10:55:24,513  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 10:55:24,514  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 10:55:24,514  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 10:55:24,525  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 10:55:24,525  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 10:55:24,525  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 10:55:24,530  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 10:55:25,059  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 10:55:25,059  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 10:56:33,117  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 10:56:33,118  - INFO - - Train mean loss: 0.7998
- ET loss: 0.7595
- TC loss: 0.7026
- WT loss: 0.9372
- Cost time: 1.13mins â±ï¸
[0m
[0;32m2025-05-16 10:56:33,118  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 10:56:43,554  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.4352s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.362 â”‚ 0.485 â”‚ 0.521 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.255 â”‚ 0.342 â”‚ 0.38  â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.309 â”‚ 0.417 â”‚ 0.467 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.83  â”‚ 0.721 â”‚ 0.768 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6605, ET: 0.5545, TC: 0.5071, WT: 0.9200
[0m
[0;32m2025-05-16 10:56:43,652  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.6605_dice0.3622_20250516105643.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 10:56:43,652  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 10:57:50,588  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 10:57:50,589  - INFO - - Train mean loss: 0.6818
- ET loss: 0.5769
- TC loss: 0.5284
- WT loss: 0.9401
- Cost time: 1.12mins â±ï¸
[0m
[0;32m2025-05-16 10:57:50,589  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 10:58:00,720  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.1296s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.402 â”‚ 0.561 â”‚ 0.566 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.295 â”‚ 0.416 â”‚ 0.425 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.327 â”‚ 0.459 â”‚ 0.48  â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.816 â”‚ 0.836 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6150, ET: 0.4709, TC: 0.4542, WT: 0.9198
[0m
[0;32m2025-05-16 10:58:00,802  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.6150_dice0.4025_20250516105800.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 10:58:00,802  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 10:59:07,532  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 10:59:07,532  - INFO - - Train mean loss: 0.6422
- ET loss: 0.5063
- TC loss: 0.4822
- WT loss: 0.9382
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-16 10:59:07,532  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 10:59:17,551  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:10.0182s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.477 â”‚ 0.677 â”‚ 0.674 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.38  â”‚ 0.55  â”‚ 0.548 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.476 â”‚ 0.677 â”‚ 0.708 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.821 â”‚ 0.729 â”‚ 0.734 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5341, ET: 0.3442, TC: 0.3386, WT: 0.9195
[0m
[1;31m2025-05-16 10:59:17,553  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.6150_dice0.4025_20250516105800.pth[0m
[0;32m2025-05-16 10:59:17,634  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.5341_dice0.4774_20250516105917.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 10:59:17,634  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 11:00:24,377  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 11:00:24,378  - INFO - - Train mean loss: 0.6080
- ET loss: 0.4617
- TC loss: 0.4253
- WT loss: 0.9372
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-16 11:00:24,378  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:00:34,725  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:10.3461s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.49  â”‚ 0.695 â”‚ 0.695 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.396 â”‚ 0.572 â”‚ 0.573 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.491 â”‚ 0.701 â”‚ 0.729 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.826 â”‚ 0.735 â”‚ 0.744 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5198, ET: 0.3229, TC: 0.3169, WT: 0.9195
[0m
[1;31m2025-05-16 11:00:34,726  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.5341_dice0.4774_20250516105917.pth[0m
[0;32m2025-05-16 11:00:34,822  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.5198_dice0.4901_20250516110034.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:00:34,823  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 11:01:41,618  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 11:01:41,618  - INFO - - Train mean loss: 0.6051
- ET loss: 0.4492
- TC loss: 0.4245
- WT loss: 0.9415
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-16 11:01:41,618  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 11:01:51,867  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:10.2478s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.491 â”‚ 0.688 â”‚ 0.703 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.395 â”‚ 0.563 â”‚ 0.58  â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.449 â”‚ 0.631 â”‚ 0.674 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.805 â”‚ 0.811 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5186, ET: 0.3275, TC: 0.3088, WT: 0.9195
[0m
[1;31m2025-05-16 11:01:51,868  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.5198_dice0.4901_20250516110034.pth[0m
[0;32m2025-05-16 11:01:51,963  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.5186_dice0.4906_20250516110151.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:01:51,963  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 11:02:58,992  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 11:02:58,992  - INFO - - Train mean loss: 0.5952
- ET loss: 0.4312
- TC loss: 0.4143
- WT loss: 0.9401
- Cost time: 1.12mins â±ï¸
[0m
[0;32m2025-05-16 11:02:58,992  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 11:03:09,213  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:10.2196s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.485 â”‚ 0.671 â”‚ 0.704 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.389 â”‚ 0.543 â”‚ 0.581 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.427 â”‚ 0.584 â”‚ 0.656 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.844 â”‚ 0.833 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5229, ET: 0.3405, TC: 0.3085, WT: 0.9195
[0m
[0;33m2025-05-16 11:03:09,213  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:03:09,213  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 11:04:16,082  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 11:04:16,083  - INFO - - Train mean loss: 0.5793
- ET loss: 0.4169
- TC loss: 0.3848
- WT loss: 0.9360
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-16 11:04:16,083  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 11:04:26,213  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:10.1292s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.507 â”‚ 0.716 â”‚ 0.724 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.418 â”‚ 0.603 â”‚ 0.608 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.463 â”‚ 0.667 â”‚ 0.681 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.817 â”‚ 0.838 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5039, ET: 0.3014, TC: 0.2906, WT: 0.9195
[0m
[1;31m2025-05-16 11:04:26,215  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.5186_dice0.4906_20250516110151.pth[0m
[0;32m2025-05-16 11:04:26,292  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch7_loss0.5039_dice0.5066_20250516110426.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:04:26,293  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 11:05:33,345  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 11:05:33,345  - INFO - - Train mean loss: 0.5643
- ET loss: 0.3839
- TC loss: 0.3690
- WT loss: 0.9401
- Cost time: 1.12mins â±ï¸
[0m
[0;32m2025-05-16 11:05:33,345  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 11:05:43,739  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:10.3926s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.532 â”‚ 0.751 â”‚ 0.764 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.45  â”‚ 0.646 â”‚ 0.661 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.529 â”‚ 0.757 â”‚ 0.786 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.852 â”‚ 0.771 â”‚ 0.784 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4763, ET: 0.2623, TC: 0.2472, WT: 0.9195
[0m
[1;31m2025-05-16 11:05:43,740  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.5039_dice0.5066_20250516110426.pth[0m
[0;32m2025-05-16 11:05:43,819  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch8_loss0.4763_dice0.5316_20250516110543.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:05:43,820  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 11:06:50,324  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 11:06:50,324  - INFO - - Train mean loss: 0.5555
- ET loss: 0.3794
- TC loss: 0.3496
- WT loss: 0.9376
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-16 11:06:50,324  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 11:07:00,783  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:10.4578s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.526 â”‚ 0.741 â”‚ 0.758 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.442 â”‚ 0.633 â”‚ 0.651 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.49  â”‚ 0.697 â”‚ 0.731 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.823 â”‚ 0.833 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4826, ET: 0.2730, TC: 0.2552, WT: 0.9195
[0m
[0;33m2025-05-16 11:07:00,783  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:07:00,784  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-16 11:08:07,948  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-16 11:08:07,948  - INFO - - Train mean loss: 0.5380
- ET loss: 0.3507
- TC loss: 0.3247
- WT loss: 0.9385
- Cost time: 1.12mins â±ï¸
[0m
[0;32m2025-05-16 11:08:07,948  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 11:08:18,718  - INFO - === [Epoch 10/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:10.7687s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.537 â”‚ 0.76  â”‚ 0.77  â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.458 â”‚ 0.66  â”‚ 0.672 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.539 â”‚ 0.772 â”‚ 0.804 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.851 â”‚ 0.772 â”‚ 0.779 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4701, ET: 0.2521, TC: 0.2387, WT: 0.9195
[0m
[1;31m2025-05-16 11:08:18,719  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.4763_dice0.5316_20250516110543.pth[0m
[0;32m2025-05-16 11:08:18,809  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch10_loss0.4701_dice0.5370_20250516110818.pth;             Size 8.88 MB[0m
[1;31m2025-05-16 11:08:18,809  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4701 at epoch 10[0m
[0;32m2025-05-16 11:08:18,809  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-16 11:08:18,816  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/DCLA_UNet_v3_final_model.pth[0m
[1;31m2025-05-16 11:08:18,816  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-16 11:08:18,816  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[0;32m2025-05-16 11:15:28,427  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:15:31,899  - INFO - Total number of parameters: 0.60 M[0m
[0;32m2025-05-16 11:15:31,903  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:15:31,903  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:15:31,903  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:15:31,903  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:15:31,903  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:15:31,913  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:15:31,913  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:15:31,913  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:15:31,920  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.60 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:15:32,397  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:15:32,398  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:16:38,909  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:16:38,910  - INFO - - Train mean loss: 0.8784
- ET loss: 0.9109
- TC loss: 0.8866
- WT loss: 0.8377
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-16 11:16:38,910  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:16:49,358  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.4463s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.529 â”‚ 0.463 â”‚ 0.487 â”‚ 0.636 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.395 â”‚ 0.323 â”‚ 0.349 â”‚ 0.511 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.533 â”‚ 0.398 â”‚ 0.421 â”‚ 0.779 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.678 â”‚ 0.694 â”‚ 0.748 â”‚ 0.591 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4926, ET: 0.5621, TC: 0.5385, WT: 0.3771
[0m
[1;31m2025-05-16 11:16:49,359  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.4701_dice0.5370_20250516110818.pth[0m
[0;32m2025-05-16 11:16:49,443  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4926_dice0.5286_20250516111649.pth;             Size 7.83 MB[0m
[0;32m2025-05-16 11:16:49,444  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:17:54,961  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:17:54,962  - INFO - - Train mean loss: 0.5311
- ET loss: 0.5963
- TC loss: 0.5903
- WT loss: 0.4068
- Cost time: 1.09mins â±ï¸
[0m
[0;32m2025-05-16 11:17:54,962  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:18:05,296  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.3336s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.593 â”‚ 0.593 â”‚ 0.472 â”‚ 0.715 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.462 â”‚ 0.454 â”‚ 0.334 â”‚ 0.599 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.556 â”‚ 0.516 â”‚ 0.375 â”‚ 0.778 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.774 â”‚ 0.752 â”‚ 0.839 â”‚ 0.731 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4210, ET: 0.4362, TC: 0.5345, WT: 0.2925
[0m
[1;31m2025-05-16 11:18:05,298  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v3_final_model.pth[0m
[0;32m2025-05-16 11:18:05,394  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4210_dice0.5932_20250516111805.pth;             Size 7.83 MB[0m
[0;32m2025-05-16 11:18:05,394  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 11:19:10,778  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 11:19:10,778  - INFO - - Train mean loss: 0.5007
- ET loss: 0.5346
- TC loss: 0.5981
- WT loss: 0.3694
- Cost time: 1.09mins â±ï¸
[0m
[0;32m2025-05-16 11:19:10,778  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:19:20,973  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:10.1936s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.625 â”‚ 0.636 â”‚ 0.494 â”‚ 0.746 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.491 â”‚ 0.498 â”‚ 0.351 â”‚ 0.624 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.567 â”‚ 0.558 â”‚ 0.385 â”‚ 0.759 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.81  â”‚ 0.794 â”‚ 0.853 â”‚ 0.782 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3922, ET: 0.3928, TC: 0.5157, WT: 0.2680
[0m
[1;31m2025-05-16 11:19:20,974  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.4926_dice0.5286_20250516111649.pth[0m
[0;32m2025-05-16 11:19:21,060  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3922_dice0.6252_20250516111920.pth;             Size 7.83 MB[0m
[0;32m2025-05-16 11:19:21,060  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:19:45,055  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:19:48,482  - INFO - Total number of parameters: 0.60 M[0m
[0;32m2025-05-16 11:19:48,484  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:19:48,484  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:19:48,484  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:19:48,484  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:19:48,484  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:19:48,491  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:19:48,491  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:19:48,491  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:19:48,494  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.60 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:19:48,836  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:19:48,837  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:20:48,578  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:20:48,579  - INFO - - Train mean loss: 0.7098
- ET loss: 0.8247
- TC loss: 0.7460
- WT loss: 0.5589
- Cost time: 1.00mins â±ï¸
[0m
[0;32m2025-05-16 11:20:48,579  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:20:58,524  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.9434s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.521 â”‚ 0.363 â”‚ 0.475 â”‚ 0.726 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.395 â”‚ 0.235 â”‚ 0.336 â”‚ 0.613 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.516 â”‚ 0.266 â”‚ 0.4   â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.719 â”‚ 0.738 â”‚ 0.763 â”‚ 0.657 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4851, ET: 0.6443, TC: 0.5329, WT: 0.2783
[0m
[1;31m2025-05-16 11:20:58,526  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4210_dice0.5932_20250516111805.pth[0m
[0;32m2025-05-16 11:20:58,620  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4851_dice0.5214_20250516112058.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:20:58,620  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:21:57,204  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:21:57,205  - INFO - - Train mean loss: 0.5222
- ET loss: 0.6878
- TC loss: 0.5531
- WT loss: 0.3257
- Cost time: 0.98mins â±ï¸
[0m
[0;32m2025-05-16 11:21:57,205  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:22:06,898  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:9.6917s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.563 â”‚ 0.414 â”‚ 0.532 â”‚ 0.744 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.434 â”‚ 0.279 â”‚ 0.39  â”‚ 0.633 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.567 â”‚ 0.318 â”‚ 0.458 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.759 â”‚ 0.795 â”‚ 0.817 â”‚ 0.664 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4403, ET: 0.5901, TC: 0.4724, WT: 0.2584
[0m
[1;31m2025-05-16 11:22:06,899  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3922_dice0.6252_20250516111920.pth[0m
[0;32m2025-05-16 11:22:06,994  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4403_dice0.5631_20250516112206.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:22:06,994  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 11:23:05,619  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 11:23:05,619  - INFO - - Train mean loss: 0.5309
- ET loss: 0.6889
- TC loss: 0.5649
- WT loss: 0.3389
- Cost time: 0.98mins â±ï¸
[0m
[0;32m2025-05-16 11:23:05,619  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:23:15,318  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:9.6971s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.573 â”‚ 0.406 â”‚ 0.527 â”‚ 0.788 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.445 â”‚ 0.271 â”‚ 0.384 â”‚ 0.68  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.53  â”‚ 0.287 â”‚ 0.413 â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.826 â”‚ 0.863 â”‚ 0.88  â”‚ 0.735 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4314, ET: 0.5982, TC: 0.4786, WT: 0.2173
[0m
[1;31m2025-05-16 11:23:15,320  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.4851_dice0.5214_20250516112058.pth[0m
[0;32m2025-05-16 11:23:15,413  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.4314_dice0.5735_20250516112315.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:23:15,414  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 11:24:14,015  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 11:24:14,015  - INFO - - Train mean loss: 0.4980
- ET loss: 0.6585
- TC loss: 0.5207
- WT loss: 0.3148
- Cost time: 0.98mins â±ï¸
[0m
[0;32m2025-05-16 11:24:14,015  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:24:23,456  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:9.4403s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.587 â”‚ 0.437 â”‚ 0.561 â”‚ 0.763 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.455 â”‚ 0.299 â”‚ 0.419 â”‚ 0.648 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.565 â”‚ 0.319 â”‚ 0.458 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.801 â”‚ 0.853 â”‚ 0.871 â”‚ 0.681 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4165, ET: 0.5663, TC: 0.4434, WT: 0.2398
[0m
[1;31m2025-05-16 11:24:23,457  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4403_dice0.5631_20250516112206.pth[0m
[0;32m2025-05-16 11:24:23,532  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.4165_dice0.5870_20250516112423.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:24:23,533  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 11:25:22,888  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 11:25:22,888  - INFO - - Train mean loss: 0.4860
- ET loss: 0.6419
- TC loss: 0.5041
- WT loss: 0.3121
- Cost time: 0.99mins â±ï¸
[0m
[0;32m2025-05-16 11:25:22,888  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 11:25:32,347  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:9.4566s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.441 â”‚ 0.564 â”‚ 0.765 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.458 â”‚ 0.303 â”‚ 0.422 â”‚ 0.649 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.564 â”‚ 0.319 â”‚ 0.455 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.807 â”‚ 0.86  â”‚ 0.878 â”‚ 0.681 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4132, ET: 0.5619, TC: 0.4400, WT: 0.2376
[0m
[1;31m2025-05-16 11:25:32,348  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.4314_dice0.5735_20250516112315.pth[0m
[0;32m2025-05-16 11:25:32,438  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.4132_dice0.5901_20250516112532.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:25:32,438  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 11:26:31,256  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 11:26:31,256  - INFO - - Train mean loss: 0.4879
- ET loss: 0.6230
- TC loss: 0.4891
- WT loss: 0.3514
- Cost time: 0.98mins â±ï¸
[0m
[0;32m2025-05-16 11:26:31,256  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 11:26:40,822  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:9.5645s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.597 â”‚ 0.496 â”‚ 0.615 â”‚ 0.679 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.458 â”‚ 0.355 â”‚ 0.478 â”‚ 0.543 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.627 â”‚ 0.388 â”‚ 0.547 â”‚ 0.948 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.736 â”‚ 0.82  â”‚ 0.833 â”‚ 0.555 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4053, ET: 0.5069, TC: 0.3882, WT: 0.3209
[0m
[1;31m2025-05-16 11:26:40,824  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.4165_dice0.5870_20250516112423.pth[0m
[0;32m2025-05-16 11:26:40,918  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch6_loss0.4053_dice0.5967_20250516112640.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:26:40,918  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 11:27:39,279  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 11:27:39,279  - INFO - - Train mean loss: 0.4801
- ET loss: 0.6061
- TC loss: 0.4689
- WT loss: 0.3654
- Cost time: 0.97mins â±ï¸
[0m
[0;32m2025-05-16 11:27:39,279  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 11:27:48,157  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:8.8769s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.6   â”‚ 0.503 â”‚ 0.623 â”‚ 0.675 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.463 â”‚ 0.361 â”‚ 0.488 â”‚ 0.54  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.621 â”‚ 0.387 â”‚ 0.547 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.753 â”‚ 0.844 â”‚ 0.856 â”‚ 0.56  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4014, ET: 0.5003, TC: 0.3799, WT: 0.3241
[0m
[1;31m2025-05-16 11:27:48,159  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.4132_dice0.5901_20250516112532.pth[0m
[0;32m2025-05-16 11:27:48,236  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch7_loss0.4014_dice0.6003_20250516112748.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:27:48,236  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 11:28:46,652  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 11:28:46,652  - INFO - - Train mean loss: 0.4748
- ET loss: 0.5885
- TC loss: 0.4519
- WT loss: 0.3841
- Cost time: 0.97mins â±ï¸
[0m
[0;32m2025-05-16 11:28:46,652  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 11:28:55,488  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:8.8347s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.472 â”‚ 0.596 â”‚ 0.728 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.463 â”‚ 0.331 â”‚ 0.457 â”‚ 0.6   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.585 â”‚ 0.346 â”‚ 0.492 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.794 â”‚ 0.871 â”‚ 0.884 â”‚ 0.628 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4034, ET: 0.5306, TC: 0.4071, WT: 0.2725
[0m
[0;33m2025-05-16 11:28:55,488  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:28:55,488  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 11:29:53,951  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 11:29:53,951  - INFO - - Train mean loss: 0.4590
- ET loss: 0.5684
- TC loss: 0.4356
- WT loss: 0.3729
- Cost time: 0.97mins â±ï¸
[0m
[0;32m2025-05-16 11:29:53,951  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 11:30:02,706  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:8.7540s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.612 â”‚ 0.527 â”‚ 0.651 â”‚ 0.658 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.474 â”‚ 0.385 â”‚ 0.52  â”‚ 0.518 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.628 â”‚ 0.402 â”‚ 0.566 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.76  â”‚ 0.865 â”‚ 0.877 â”‚ 0.539 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3898, ET: 0.4762, TC: 0.3523, WT: 0.3408
[0m
[1;31m2025-05-16 11:30:02,707  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.4053_dice0.5967_20250516112640.pth[0m
[0;32m2025-05-16 11:30:02,783  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch9_loss0.3898_dice0.6119_20250516113002.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:30:02,783  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 11:31:01,333  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:31:09,287  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:33:25,528  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:33:29,049  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-16 11:33:29,052  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:33:29,052  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:33:29,052  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:33:29,052  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:33:29,052  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:33:29,059  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:33:29,060  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:33:29,060  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:33:29,063  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v4                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.65 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:33:34,596  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:33:38,043  - INFO - Total number of parameters: 0.97 M[0m
[0;32m2025-05-16 11:33:38,045  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:33:38,046  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:33:38,046  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:33:38,046  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:33:38,046  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:33:38,053  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:33:38,053  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:33:38,053  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:33:38,057  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLK_v4                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.97 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:34:12,474  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:34:15,815  - INFO - Total number of parameters: 0.60 M[0m
[0;32m2025-05-16 11:34:15,818  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:34:15,818  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:34:15,818  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:34:15,818  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:34:15,818  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:34:15,825  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:34:15,825  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:34:15,825  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:34:15,829  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v4                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.60 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:34:21,755  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:34:25,125  - INFO - Total number of parameters: 0.93 M[0m
[0;32m2025-05-16 11:34:25,127  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:34:25,127  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:34:25,127  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:34:25,128  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:34:25,128  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:34:25,135  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:34:25,135  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:34:25,135  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:34:25,139  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLK_v4                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.93 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:34:25,374  - INFO - 
model: ResUNetBaseline_S_SLK_v4
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:34:25,374  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:35:01,005  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:35:01,006  - INFO - - Train mean loss: 0.7696
- ET loss: 0.7296
- TC loss: 0.6670
- WT loss: 0.9123
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-16 11:35:01,006  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:35:09,832  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLK_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.8249s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.412 â”‚ 0.518 â”‚ 0.624 â”‚ 0.093 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.308 â”‚ 0.379 â”‚ 0.495 â”‚ 0.05  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.388 â”‚ 0.475 â”‚ 0.638 â”‚ 0.05  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.8   â”‚ 0.714 â”‚ 0.721 â”‚ 0.964 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5937, ET: 0.4895, TC: 0.3848, WT: 0.9067
[0m
[0;32m2025-05-16 11:35:09,876  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLK_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5937_dice0.4117_20250516113509.pth;             Size 11.30 MB[0m
[0;32m2025-05-16 11:35:09,877  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:35:44,807  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:35:44,807  - INFO - - Train mean loss: 0.6537
- ET loss: 0.5538
- TC loss: 0.5003
- WT loss: 0.9070
- Cost time: 0.58mins â±ï¸
[0m
[0;32m2025-05-16 11:35:44,807  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:35:53,009  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_SLK_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:8.1992s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.449 â”‚ 0.59  â”‚ 0.66  â”‚ 0.098 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.351 â”‚ 0.459 â”‚ 0.543 â”‚ 0.053 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.492 â”‚ 0.627 â”‚ 0.795 â”‚ 0.053 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.76  â”‚ 0.662 â”‚ 0.638 â”‚ 0.98  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5529, ET: 0.4134, TC: 0.3436, WT: 0.9017
[0m
[0;32m2025-05-16 11:35:53,044  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLK_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5529_dice0.4494_20250516113553.pth;             Size 11.30 MB[0m
[0;32m2025-05-16 11:35:53,045  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:36:27,493  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:36:30,996  - INFO - Total number of parameters: 2.38 M[0m
[0;32m2025-05-16 11:36:31,000  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:36:31,000  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:36:31,000  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:36:31,000  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:36:31,000  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:36:31,009  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:36:31,010  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:36:31,010  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:36:31,016  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v4                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 2.38 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:37:22,950  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:37:26,421  - INFO - Total number of parameters: 2.38 M[0m
[0;32m2025-05-16 11:37:26,424  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:37:26,424  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:37:26,424  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:37:26,424  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:37:26,424  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:37:26,431  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:37:26,431  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:37:26,431  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:37:26,435  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v4                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 2.38 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:37:31,596  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:42:04,276  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:42:07,713  - INFO - Total number of parameters: 0.74 M[0m
[0;32m2025-05-16 11:42:07,716  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:42:07,716  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:42:07,716  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:42:07,716  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:42:07,716  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:42:07,724  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:42:07,724  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:42:07,724  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:42:07,728  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v4                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.74 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:42:08,045  - INFO - 
model: DCLA_UNet_v4
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:42:08,046  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:43:09,883  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:43:09,883  - INFO - - Train mean loss: 0.6467
- ET loss: 0.6624
- TC loss: 0.6496
- WT loss: 0.6280
- Cost time: 1.03mins â±ï¸
[0m
[0;32m2025-05-16 11:43:09,883  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:43:19,501  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.6160s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.656 â”‚ 0.581 â”‚ 0.632 â”‚ 0.753 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.527 â”‚ 0.442 â”‚ 0.505 â”‚ 0.635 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.643 â”‚ 0.515 â”‚ 0.639 â”‚ 0.777 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.751 â”‚ 0.769 â”‚ 0.72  â”‚ 0.763 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3691, ET: 0.4413, TC: 0.3912, WT: 0.2748
[0m
[0;32m2025-05-16 11:43:19,565  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3691_dice0.6556_20250516114319.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:43:19,566  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:44:20,068  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:44:20,069  - INFO - - Train mean loss: 0.4557
- ET loss: 0.5208
- TC loss: 0.4954
- WT loss: 0.3511
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:44:20,069  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:44:30,216  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.1457s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.704 â”‚ 0.665 â”‚ 0.662 â”‚ 0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.588 â”‚ 0.54  â”‚ 0.544 â”‚ 0.679 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.75  â”‚ 0.655 â”‚ 0.757 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.72  â”‚ 0.741 â”‚ 0.652 â”‚ 0.765 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3134, ET: 0.3544, TC: 0.3542, WT: 0.2316
[0m
[0;32m2025-05-16 11:44:30,292  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3134_dice0.7041_20250516114430.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:44:30,292  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 11:45:31,111  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 11:45:31,112  - INFO - - Train mean loss: 0.4137
- ET loss: 0.4662
- TC loss: 0.4601
- WT loss: 0.3149
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:45:31,112  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:45:41,029  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:9.9152s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.712 â”‚ 0.669 â”‚ 0.683 â”‚ 0.785 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.597 â”‚ 0.544 â”‚ 0.567 â”‚ 0.679 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.764 â”‚ 0.646 â”‚ 0.762 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.727 â”‚ 0.765 â”‚ 0.684 â”‚ 0.732 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3013, ET: 0.3468, TC: 0.3316, WT: 0.2255
[0m
[1;31m2025-05-16 11:45:41,030  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3134_dice0.7041_20250516114430.pth[0m
[0;32m2025-05-16 11:45:41,102  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3013_dice0.7122_20250516114541.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:45:41,103  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 11:46:42,161  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 11:46:42,162  - INFO - - Train mean loss: 0.4002
- ET loss: 0.4480
- TC loss: 0.4497
- WT loss: 0.3030
- Cost time: 1.02mins â±ï¸
[0m
[0;32m2025-05-16 11:46:42,162  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:46:52,004  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:9.8415s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.73  â”‚ 0.696 â”‚ 0.693 â”‚ 0.802 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.615 â”‚ 0.575 â”‚ 0.577 â”‚ 0.694 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.742 â”‚ 0.665 â”‚ 0.767 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.77  â”‚ 0.788 â”‚ 0.69  â”‚ 0.833 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2847, ET: 0.3196, TC: 0.3198, WT: 0.2147
[0m
[1;31m2025-05-16 11:46:52,006  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3013_dice0.7122_20250516114541.pth[0m
[0;32m2025-05-16 11:46:52,085  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.2847_dice0.7302_20250516114652.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:46:52,086  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 11:47:52,978  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 11:47:52,978  - INFO - - Train mean loss: 0.3805
- ET loss: 0.4289
- TC loss: 0.4338
- WT loss: 0.2789
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:47:52,978  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 11:48:02,582  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:9.6035s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.729 â”‚ 0.67  â”‚ 0.706 â”‚ 0.81  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.613 â”‚ 0.542 â”‚ 0.591 â”‚ 0.706 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.729 â”‚ 0.606 â”‚ 0.748 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.791 â”‚ 0.818 â”‚ 0.745 â”‚ 0.812 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2829, ET: 0.3416, TC: 0.3056, WT: 0.2015
[0m
[1;31m2025-05-16 11:48:02,584  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2847_dice0.7302_20250516114652.pth[0m
[0;32m2025-05-16 11:48:02,647  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.2829_dice0.7285_20250516114802.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:48:02,648  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 11:49:03,367  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 11:49:03,368  - INFO - - Train mean loss: 0.3568
- ET loss: 0.4017
- TC loss: 0.4044
- WT loss: 0.2642
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:49:03,368  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 11:49:12,903  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:9.5341s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.737 â”‚ 0.717 â”‚ 0.691 â”‚ 0.803 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.629 â”‚ 0.606 â”‚ 0.579 â”‚ 0.703 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.818 â”‚ 0.735 â”‚ 0.828 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.716 â”‚ 0.75  â”‚ 0.64  â”‚ 0.758 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2727, ET: 0.2958, TC: 0.3186, WT: 0.2037
[0m
[1;31m2025-05-16 11:49:12,904  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.2829_dice0.7285_20250516114802.pth[0m
[0;32m2025-05-16 11:49:13,208  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch6_loss0.2727_dice0.7372_20250516114912.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:49:13,209  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 11:50:13,977  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 11:50:13,977  - INFO - - Train mean loss: 0.3843
- ET loss: 0.4268
- TC loss: 0.4448
- WT loss: 0.2814
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:50:13,977  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 11:50:23,712  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:9.7336s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.73  â”‚ 0.664 â”‚ 0.711 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.613 â”‚ 0.535 â”‚ 0.594 â”‚ 0.711 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.694 â”‚ 0.571 â”‚ 0.713 â”‚ 0.798 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.832 â”‚ 0.857 â”‚ 0.783 â”‚ 0.857 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2798, ET: 0.3452, TC: 0.2990, WT: 0.1953
[0m
[0;33m2025-05-16 11:50:23,712  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:50:23,713  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 11:51:24,592  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 11:51:24,593  - INFO - - Train mean loss: 0.3821
- ET loss: 0.4389
- TC loss: 0.4475
- WT loss: 0.2600
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:51:24,593  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 11:51:34,130  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:9.5361s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.742 â”‚ 0.697 â”‚ 0.718 â”‚ 0.81  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.633 â”‚ 0.578 â”‚ 0.609 â”‚ 0.712 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.788 â”‚ 0.659 â”‚ 0.801 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.76  â”‚ 0.8   â”‚ 0.715 â”‚ 0.763 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2658, ET: 0.3119, TC: 0.2909, WT: 0.1946
[0m
[1;31m2025-05-16 11:51:34,131  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.2727_dice0.7372_20250516114912.pth[0m
[0;32m2025-05-16 11:51:34,193  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch8_loss0.2658_dice0.7417_20250516115134.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:51:34,194  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 11:52:35,627  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 11:52:35,627  - INFO - - Train mean loss: 0.3619
- ET loss: 0.4106
- TC loss: 0.4188
- WT loss: 0.2562
- Cost time: 1.02mins â±ï¸
[0m
[0;32m2025-05-16 11:52:35,627  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 11:52:44,699  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:9.0711s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.747 â”‚ 0.702 â”‚ 0.724 â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.635 â”‚ 0.584 â”‚ 0.614 â”‚ 0.708 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.724 â”‚ 0.637 â”‚ 0.762 â”‚ 0.772 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.847 â”‚ 0.754 â”‚ 0.883 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2631, ET: 0.3076, TC: 0.2861, WT: 0.1956
[0m
[1;31m2025-05-16 11:52:44,701  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.2658_dice0.7417_20250516115134.pth[0m
[0;32m2025-05-16 11:52:44,764  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch9_loss0.2631_dice0.7469_20250516115244.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:52:44,764  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-16 11:53:45,272  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-16 11:53:45,272  - INFO - - Train mean loss: 0.3358
- ET loss: 0.3764
- TC loss: 0.3896
- WT loss: 0.2413
- Cost time: 1.01mins â±ï¸
[0m
[0;32m2025-05-16 11:53:45,272  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 11:53:54,236  - INFO - === [Epoch 10/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:8.9628s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.756 â”‚ 0.715 â”‚ 0.726 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.65  â”‚ 0.602 â”‚ 0.62  â”‚ 0.727 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.761 â”‚ 0.664 â”‚ 0.796 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.803 â”‚ 0.827 â”‚ 0.73  â”‚ 0.852 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2524, ET: 0.2932, TC: 0.2821, WT: 0.1819
[0m
[1;31m2025-05-16 11:53:54,238  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.2631_dice0.7469_20250516115244.pth[0m
[0;32m2025-05-16 11:53:54,299  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch10_loss0.2524_dice0.7565_20250516115354.pth;             Size 9.36 MB[0m
[1;31m2025-05-16 11:53:54,300  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.2524 at epoch 10[0m
[0;32m2025-05-16 11:53:54,300  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-16 11:53:54,305  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/DCLA_UNet_v4_final_model.pth[0m
[1;31m2025-05-16 11:53:54,305  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-16 11:53:54,305  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-16 11:54:47,022  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.758 â”‚ 0.72  â”‚ 0.708 â”‚  0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.642 â”‚ 0.594 â”‚ 0.588 â”‚  0.745 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.819 â”‚ 0.693 â”‚ 0.871 â”‚  0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.77  â”‚ 0.812 â”‚ 0.664 â”‚  0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  9.966 â”‚ 9.365 â”‚ 9.544 â”‚ 10.988 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.2501;ET: 0.2909;ET: 0.2909;TC: 0.2990;WT: 0.1603
[0m
[0;32m2025-05-16 11:54:47,022  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-16 11:54:47,023  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/logs/2025-05-16.log[0m
[0;32m2025-05-16 11:54:52,824  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 11:54:56,247  - INFO - Total number of parameters: 0.93 M[0m
[0;32m2025-05-16 11:54:56,250  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 11:54:56,250  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:54:56,250  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:54:56,250  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 11:54:56,250  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 11:54:56,257  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 11:54:56,258  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 11:54:56,258  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 11:54:56,261  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLK_v4                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.93 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 11:54:56,488  - INFO - 
model: ResUNetBaseline_S_SLK_v4
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:54:56,488  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:55:33,078  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:55:33,079  - INFO - - Train mean loss: 0.6166
- ET loss: 0.7464
- TC loss: 0.6563
- WT loss: 0.4471
- Cost time: 0.61mins â±ï¸
[0m
[0;32m2025-05-16 11:55:33,079  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:55:41,803  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLK_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.7223s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.595 â”‚ 0.47  â”‚ 0.535 â”‚ 0.78  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.466 â”‚ 0.329 â”‚ 0.393 â”‚ 0.676 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.566 â”‚ 0.364 â”‚ 0.479 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.759 â”‚ 0.782 â”‚ 0.744 â”‚ 0.752 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4187, ET: 0.5483, TC: 0.4843, WT: 0.2235
[0m
[1;31m2025-05-16 11:55:41,805  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5529_dice0.4494_20250516113553.pth[0m
[0;32m2025-05-16 11:55:41,845  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLK_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4187_dice0.5950_20250516115541.pth;             Size 11.30 MB[0m
[0;32m2025-05-16 11:55:41,845  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 16:47:37,251  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 16:47:39,398  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-16 16:47:39,405  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 16:47:39,405  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:47:39,405  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:47:39,406  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:47:39,406  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 16:47:39,412  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 16:47:39,412  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 16:47:39,412  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 16:47:39,415  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.64 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 16:47:40,011  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 16:47:40,011  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 16:48:20,582  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 16:48:22,563  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-16 16:48:22,565  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 16:48:22,565  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:48:22,565  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:48:22,565  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:48:22,565  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 16:48:22,569  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 16:48:22,570  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 16:48:22,570  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 16:48:22,572  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.64 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 16:48:22,798  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 16:48:22,798  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 16:50:52,378  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 16:50:52,378  - INFO - - Train mean loss: 0.6343
- ET loss: 0.7345
- TC loss: 0.6521
- WT loss: 0.5164
- Cost time: 2.49mins â±ï¸
[0m
[0;32m2025-05-16 16:50:52,378  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 16:51:11,530  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:19.1510s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.558 â”‚ 0.402 â”‚ 0.533 â”‚ 0.739 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.428 â”‚ 0.271 â”‚ 0.395 â”‚ 0.618 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.537 â”‚ 0.294 â”‚ 0.439 â”‚ 0.879 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.798 â”‚ 0.858 â”‚ 0.861 â”‚ 0.675 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4438, ET: 0.5999, TC: 0.4692, WT: 0.2624
[0m
[0;32m2025-05-16 16:51:11,630  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4438_dice0.5579_20250516165111.pth;             Size 8.18 MB[0m
[0;32m2025-05-16 16:51:11,630  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 16:52:44,960  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 16:52:46,946  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-16 16:52:46,948  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 16:52:46,948  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:52:46,948  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:52:46,948  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:52:46,948  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 16:52:46,953  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 16:52:46,953  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 16:52:46,953  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 16:52:46,956  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.65 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 16:52:47,183  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 16:52:47,183  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 16:55:22,155  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 16:55:22,156  - INFO - - Train mean loss: 0.6811
- ET loss: 0.5411
- TC loss: 0.5608
- WT loss: 0.9412
- Cost time: 2.58mins â±ï¸
[0m
[0;32m2025-05-16 16:55:22,156  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 16:55:42,894  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 16:55:44,915  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-16 16:55:44,917  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 16:55:44,917  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:55:44,917  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:55:44,917  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 16:55:44,917  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 16:55:44,922  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 16:55:44,922  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 16:55:44,922  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 16:55:44,924  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.64 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 16:55:45,213  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 16:55:45,213  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 16:58:20,888  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 16:58:20,888  - INFO - - Train mean loss: 0.5994
- ET loss: 0.6608
- TC loss: 0.6275
- WT loss: 0.5100
- Cost time: 2.59mins â±ï¸
[0m
[0;32m2025-05-16 16:58:20,888  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 16:58:40,637  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:19.7479s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.636 â”‚ 0.58  â”‚ 0.603 â”‚ 0.724 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.503 â”‚ 0.439 â”‚ 0.474 â”‚ 0.596 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.75  â”‚ 0.633 â”‚ 0.771 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.626 â”‚ 0.644 â”‚ 0.574 â”‚ 0.661 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3696, ET: 0.4248, TC: 0.4011, WT: 0.2830
[0m
[0;32m2025-05-16 16:58:40,732  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3696_dice0.6357_20250516165840.pth;             Size 8.21 MB[0m
[0;32m2025-05-16 16:58:40,732  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 17:01:57,196  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 17:01:59,213  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 17:01:59,215  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 17:01:59,215  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 17:01:59,215  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 17:01:59,215  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 17:01:59,215  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 17:01:59,220  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 17:01:59,220  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 17:01:59,220  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 17:01:59,222  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 17:01:59,474  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 17:01:59,474  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 17:04:36,163  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 17:04:36,163  - INFO - - Train mean loss: 0.7709
- ET loss: 0.7077
- TC loss: 0.6605
- WT loss: 0.9446
- Cost time: 2.61mins â±ï¸
[0m
[0;32m2025-05-16 17:04:36,163  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 17:04:55,976  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:19.8111s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.4   â”‚ 0.499 â”‚ 0.622 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.291 â”‚ 0.352 â”‚ 0.479 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.308 â”‚ 0.363 â”‚ 0.519 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.884 â”‚ 0.856 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6044, ET: 0.5078, TC: 0.3855, WT: 0.9200
[0m
[1;31m2025-05-16 17:04:55,977  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.3696_dice0.6357_20250516165840.pth[0m
[0;32m2025-05-16 17:04:56,063  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.6044_dice0.4003_20250516170455.pth;             Size 8.79 MB[0m
[0;32m2025-05-16 17:04:56,064  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 17:06:53,021  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 17:06:55,045  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 17:06:55,046  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 17:06:55,047  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 17:06:55,047  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 17:06:55,047  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 17:06:55,047  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 17:06:55,052  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 17:06:55,052  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 17:06:55,052  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 17:06:55,054  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v3                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 17:06:55,452  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 17:06:55,452  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 17:09:49,649  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 17:09:49,649  - INFO - - Train mean loss: 0.6565
- ET loss: 0.7067
- TC loss: 0.6676
- WT loss: 0.5952
- Cost time: 2.90mins â±ï¸
[0m
[0;32m2025-05-16 17:09:49,649  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 17:10:13,266  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:23.6154s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.651 â”‚ 0.589 â”‚ 0.634 â”‚ 0.73  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.517 â”‚ 0.445 â”‚ 0.501 â”‚ 0.606 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.731 â”‚ 0.568 â”‚ 0.732 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.664 â”‚ 0.7   â”‚ 0.638 â”‚ 0.654 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3529, ET: 0.4161, TC: 0.3692, WT: 0.2733
[0m
[1;31m2025-05-16 17:10:13,267  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.6044_dice0.4003_20250516170455.pth[0m
[0;32m2025-05-16 17:10:13,392  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3529_dice0.6510_20250516171013.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:10:13,392  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 17:13:05,189  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 17:13:05,190  - INFO - - Train mean loss: 0.4391
- ET loss: 0.5081
- TC loss: 0.4735
- WT loss: 0.3357
- Cost time: 2.86mins â±ï¸
[0m
[0;32m2025-05-16 17:13:05,190  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 17:13:28,720  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:23.5298s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.702 â”‚ 0.622 â”‚ 0.697 â”‚ 0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.571 â”‚ 0.478 â”‚ 0.564 â”‚ 0.669 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.658 â”‚ 0.528 â”‚ 0.669 â”‚ 0.779 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.808 â”‚ 0.822 â”‚ 0.781 â”‚ 0.821 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3055, ET: 0.3839, TC: 0.3135, WT: 0.2192
[0m
[1;31m2025-05-16 17:13:28,721  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.3529_dice0.6510_20250516171013.pth[0m
[0;32m2025-05-16 17:13:28,823  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3055_dice0.7018_20250516171328.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:13:28,824  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 17:16:20,663  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 17:16:20,663  - INFO - - Train mean loss: 0.3840
- ET loss: 0.4406
- TC loss: 0.4117
- WT loss: 0.2997
- Cost time: 2.86mins â±ï¸
[0m
[0;32m2025-05-16 17:16:20,663  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 17:16:44,191  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:23.5277s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.718 â”‚ 0.66  â”‚ 0.717 â”‚ 0.777 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.591 â”‚ 0.521 â”‚ 0.591 â”‚ 0.661 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.75  â”‚ 0.622 â”‚ 0.727 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.744 â”‚ 0.754 â”‚ 0.766 â”‚ 0.712 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2872, ET: 0.3462, TC: 0.2904, WT: 0.2251
[0m
[1;31m2025-05-16 17:16:44,192  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3055_dice0.7018_20250516171328.pth[0m
[0;32m2025-05-16 17:16:44,290  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.2872_dice0.7178_20250516171644.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:16:44,291  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 17:19:36,358  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 17:19:36,359  - INFO - - Train mean loss: 0.3770
- ET loss: 0.4328
- TC loss: 0.4088
- WT loss: 0.2894
- Cost time: 2.87mins â±ï¸
[0m
[0;32m2025-05-16 17:19:36,359  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 17:19:59,899  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:23.5402s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.728 â”‚ 0.679 â”‚ 0.718 â”‚ 0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.604 â”‚ 0.544 â”‚ 0.594 â”‚ 0.673 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.781 â”‚ 0.685 â”‚ 0.788 â”‚ 0.869 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.727 â”‚ 0.724 â”‚ 0.71  â”‚ 0.747 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2759, ET: 0.3259, TC: 0.2867, WT: 0.2151
[0m
[1;31m2025-05-16 17:19:59,900  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.2872_dice0.7178_20250516171644.pth[0m
[0;32m2025-05-16 17:20:00,259  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.2759_dice0.7277_20250516171959.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:20:00,259  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 17:22:53,803  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 17:22:53,803  - INFO - - Train mean loss: 0.3772
- ET loss: 0.4266
- TC loss: 0.4116
- WT loss: 0.2935
- Cost time: 2.89mins â±ï¸
[0m
[0;32m2025-05-16 17:22:53,803  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 17:23:17,395  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:23.5906s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.733 â”‚ 0.671 â”‚ 0.726 â”‚ 0.802 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.607 â”‚ 0.53  â”‚ 0.601 â”‚ 0.69  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.688 â”‚ 0.579 â”‚ 0.681 â”‚ 0.804 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.833 â”‚ 0.843 â”‚ 0.831 â”‚ 0.825 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2718, ET: 0.3342, TC: 0.2800, WT: 0.2011
[0m
[1;31m2025-05-16 17:23:17,396  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2759_dice0.7277_20250516171959.pth[0m
[0;32m2025-05-16 17:23:17,490  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.2718_dice0.7328_20250516172317.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:23:17,491  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 17:26:10,110  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 17:26:10,110  - INFO - - Train mean loss: 0.3572
- ET loss: 0.3992
- TC loss: 0.3921
- WT loss: 0.2803
- Cost time: 2.88mins â±ï¸
[0m
[0;32m2025-05-16 17:26:10,110  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 17:26:34,054  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:23.9433s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.723 â”‚ 0.667 â”‚ 0.706 â”‚ 0.797 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.597 â”‚ 0.529 â”‚ 0.58  â”‚ 0.684 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.649 â”‚ 0.558 â”‚ 0.622 â”‚ 0.766 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.869 â”‚ 0.874 â”‚ 0.873 â”‚ 0.859 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2829, ET: 0.3398, TC: 0.3016, WT: 0.2072
[0m
[0;33m2025-05-16 17:26:34,054  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 17:26:34,054  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 17:29:26,720  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 17:29:26,721  - INFO - - Train mean loss: 0.3468
- ET loss: 0.3879
- TC loss: 0.3793
- WT loss: 0.2732
- Cost time: 2.88mins â±ï¸
[0m
[0;32m2025-05-16 17:29:26,721  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 17:29:50,215  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:23.4938s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.751 â”‚ 0.722 â”‚ 0.727 â”‚ 0.804 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.635 â”‚ 0.599 â”‚ 0.61  â”‚ 0.696 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.776 â”‚ 0.772 â”‚ 0.72  â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.771 â”‚ 0.709 â”‚ 0.802 â”‚ 0.801 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2554, ET: 0.2871, TC: 0.2802, WT: 0.1989
[0m
[1;31m2025-05-16 17:29:50,216  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.2718_dice0.7328_20250516172317.pth[0m
[0;32m2025-05-16 17:29:50,313  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch7_loss0.2554_dice0.7508_20250516172950.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:29:50,313  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 17:32:42,278  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 17:32:42,279  - INFO - - Train mean loss: 0.3711
- ET loss: 0.4130
- TC loss: 0.4117
- WT loss: 0.2885
- Cost time: 2.87mins â±ï¸
[0m
[0;32m2025-05-16 17:32:42,279  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 17:33:05,795  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:23.5156s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.779 â”‚ 0.747 â”‚ 0.767 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.667 â”‚ 0.626 â”‚ 0.657 â”‚ 0.719 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.772 â”‚ 0.711 â”‚ 0.755 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.816 â”‚ 0.811 â”‚ 0.82  â”‚ 0.818 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2267, ET: 0.2604, TC: 0.2394, WT: 0.1804
[0m
[1;31m2025-05-16 17:33:05,796  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.2554_dice0.7508_20250516172950.pth[0m
[0;32m2025-05-16 17:33:05,886  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch8_loss0.2267_dice0.7786_20250516173305.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 17:33:05,886  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 17:36:02,247  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 17:36:02,247  - INFO - - Train mean loss: 0.3429
- ET loss: 0.3828
- TC loss: 0.3743
- WT loss: 0.2715
- Cost time: 2.94mins â±ï¸
[0m
[0;32m2025-05-16 17:36:02,247  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 17:36:25,785  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:23.5373s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.776 â”‚ 0.751 â”‚ 0.768 â”‚ 0.81  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.666 â”‚ 0.633 â”‚ 0.659 â”‚ 0.706 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.824 â”‚ 0.775 â”‚ 0.802 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.766 â”‚ 0.752 â”‚ 0.775 â”‚ 0.769 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2283, ET: 0.2553, TC: 0.2384, WT: 0.1912
[0m
[0;33m2025-05-16 17:36:25,785  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 17:36:25,785  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-16 17:39:25,770  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-16 17:39:25,770  - INFO - - Train mean loss: 0.3375
- ET loss: 0.3802
- TC loss: 0.3652
- WT loss: 0.2671
- Cost time: 3.00mins â±ï¸
[0m
[0;32m2025-05-16 17:39:25,770  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 17:39:49,284  - INFO - === [Epoch 10/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:23.5137s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.777 â”‚ 0.753 â”‚ 0.772 â”‚ 0.806 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.663 â”‚ 0.634 â”‚ 0.663 â”‚ 0.693 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.747 â”‚ 0.72  â”‚ 0.761 â”‚ 0.76  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.84  â”‚ 0.815 â”‚ 0.82  â”‚ 0.884 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2273, ET: 0.2520, TC: 0.2333, WT: 0.1965
[0m
[0;33m2025-05-16 17:39:49,285  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/5[0m
[1;31m2025-05-16 17:39:49,285  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.2267 at epoch 8[0m
[0;32m2025-05-16 17:39:49,285  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-16 17:39:49,292  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/DCLA_UNet_v3_final_model.pth[0m
[1;31m2025-05-16 17:39:49,292  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-16 17:39:49,292  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-16 17:40:33,482  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.734 â”‚  0.688 â”‚  0.728 â”‚  0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.619 â”‚  0.566 â”‚  0.611 â”‚  0.68  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.756 â”‚  0.675 â”‚  0.764 â”‚  0.83  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.763 â”‚  0.763 â”‚  0.75  â”‚  0.776 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 19.546 â”‚ 18.107 â”‚ 15.29  â”‚ 25.241 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.2723;ET: 0.3211;ET: 0.3211;TC: 0.2793;WT: 0.2165
[0m
[0;32m2025-05-16 17:40:33,482  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-16 17:40:33,482  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/logs/2025-05-16.log[0m
[0;32m2025-05-16 18:42:00,358  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:06,111  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:11,564  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:16,985  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:22,442  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:27,998  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:33,557  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 18:42:39,266  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 20:18:30,182  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 20:18:32,394  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 20:18:32,399  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 20:18:32,399  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:18:32,400  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:18:32,400  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:18:32,400  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 20:18:32,406  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 20:18:32,407  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 20:18:32,407  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 20:18:32,409  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 20:18:33,077  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 20:18:33,077  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 20:21:31,952  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 20:21:31,952  - INFO - - Train mean loss: 0.7491
- ET loss: 0.6611
- TC loss: 0.6419
- WT loss: 0.9443
- Cost time: 2.98mins â±ï¸
[0m
[0;32m2025-05-16 20:21:31,952  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 20:21:55,965  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.0120s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.413 â”‚ 0.557 â”‚ 0.603 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.309 â”‚ 0.414 â”‚ 0.469 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.404 â”‚ 0.514 â”‚ 0.656 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.821 â”‚ 0.766 â”‚ 0.696 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5898, ET: 0.4485, TC: 0.4009, WT: 0.9200
[0m
[0;32m2025-05-16 20:21:56,059  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5898_dice0.4133_20250516202155.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 20:21:56,059  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 20:24:49,431  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 20:24:49,431  - INFO - - Train mean loss: 0.6527
- ET loss: 0.5172
- TC loss: 0.4977
- WT loss: 0.9432
- Cost time: 2.89mins â±ï¸
[0m
[0;32m2025-05-16 20:24:49,431  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 20:25:13,188  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:23.7561s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.442 â”‚ 0.632 â”‚ 0.615 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.343 â”‚ 0.495 â”‚ 0.491 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.519 â”‚ 0.703 â”‚ 0.812 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.75  â”‚ 0.672 â”‚ 0.578 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5594, ET: 0.3707, TC: 0.3874, WT: 0.9200
[0m
[0;32m2025-05-16 20:25:13,273  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5594_dice0.4423_20250516202513.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 20:25:13,274  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 20:28:07,524  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 20:28:07,524  - INFO - - Train mean loss: 0.6321
- ET loss: 0.4773
- TC loss: 0.4765
- WT loss: 0.9425
- Cost time: 2.90mins â±ï¸
[0m
[0;32m2025-05-16 20:28:07,524  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 20:28:31,265  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:23.7398s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.465 â”‚ 0.645 â”‚ 0.672 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.362 â”‚ 0.503 â”‚ 0.539 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.444 â”‚ 0.575 â”‚ 0.713 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.848 â”‚ 0.823 â”‚ 0.721 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5378, ET: 0.3608, TC: 0.3324, WT: 0.9200
[0m
[1;31m2025-05-16 20:28:31,266  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5594_dice0.4423_20250516202513.pth[0m
[0;32m2025-05-16 20:28:31,355  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.5378_dice0.4654_20250516202831.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 20:28:31,356  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 20:31:24,229  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 20:31:24,229  - INFO - - Train mean loss: 0.5947
- ET loss: 0.4218
- TC loss: 0.4209
- WT loss: 0.9414
- Cost time: 2.88mins â±ï¸
[0m
[0;32m2025-05-16 20:31:24,229  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 20:31:48,018  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:23.7889s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.443 â”‚ 0.59  â”‚ 0.658 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.338 â”‚ 0.448 â”‚ 0.522 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.381 â”‚ 0.479 â”‚ 0.622 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.882 â”‚ 0.801 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5613, ET: 0.4161, TC: 0.3477, WT: 0.9200
[0m
[0;33m2025-05-16 20:31:48,019  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 20:31:48,019  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 20:34:45,190  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 20:34:45,191  - INFO - - Train mean loss: 0.6092
- ET loss: 0.4386
- TC loss: 0.4466
- WT loss: 0.9423
- Cost time: 2.95mins â±ï¸
[0m
[0;32m2025-05-16 20:34:45,191  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 20:35:12,122  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:26.9307s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.48  â”‚ 0.711 â”‚ 0.65  â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.383 â”‚ 0.584 â”‚ 0.521 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.545 â”‚ 0.751 â”‚ 0.842 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.767 â”‚ 0.72  â”‚ 0.579 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5214, ET: 0.2928, TC: 0.3514, WT: 0.9200
[0m
[1;31m2025-05-16 20:35:12,123  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.5378_dice0.4654_20250516202831.pth[0m
[0;32m2025-05-16 20:35:12,209  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.5214_dice0.4803_20250516203512.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 20:35:12,209  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 20:38:23,605  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 20:38:23,605  - INFO - - Train mean loss: 0.6098
- ET loss: 0.4427
- TC loss: 0.4413
- WT loss: 0.9453
- Cost time: 3.19mins â±ï¸
[0m
[0;32m2025-05-16 20:38:23,605  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 20:38:49,757  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:26.1514s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.493 â”‚ 0.704 â”‚ 0.694 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.394 â”‚ 0.573 â”‚ 0.567 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.499 â”‚ 0.666 â”‚ 0.79  â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.829 â”‚ 0.808 â”‚ 0.679 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5103, ET: 0.3011, TC: 0.3097, WT: 0.9200
[0m
[1;31m2025-05-16 20:38:49,758  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.5214_dice0.4803_20250516203512.pth[0m
[0;32m2025-05-16 20:38:49,837  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch6_loss0.5103_dice0.4926_20250516203849.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 20:38:49,838  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 20:42:08,578  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 20:42:08,578  - INFO - - Train mean loss: 0.5903
- ET loss: 0.4086
- TC loss: 0.4186
- WT loss: 0.9437
- Cost time: 3.31mins â±ï¸
[0m
[0;32m2025-05-16 20:42:08,578  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 20:42:35,480  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:26.9017s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.487 â”‚ 0.688 â”‚ 0.693 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.388 â”‚ 0.554 â”‚ 0.567 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.499 â”‚ 0.659 â”‚ 0.796 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.823 â”‚ 0.791 â”‚ 0.677 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5147, ET: 0.3150, TC: 0.3091, WT: 0.9200
[0m
[0;33m2025-05-16 20:42:35,480  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 20:42:35,480  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 20:45:48,739  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 20:45:48,739  - INFO - - Train mean loss: 0.5967
- ET loss: 0.4149
- TC loss: 0.4318
- WT loss: 0.9434
- Cost time: 3.22mins â±ï¸
[0m
[0;32m2025-05-16 20:45:48,739  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 20:46:12,951  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:24.2116s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.472 â”‚ 0.648 â”‚ 0.688 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.369 â”‚ 0.51  â”‚ 0.556 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.423 â”‚ 0.546 â”‚ 0.682 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.881 â”‚ 0.77  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5309, ET: 0.3561, TC: 0.3165, WT: 0.9200
[0m
[0;33m2025-05-16 20:46:12,952  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/5[0m
[0;32m2025-05-16 20:46:12,952  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 20:49:31,863  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 20:49:31,863  - INFO - - Train mean loss: 0.5819
- ET loss: 0.3893
- TC loss: 0.4151
- WT loss: 0.9414
- Cost time: 3.32mins â±ï¸
[0m
[0;32m2025-05-16 20:49:31,863  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 20:49:58,220  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:26.3564s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.489 â”‚ 0.683 â”‚ 0.705 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.39  â”‚ 0.551 â”‚ 0.578 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.459 â”‚ 0.601 â”‚ 0.735 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.866 â”‚ 0.745 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5142, ET: 0.3227, TC: 0.2998, WT: 0.9200
[0m
[0;33m2025-05-16 20:49:58,220  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/5[0m
[0;32m2025-05-16 20:49:58,220  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-16 20:53:03,430  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-16 20:53:03,431  - INFO - - Train mean loss: 0.5670
- ET loss: 0.3703
- TC loss: 0.3866
- WT loss: 0.9440
- Cost time: 3.09mins â±ï¸
[0m
[0;32m2025-05-16 20:53:03,431  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 20:53:29,134  - INFO - === [Epoch 10/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:25.7029s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.508 â”‚ 0.731 â”‚ 0.713 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.411 â”‚ 0.603 â”‚ 0.587 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.501 â”‚ 0.668 â”‚ 0.791 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.846 â”‚ 0.843 â”‚ 0.694 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4942, ET: 0.2730, TC: 0.2897, WT: 0.9200
[0m
[1;31m2025-05-16 20:53:29,136  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.5103_dice0.4926_20250516203849.pth[0m
[0;32m2025-05-16 20:53:29,218  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch10_loss0.4942_dice0.5079_20250516205329.pth;             Size 8.80 MB[0m
[1;31m2025-05-16 20:53:29,218  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4942 at epoch 10[0m
[0;32m2025-05-16 20:53:29,218  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-16 20:53:29,223  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-16 20:53:29,223  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-16 20:53:29,223  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-16 20:54:14,951  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.465 â”‚  0.68  â”‚  0.635 â”‚  0.079 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.37  â”‚  0.555 â”‚  0.513 â”‚  0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.49  â”‚  0.655 â”‚  0.773 â”‚  0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.791 â”‚  0.788 â”‚  0.586 â”‚  1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 42.835 â”‚ 14.752 â”‚ 16.63  â”‚ 97.123 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5368;ET: 0.3239;ET: 0.3239;TC: 0.3654;WT: 0.9213
[0m
[0;32m2025-05-16 20:54:14,951  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-16 20:54:14,952  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/logs/2025-05-16.log[0m
[0;32m2025-05-16 20:54:21,729  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 20:54:23,932  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-16 20:54:23,935  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 20:54:23,935  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:54:23,935  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:54:23,935  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:54:23,935  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 20:54:23,941  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 20:54:23,941  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 20:54:23,941  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 20:54:23,944  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 20:54:24,287  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 20:54:24,287  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 20:55:33,112  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 20:55:33,112  - INFO - - Train mean loss: 0.6477
- ET loss: 0.6671
- TC loss: 0.6621
- WT loss: 0.6138
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-16 20:55:33,113  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 20:55:44,619  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.5052s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.632 â”‚ 0.571 â”‚ 0.577 â”‚ 0.747 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.497 â”‚ 0.43  â”‚ 0.445 â”‚ 0.617 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.565 â”‚ 0.493 â”‚ 0.501 â”‚ 0.701 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.837 â”‚ 0.814 â”‚ 0.844 â”‚ 0.853 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3823, ET: 0.4543, TC: 0.4351, WT: 0.2576
[0m
[0;32m2025-05-16 20:55:44,693  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3823_dice0.6318_20250516205544.pth;             Size 12.43 MB[0m
[0;32m2025-05-16 20:55:44,694  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 20:57:01,134  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 20:57:01,135  - INFO - - Train mean loss: 0.4289
- ET loss: 0.4886
- TC loss: 0.4865
- WT loss: 0.3116
- Cost time: 1.27mins â±ï¸
[0m
[0;32m2025-05-16 20:57:01,135  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 20:57:20,960  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 20:57:22,976  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 20:57:22,978  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 20:57:22,978  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:57:22,978  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:57:22,978  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 20:57:22,978  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 20:57:22,983  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 20:57:22,984  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 20:57:22,984  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 20:57:22,986  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 20:57:23,385  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 20:57:23,385  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 21:00:18,489  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 21:00:18,490  - INFO - - Train mean loss: 0.7499
- ET loss: 0.6994
- TC loss: 0.6061
- WT loss: 0.9442
- Cost time: 2.92mins â±ï¸
[0m
[0;32m2025-05-16 21:00:18,490  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 21:00:42,445  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:23.9542s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.447 â”‚ 0.617 â”‚ 0.644 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.344 â”‚ 0.478 â”‚ 0.512 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.449 â”‚ 0.589 â”‚ 0.716 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.786 â”‚ 0.697 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5606, ET: 0.3955, TC: 0.3664, WT: 0.9200
[0m
[1;31m2025-05-16 21:00:42,447  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.4942_dice0.5079_20250516205329.pth[0m
[0;32m2025-05-16 21:00:42,542  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5606_dice0.4469_20250516210042.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 21:00:42,542  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 21:03:37,985  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 21:03:37,985  - INFO - - Train mean loss: 0.6233
- ET loss: 0.4570
- TC loss: 0.4698
- WT loss: 0.9432
- Cost time: 2.92mins â±ï¸
[0m
[0;32m2025-05-16 21:03:37,985  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 21:04:05,719  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:27.7329s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.471 â”‚ 0.687 â”‚ 0.645 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.374 â”‚ 0.559 â”‚ 0.521 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.543 â”‚ 0.746 â”‚ 0.841 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.765 â”‚ 0.71  â”‚ 0.584 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5323, ET: 0.3184, TC: 0.3585, WT: 0.9200
[0m
[1;31m2025-05-16 21:04:05,720  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-16 21:04:05,805  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5323_dice0.4706_20250516210405.pth;             Size 8.80 MB[0m
[0;32m2025-05-16 21:04:05,806  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 21:06:56,551  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:06:58,606  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 21:06:58,608  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:06:58,608  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:06:58,608  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:06:58,608  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:06:58,608  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:06:58,613  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 21:06:58,613  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 21:06:58,613  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 21:06:58,615  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:06:58,905  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 21:06:58,906  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 21:09:39,662  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 21:09:39,663  - INFO - - Train mean loss: 0.8423
- ET loss: 0.6057
- TC loss: 0.9775
- WT loss: 0.9436
- Cost time: 2.68mins â±ï¸
[0m
[0;32m2025-05-16 21:09:39,663  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 21:10:00,056  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:20.3917s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.231 â”‚ 0.581 â”‚ 0.031 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.164 â”‚ 0.435 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.173 â”‚ 0.461 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.954 â”‚ 0.878 â”‚ 0.983 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7754, ET: 0.4376, TC: 0.9685, WT: 0.9200
[0m
[1;31m2025-05-16 21:10:00,057  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.5606_dice0.4469_20250516210042.pth[0m
[0;32m2025-05-16 21:10:00,182  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7754_dice0.2307_20250516211000.pth;             Size 8.79 MB[0m
[0;32m2025-05-16 21:10:00,183  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 21:12:39,740  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 21:12:39,740  - INFO - - Train mean loss: 0.7914
- ET loss: 0.4578
- TC loss: 0.9756
- WT loss: 0.9409
- Cost time: 2.66mins â±ï¸
[0m
[0;32m2025-05-16 21:12:39,741  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 21:12:59,769  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:20.0273s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.257 â”‚ 0.659 â”‚ 0.031 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.193 â”‚ 0.52  â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.208 â”‚ 0.567 â”‚ 0.016 â”‚ 0.042 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.949 â”‚ 0.864 â”‚ 0.983 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7463, ET: 0.3503, TC: 0.9685, WT: 0.9200
[0m
[1;31m2025-05-16 21:12:59,770  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5323_dice0.4706_20250516210405.pth[0m
[0;32m2025-05-16 21:12:59,877  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.7463_dice0.2569_20250516211259.pth;             Size 8.79 MB[0m
[0;32m2025-05-16 21:12:59,878  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 21:16:17,382  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:16:19,374  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 21:16:19,375  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:16:19,376  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:16:19,376  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:16:19,376  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:16:19,376  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:16:19,382  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 21:16:19,382  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 21:16:19,382  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 21:16:19,384  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:16:19,784  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 21:16:19,784  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 21:19:15,060  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 21:19:15,061  - INFO - - Train mean loss: 0.5945
- ET loss: 0.6243
- TC loss: 0.5944
- WT loss: 0.5649
- Cost time: 2.92mins â±ï¸
[0m
[0;32m2025-05-16 21:19:15,061  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 21:19:39,178  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.1162s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.697 â”‚ 0.612 â”‚ 0.705 â”‚ 0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.564 â”‚ 0.466 â”‚ 0.576 â”‚ 0.651 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.683 â”‚ 0.515 â”‚ 0.7   â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.776 â”‚ 0.815 â”‚ 0.756 â”‚ 0.757 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3132, ET: 0.3946, TC: 0.3052, WT: 0.2397
[0m
[1;31m2025-05-16 21:19:39,179  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.7754_dice0.2307_20250516211000.pth[0m
[0;32m2025-05-16 21:19:39,312  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3132_dice0.6970_20250516211939.pth;             Size 8.95 MB[0m
[0;32m2025-05-16 21:19:39,312  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 21:21:24,963  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:21:26,953  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-16 21:21:26,955  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:21:26,955  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:21:26,955  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:21:26,955  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:21:26,955  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:21:26,960  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 21:21:26,960  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 21:21:26,960  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 21:21:26,962  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:21:27,307  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 21:21:27,307  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 21:24:18,261  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 21:24:18,262  - INFO - - Train mean loss: 0.7381
- ET loss: 1.0000
- TC loss: 0.6945
- WT loss: 0.5198
- Cost time: 2.85mins â±ï¸
[0m
[0;32m2025-05-16 21:24:18,262  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 21:24:41,921  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:23.6577s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.406 â”‚    0 â”‚ 0.543 â”‚ 0.676 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.317 â”‚    0 â”‚ 0.406 â”‚ 0.547 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.474 â”‚    0 â”‚ 0.493 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.45  â”‚    0 â”‚ 0.779 â”‚ 0.57  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5944, ET: 1.0000, TC: 0.4590, WT: 0.3242
[0m
[0;32m2025-05-16 21:24:42,005  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5944_dice0.4065_20250516212441.pth;             Size 8.66 MB[0m
[0;32m2025-05-16 21:24:42,005  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 21:27:33,955  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 21:27:33,955  - INFO - - Train mean loss: 0.6252
- ET loss: 1.0000
- TC loss: 0.5618
- WT loss: 0.3138
- Cost time: 2.87mins â±ï¸
[0m
[0;32m2025-05-16 21:27:33,955  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 21:27:57,650  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:23.6939s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.376 â”‚    0 â”‚ 0.395 â”‚ 0.734 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.29  â”‚    0 â”‚ 0.268 â”‚ 0.603 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.305 â”‚    0 â”‚ 0.271 â”‚ 0.642 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.624 â”‚    0 â”‚ 0.967 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6260, ET: 1.0000, TC: 0.6077, WT: 0.2703
[0m
[0;33m2025-05-16 21:27:57,650  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-16 21:27:57,650  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 21:30:06,213  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:30:08,207  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-16 21:30:08,208  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:30:08,208  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:30:08,208  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:30:08,209  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:30:08,209  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:30:08,215  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 21:30:08,215  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 21:30:08,215  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 21:30:08,217  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/workspace/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/workspace/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 4                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/workspace/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/workspace/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/workspace/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                         â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:30:08,458  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 21:30:08,458  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 21:32:44,711  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 21:32:44,712  - INFO - - Train mean loss: 0.7966
- ET loss: 1.0000
- TC loss: 0.7539
- WT loss: 0.6358
- Cost time: 2.60mins â±ï¸
[0m
[0;32m2025-05-16 21:32:44,712  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 21:33:05,075  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:20.3616s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.448 â”‚    0 â”‚ 0.59  â”‚ 0.753 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.358 â”‚    0 â”‚ 0.451 â”‚ 0.622 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.43  â”‚    0 â”‚ 0.525 â”‚ 0.764 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.523 â”‚    0 â”‚ 0.795 â”‚ 0.775 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5559, ET: 1.0000, TC: 0.4133, WT: 0.2543
[0m
[0;32m2025-05-16 21:33:05,163  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5559_dice0.4478_20250516213305.pth;             Size 8.64 MB[0m
[0;32m2025-05-16 21:33:05,163  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 21:56:14,875  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:56:18,209  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-16 21:56:18,212  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:56:18,212  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:56:18,212  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:56:18,213  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:56:18,213  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:56:18,219  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-16 21:56:18,219  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-16 21:56:18,219  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-16 21:56:18,223  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv1_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:56:21,647  - INFO - 
model: ResUNetBaseline_S_SLKv1_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-16 21:56:21,647  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-16 21:57:13,956  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:57:17,155  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-16 21:57:17,158  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:57:17,158  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:57:17,158  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:57:17,158  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:57:17,158  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:57:17,165  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-16 21:57:17,165  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-16 21:57:17,165  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-16 21:57:17,168  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv1_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:57:19,943  - INFO - 
model: ResUNetBaseline_S_SLKv1_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-16 21:57:19,944  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-16 21:57:46,300  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 21:57:50,281  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-16 21:57:50,285  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 21:57:50,285  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:57:50,285  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:57:50,285  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 21:57:50,285  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 21:57:50,296  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 21:57:50,296  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 21:57:50,296  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 21:57:50,301  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv1_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 21:57:50,603  - INFO - 
model: ResUNetBaseline_S_SLKv1_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 21:57:50,603  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 21:58:27,528  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 21:58:27,528  - INFO - - Train mean loss: 0.7614
- ET loss: 0.6524
- TC loss: 0.6941
- WT loss: 0.9377
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-16 21:58:27,528  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 22:00:50,360  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 22:00:53,639  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-16 22:00:53,642  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 22:00:53,642  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 22:00:53,642  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 22:00:53,642  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 22:00:53,642  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 22:00:53,649  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-16 22:00:53,649  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-16 22:00:53,649  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-16 22:00:53,653  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 22:00:53,998  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 22:00:53,998  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 22:01:29,590  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 22:01:29,590  - INFO - - Train mean loss: 0.7616
- ET loss: 0.7833
- TC loss: 0.7651
- WT loss: 0.7364
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-16 22:01:29,590  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 22:01:38,742  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.1504s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.506 â”‚ 0.467 â”‚ 0.482 â”‚ 0.569 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.379 â”‚ 0.342 â”‚ 0.359 â”‚ 0.436 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.573 â”‚ 0.498 â”‚ 0.561 â”‚ 0.659 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.641 â”‚ 0.658 â”‚ 0.617 â”‚ 0.649 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5162, ET: 0.5493, TC: 0.5474, WT: 0.4520
[0m
[0;32m2025-05-16 22:01:38,787  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5162_dice0.5059_20250516220138.pth;             Size 12.43 MB[0m
[0;32m2025-05-16 22:01:38,787  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 22:05:41,630  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-16 22:05:44,917  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-16 22:05:44,920  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-16 22:05:44,920  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-16 22:05:44,920  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 22:05:44,920  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-16 22:05:44,920  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-16 22:05:44,927  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-16 22:05:44,927  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-16 22:05:44,927  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-16 22:05:44,931  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv1_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-16 22:05:47,733  - INFO - 
model: ResUNetBaseline_S_SLKv1_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-16 22:05:47,733  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-16 22:08:06,604  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-16 22:08:06,606  - INFO - - Train mean loss: 0.6404
- ET loss: 0.4862
- TC loss: 0.4924
- WT loss: 0.9424
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-16 22:08:06,606  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-16 22:08:39,039  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:32.4309s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.517 â”‚ 0.721 â”‚ 0.746 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.427 â”‚ 0.605 â”‚ 0.632 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.488 â”‚ 0.706 â”‚ 0.713 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.78  â”‚ 0.835 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4898, ET: 0.2891, TC: 0.2641, WT: 0.9163
[0m
[0;32m2025-05-16 22:08:39,087  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.4898_dice0.5169_20250516220839.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:08:39,087  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-16 22:10:54,464  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-16 22:10:54,466  - INFO - - Train mean loss: 0.5593
- ET loss: 0.3741
- TC loss: 0.3614
- WT loss: 0.9425
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 22:10:54,466  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-16 22:11:26,797  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:32.3288s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.546 â”‚ 0.762 â”‚ 0.794 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.466 â”‚ 0.655 â”‚ 0.699 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.534 â”‚ 0.731 â”‚ 0.828 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.831 â”‚ 0.802 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4566, ET: 0.2427, TC: 0.2106, WT: 0.9164
[0m
[0;32m2025-05-16 22:11:26,836  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.4566_dice0.5465_20250516221126.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:11:26,836  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-16 22:13:44,541  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-16 22:13:44,543  - INFO - - Train mean loss: 0.5449
- ET loss: 0.3540
- TC loss: 0.3387
- WT loss: 0.9419
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-16 22:13:44,543  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-16 22:14:15,075  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:30.5307s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.56  â”‚ 0.781 â”‚ 0.814 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.486 â”‚ 0.685 â”‚ 0.729 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.565 â”‚ 0.79  â”‚ 0.862 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.809 â”‚ 0.806 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4429, ET: 0.2219, TC: 0.1903, WT: 0.9164
[0m
[1;31m2025-05-16 22:14:15,077  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4566_dice0.5465_20250516221126.pth[0m
[0;32m2025-05-16 22:14:15,111  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.4429_dice0.5596_20250516221415.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:14:15,111  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-16 22:16:27,424  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-16 22:16:27,425  - INFO - - Train mean loss: 0.5310
- ET loss: 0.3362
- TC loss: 0.3142
- WT loss: 0.9425
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-16 22:16:27,425  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-16 22:16:57,920  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:30.4939s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.547 â”‚ 0.773 â”‚ 0.786 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.471 â”‚ 0.674 â”‚ 0.696 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.515 â”‚ 0.745 â”‚ 0.756 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.843 â”‚ 0.877 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4560, ET: 0.2314, TC: 0.2201, WT: 0.9164
[0m
[0;33m2025-05-16 22:16:57,920  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 22:16:57,920  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-16 22:19:14,854  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-16 22:19:14,855  - INFO - - Train mean loss: 0.5209
- ET loss: 0.3257
- TC loss: 0.2935
- WT loss: 0.9436
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-16 22:19:14,855  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-16 22:19:45,280  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:30.4236s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.566 â”‚ 0.788 â”‚ 0.826 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.497 â”‚ 0.696 â”‚ 0.751 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.552 â”‚ 0.777 â”‚ 0.835 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.828 â”‚ 0.85  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4357, ET: 0.2137, TC: 0.1769, WT: 0.9164
[0m
[1;31m2025-05-16 22:19:45,281  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.4429_dice0.5596_20250516221415.pth[0m
[0;32m2025-05-16 22:19:45,316  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.4357_dice0.5660_20250516221945.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:19:45,317  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-16 22:22:00,053  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-16 22:22:00,054  - INFO - - Train mean loss: 0.5121
- ET loss: 0.3126
- TC loss: 0.2819
- WT loss: 0.9419
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-16 22:22:00,054  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-16 22:22:30,497  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:30.4424s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.573 â”‚ 0.797 â”‚ 0.838 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.506 â”‚ 0.707 â”‚ 0.765 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.554 â”‚ 0.782 â”‚ 0.836 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.909 â”‚ 0.848 â”‚ 0.879 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4288, ET: 0.2055, TC: 0.1647, WT: 0.9164
[0m
[1;31m2025-05-16 22:22:30,499  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.4357_dice0.5660_20250516221945.pth[0m
[0;32m2025-05-16 22:22:30,535  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.4288_dice0.5729_20250516222230.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:22:30,535  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-16 22:24:46,590  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-16 22:24:46,592  - INFO - - Train mean loss: 0.5205
- ET loss: 0.3271
- TC loss: 0.2910
- WT loss: 0.9435
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 22:24:46,592  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-16 22:25:18,319  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:31.7260s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.569 â”‚ 0.791 â”‚ 0.833 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.499 â”‚ 0.696 â”‚ 0.756 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.535 â”‚ 0.751 â”‚ 0.81  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.922 â”‚ 0.869 â”‚ 0.897 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4327, ET: 0.2118, TC: 0.1700, WT: 0.9163
[0m
[0;33m2025-05-16 22:25:18,319  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 22:25:18,319  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-16 22:27:34,494  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-16 22:27:34,496  - INFO - - Train mean loss: 0.5105
- ET loss: 0.3112
- TC loss: 0.2792
- WT loss: 0.9412
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 22:27:34,496  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-16 22:28:05,784  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:31.2856s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.575 â”‚ 0.8   â”‚ 0.842 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.51  â”‚ 0.713 â”‚ 0.773 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.557 â”‚ 0.789 â”‚ 0.837 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.848 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4262, ET: 0.2020, TC: 0.1603, WT: 0.9163
[0m
[1;31m2025-05-16 22:28:05,786  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.4288_dice0.5729_20250516222230.pth[0m
[0;32m2025-05-16 22:28:05,830  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch8_loss0.4262_dice0.5752_20250516222805.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:28:05,830  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-16 22:30:22,991  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-16 22:30:22,992  - INFO - - Train mean loss: 0.5126
- ET loss: 0.3140
- TC loss: 0.2814
- WT loss: 0.9424
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-16 22:30:22,992  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-16 22:30:54,529  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:31.5356s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.581 â”‚ 0.809 â”‚ 0.852 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.517 â”‚ 0.723 â”‚ 0.784 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.569 â”‚ 0.804 â”‚ 0.858 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.907 â”‚ 0.845 â”‚ 0.876 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4198, ET: 0.1930, TC: 0.1500, WT: 0.9163
[0m
[1;31m2025-05-16 22:30:54,531  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.4262_dice0.5752_20250516222805.pth[0m
[0;32m2025-05-16 22:30:54,569  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.4198_dice0.5814_20250516223054.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:30:54,569  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-16 22:33:10,320  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-16 22:33:10,321  - INFO - - Train mean loss: 0.4984
- ET loss: 0.2960
- TC loss: 0.2561
- WT loss: 0.9431
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 22:33:10,321  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-16 22:33:40,700  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:30.3777s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.574 â”‚ 0.801 â”‚ 0.838 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.507 â”‚ 0.713 â”‚ 0.764 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.568 â”‚ 0.829 â”‚ 0.83  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.8   â”‚ 0.879 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4271, ET: 0.2007, TC: 0.1643, WT: 0.9163
[0m
[0;33m2025-05-16 22:33:40,700  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 22:33:40,700  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-16 22:35:55,725  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-16 22:35:55,728  - INFO - - Train mean loss: 0.4940
- ET loss: 0.2862
- TC loss: 0.2538
- WT loss: 0.9421
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-16 22:35:55,728  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-16 22:36:26,273  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:30.5443s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.581 â”‚ 0.811 â”‚ 0.849 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.517 â”‚ 0.726 â”‚ 0.781 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.565 â”‚ 0.801 â”‚ 0.848 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.911 â”‚ 0.85  â”‚ 0.882 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4200, ET: 0.1906, TC: 0.1531, WT: 0.9163
[0m
[0;33m2025-05-16 22:36:26,273  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 22:36:26,273  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-16 22:38:40,995  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-16 22:38:40,996  - INFO - - Train mean loss: 0.4860
- ET loss: 0.2780
- TC loss: 0.2395
- WT loss: 0.9406
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-16 22:38:40,996  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-16 22:39:10,767  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:29.7698s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.586 â”‚ 0.815 â”‚ 0.859 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.523 â”‚ 0.73  â”‚ 0.793 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.567 â”‚ 0.797 â”‚ 0.858 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.856 â”‚ 0.883 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4153, ET: 0.1863, TC: 0.1432, WT: 0.9163
[0m
[1;31m2025-05-16 22:39:10,769  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.4198_dice0.5814_20250516223054.pth[0m
[0;32m2025-05-16 22:39:10,810  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.4153_dice0.5858_20250516223910.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:39:10,810  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-16 22:41:27,366  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-16 22:41:27,367  - INFO - - Train mean loss: 0.5024
- ET loss: 0.2969
- TC loss: 0.2663
- WT loss: 0.9442
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-16 22:41:27,367  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-16 22:41:58,263  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:30.8942s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.586 â”‚ 0.817 â”‚ 0.858 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.524 â”‚ 0.734 â”‚ 0.793 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.584 â”‚ 0.824 â”‚ 0.883 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.837 â”‚ 0.861 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4146, ET: 0.1842, TC: 0.1433, WT: 0.9163
[0m
[1;31m2025-05-16 22:41:58,265  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.4153_dice0.5858_20250516223910.pth[0m
[0;32m2025-05-16 22:41:58,308  - INFO - âœ¨ Saved checkpoint (epoch 13) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.4146_dice0.5863_20250516224158.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:41:58,309  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-16 22:44:14,055  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-16 22:44:14,056  - INFO - - Train mean loss: 0.5032
- ET loss: 0.2996
- TC loss: 0.2677
- WT loss: 0.9424
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 22:44:14,056  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-16 22:44:44,653  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:30.5957s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.582 â”‚ 0.812 â”‚ 0.85  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.518 â”‚ 0.728 â”‚ 0.782 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.849 â”‚ 0.905 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.803 â”‚ 0.827 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4188, ET: 0.1895, TC: 0.1507, WT: 0.9163
[0m
[0;33m2025-05-16 22:44:44,653  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 22:44:44,653  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-16 22:47:01,668  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-16 22:47:01,671  - INFO - - Train mean loss: 0.5031
- ET loss: 0.3010
- TC loss: 0.2662
- WT loss: 0.9423
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-16 22:47:01,671  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-16 22:47:32,290  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:30.6177s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.582 â”‚ 0.817 â”‚ 0.844 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.519 â”‚ 0.736 â”‚ 0.777 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.57  â”‚ 0.817 â”‚ 0.847 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.909 â”‚ 0.844 â”‚ 0.882 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4195, ET: 0.1844, TC: 0.1576, WT: 0.9163
[0m
[0;33m2025-05-16 22:47:32,291  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 22:47:32,291  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-16 22:49:48,541  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-16 22:49:48,542  - INFO - - Train mean loss: 0.4960
- ET loss: 0.2918
- TC loss: 0.2545
- WT loss: 0.9417
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 22:49:48,542  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-16 22:50:20,178  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:31.6336s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.587 â”‚ 0.819 â”‚ 0.859 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.524 â”‚ 0.735 â”‚ 0.794 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.568 â”‚ 0.805 â”‚ 0.856 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.857 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4137, ET: 0.1827, TC: 0.1422, WT: 0.9163
[0m
[1;31m2025-05-16 22:50:20,180  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch13_loss0.4146_dice0.5863_20250516224158.pth[0m
[0;32m2025-05-16 22:50:20,216  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.4137_dice0.5872_20250516225020.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:50:20,216  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-16 22:52:35,946  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-16 22:52:35,947  - INFO - - Train mean loss: 0.4922
- ET loss: 0.2864
- TC loss: 0.2483
- WT loss: 0.9420
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 22:52:35,948  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-16 22:53:07,667  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:31.7180s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.579 â”‚ 0.808 â”‚ 0.844 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.516 â”‚ 0.724 â”‚ 0.778 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.584 â”‚ 0.828 â”‚ 0.88  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.818 â”‚ 0.842 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4221, ET: 0.1934, TC: 0.1566, WT: 0.9163
[0m
[0;33m2025-05-16 22:53:07,668  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 22:53:07,668  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-16 22:55:24,096  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-16 22:55:24,098  - INFO - - Train mean loss: 0.4904
- ET loss: 0.2819
- TC loss: 0.2470
- WT loss: 0.9422
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 22:55:24,098  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-16 22:55:54,474  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:30.3737s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.588 â”‚ 0.819 â”‚ 0.862 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.528 â”‚ 0.739 â”‚ 0.801 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.589 â”‚ 0.833 â”‚ 0.891 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.83  â”‚ 0.857 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4125, ET: 0.1824, TC: 0.1387, WT: 0.9163
[0m
[1;31m2025-05-16 22:55:54,475  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.4137_dice0.5872_20250516225020.pth[0m
[0;32m2025-05-16 22:55:54,512  - INFO - âœ¨ Saved checkpoint (epoch 18) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch18_loss0.4125_dice0.5882_20250516225554.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 22:55:54,513  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-16 22:58:07,555  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-16 22:58:07,556  - INFO - - Train mean loss: 0.4938
- ET loss: 0.2890
- TC loss: 0.2502
- WT loss: 0.9421
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-16 22:58:07,556  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-16 22:58:39,702  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:32.1445s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.584 â”‚ 0.818 â”‚ 0.852 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.523 â”‚ 0.736 â”‚ 0.787 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.571 â”‚ 0.816 â”‚ 0.851 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.845 â”‚ 0.884 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4164, ET: 0.1837, TC: 0.1492, WT: 0.9163
[0m
[0;33m2025-05-16 22:58:39,702  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 22:58:39,702  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-16 23:00:55,855  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-16 23:00:55,857  - INFO - - Train mean loss: 0.4848
- ET loss: 0.2744
- TC loss: 0.2391
- WT loss: 0.9410
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 23:00:55,857  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-16 23:01:26,614  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:30.7560s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.823 â”‚ 0.863 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.529 â”‚ 0.741 â”‚ 0.802 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.603 â”‚ 0.86  â”‚ 0.904 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.809 â”‚ 0.849 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4108, ET: 0.1781, TC: 0.1380, WT: 0.9163
[0m
[1;31m2025-05-16 23:01:26,617  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch18_loss0.4125_dice0.5882_20250516225554.pth[0m
[0;32m2025-05-16 23:01:26,659  - INFO - âœ¨ Saved checkpoint (epoch 20) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch20_loss0.4108_dice0.5900_20250516230126.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:01:26,659  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-16 23:03:40,839  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-16 23:03:40,840  - INFO - - Train mean loss: 0.4941
- ET loss: 0.2879
- TC loss: 0.2531
- WT loss: 0.9414
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-16 23:03:40,841  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-16 23:04:13,393  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:32.5513s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.825 â”‚ 0.861 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.529 â”‚ 0.746 â”‚ 0.797 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.578 â”‚ 0.826 â”‚ 0.862 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.844 â”‚ 0.885 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4109, ET: 0.1762, TC: 0.1403, WT: 0.9163
[0m
[0;33m2025-05-16 23:04:13,393  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 23:04:13,393  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-16 23:06:29,356  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-16 23:06:29,357  - INFO - - Train mean loss: 0.4825
- ET loss: 0.2728
- TC loss: 0.2333
- WT loss: 0.9414
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 23:06:29,358  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-16 23:07:00,303  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:30.9441s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.591 â”‚ 0.825 â”‚ 0.864 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.529 â”‚ 0.742 â”‚ 0.801 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.586 â”‚ 0.834 â”‚ 0.881 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.837 â”‚ 0.873 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4106, ET: 0.1780, TC: 0.1376, WT: 0.9163
[0m
[1;31m2025-05-16 23:07:00,305  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch20_loss0.4108_dice0.5900_20250516230126.pth[0m
[0;32m2025-05-16 23:07:00,347  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.4106_dice0.5909_20250516230700.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:07:00,348  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-16 23:09:15,333  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-16 23:09:15,335  - INFO - - Train mean loss: 0.4847
- ET loss: 0.2756
- TC loss: 0.2368
- WT loss: 0.9416
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-16 23:09:15,335  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-16 23:09:45,738  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:30.4016s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.584 â”‚ 0.82  â”‚ 0.847 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.522 â”‚ 0.74  â”‚ 0.781 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.56  â”‚ 0.808 â”‚ 0.827 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.921 â”‚ 0.859 â”‚ 0.903 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4171, ET: 0.1808, TC: 0.1542, WT: 0.9163
[0m
[0;33m2025-05-16 23:09:45,738  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 23:09:45,738  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-16 23:12:00,179  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-16 23:12:00,181  - INFO - - Train mean loss: 0.4933
- ET loss: 0.2888
- TC loss: 0.2498
- WT loss: 0.9414
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-16 23:12:00,181  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-16 23:12:30,741  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:30.5591s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.589 â”‚ 0.82  â”‚ 0.862 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.53  â”‚ 0.742 â”‚ 0.803 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.605 â”‚ 0.863 â”‚ 0.908 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.808 â”‚ 0.847 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4119, ET: 0.1812, TC: 0.1383, WT: 0.9163
[0m
[0;33m2025-05-16 23:12:30,741  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 23:12:30,741  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-16 23:14:44,488  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-16 23:14:44,491  - INFO - - Train mean loss: 0.4841
- ET loss: 0.2730
- TC loss: 0.2357
- WT loss: 0.9435
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-16 23:14:44,491  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-16 23:15:15,023  - INFO - === [Epoch 25/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:30.5312s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.824 â”‚ 0.862 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.531 â”‚ 0.745 â”‚ 0.802 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.596 â”‚ 0.854 â”‚ 0.889 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.819 â”‚ 0.865 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4108, ET: 0.1776, TC: 0.1386, WT: 0.9163
[0m
[0;33m2025-05-16 23:15:15,024  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 23:15:15,024  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-16 23:17:31,476  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-16 23:17:31,479  - INFO - - Train mean loss: 0.4894
- ET loss: 0.2828
- TC loss: 0.2441
- WT loss: 0.9413
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-16 23:17:31,479  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-16 23:18:03,002  - INFO - === [Epoch 26/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:31.5213s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.591 â”‚ 0.828 â”‚ 0.862 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.532 â”‚ 0.75  â”‚ 0.8   â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.578 â”‚ 0.826 â”‚ 0.865 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.854 â”‚ 0.89  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4093, ET: 0.1727, TC: 0.1390, WT: 0.9163
[0m
[1;31m2025-05-16 23:18:03,005  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.4106_dice0.5909_20250516230700.pth[0m
[0;32m2025-05-16 23:18:03,051  - INFO - âœ¨ Saved checkpoint (epoch 26) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch26_loss0.4093_dice0.5914_20250516231803.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:18:03,052  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-16 23:20:18,215  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-16 23:20:18,219  - INFO - - Train mean loss: 0.4883
- ET loss: 0.2806
- TC loss: 0.2417
- WT loss: 0.9426
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-16 23:20:18,219  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-16 23:20:49,688  - INFO - === [Epoch 27/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:31.4683s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.593 â”‚ 0.826 â”‚ 0.868 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.532 â”‚ 0.745 â”‚ 0.806 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.574 â”‚ 0.813 â”‚ 0.865 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.923 â”‚ 0.868 â”‚ 0.902 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4081, ET: 0.1751, TC: 0.1328, WT: 0.9163
[0m
[1;31m2025-05-16 23:20:49,690  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch26_loss0.4093_dice0.5914_20250516231803.pth[0m
[0;32m2025-05-16 23:20:49,728  - INFO - âœ¨ Saved checkpoint (epoch 27) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch27_loss0.4081_dice0.5927_20250516232049.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:20:49,728  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-16 23:23:03,828  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-16 23:23:03,830  - INFO - - Train mean loss: 0.4834
- ET loss: 0.2725
- TC loss: 0.2372
- WT loss: 0.9407
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-16 23:23:03,830  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-16 23:23:35,284  - INFO - === [Epoch 28/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:31.4521s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.823 â”‚ 0.864 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.53  â”‚ 0.743 â”‚ 0.802 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.572 â”‚ 0.813 â”‚ 0.86  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.92  â”‚ 0.862 â”‚ 0.899 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4105, ET: 0.1779, TC: 0.1372, WT: 0.9163
[0m
[0;33m2025-05-16 23:23:35,284  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 23:23:35,284  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-16 23:25:50,868  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-16 23:25:50,870  - INFO - - Train mean loss: 0.4745
- ET loss: 0.2616
- TC loss: 0.2189
- WT loss: 0.9429
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 23:25:50,870  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-16 23:26:22,244  - INFO - === [Epoch 29/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:31.3730s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.827 â”‚ 0.858 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.53  â”‚ 0.75  â”‚ 0.795 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.588 â”‚ 0.854 â”‚ 0.866 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.827 â”‚ 0.881 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4110, ET: 0.1735, TC: 0.1432, WT: 0.9163
[0m
[0;33m2025-05-16 23:26:22,244  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 23:26:22,244  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-16 23:28:37,539  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-16 23:28:37,541  - INFO - - Train mean loss: 0.4800
- ET loss: 0.2710
- TC loss: 0.2279
- WT loss: 0.9410
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-16 23:28:37,541  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-16 23:29:08,627  - INFO - === [Epoch 30/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:31.0855s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.593 â”‚ 0.83  â”‚ 0.866 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.535 â”‚ 0.753 â”‚ 0.808 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.586 â”‚ 0.836 â”‚ 0.878 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.908 â”‚ 0.846 â”‚ 0.878 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4075, ET: 0.1716, TC: 0.1347, WT: 0.9163
[0m
[1;31m2025-05-16 23:29:08,629  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch27_loss0.4081_dice0.5927_20250516232049.pth[0m
[0;32m2025-05-16 23:29:08,671  - INFO - âœ¨ Saved checkpoint (epoch 30) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch30_loss0.4075_dice0.5932_20250516232908.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:29:08,671  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-16 23:31:25,821  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-16 23:31:25,823  - INFO - - Train mean loss: 0.4839
- ET loss: 0.2736
- TC loss: 0.2351
- WT loss: 0.9429
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-16 23:31:25,823  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-16 23:31:57,601  - INFO - === [Epoch 31/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:31.7767s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.594 â”‚ 0.827 â”‚ 0.87  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.536 â”‚ 0.749 â”‚ 0.813 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.583 â”‚ 0.829 â”‚ 0.876 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.852 â”‚ 0.888 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4070, ET: 0.1741, TC: 0.1304, WT: 0.9163
[0m
[1;31m2025-05-16 23:31:57,603  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch30_loss0.4075_dice0.5932_20250516232908.pth[0m
[0;32m2025-05-16 23:31:57,644  - INFO - âœ¨ Saved checkpoint (epoch 31) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch31_loss0.4070_dice0.5936_20250516233157.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:31:57,645  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-16 23:34:12,293  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-16 23:34:12,294  - INFO - - Train mean loss: 0.4815
- ET loss: 0.2726
- TC loss: 0.2302
- WT loss: 0.9416
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-16 23:34:12,294  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-16 23:34:43,641  - INFO - === [Epoch 32/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:31.3461s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.593 â”‚ 0.83  â”‚ 0.865 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.534 â”‚ 0.753 â”‚ 0.806 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.598 â”‚ 0.859 â”‚ 0.891 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.823 â”‚ 0.866 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4079, ET: 0.1713, TC: 0.1361, WT: 0.9163
[0m
[0;33m2025-05-16 23:34:43,641  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 23:34:43,641  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-16 23:36:58,210  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-16 23:36:58,211  - INFO - - Train mean loss: 0.4858
- ET loss: 0.2778
- TC loss: 0.2365
- WT loss: 0.9433
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-16 23:36:58,211  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-16 23:37:28,594  - INFO - === [Epoch 33/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:30.3813s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.595 â”‚ 0.829 â”‚ 0.872 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.537 â”‚ 0.753 â”‚ 0.815 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.845 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.842 â”‚ 0.874 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4055, ET: 0.1715, TC: 0.1287, WT: 0.9163
[0m
[1;31m2025-05-16 23:37:28,596  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch31_loss0.4070_dice0.5936_20250516233157.pth[0m
[0;32m2025-05-16 23:37:28,638  - INFO - âœ¨ Saved checkpoint (epoch 33) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch33_loss0.4055_dice0.5949_20250516233728.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:37:28,638  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-16 23:39:42,035  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-16 23:39:42,037  - INFO - - Train mean loss: 0.4760
- ET loss: 0.2611
- TC loss: 0.2245
- WT loss: 0.9426
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-16 23:39:42,037  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-16 23:40:13,452  - INFO - === [Epoch 34/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:31.4135s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.596 â”‚ 0.831 â”‚ 0.874 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.538 â”‚ 0.753 â”‚ 0.817 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.58  â”‚ 0.82  â”‚ 0.877 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.919 â”‚ 0.864 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4042, ET: 0.1695, TC: 0.1268, WT: 0.9163
[0m
[1;31m2025-05-16 23:40:13,455  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch33_loss0.4055_dice0.5949_20250516233728.pth[0m
[0;32m2025-05-16 23:40:13,498  - INFO - âœ¨ Saved checkpoint (epoch 34) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch34_loss0.4042_dice0.5964_20250516234013.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:40:13,498  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-16 23:42:28,827  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-16 23:42:28,828  - INFO - - Train mean loss: 0.4729
- ET loss: 0.2600
- TC loss: 0.2174
- WT loss: 0.9411
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 23:42:28,828  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-16 23:42:59,382  - INFO - === [Epoch 35/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:30.5518s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.596 â”‚ 0.835 â”‚ 0.871 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.538 â”‚ 0.758 â”‚ 0.812 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.859 â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.837 â”‚ 0.882 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4043, ET: 0.1665, TC: 0.1300, WT: 0.9163
[0m
[0;33m2025-05-16 23:42:59,382  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 23:42:59,382  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-16 23:45:16,224  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-16 23:45:16,226  - INFO - - Train mean loss: 0.4646
- ET loss: 0.2478
- TC loss: 0.2051
- WT loss: 0.9409
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-16 23:45:16,226  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-16 23:45:48,101  - INFO - === [Epoch 36/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:31.8737s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.593 â”‚ 0.827 â”‚ 0.867 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.535 â”‚ 0.752 â”‚ 0.81  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.602 â”‚ 0.862 â”‚ 0.901 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.819 â”‚ 0.862 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4077, ET: 0.1738, TC: 0.1332, WT: 0.9163
[0m
[0;33m2025-05-16 23:45:48,102  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 23:45:48,102  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-16 23:48:05,337  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-16 23:48:05,338  - INFO - - Train mean loss: 0.4842
- ET loss: 0.2730
- TC loss: 0.2363
- WT loss: 0.9434
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-16 23:48:05,338  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-16 23:48:36,949  - INFO - === [Epoch 37/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:31.6087s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.598 â”‚ 0.835 â”‚ 0.875 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.54  â”‚ 0.758 â”‚ 0.817 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.587 â”‚ 0.834 â”‚ 0.882 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.919 â”‚ 0.862 â”‚ 0.896 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4026, ET: 0.1660, TC: 0.1256, WT: 0.9163
[0m
[1;31m2025-05-16 23:48:36,951  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch34_loss0.4042_dice0.5964_20250516234013.pth[0m
[0;32m2025-05-16 23:48:36,993  - INFO - âœ¨ Saved checkpoint (epoch 37) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch37_loss0.4026_dice0.5980_20250516234836.pth;             Size 12.35 MB[0m
[0;32m2025-05-16 23:48:36,994  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-16 23:50:54,438  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-16 23:50:54,439  - INFO - - Train mean loss: 0.4757
- ET loss: 0.2642
- TC loss: 0.2218
- WT loss: 0.9410
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-16 23:50:54,439  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-16 23:51:25,456  - INFO - === [Epoch 38/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:31.0160s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.597 â”‚ 0.831 â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.539 â”‚ 0.754 â”‚ 0.819 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.586 â”‚ 0.83  â”‚ 0.884 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.851 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4038, ET: 0.1701, TC: 0.1249, WT: 0.9163
[0m
[0;33m2025-05-16 23:51:25,456  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-16 23:51:25,456  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-16 23:53:40,791  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-16 23:53:40,792  - INFO - - Train mean loss: 0.4882
- ET loss: 0.2822
- TC loss: 0.2392
- WT loss: 0.9433
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-16 23:53:40,792  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-16 23:54:11,647  - INFO - === [Epoch 39/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:30.8548s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.597 â”‚ 0.832 â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.538 â”‚ 0.753 â”‚ 0.817 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.581 â”‚ 0.82  â”‚ 0.877 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.924 â”‚ 0.87  â”‚ 0.903 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4032, ET: 0.1690, TC: 0.1244, WT: 0.9163
[0m
[0;33m2025-05-16 23:54:11,648  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-16 23:54:11,648  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-16 23:56:25,743  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-16 23:56:25,744  - INFO - - Train mean loss: 0.4620
- ET loss: 0.2428
- TC loss: 0.2025
- WT loss: 0.9406
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-16 23:56:25,745  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-16 23:56:56,765  - INFO - === [Epoch 40/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:31.0197s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.59  â”‚ 0.826 â”‚ 0.861 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.53  â”‚ 0.747 â”‚ 0.798 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.572 â”‚ 0.817 â”‚ 0.854 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.92  â”‚ 0.861 â”‚ 0.9   â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4104, ET: 0.1750, TC: 0.1399, WT: 0.9163
[0m
[0;33m2025-05-16 23:56:56,765  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-16 23:56:56,765  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-16 23:59:14,585  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-16 23:59:14,586  - INFO - - Train mean loss: 0.4783
- ET loss: 0.2677
- TC loss: 0.2254
- WT loss: 0.9417
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-16 23:59:14,587  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-16 23:59:46,269  - INFO - === [Epoch 41/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:31.6813s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.592 â”‚ 0.828 â”‚ 0.865 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.534 â”‚ 0.752 â”‚ 0.807 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.589 â”‚ 0.843 â”‚ 0.879 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.844 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4080, ET: 0.1727, TC: 0.1351, WT: 0.9163
[0m
[0;33m2025-05-16 23:59:46,269  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-16 23:59:46,269  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-17 00:02:00,435  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-17 00:02:00,436  - INFO - - Train mean loss: 0.4829
- ET loss: 0.2721
- TC loss: 0.2318
- WT loss: 0.9447
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 00:02:00,436  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-17 00:02:32,056  - INFO - === [Epoch 42/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:31.6195s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.594 â”‚ 0.832 â”‚ 0.867 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.535 â”‚ 0.755 â”‚ 0.807 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.579 â”‚ 0.827 â”‚ 0.866 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.92  â”‚ 0.862 â”‚ 0.899 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4063, ET: 0.1689, TC: 0.1336, WT: 0.9163
[0m
[0;33m2025-05-17 00:02:32,057  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 00:02:32,057  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-17 00:04:47,002  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-17 00:04:47,003  - INFO - - Train mean loss: 0.4792
- ET loss: 0.2675
- TC loss: 0.2265
- WT loss: 0.9435
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 00:04:47,003  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-17 00:05:18,691  - INFO - === [Epoch 43/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:31.6868s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.597 â”‚ 0.834 â”‚ 0.875 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.54  â”‚ 0.758 â”‚ 0.818 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.582 â”‚ 0.826 â”‚ 0.876 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.92  â”‚ 0.862 â”‚ 0.898 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4030, ET: 0.1671, TC: 0.1257, WT: 0.9163
[0m
[0;33m2025-05-17 00:05:18,691  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 00:05:18,691  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-17 00:07:35,721  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-17 00:07:35,722  - INFO - - Train mean loss: 0.4676
- ET loss: 0.2517
- TC loss: 0.2095
- WT loss: 0.9417
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 00:07:35,722  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-17 00:08:07,469  - INFO - === [Epoch 44/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:31.7460s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.836 â”‚ 0.877 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.762 â”‚ 0.822 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.842 â”‚ 0.899 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.907 â”‚ 0.848 â”‚ 0.874 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4015, ET: 0.1647, TC: 0.1233, WT: 0.9163
[0m
[1;31m2025-05-17 00:08:07,471  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch37_loss0.4026_dice0.5980_20250516234836.pth[0m
[0;32m2025-05-17 00:08:07,506  - INFO - âœ¨ Saved checkpoint (epoch 44) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch44_loss0.4015_dice0.5989_20250517000807.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 00:08:07,506  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-17 00:10:23,998  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-17 00:10:24,000  - INFO - - Train mean loss: 0.4707
- ET loss: 0.2554
- TC loss: 0.2139
- WT loss: 0.9428
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 00:10:24,000  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-17 00:10:55,487  - INFO - === [Epoch 45/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:31.4860s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.598 â”‚ 0.835 â”‚ 0.875 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.541 â”‚ 0.759 â”‚ 0.819 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.856 â”‚ 0.9   â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.838 â”‚ 0.876 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4027, ET: 0.1662, TC: 0.1255, WT: 0.9163
[0m
[0;33m2025-05-17 00:10:55,487  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 00:10:55,487  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-17 00:13:13,598  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-17 00:13:13,600  - INFO - - Train mean loss: 0.4733
- ET loss: 0.2618
- TC loss: 0.2169
- WT loss: 0.9413
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 00:13:13,600  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-17 00:13:45,123  - INFO - === [Epoch 46/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:31.5223s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.595 â”‚ 0.833 â”‚ 0.869 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.536 â”‚ 0.754 â”‚ 0.808 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.573 â”‚ 0.815 â”‚ 0.859 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.926 â”‚ 0.872 â”‚ 0.907 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4053, ET: 0.1684, TC: 0.1313, WT: 0.9163
[0m
[0;33m2025-05-17 00:13:45,123  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 00:13:45,123  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-17 00:16:01,757  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-17 00:16:01,758  - INFO - - Train mean loss: 0.4793
- ET loss: 0.2677
- TC loss: 0.2267
- WT loss: 0.9435
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 00:16:01,758  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-17 00:16:33,932  - INFO - === [Epoch 47/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:32.1731s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.597 â”‚ 0.835 â”‚ 0.871 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.539 â”‚ 0.759 â”‚ 0.813 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.604 â”‚ 0.867 â”‚ 0.901 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.829 â”‚ 0.872 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4038, ET: 0.1658, TC: 0.1292, WT: 0.9163
[0m
[0;33m2025-05-17 00:16:33,933  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 00:16:33,933  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-17 00:18:49,588  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-17 00:18:49,589  - INFO - - Train mean loss: 0.4672
- ET loss: 0.2519
- TC loss: 0.2100
- WT loss: 0.9398
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 00:18:49,589  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-17 00:19:20,582  - INFO - === [Epoch 48/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:30.9917s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.598 â”‚ 0.834 â”‚ 0.875 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.54  â”‚ 0.758 â”‚ 0.818 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.602 â”‚ 0.86  â”‚ 0.901 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.831 â”‚ 0.871 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4029, ET: 0.1673, TC: 0.1252, WT: 0.9163
[0m
[0;33m2025-05-17 00:19:20,582  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 00:19:20,582  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-17 00:21:38,278  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-17 00:21:38,279  - INFO - - Train mean loss: 0.4691
- ET loss: 0.2558
- TC loss: 0.2095
- WT loss: 0.9420
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 00:21:38,279  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-17 00:22:09,728  - INFO - === [Epoch 49/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:31.4475s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.836 â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.762 â”‚ 0.821 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.605 â”‚ 0.865 â”‚ 0.906 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.832 â”‚ 0.873 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4020, ET: 0.1650, TC: 0.1247, WT: 0.9163
[0m
[0;33m2025-05-17 00:22:09,728  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 00:22:09,728  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-17 00:24:26,882  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-17 00:24:26,883  - INFO - - Train mean loss: 0.4755
- ET loss: 0.2653
- TC loss: 0.2192
- WT loss: 0.9419
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 00:24:26,884  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-17 00:24:58,303  - INFO - === [Epoch 50/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:31.4181s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.834 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.761 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.604 â”‚ 0.86  â”‚ 0.908 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.833 â”‚ 0.871 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4017, ET: 0.1666, TC: 0.1221, WT: 0.9163
[0m
[0;33m2025-05-17 00:24:58,303  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 00:24:58,303  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-17 00:27:12,727  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-17 00:27:12,728  - INFO - - Train mean loss: 0.4715
- ET loss: 0.2581
- TC loss: 0.2146
- WT loss: 0.9420
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 00:27:12,728  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-17 00:27:44,426  - INFO - === [Epoch 51/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:31.6966s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.841 â”‚ 0.881 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.766 â”‚ 0.826 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.842 â”‚ 0.895 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.86  â”‚ 0.889 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3989, ET: 0.1603, TC: 0.1200, WT: 0.9163
[0m
[1;31m2025-05-17 00:27:44,428  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch44_loss0.4015_dice0.5989_20250517000807.pth[0m
[0;32m2025-05-17 00:27:44,466  - INFO - âœ¨ Saved checkpoint (epoch 51) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch51_loss0.3989_dice0.6016_20250517002744.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 00:27:44,467  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-17 00:29:57,607  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-17 00:29:57,608  - INFO - - Train mean loss: 0.4820
- ET loss: 0.2690
- TC loss: 0.2336
- WT loss: 0.9434
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 00:29:57,608  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-17 00:30:30,221  - INFO - === [Epoch 52/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:32.6112s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.598 â”‚ 0.835 â”‚ 0.875 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.541 â”‚ 0.761 â”‚ 0.819 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.856 â”‚ 0.9   â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.836 â”‚ 0.873 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4024, ET: 0.1654, TC: 0.1253, WT: 0.9163
[0m
[0;33m2025-05-17 00:30:30,222  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 00:30:30,222  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-17 00:32:47,407  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-17 00:32:47,409  - INFO - - Train mean loss: 0.4684
- ET loss: 0.2526
- TC loss: 0.2105
- WT loss: 0.9420
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 00:32:47,409  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-17 00:33:19,933  - INFO - === [Epoch 53/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:32.5223s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.839 â”‚ 0.873 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.541 â”‚ 0.765 â”‚ 0.815 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.853 â”‚ 0.884 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.846 â”‚ 0.884 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4020, ET: 0.1616, TC: 0.1280, WT: 0.9163
[0m
[0;33m2025-05-17 00:33:19,933  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 00:33:19,933  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-17 00:35:35,395  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-17 00:35:35,398  - INFO - - Train mean loss: 0.4651
- ET loss: 0.2500
- TC loss: 0.2036
- WT loss: 0.9419
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 00:35:35,398  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-17 00:36:05,473  - INFO - === [Epoch 54/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:30.0733s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.838 â”‚ 0.875 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.542 â”‚ 0.763 â”‚ 0.818 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.591 â”‚ 0.846 â”‚ 0.883 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.851 â”‚ 0.894 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4014, ET: 0.1628, TC: 0.1251, WT: 0.9163
[0m
[0;33m2025-05-17 00:36:05,473  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 00:36:05,473  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-17 00:38:20,898  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-17 00:38:20,899  - INFO - - Train mean loss: 0.4685
- ET loss: 0.2533
- TC loss: 0.2112
- WT loss: 0.9410
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 00:38:20,899  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-17 00:38:52,886  - INFO - === [Epoch 55/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:31.9851s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.841 â”‚ 0.881 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.766 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.593 â”‚ 0.844 â”‚ 0.891 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.917 â”‚ 0.857 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3987, ET: 0.1599, TC: 0.1198, WT: 0.9163
[0m
[1;31m2025-05-17 00:38:52,888  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch51_loss0.3989_dice0.6016_20250517002744.pth[0m
[0;32m2025-05-17 00:38:52,923  - INFO - âœ¨ Saved checkpoint (epoch 55) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch55_loss0.3987_dice0.6019_20250517003852.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 00:38:52,924  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-17 00:41:09,296  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-17 00:41:09,298  - INFO - - Train mean loss: 0.4678
- ET loss: 0.2537
- TC loss: 0.2082
- WT loss: 0.9416
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 00:41:09,298  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-17 00:41:40,435  - INFO - === [Epoch 56/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:31.1360s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.6   â”‚ 0.84  â”‚ 0.877 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.764 â”‚ 0.82  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.593 â”‚ 0.844 â”‚ 0.889 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.917 â”‚ 0.858 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4003, ET: 0.1614, TC: 0.1232, WT: 0.9163
[0m
[0;33m2025-05-17 00:41:40,435  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 00:41:40,435  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-17 00:43:55,614  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-17 00:43:55,615  - INFO - - Train mean loss: 0.4699
- ET loss: 0.2572
- TC loss: 0.2111
- WT loss: 0.9415
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 00:43:55,616  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-17 00:44:26,737  - INFO - === [Epoch 57/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:31.1204s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.596 â”‚ 0.836 â”‚ 0.87  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.54  â”‚ 0.763 â”‚ 0.813 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.588 â”‚ 0.842 â”‚ 0.879 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.855 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4040, ET: 0.1647, TC: 0.1309, WT: 0.9163
[0m
[0;33m2025-05-17 00:44:26,737  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 00:44:26,737  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-17 00:46:45,957  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-17 00:46:45,958  - INFO - - Train mean loss: 0.4650
- ET loss: 0.2475
- TC loss: 0.2045
- WT loss: 0.9431
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 00:46:45,958  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-17 00:47:18,041  - INFO - === [Epoch 58/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:32.0815s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.6   â”‚ 0.84  â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.765 â”‚ 0.82  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.592 â”‚ 0.842 â”‚ 0.888 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.918 â”‚ 0.861 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4006, ET: 0.1608, TC: 0.1247, WT: 0.9163
[0m
[0;33m2025-05-17 00:47:18,041  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 00:47:18,041  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-17 00:49:34,103  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-17 00:49:34,104  - INFO - - Train mean loss: 0.4722
- ET loss: 0.2592
- TC loss: 0.2146
- WT loss: 0.9429
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 00:49:34,104  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-17 00:50:05,334  - INFO - === [Epoch 59/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:31.2289s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.841 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.767 â”‚ 0.821 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.596 â”‚ 0.853 â”‚ 0.891 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.856 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3995, ET: 0.1598, TC: 0.1223, WT: 0.9163
[0m
[0;33m2025-05-17 00:50:05,334  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 00:50:05,334  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-17 00:52:22,737  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-17 00:52:22,738  - INFO - - Train mean loss: 0.4669
- ET loss: 0.2520
- TC loss: 0.2059
- WT loss: 0.9428
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 00:52:22,738  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-17 00:52:54,215  - INFO - === [Epoch 60/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:31.4759s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.845 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.77  â”‚ 0.822 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.851 â”‚ 0.888 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.919 â”‚ 0.859 â”‚ 0.897 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3979, ET: 0.1562, TC: 0.1213, WT: 0.9163
[0m
[1;31m2025-05-17 00:52:54,217  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch55_loss0.3987_dice0.6019_20250517003852.pth[0m
[0;32m2025-05-17 00:52:54,252  - INFO - âœ¨ Saved checkpoint (epoch 60) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch60_loss0.3979_dice0.6026_20250517005254.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 00:52:54,253  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-17 00:55:11,121  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-17 00:55:11,122  - INFO - - Train mean loss: 0.4754
- ET loss: 0.2640
- TC loss: 0.2184
- WT loss: 0.9437
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 00:55:11,122  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-17 00:55:42,256  - INFO - === [Epoch 61/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:31.1323s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.839 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.764 â”‚ 0.823 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.843 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.918 â”‚ 0.861 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3998, ET: 0.1619, TC: 0.1212, WT: 0.9163
[0m
[0;33m2025-05-17 00:55:42,256  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 00:55:42,256  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-17 00:57:56,657  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-17 00:57:56,658  - INFO - - Train mean loss: 0.4602
- ET loss: 0.2426
- TC loss: 0.1971
- WT loss: 0.9408
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 00:57:56,658  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-17 00:58:28,239  - INFO - === [Epoch 62/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:31.5794s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.841 â”‚ 0.882 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.765 â”‚ 0.826 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.591 â”‚ 0.835 â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.919 â”‚ 0.866 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3982, ET: 0.1598, TC: 0.1185, WT: 0.9163
[0m
[0;33m2025-05-17 00:58:28,239  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 00:58:28,239  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-17 01:00:43,236  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-17 01:00:43,237  - INFO - - Train mean loss: 0.4687
- ET loss: 0.2560
- TC loss: 0.2093
- WT loss: 0.9408
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 01:00:43,237  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-17 01:01:14,645  - INFO - === [Epoch 63/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:31.4070s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.842 â”‚ 0.881 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.767 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.847 â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.856 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3985, ET: 0.1592, TC: 0.1199, WT: 0.9163
[0m
[0;33m2025-05-17 01:01:14,645  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 01:01:14,645  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-17 01:03:28,038  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-17 01:03:28,039  - INFO - - Train mean loss: 0.4683
- ET loss: 0.2542
- TC loss: 0.2073
- WT loss: 0.9436
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 01:03:28,039  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-17 01:04:00,187  - INFO - === [Epoch 64/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:32.1465s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.841 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.767 â”‚ 0.822 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.855 â”‚ 0.902 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.914 â”‚ 0.854 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3997, ET: 0.1600, TC: 0.1229, WT: 0.9163
[0m
[0;33m2025-05-17 01:04:00,187  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 01:04:00,187  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-17 01:06:17,238  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-17 01:06:17,239  - INFO - - Train mean loss: 0.4610
- ET loss: 0.2421
- TC loss: 0.1997
- WT loss: 0.9411
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 01:06:17,239  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-17 01:06:49,534  - INFO - === [Epoch 65/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:32.2940s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.841 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.768 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.855 â”‚ 0.898 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.851 â”‚ 0.886 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3990, ET: 0.1594, TC: 0.1212, WT: 0.9163
[0m
[0;33m2025-05-17 01:06:49,534  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 01:06:49,534  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-17 01:09:06,665  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-17 01:09:06,666  - INFO - - Train mean loss: 0.4727
- ET loss: 0.2597
- TC loss: 0.2157
- WT loss: 0.9427
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 01:09:06,666  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-17 01:09:38,460  - INFO - === [Epoch 66/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:31.7923s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.842 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.768 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.847 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.919 â”‚ 0.862 â”‚ 0.895 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3984, ET: 0.1583, TC: 0.1206, WT: 0.9163
[0m
[0;33m2025-05-17 01:09:38,460  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 01:09:38,460  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-17 01:11:55,569  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-17 01:11:55,571  - INFO - - Train mean loss: 0.4680
- ET loss: 0.2532
- TC loss: 0.2093
- WT loss: 0.9416
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 01:11:55,571  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-17 01:12:27,147  - INFO - === [Epoch 67/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:31.5751s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.843 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.769 â”‚ 0.823 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.597 â”‚ 0.855 â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.855 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3986, ET: 0.1578, TC: 0.1218, WT: 0.9163
[0m
[0;33m2025-05-17 01:12:27,147  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 01:12:27,147  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-17 01:14:44,333  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-17 01:14:44,335  - INFO - - Train mean loss: 0.4594
- ET loss: 0.2400
- TC loss: 0.1965
- WT loss: 0.9417
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 01:14:44,335  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-17 01:15:16,419  - INFO - === [Epoch 68/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:32.0838s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.839 â”‚ 0.881 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.766 â”‚ 0.827 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.602 â”‚ 0.858 â”‚ 0.904 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.848 â”‚ 0.882 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3990, ET: 0.1614, TC: 0.1194, WT: 0.9163
[0m
[0;33m2025-05-17 01:15:16,420  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-17 01:15:16,420  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-17 01:17:31,773  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-17 01:17:31,774  - INFO - - Train mean loss: 0.4749
- ET loss: 0.2629
- TC loss: 0.2187
- WT loss: 0.9432
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 01:17:31,774  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-17 01:18:03,542  - INFO - === [Epoch 69/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:31.7666s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.843 â”‚ 0.872 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.769 â”‚ 0.814 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.863 â”‚ 0.89  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.846 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4010, ET: 0.1580, TC: 0.1287, WT: 0.9163
[0m
[0;33m2025-05-17 01:18:03,542  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-17 01:18:03,542  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-17 01:20:21,575  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-17 01:20:21,576  - INFO - - Train mean loss: 0.4654
- ET loss: 0.2507
- TC loss: 0.2041
- WT loss: 0.9415
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 01:20:21,576  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-17 01:20:53,421  - INFO - === [Epoch 70/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:31.8434s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.845 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.771 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.602 â”‚ 0.865 â”‚ 0.896 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.847 â”‚ 0.89  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3976, ET: 0.1560, TC: 0.1206, WT: 0.9163
[0m
[1;31m2025-05-17 01:20:53,423  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch60_loss0.3979_dice0.6026_20250517005254.pth[0m
[0;32m2025-05-17 01:20:53,465  - INFO - âœ¨ Saved checkpoint (epoch 70) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch70_loss0.3976_dice0.6028_20250517012053.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 01:20:53,465  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-17 01:23:09,992  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-17 01:23:09,993  - INFO - - Train mean loss: 0.4692
- ET loss: 0.2564
- TC loss: 0.2089
- WT loss: 0.9424
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 01:23:09,993  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-17 01:23:41,491  - INFO - === [Epoch 71/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:31.4966s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.843 â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.769 â”‚ 0.82  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.593 â”‚ 0.851 â”‚ 0.885 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.853 â”‚ 0.896 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3995, ET: 0.1582, TC: 0.1242, WT: 0.9163
[0m
[0;33m2025-05-17 01:23:41,491  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 01:23:41,491  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-17 01:26:01,150  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-17 01:26:01,151  - INFO - - Train mean loss: 0.4703
- ET loss: 0.2576
- TC loss: 0.2105
- WT loss: 0.9429
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 01:26:01,152  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-17 01:26:33,825  - INFO - === [Epoch 72/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:32.6724s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.839 â”‚ 0.874 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.766 â”‚ 0.819 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.862 â”‚ 0.893 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.907 â”‚ 0.839 â”‚ 0.882 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4014, ET: 0.1615, TC: 0.1262, WT: 0.9163
[0m
[0;33m2025-05-17 01:26:33,826  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 01:26:33,826  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-17 01:28:54,502  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-17 01:28:54,503  - INFO - - Train mean loss: 0.4630
- ET loss: 0.2458
- TC loss: 0.1993
- WT loss: 0.9440
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-17 01:28:54,503  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-17 01:29:26,076  - INFO - === [Epoch 73/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:31.5713s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.6   â”‚ 0.841 â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.768 â”‚ 0.821 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.597 â”‚ 0.856 â”‚ 0.891 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.911 â”‚ 0.848 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4002, ET: 0.1597, TC: 0.1247, WT: 0.9163
[0m
[0;33m2025-05-17 01:29:26,077  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 01:29:26,077  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-17 01:31:42,160  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-17 01:31:42,162  - INFO - - Train mean loss: 0.4673
- ET loss: 0.2517
- TC loss: 0.2094
- WT loss: 0.9410
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 01:31:42,162  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-17 01:32:13,680  - INFO - === [Epoch 74/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:31.5174s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.599 â”‚ 0.839 â”‚ 0.873 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.543 â”‚ 0.766 â”‚ 0.818 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.85  â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.849 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4018, ET: 0.1620, TC: 0.1271, WT: 0.9163
[0m
[0;33m2025-05-17 01:32:13,680  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 01:32:13,680  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-17 01:34:26,814  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-17 01:34:26,815  - INFO - - Train mean loss: 0.4625
- ET loss: 0.2453
- TC loss: 0.1992
- WT loss: 0.9430
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 01:34:26,816  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-17 01:34:57,462  - INFO - === [Epoch 75/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:30.6455s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.841 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.766 â”‚ 0.822 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.584 â”‚ 0.828 â”‚ 0.878 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.926 â”‚ 0.874 â”‚ 0.905 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3994, ET: 0.1598, TC: 0.1221, WT: 0.9163
[0m
[0;33m2025-05-17 01:34:57,462  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 01:34:57,462  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-17 01:37:10,449  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-17 01:37:10,451  - INFO - - Train mean loss: 0.4728
- ET loss: 0.2599
- TC loss: 0.2143
- WT loss: 0.9442
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 01:37:10,451  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-17 01:37:41,087  - INFO - === [Epoch 76/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:30.6350s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.842 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.769 â”‚ 0.823 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.849 â”‚ 0.89  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.855 â”‚ 0.894 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3990, ET: 0.1585, TC: 0.1221, WT: 0.9163
[0m
[0;33m2025-05-17 01:37:41,087  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 01:37:41,087  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-17 01:39:57,833  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-17 01:39:57,834  - INFO - - Train mean loss: 0.4581
- ET loss: 0.2399
- TC loss: 0.1931
- WT loss: 0.9414
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 01:39:57,834  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-17 01:40:29,147  - INFO - === [Epoch 77/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:31.3116s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.842 â”‚ 0.876 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.769 â”‚ 0.821 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.596 â”‚ 0.85  â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.914 â”‚ 0.855 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3996, ET: 0.1586, TC: 0.1239, WT: 0.9163
[0m
[0;33m2025-05-17 01:40:29,147  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 01:40:29,147  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-17 01:42:43,920  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-17 01:42:43,922  - INFO - - Train mean loss: 0.4628
- ET loss: 0.2463
- TC loss: 0.2005
- WT loss: 0.9417
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 01:42:43,922  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-17 01:43:14,683  - INFO - === [Epoch 78/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:30.7601s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.841 â”‚ 0.881 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.769 â”‚ 0.828 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.601 â”‚ 0.856 â”‚ 0.903 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.911 â”‚ 0.851 â”‚ 0.883 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3984, ET: 0.1595, TC: 0.1193, WT: 0.9163
[0m
[0;33m2025-05-17 01:43:14,684  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-17 01:43:14,684  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-17 01:45:31,418  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-17 01:45:31,420  - INFO - - Train mean loss: 0.4593
- ET loss: 0.2408
- TC loss: 0.1936
- WT loss: 0.9435
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 01:45:31,420  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-17 01:46:01,967  - INFO - === [Epoch 79/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:30.5467s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.771 â”‚ 0.822 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.597 â”‚ 0.853 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.914 â”‚ 0.854 â”‚ 0.889 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3987, ET: 0.1570, TC: 0.1228, WT: 0.9163
[0m
[0;33m2025-05-17 01:46:01,968  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-17 01:46:01,968  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-17 01:48:16,280  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-17 01:48:16,282  - INFO - - Train mean loss: 0.4652
- ET loss: 0.2501
- TC loss: 0.2045
- WT loss: 0.9409
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 01:48:16,282  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-17 01:48:46,880  - INFO - === [Epoch 80/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:30.5973s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.601 â”‚ 0.843 â”‚ 0.877 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.77  â”‚ 0.821 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.847 â”‚ 0.89  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.917 â”‚ 0.859 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3992, ET: 0.1577, TC: 0.1236, WT: 0.9163
[0m
[0;33m2025-05-17 01:48:46,880  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-17 01:48:46,881  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-17 01:51:04,701  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-17 01:51:04,703  - INFO - - Train mean loss: 0.4620
- ET loss: 0.2439
- TC loss: 0.2002
- WT loss: 0.9419
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 01:51:04,703  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-17 01:51:35,056  - INFO - === [Epoch 81/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:30.3521s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.771 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.603 â”‚ 0.861 â”‚ 0.902 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.85  â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3981, ET: 0.1567, TC: 0.1211, WT: 0.9163
[0m
[0;33m2025-05-17 01:51:35,056  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-17 01:51:35,056  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-17 01:53:50,312  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-17 01:53:50,314  - INFO - - Train mean loss: 0.4605
- ET loss: 0.2430
- TC loss: 0.1952
- WT loss: 0.9431
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 01:53:50,314  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-17 01:54:20,182  - INFO - === [Epoch 82/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:29.8670s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.844 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.771 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.86  â”‚ 0.897 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.853 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3977, ET: 0.1562, TC: 0.1206, WT: 0.9163
[0m
[0;33m2025-05-17 01:54:20,183  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[0;32m2025-05-17 01:54:20,183  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-17 01:56:35,084  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-17 01:56:35,086  - INFO - - Train mean loss: 0.4603
- ET loss: 0.2435
- TC loss: 0.1962
- WT loss: 0.9412
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 01:56:35,086  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-17 01:57:06,642  - INFO - === [Epoch 83/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:31.5550s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.604 â”‚ 0.844 â”‚ 0.884 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.548 â”‚ 0.77  â”‚ 0.829 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.847 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.918 â”‚ 0.861 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3968, ET: 0.1572, TC: 0.1170, WT: 0.9163
[0m
[1;31m2025-05-17 01:57:06,644  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch70_loss0.3976_dice0.6028_20250517012053.pth[0m
[0;32m2025-05-17 01:57:06,684  - INFO - âœ¨ Saved checkpoint (epoch 83) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch83_loss0.3968_dice0.6037_20250517015706.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 01:57:06,684  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-17 01:59:23,974  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-17 01:59:23,975  - INFO - - Train mean loss: 0.4653
- ET loss: 0.2513
- TC loss: 0.2032
- WT loss: 0.9413
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 01:59:23,975  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-17 01:59:54,776  - INFO - === [Epoch 84/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:30.7993s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.843 â”‚ 0.878 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.77  â”‚ 0.823 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.863 â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.911 â”‚ 0.845 â”‚ 0.889 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3988, ET: 0.1578, TC: 0.1223, WT: 0.9163
[0m
[0;33m2025-05-17 01:59:54,776  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 01:59:54,776  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-17 02:02:09,623  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-17 02:02:09,624  - INFO - - Train mean loss: 0.4592
- ET loss: 0.2423
- TC loss: 0.1949
- WT loss: 0.9404
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 02:02:09,625  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-17 02:02:40,580  - INFO - === [Epoch 85/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:30.9544s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.604 â”‚ 0.845 â”‚ 0.882 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.548 â”‚ 0.772 â”‚ 0.828 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.856 â”‚ 0.896 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.854 â”‚ 0.89  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3967, ET: 0.1557, TC: 0.1181, WT: 0.9163
[0m
[1;31m2025-05-17 02:02:40,582  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch83_loss0.3968_dice0.6037_20250517015706.pth[0m
[0;32m2025-05-17 02:02:40,624  - INFO - âœ¨ Saved checkpoint (epoch 85) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch85_loss0.3967_dice0.6038_20250517020240.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 02:02:40,624  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-17 02:04:57,030  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-17 02:04:57,031  - INFO - - Train mean loss: 0.4579
- ET loss: 0.2422
- TC loss: 0.1900
- WT loss: 0.9415
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 02:04:57,031  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-17 02:05:28,190  - INFO - === [Epoch 86/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:31.1581s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.604 â”‚ 0.846 â”‚ 0.883 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.549 â”‚ 0.774 â”‚ 0.829 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.858 â”‚ 0.896 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.853 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3962, ET: 0.1547, TC: 0.1177, WT: 0.9163
[0m
[1;31m2025-05-17 02:05:28,191  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch85_loss0.3967_dice0.6038_20250517020240.pth[0m
[0;32m2025-05-17 02:05:28,564  - INFO - âœ¨ Saved checkpoint (epoch 86) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch86_loss0.3962_dice0.6043_20250517020528.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 02:05:28,565  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-17 02:07:41,759  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-17 02:07:41,761  - INFO - - Train mean loss: 0.4706
- ET loss: 0.2592
- TC loss: 0.2100
- WT loss: 0.9426
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 02:07:41,761  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-17 02:08:13,083  - INFO - === [Epoch 87/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:31.3210s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.772 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.858 â”‚ 0.895 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.856 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3981, ET: 0.1564, TC: 0.1215, WT: 0.9163
[0m
[0;33m2025-05-17 02:08:13,083  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 02:08:13,083  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-17 02:10:26,980  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-17 02:10:26,982  - INFO - - Train mean loss: 0.4585
- ET loss: 0.2407
- TC loss: 0.1930
- WT loss: 0.9416
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 02:10:26,982  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-17 02:10:57,830  - INFO - === [Epoch 88/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:30.8473s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.846 â”‚ 0.881 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.772 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.595 â”‚ 0.851 â”‚ 0.89  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.92  â”‚ 0.863 â”‚ 0.898 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3971, ET: 0.1552, TC: 0.1199, WT: 0.9163
[0m
[0;33m2025-05-17 02:10:57,830  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 02:10:57,830  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-17 02:13:15,905  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-17 02:13:15,906  - INFO - - Train mean loss: 0.4544
- ET loss: 0.2359
- TC loss: 0.1854
- WT loss: 0.9418
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 02:13:15,906  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-17 02:13:46,775  - INFO - === [Epoch 89/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:30.8680s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.846 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.773 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.859 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.855 â”‚ 0.893 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3973, ET: 0.1549, TC: 0.1208, WT: 0.9163
[0m
[0;33m2025-05-17 02:13:46,776  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 02:13:46,776  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-17 02:16:04,114  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-17 02:16:04,115  - INFO - - Train mean loss: 0.4810
- ET loss: 0.2727
- TC loss: 0.2266
- WT loss: 0.9436
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 02:16:04,115  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-17 02:16:34,365  - INFO - === [Epoch 90/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:30.2490s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.604 â”‚ 0.846 â”‚ 0.883 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.549 â”‚ 0.773 â”‚ 0.829 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.601 â”‚ 0.86  â”‚ 0.899 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.852 â”‚ 0.889 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3962, ET: 0.1550, TC: 0.1173, WT: 0.9163
[0m
[1;31m2025-05-17 02:16:34,368  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch86_loss0.3962_dice0.6043_20250517020528.pth[0m
[0;32m2025-05-17 02:16:34,410  - INFO - âœ¨ Saved checkpoint (epoch 90) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch90_loss0.3962_dice0.6042_20250517021634.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 02:16:34,410  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-17 02:18:50,062  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-17 02:18:50,064  - INFO - - Train mean loss: 0.4650
- ET loss: 0.2505
- TC loss: 0.2013
- WT loss: 0.9432
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 02:18:50,064  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-17 02:19:22,376  - INFO - === [Epoch 91/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:32.3106s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.845 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.773 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.601 â”‚ 0.861 â”‚ 0.896 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.853 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3974, ET: 0.1557, TC: 0.1202, WT: 0.9163
[0m
[0;33m2025-05-17 02:19:22,376  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 02:19:22,377  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-17 02:21:39,841  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-17 02:21:39,845  - INFO - - Train mean loss: 0.4589
- ET loss: 0.2410
- TC loss: 0.1911
- WT loss: 0.9446
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 02:21:39,845  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-17 02:22:12,221  - INFO - === [Epoch 92/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:32.3742s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.843 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.771 â”‚ 0.826 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.601 â”‚ 0.861 â”‚ 0.896 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.911 â”‚ 0.847 â”‚ 0.887 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3982, ET: 0.1579, TC: 0.1203, WT: 0.9163
[0m
[0;33m2025-05-17 02:22:12,221  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 02:22:12,221  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-17 02:24:30,505  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-17 02:24:30,507  - INFO - - Train mean loss: 0.4681
- ET loss: 0.2543
- TC loss: 0.2085
- WT loss: 0.9414
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 02:24:30,507  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-17 02:25:02,481  - INFO - === [Epoch 93/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:31.9729s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.845 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.772 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.597 â”‚ 0.856 â”‚ 0.892 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.853 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3978, ET: 0.1562, TC: 0.1208, WT: 0.9163
[0m
[0;33m2025-05-17 02:25:02,482  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 02:25:02,482  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-17 02:27:18,259  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-17 02:27:18,260  - INFO - - Train mean loss: 0.4625
- ET loss: 0.2456
- TC loss: 0.2008
- WT loss: 0.9411
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 02:27:18,260  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-17 02:27:49,436  - INFO - === [Epoch 94/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:31.1739s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.844 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.771 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.598 â”‚ 0.856 â”‚ 0.893 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.914 â”‚ 0.853 â”‚ 0.89  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3979, ET: 0.1569, TC: 0.1206, WT: 0.9163
[0m
[0;33m2025-05-17 02:27:49,437  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 02:27:49,437  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-17 02:30:06,097  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-17 02:30:06,099  - INFO - - Train mean loss: 0.4560
- ET loss: 0.2383
- TC loss: 0.1892
- WT loss: 0.9405
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 02:30:06,099  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-17 02:30:37,408  - INFO - === [Epoch 95/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:31.3075s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.771 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.596 â”‚ 0.852 â”‚ 0.89  â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.916 â”‚ 0.856 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3981, ET: 0.1569, TC: 0.1210, WT: 0.9163
[0m
[0;33m2025-05-17 02:30:37,408  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 02:30:37,408  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-17 02:32:53,286  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-17 02:32:53,287  - INFO - - Train mean loss: 0.4707
- ET loss: 0.2587
- TC loss: 0.2120
- WT loss: 0.9414
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 02:32:53,287  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-17 02:33:24,094  - INFO - === [Epoch 96/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:30.8057s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.844 â”‚ 0.88  â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.772 â”‚ 0.825 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.858 â”‚ 0.894 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.851 â”‚ 0.889 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3978, ET: 0.1568, TC: 0.1204, WT: 0.9163
[0m
[0;33m2025-05-17 02:33:24,094  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 02:33:24,094  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-17 02:35:38,321  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-17 02:35:38,322  - INFO - - Train mean loss: 0.4580
- ET loss: 0.2403
- TC loss: 0.1916
- WT loss: 0.9421
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 02:35:38,322  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-17 02:36:08,508  - INFO - === [Epoch 97/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:30.1850s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.771 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.596 â”‚ 0.853 â”‚ 0.891 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.855 â”‚ 0.891 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3984, ET: 0.1572, TC: 0.1216, WT: 0.9163
[0m
[0;33m2025-05-17 02:36:08,508  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 02:36:08,508  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-17 02:38:25,709  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-17 02:38:25,711  - INFO - - Train mean loss: 0.4598
- ET loss: 0.2417
- TC loss: 0.1960
- WT loss: 0.9419
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 02:38:25,711  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-17 02:38:56,699  - INFO - === [Epoch 98/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:30.9868s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.603 â”‚ 0.845 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.772 â”‚ 0.824 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.598 â”‚ 0.854 â”‚ 0.896 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.918 â”‚ 0.859 â”‚ 0.895 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3978, ET: 0.1561, TC: 0.1210, WT: 0.9163
[0m
[0;33m2025-05-17 02:38:56,699  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-17 02:38:56,699  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-17 02:41:10,458  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-17 02:41:10,459  - INFO - - Train mean loss: 0.4752
- ET loss: 0.2641
- TC loss: 0.2182
- WT loss: 0.9434
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 02:41:10,459  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-17 02:41:41,087  - INFO - === [Epoch 99/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:30.6269s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.877 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.771 â”‚ 0.822 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.858 â”‚ 0.893 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.854 â”‚ 0.892 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3986, ET: 0.1566, TC: 0.1229, WT: 0.9163
[0m
[0;33m2025-05-17 02:41:41,087  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-17 02:41:41,087  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-17 02:44:00,191  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-17 02:44:00,193  - INFO - - Train mean loss: 0.4529
- ET loss: 0.2310
- TC loss: 0.1858
- WT loss: 0.9419
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 02:44:00,193  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-17 02:44:30,922  - INFO - === [Epoch 100/100] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:30.7282s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚ 0.844 â”‚ 0.879 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.546 â”‚ 0.771 â”‚ 0.823 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.858 â”‚ 0.897 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.913 â”‚ 0.85  â”‚ 0.889 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3984, ET: 0.1571, TC: 0.1219, WT: 0.9163
[0m
[0;33m2025-05-17 02:44:30,923  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[1;31m2025-05-17 02:44:31,728  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.3962 at epoch 90[0m
[0;32m2025-05-17 02:44:31,728  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 02:44:31,737  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/ResUNetBaseline_S_SLKv1_v2_final_model.pth[0m
[1;31m2025-05-17 02:44:31,737  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 02:44:31,737  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 02:48:01,709  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.596 â”‚  0.82  â”‚ 0.884 â”‚  0.085 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.536 â”‚  0.741 â”‚ 0.822 â”‚  0.045 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚  0.834 â”‚ 0.921 â”‚  0.045 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚  0.832 â”‚ 0.877 â”‚  1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 36.541 â”‚ 10.284 â”‚ 5.776 â”‚ 93.563 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4043;ET: 0.1805;ET: 0.1805;TC: 0.1169;WT: 0.9155
[0m
[0;32m2025-05-17 02:48:01,710  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 02:48:01,710  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-16.log[0m
[0;32m2025-05-17 02:48:08,161  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 02:48:11,445  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 02:48:11,448  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 02:48:11,448  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 02:48:11,448  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 02:48:11,448  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 02:48:11,448  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 02:48:11,455  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 02:48:11,455  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 02:48:11,455  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 02:48:11,459  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 02:48:14,459  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 02:48:14,459  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 02:50:34,475  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 02:50:34,477  - INFO - - Train mean loss: 0.5693
- ET loss: 0.5983
- TC loss: 0.6238
- WT loss: 0.4858
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 02:50:34,477  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 02:51:06,871  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:32.3932s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.638 â”‚ 0.589 â”‚ 0.59  â”‚ 0.734 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.507 â”‚ 0.455 â”‚ 0.458 â”‚ 0.607 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.602 â”‚ 0.513 â”‚ 0.6   â”‚ 0.693 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.785 â”‚ 0.812 â”‚ 0.704 â”‚ 0.839 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3841, ET: 0.4318, TC: 0.4303, WT: 0.2903
[0m
[0;32m2025-05-17 02:51:06,917  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.3841_dice0.6376_20250517025106.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 02:51:06,918  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 02:53:23,029  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 02:53:23,031  - INFO - - Train mean loss: 0.4053
- ET loss: 0.4447
- TC loss: 0.4716
- WT loss: 0.2996
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 02:53:23,031  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 02:53:53,876  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:30.8442s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.721 â”‚ 0.672 â”‚ 0.678 â”‚ 0.813 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.601 â”‚ 0.542 â”‚ 0.554 â”‚ 0.708 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.733 â”‚ 0.601 â”‚ 0.713 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.777 â”‚ 0.832 â”‚ 0.719 â”‚ 0.781 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2870, ET: 0.3380, TC: 0.3296, WT: 0.1933
[0m
[0;32m2025-05-17 02:53:53,919  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.2870_dice0.7212_20250517025353.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 02:53:53,919  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-17 02:56:12,053  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-17 02:56:12,054  - INFO - - Train mean loss: 0.3663
- ET loss: 0.3958
- TC loss: 0.4374
- WT loss: 0.2658
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 02:56:12,054  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-17 02:56:42,704  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:30.6489s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.736 â”‚ 0.717 â”‚ 0.677 â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.623 â”‚ 0.601 â”‚ 0.556 â”‚ 0.711 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.798 â”‚ 0.693 â”‚ 0.781 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.742 â”‚ 0.803 â”‚ 0.662 â”‚ 0.759 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2681, ET: 0.2894, TC: 0.3264, WT: 0.1883
[0m
[1;31m2025-05-17 02:56:42,706  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.2870_dice0.7212_20250517025353.pth[0m
[0;32m2025-05-17 02:56:42,747  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.2681_dice0.7365_20250517025642.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 02:56:42,747  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-17 02:58:59,698  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-17 02:58:59,699  - INFO - - Train mean loss: 0.3467
- ET loss: 0.3751
- TC loss: 0.4186
- WT loss: 0.2465
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 02:58:59,699  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-17 02:59:30,942  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:31.2414s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.753 â”‚ 0.725 â”‚ 0.695 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.643 â”‚ 0.61  â”‚ 0.576 â”‚ 0.744 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.746 â”‚ 0.662 â”‚ 0.752 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.818 â”‚ 0.855 â”‚ 0.706 â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2538, ET: 0.2829, TC: 0.3100, WT: 0.1686
[0m
[1;31m2025-05-17 02:59:30,944  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.2681_dice0.7365_20250517025642.pth[0m
[0;32m2025-05-17 02:59:30,989  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.2538_dice0.7531_20250517025930.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 02:59:30,989  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-17 03:01:49,802  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-17 03:01:49,803  - INFO - - Train mean loss: 0.3325
- ET loss: 0.3621
- TC loss: 0.4064
- WT loss: 0.2292
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 03:01:49,803  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-17 03:02:21,110  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:31.3067s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.773 â”‚ 0.763 â”‚ 0.715 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.67  â”‚ 0.66  â”‚ 0.6   â”‚ 0.751 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.847 â”‚ 0.753 â”‚ 0.846 â”‚ 0.94  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.75  â”‚ 0.807 â”‚ 0.657 â”‚ 0.787 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2302, ET: 0.2420, TC: 0.2877, WT: 0.1608
[0m
[1;31m2025-05-17 03:02:21,112  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2538_dice0.7531_20250517025930.pth[0m
[0;32m2025-05-17 03:02:21,154  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.2302_dice0.7734_20250517030221.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:02:21,154  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-17 03:04:36,625  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-17 03:04:36,626  - INFO - - Train mean loss: 0.3200
- ET loss: 0.3494
- TC loss: 0.3955
- WT loss: 0.2150
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 03:04:36,626  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-17 03:05:06,982  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:30.3551s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.778 â”‚ 0.741 â”‚ 0.718 â”‚ 0.876 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.674 â”‚ 0.627 â”‚ 0.6   â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.772 â”‚ 0.669 â”‚ 0.765 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.833 â”‚ 0.879 â”‚ 0.729 â”‚ 0.89  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2271, ET: 0.2653, TC: 0.2859, WT: 0.1302
[0m
[1;31m2025-05-17 03:05:06,984  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.2302_dice0.7734_20250517030221.pth[0m
[0;32m2025-05-17 03:05:07,025  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.2271_dice0.7781_20250517030506.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:05:07,026  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-17 03:07:23,963  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-17 03:07:23,964  - INFO - - Train mean loss: 0.3279
- ET loss: 0.3587
- TC loss: 0.4079
- WT loss: 0.2172
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 03:07:23,964  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-17 03:07:54,848  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:30.8823s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.78  â”‚ 0.739 â”‚ 0.73  â”‚ 0.87  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.674 â”‚ 0.624 â”‚ 0.615 â”‚ 0.783 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.759 â”‚ 0.663 â”‚ 0.772 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.845 â”‚ 0.877 â”‚ 0.735 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2258, ET: 0.2662, TC: 0.2737, WT: 0.1375
[0m
[1;31m2025-05-17 03:07:54,850  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.2271_dice0.7781_20250517030506.pth[0m
[0;32m2025-05-17 03:07:54,899  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.2258_dice0.7796_20250517030754.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:07:54,899  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-17 03:10:14,101  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-17 03:10:14,102  - INFO - - Train mean loss: 0.3120
- ET loss: 0.3381
- TC loss: 0.3882
- WT loss: 0.2098
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 03:10:14,102  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-17 03:10:45,378  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:31.2758s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.779 â”‚ 0.772 â”‚ 0.718 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.676 â”‚ 0.671 â”‚ 0.603 â”‚ 0.753 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.776 â”‚ 0.728 â”‚ 0.807 â”‚ 0.793 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.83  â”‚ 0.859 â”‚ 0.692 â”‚ 0.94  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2276, ET: 0.2327, TC: 0.2849, WT: 0.1652
[0m
[0;33m2025-05-17 03:10:45,378  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 03:10:45,378  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-17 03:13:03,215  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-17 03:13:03,217  - INFO - - Train mean loss: 0.3103
- ET loss: 0.3405
- TC loss: 0.3901
- WT loss: 0.2003
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 03:13:03,217  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-17 03:13:34,665  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:31.4475s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.79  â”‚ 0.745 â”‚ 0.737 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.688 â”‚ 0.63  â”‚ 0.623 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.777 â”‚ 0.663 â”‚ 0.775 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.848 â”‚ 0.895 â”‚ 0.75  â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2144, ET: 0.2608, TC: 0.2666, WT: 0.1157
[0m
[1;31m2025-05-17 03:13:34,667  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.2258_dice0.7796_20250517030754.pth[0m
[0;32m2025-05-17 03:13:34,712  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.2144_dice0.7901_20250517031334.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:13:34,713  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-17 03:15:51,523  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-17 03:15:51,525  - INFO - - Train mean loss: 0.3035
- ET loss: 0.3271
- TC loss: 0.3784
- WT loss: 0.2051
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 03:15:51,525  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-17 03:16:22,623  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:31.0959s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.795 â”‚ 0.781 â”‚ 0.732 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.699 â”‚ 0.682 â”‚ 0.621 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.843 â”‚ 0.758 â”‚ 0.847 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.791 â”‚ 0.841 â”‚ 0.684 â”‚ 0.848 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2068, ET: 0.2218, TC: 0.2695, WT: 0.1290
[0m
[1;31m2025-05-17 03:16:22,625  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.2144_dice0.7901_20250517031334.pth[0m
[0;32m2025-05-17 03:16:22,680  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.2068_dice0.7955_20250517031622.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:16:22,680  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-17 03:18:41,723  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-17 03:18:41,725  - INFO - - Train mean loss: 0.2928
- ET loss: 0.3161
- TC loss: 0.3696
- WT loss: 0.1927
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 03:18:41,725  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-17 03:19:12,863  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:31.1370s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.799 â”‚ 0.779 â”‚ 0.743 â”‚ 0.876 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.701 â”‚ 0.677 â”‚ 0.631 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.723 â”‚ 0.82  â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.839 â”‚ 0.879 â”‚ 0.718 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2047, ET: 0.2259, TC: 0.2602, WT: 0.1280
[0m
[1;31m2025-05-17 03:19:12,865  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.2068_dice0.7955_20250517031622.pth[0m
[0;32m2025-05-17 03:19:12,907  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.2047_dice0.7991_20250517031912.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:19:12,907  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-17 03:21:32,645  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-17 03:21:32,647  - INFO - - Train mean loss: 0.2798
- ET loss: 0.3037
- TC loss: 0.3606
- WT loss: 0.1752
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 03:21:32,647  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-17 03:22:04,194  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:31.5460s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.807 â”‚ 0.782 â”‚ 0.746 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.712 â”‚ 0.68  â”‚ 0.637 â”‚ 0.819 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.821 â”‚ 0.734 â”‚ 0.836 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.866 â”‚ 0.711 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1958, ET: 0.2214, TC: 0.2553, WT: 0.1108
[0m
[1;31m2025-05-17 03:22:04,195  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.2047_dice0.7991_20250517031912.pth[0m
[0;32m2025-05-17 03:22:04,237  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.1958_dice0.8069_20250517032204.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:22:04,238  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-17 03:24:24,141  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-17 03:24:24,142  - INFO - - Train mean loss: 0.2962
- ET loss: 0.3275
- TC loss: 0.3766
- WT loss: 0.1844
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 03:24:24,142  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-17 03:24:56,125  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:31.9821s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.8   â”‚ 0.786 â”‚ 0.731 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.703 â”‚ 0.687 â”‚ 0.618 â”‚ 0.805 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.821 â”‚ 0.751 â”‚ 0.836 â”‚ 0.876 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.82  â”‚ 0.859 â”‚ 0.694 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2031, ET: 0.2173, TC: 0.2705, WT: 0.1214
[0m
[0;33m2025-05-17 03:24:56,125  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 03:24:56,126  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-17 03:27:12,883  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-17 03:27:12,884  - INFO - - Train mean loss: 0.2959
- ET loss: 0.3220
- TC loss: 0.3749
- WT loss: 0.1907
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 03:27:12,884  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-17 03:27:44,022  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:31.1368s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.798 â”‚ 0.792 â”‚ 0.736 â”‚ 0.868 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.7   â”‚ 0.695 â”‚ 0.623 â”‚ 0.782 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.749 â”‚ 0.831 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.838 â”‚ 0.868 â”‚ 0.698 â”‚ 0.949 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2046, ET: 0.2115, TC: 0.2659, WT: 0.1365
[0m
[0;33m2025-05-17 03:27:44,022  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 03:27:44,022  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-17 03:29:59,572  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-17 03:29:59,573  - INFO - - Train mean loss: 0.2987
- ET loss: 0.3244
- TC loss: 0.3772
- WT loss: 0.1944
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 03:29:59,573  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-17 03:30:30,925  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:31.3513s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.805 â”‚ 0.784 â”‚ 0.741 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.711 â”‚ 0.685 â”‚ 0.631 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.822 â”‚ 0.742 â”‚ 0.837 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.825 â”‚ 0.864 â”‚ 0.702 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1968, ET: 0.2183, TC: 0.2603, WT: 0.1118
[0m
[0;33m2025-05-17 03:30:30,925  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 03:30:30,925  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-17 03:32:47,442  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-17 03:32:47,443  - INFO - - Train mean loss: 0.2864
- ET loss: 0.3191
- TC loss: 0.3613
- WT loss: 0.1789
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 03:32:47,443  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-17 03:33:18,381  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:30.9366s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.814 â”‚ 0.796 â”‚ 0.749 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.722 â”‚ 0.7   â”‚ 0.641 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.84  â”‚ 0.763 â”‚ 0.856 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.821 â”‚ 0.861 â”‚ 0.698 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1883, ET: 0.2062, TC: 0.2525, WT: 0.1063
[0m
[1;31m2025-05-17 03:33:18,383  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.1958_dice0.8069_20250517032204.pth[0m
[0;32m2025-05-17 03:33:18,425  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.1883_dice0.8139_20250517033318.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:33:18,425  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-17 03:35:34,152  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-17 03:35:34,154  - INFO - - Train mean loss: 0.2845
- ET loss: 0.3194
- TC loss: 0.3550
- WT loss: 0.1792
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 03:35:34,154  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-17 03:36:05,032  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:30.8775s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.799 â”‚ 0.785 â”‚ 0.718 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.706 â”‚ 0.691 â”‚ 0.605 â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.82  â”‚ 0.909 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.764 â”‚ 0.783 â”‚ 0.622 â”‚ 0.887 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2031, ET: 0.2167, TC: 0.2827, WT: 0.1099
[0m
[0;33m2025-05-17 03:36:05,033  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 03:36:05,033  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-17 03:38:20,190  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-17 03:38:20,191  - INFO - - Train mean loss: 0.2784
- ET loss: 0.3053
- TC loss: 0.3557
- WT loss: 0.1740
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 03:38:20,191  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-17 03:38:50,708  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:30.5162s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.811 â”‚ 0.792 â”‚ 0.746 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.719 â”‚ 0.695 â”‚ 0.638 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.839 â”‚ 0.762 â”‚ 0.856 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.823 â”‚ 0.859 â”‚ 0.701 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1908, ET: 0.2101, TC: 0.2552, WT: 0.1072
[0m
[0;33m2025-05-17 03:38:50,708  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 03:38:50,708  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-17 03:41:07,693  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-17 03:41:07,694  - INFO - - Train mean loss: 0.2871
- ET loss: 0.3204
- TC loss: 0.3602
- WT loss: 0.1808
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 03:41:07,694  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-17 03:41:38,737  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:31.0416s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.814 â”‚ 0.789 â”‚ 0.752 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.722 â”‚ 0.69  â”‚ 0.646 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.77  â”‚ 0.882 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.806 â”‚ 0.837 â”‚ 0.688 â”‚ 0.893 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1880, ET: 0.2131, TC: 0.2483, WT: 0.1025
[0m
[1;31m2025-05-17 03:41:38,739  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.1883_dice0.8139_20250517033318.pth[0m
[0;32m2025-05-17 03:41:38,781  - INFO - âœ¨ Saved checkpoint (epoch 19) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch19_loss0.1880_dice0.8137_20250517034138.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:41:38,781  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-17 03:43:54,442  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-17 03:43:54,443  - INFO - - Train mean loss: 0.2784
- ET loss: 0.3229
- TC loss: 0.3350
- WT loss: 0.1774
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 03:43:54,443  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-17 03:44:24,839  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:30.3942s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.812 â”‚ 0.8   â”‚ 0.738 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.72  â”‚ 0.707 â”‚ 0.629 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.855 â”‚ 0.794 â”‚ 0.877 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.807 â”‚ 0.835 â”‚ 0.67  â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1901, ET: 0.2016, TC: 0.2627, WT: 0.1060
[0m
[0;33m2025-05-17 03:44:24,839  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 03:44:24,839  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-17 03:46:42,712  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-17 03:46:42,713  - INFO - - Train mean loss: 0.2841
- ET loss: 0.3227
- TC loss: 0.3519
- WT loss: 0.1777
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 03:46:42,713  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-17 03:47:13,236  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:30.5222s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.818 â”‚ 0.755 â”‚ 0.801 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.726 â”‚ 0.646 â”‚ 0.707 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.828 â”‚ 0.708 â”‚ 0.882 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.844 â”‚ 0.854 â”‚ 0.76  â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1841, ET: 0.2460, TC: 0.2006, WT: 0.1057
[0m
[1;31m2025-05-17 03:47:13,239  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch19_loss0.1880_dice0.8137_20250517034138.pth[0m
[0;32m2025-05-17 03:47:13,291  - INFO - âœ¨ Saved checkpoint (epoch 21) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.1841_dice0.8177_20250517034713.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:47:13,291  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-17 03:49:31,281  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-17 03:49:31,283  - INFO - - Train mean loss: 0.2725
- ET loss: 0.3293
- TC loss: 0.3212
- WT loss: 0.1670
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 03:49:31,283  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-17 03:50:02,255  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:30.9705s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.81  â”‚ 0.757 â”‚ 0.799 â”‚ 0.875 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.714 â”‚ 0.645 â”‚ 0.708 â”‚ 0.789 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.8   â”‚ 0.703 â”‚ 0.878 â”‚ 0.819 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.86  â”‚ 0.86  â”‚ 0.764 â”‚ 0.958 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1916, ET: 0.2447, TC: 0.2018, WT: 0.1285
[0m
[0;33m2025-05-17 03:50:02,255  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 03:50:02,255  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-17 03:52:19,125  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-17 03:52:19,127  - INFO - - Train mean loss: 0.2710
- ET loss: 0.3309
- TC loss: 0.3155
- WT loss: 0.1666
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 03:52:19,127  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-17 03:52:50,162  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:31.0345s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.816 â”‚ 0.731 â”‚ 0.819 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.724 â”‚ 0.61  â”‚ 0.735 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.789 â”‚ 0.639 â”‚ 0.83  â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.902 â”‚ 0.841 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1856, ET: 0.2704, TC: 0.1823, WT: 0.1041
[0m
[0;33m2025-05-17 03:52:50,163  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 03:52:50,163  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-17 03:55:06,599  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-17 03:55:06,601  - INFO - - Train mean loss: 0.2772
- ET loss: 0.3404
- TC loss: 0.3146
- WT loss: 0.1767
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 03:55:06,601  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-17 03:55:37,569  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:30.9664s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.852 â”‚ 0.815 â”‚ 0.837 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.775 â”‚ 0.728 â”‚ 0.76  â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.841 â”‚ 0.879 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.849 â”‚ 0.815 â”‚ 0.829 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1512, ET: 0.1896, TC: 0.1650, WT: 0.0989
[0m
[1;31m2025-05-17 03:55:37,571  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch21_loss0.1841_dice0.8177_20250517034713.pth[0m
[0;32m2025-05-17 03:55:37,614  - INFO - âœ¨ Saved checkpoint (epoch 24) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch24_loss0.1512_dice0.8521_20250517035537.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 03:55:37,614  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-17 03:57:55,754  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-17 03:57:55,755  - INFO - - Train mean loss: 0.2437
- ET loss: 0.2922
- TC loss: 0.2655
- WT loss: 0.1734
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 03:57:55,755  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-17 03:58:26,825  - INFO - === [Epoch 25/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:31.0690s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.847 â”‚ 0.811 â”‚ 0.834 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.77  â”‚ 0.725 â”‚ 0.758 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.85  â”‚ 0.899 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.796 â”‚ 0.808 â”‚ 0.881 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1549, ET: 0.1927, TC: 0.1674, WT: 0.1047
[0m
[0;33m2025-05-17 03:58:26,826  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 03:58:26,826  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-17 04:00:46,577  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-17 04:00:46,579  - INFO - - Train mean loss: 0.2474
- ET loss: 0.2994
- TC loss: 0.2711
- WT loss: 0.1716
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 04:00:46,579  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-17 04:01:17,483  - INFO - === [Epoch 26/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:30.9031s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.821 â”‚ 0.855 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.785 â”‚ 0.738 â”‚ 0.787 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.818 â”‚ 0.88  â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.848 â”‚ 0.86  â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1438, ET: 0.1824, TC: 0.1467, WT: 0.1023
[0m
[1;31m2025-05-17 04:01:17,485  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch24_loss0.1512_dice0.8521_20250517035537.pth[0m
[0;32m2025-05-17 04:01:17,531  - INFO - âœ¨ Saved checkpoint (epoch 26) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch26_loss0.1438_dice0.8589_20250517040117.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:01:17,531  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-17 04:03:34,148  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-17 04:03:34,149  - INFO - - Train mean loss: 0.2431
- ET loss: 0.2941
- TC loss: 0.2642
- WT loss: 0.1708
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 04:03:34,149  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-17 04:04:04,548  - INFO - === [Epoch 27/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:30.3978s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.824 â”‚ 0.861 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.791 â”‚ 0.741 â”‚ 0.794 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.828 â”‚ 0.888 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.84  â”‚ 0.858 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1393, ET: 0.1793, TC: 0.1405, WT: 0.0982
[0m
[1;31m2025-05-17 04:04:04,550  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch26_loss0.1438_dice0.8589_20250517040117.pth[0m
[0;32m2025-05-17 04:04:04,813  - INFO - âœ¨ Saved checkpoint (epoch 27) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch27_loss0.1393_dice0.8631_20250517040404.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:04:04,814  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-17 04:06:22,863  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-17 04:06:22,864  - INFO - - Train mean loss: 0.2333
- ET loss: 0.2826
- TC loss: 0.2499
- WT loss: 0.1674
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 04:06:22,864  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-17 04:06:54,545  - INFO - === [Epoch 28/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:31.6799s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.825 â”‚ 0.857 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.742 â”‚ 0.788 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.827 â”‚ 0.874 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.843 â”‚ 0.872 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1396, ET: 0.1785, TC: 0.1439, WT: 0.0965
[0m
[0;33m2025-05-17 04:06:54,545  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 04:06:54,545  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-17 04:09:11,736  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-17 04:09:11,737  - INFO - - Train mean loss: 0.2237
- ET loss: 0.2733
- TC loss: 0.2359
- WT loss: 0.1618
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 04:09:11,737  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-17 04:09:42,890  - INFO - === [Epoch 29/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:31.1519s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.823 â”‚ 0.859 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.74  â”‚ 0.79  â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.864 â”‚ 0.812 â”‚ 0.866 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.855 â”‚ 0.878 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1393, ET: 0.1797, TC: 0.1422, WT: 0.0961
[0m
[1;31m2025-05-17 04:09:42,892  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch27_loss0.1393_dice0.8631_20250517040404.pth[0m
[0;32m2025-05-17 04:09:42,934  - INFO - âœ¨ Saved checkpoint (epoch 29) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch29_loss0.1393_dice0.8631_20250517040942.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:09:42,935  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-17 04:12:00,043  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-17 04:12:00,044  - INFO - - Train mean loss: 0.2294
- ET loss: 0.2816
- TC loss: 0.2449
- WT loss: 0.1617
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 04:12:00,044  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-17 04:12:30,694  - INFO - === [Epoch 30/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:30.6488s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.82  â”‚ 0.858 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.788 â”‚ 0.736 â”‚ 0.789 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.846 â”‚ 0.794 â”‚ 0.844 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.872 â”‚ 0.901 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1408, ET: 0.1822, TC: 0.1434, WT: 0.0966
[0m
[0;33m2025-05-17 04:12:30,694  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 04:12:30,694  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-17 04:14:46,806  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-17 04:14:46,807  - INFO - - Train mean loss: 0.2303
- ET loss: 0.2838
- TC loss: 0.2455
- WT loss: 0.1616
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 04:14:46,807  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-17 04:15:17,685  - INFO - === [Epoch 31/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:30.8767s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.862 â”‚ 0.821 â”‚ 0.862 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.789 â”‚ 0.737 â”‚ 0.796 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.859 â”‚ 0.805 â”‚ 0.881 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.86  â”‚ 0.868 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1403, ET: 0.1812, TC: 0.1391, WT: 0.1007
[0m
[0;33m2025-05-17 04:15:17,685  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 04:15:17,685  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-17 04:17:33,683  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-17 04:17:33,684  - INFO - - Train mean loss: 0.2329
- ET loss: 0.2837
- TC loss: 0.2476
- WT loss: 0.1675
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 04:17:33,684  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-17 04:18:04,438  - INFO - === [Epoch 32/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:30.7522s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.83  â”‚ 0.868 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.796 â”‚ 0.749 â”‚ 0.802 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.843 â”‚ 0.895 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.837 â”‚ 0.867 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1348, ET: 0.1732, TC: 0.1332, WT: 0.0981
[0m
[1;31m2025-05-17 04:18:04,440  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch29_loss0.1393_dice0.8631_20250517040942.pth[0m
[0;32m2025-05-17 04:18:04,481  - INFO - âœ¨ Saved checkpoint (epoch 32) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch32_loss0.1348_dice0.8673_20250517041804.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:18:04,482  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-17 04:20:23,233  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-17 04:20:23,234  - INFO - - Train mean loss: 0.2332
- ET loss: 0.2912
- TC loss: 0.2495
- WT loss: 0.1588
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 04:20:23,234  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-17 04:20:54,394  - INFO - === [Epoch 33/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:31.1595s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.822 â”‚ 0.859 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.788 â”‚ 0.736 â”‚ 0.788 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.848 â”‚ 0.789 â”‚ 0.849 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.878 â”‚ 0.894 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1390, ET: 0.1799, TC: 0.1420, WT: 0.0950
[0m
[0;33m2025-05-17 04:20:54,394  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 04:20:54,395  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-17 04:23:11,606  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-17 04:23:11,608  - INFO - - Train mean loss: 0.2242
- ET loss: 0.2763
- TC loss: 0.2423
- WT loss: 0.1540
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 04:23:11,608  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-17 04:23:42,740  - INFO - === [Epoch 34/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:31.1318s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.826 â”‚ 0.867 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.793 â”‚ 0.744 â”‚ 0.799 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.871 â”‚ 0.812 â”‚ 0.877 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.858 â”‚ 0.88  â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1366, ET: 0.1757, TC: 0.1345, WT: 0.0994
[0m
[0;33m2025-05-17 04:23:42,741  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 04:23:42,741  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-17 04:25:59,335  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-17 04:25:59,336  - INFO - - Train mean loss: 0.2205
- ET loss: 0.2710
- TC loss: 0.2322
- WT loss: 0.1585
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 04:25:59,337  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-17 04:26:31,049  - INFO - === [Epoch 35/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:31.7116s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.827 â”‚ 0.868 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.747 â”‚ 0.805 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.846 â”‚ 0.881 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.832 â”‚ 0.884 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1341, ET: 0.1757, TC: 0.1330, WT: 0.0935
[0m
[1;31m2025-05-17 04:26:31,051  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch32_loss0.1348_dice0.8673_20250517041804.pth[0m
[0;32m2025-05-17 04:26:31,093  - INFO - âœ¨ Saved checkpoint (epoch 35) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch35_loss0.1341_dice0.8679_20250517042631.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:26:31,093  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-17 04:28:48,967  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-17 04:28:48,968  - INFO - - Train mean loss: 0.2095
- ET loss: 0.2587
- TC loss: 0.2197
- WT loss: 0.1500
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 04:28:48,968  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-17 04:29:20,267  - INFO - === [Epoch 36/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:31.2978s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.823 â”‚ 0.86  â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.793 â”‚ 0.74  â”‚ 0.793 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.905 â”‚ 0.876 â”‚ 0.916 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.845 â”‚ 0.795 â”‚ 0.833 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1381, ET: 0.1797, TC: 0.1411, WT: 0.0935
[0m
[0;33m2025-05-17 04:29:20,267  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 04:29:20,267  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-17 04:31:38,292  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-17 04:31:38,293  - INFO - - Train mean loss: 0.2315
- ET loss: 0.2820
- TC loss: 0.2480
- WT loss: 0.1644
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 04:31:38,293  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-17 04:32:09,619  - INFO - === [Epoch 37/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:31.3249s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.831 â”‚ 0.872 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.752 â”‚ 0.809 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.873 â”‚ 0.836 â”‚ 0.879 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.848 â”‚ 0.889 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1324, ET: 0.1716, TC: 0.1297, WT: 0.0960
[0m
[1;31m2025-05-17 04:32:09,621  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch35_loss0.1341_dice0.8679_20250517042631.pth[0m
[0;32m2025-05-17 04:32:09,662  - INFO - âœ¨ Saved checkpoint (epoch 37) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch37_loss0.1324_dice0.8696_20250517043209.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:32:09,662  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-17 04:34:27,555  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-17 04:34:27,557  - INFO - - Train mean loss: 0.2234
- ET loss: 0.2766
- TC loss: 0.2423
- WT loss: 0.1514
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 04:34:27,557  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-17 04:34:58,832  - INFO - === [Epoch 38/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:31.2744s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.83  â”‚ 0.868 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.748 â”‚ 0.801 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.859 â”‚ 0.814 â”‚ 0.86  â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.868 â”‚ 0.896 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1333, ET: 0.1718, TC: 0.1337, WT: 0.0943
[0m
[0;33m2025-05-17 04:34:58,832  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 04:34:58,832  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-17 04:37:16,259  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-17 04:37:16,260  - INFO - - Train mean loss: 0.2396
- ET loss: 0.2930
- TC loss: 0.2581
- WT loss: 0.1677
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 04:37:16,260  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-17 04:37:47,483  - INFO - === [Epoch 39/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:31.2217s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.83  â”‚ 0.867 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.796 â”‚ 0.749 â”‚ 0.799 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.855 â”‚ 0.815 â”‚ 0.847 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.868 â”‚ 0.914 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1340, ET: 0.1722, TC: 0.1351, WT: 0.0948
[0m
[0;33m2025-05-17 04:37:47,483  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 04:37:47,483  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-17 04:40:03,850  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-17 04:40:03,852  - INFO - - Train mean loss: 0.2037
- ET loss: 0.2493
- TC loss: 0.2084
- WT loss: 0.1533
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 04:40:03,852  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-17 04:40:34,383  - INFO - === [Epoch 40/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:30.5309s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.834 â”‚ 0.873 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.756 â”‚ 0.811 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.84  â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.848 â”‚ 0.888 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1287, ET: 0.1679, TC: 0.1279, WT: 0.0903
[0m
[1;31m2025-05-17 04:40:34,386  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch37_loss0.1324_dice0.8696_20250517043209.pth[0m
[0;32m2025-05-17 04:40:34,428  - INFO - âœ¨ Saved checkpoint (epoch 40) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch40_loss0.1287_dice0.8732_20250517044034.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 04:40:34,428  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-17 04:42:51,719  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-17 04:42:51,721  - INFO - - Train mean loss: 0.2192
- ET loss: 0.2694
- TC loss: 0.2339
- WT loss: 0.1542
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 04:42:51,721  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-17 04:43:22,608  - INFO - === [Epoch 41/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:30.8865s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.831 â”‚ 0.874 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.75  â”‚ 0.81  â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.81  â”‚ 0.871 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.873 â”‚ 0.9   â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1314, ET: 0.1714, TC: 0.1271, WT: 0.0957
[0m
[0;33m2025-05-17 04:43:22,609  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 04:43:22,609  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-17 04:45:41,032  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-17 04:45:41,033  - INFO - - Train mean loss: 0.2272
- ET loss: 0.2774
- TC loss: 0.2447
- WT loss: 0.1594
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 04:45:41,033  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-17 04:46:11,351  - INFO - === [Epoch 42/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:30.3167s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.832 â”‚ 0.873 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.752 â”‚ 0.811 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.827 â”‚ 0.894 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.857 â”‚ 0.879 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1290, ET: 0.1691, TC: 0.1278, WT: 0.0901
[0m
[0;33m2025-05-17 04:46:11,351  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 04:46:11,351  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-17 04:48:29,893  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-17 04:48:29,894  - INFO - - Train mean loss: 0.2215
- ET loss: 0.2763
- TC loss: 0.2353
- WT loss: 0.1529
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 04:48:29,894  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-17 04:49:00,779  - INFO - === [Epoch 43/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:30.8835s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.834 â”‚ 0.872 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.755 â”‚ 0.808 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.835 â”‚ 0.873 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.852 â”‚ 0.895 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1302, ET: 0.1684, TC: 0.1294, WT: 0.0929
[0m
[0;33m2025-05-17 04:49:00,779  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 04:49:00,779  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-17 04:51:18,005  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-17 04:51:18,006  - INFO - - Train mean loss: 0.2131
- ET loss: 0.2613
- TC loss: 0.2222
- WT loss: 0.1558
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 04:51:18,006  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-17 04:51:49,320  - INFO - === [Epoch 44/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:31.3129s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.83  â”‚ 0.87  â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.748 â”‚ 0.807 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.81  â”‚ 0.877 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.871 â”‚ 0.885 â”‚ 0.936 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1339, ET: 0.1720, TC: 0.1311, WT: 0.0987
[0m
[0;33m2025-05-17 04:51:49,320  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 04:51:49,320  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-17 04:54:07,674  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-17 04:54:07,675  - INFO - - Train mean loss: 0.2112
- ET loss: 0.2604
- TC loss: 0.2227
- WT loss: 0.1505
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 04:54:07,675  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-17 04:54:38,180  - INFO - === [Epoch 45/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:30.5031s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.828 â”‚ 0.866 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.749 â”‚ 0.803 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.853 â”‚ 0.913 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.826 â”‚ 0.845 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1330, ET: 0.1728, TC: 0.1348, WT: 0.0915
[0m
[0;33m2025-05-17 04:54:38,180  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 04:54:38,180  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-17 04:56:56,128  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-17 04:56:56,129  - INFO - - Train mean loss: 0.2156
- ET loss: 0.2698
- TC loss: 0.2273
- WT loss: 0.1498
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 04:56:56,129  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-17 04:57:26,777  - INFO - === [Epoch 46/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:30.6464s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.831 â”‚ 0.871 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.75  â”‚ 0.809 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.815 â”‚ 0.883 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.867 â”‚ 0.885 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1312, ET: 0.1711, TC: 0.1300, WT: 0.0924
[0m
[0;33m2025-05-17 04:57:26,777  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 04:57:26,777  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-17 04:59:43,296  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-17 04:59:43,297  - INFO - - Train mean loss: 0.2193
- ET loss: 0.2728
- TC loss: 0.2366
- WT loss: 0.1484
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 04:59:43,297  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-17 05:00:14,085  - INFO - === [Epoch 47/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:30.7874s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.877 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.762 â”‚ 0.815 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.85  â”‚ 0.899 â”‚ 0.937 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.846 â”‚ 0.88  â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1241, ET: 0.1620, TC: 0.1240, WT: 0.0862
[0m
[1;31m2025-05-17 05:00:14,087  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch40_loss0.1287_dice0.8732_20250517044034.pth[0m
[0;32m2025-05-17 05:00:14,130  - INFO - âœ¨ Saved checkpoint (epoch 47) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch47_loss0.1241_dice0.8774_20250517050014.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 05:00:14,130  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-17 05:02:32,999  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-17 05:02:33,000  - INFO - - Train mean loss: 0.2083
- ET loss: 0.2582
- TC loss: 0.2201
- WT loss: 0.1466
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 05:02:33,000  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-17 05:03:03,558  - INFO - === [Epoch 48/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:30.5565s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.836 â”‚ 0.878 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.759 â”‚ 0.816 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.905 â”‚ 0.869 â”‚ 0.914 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.825 â”‚ 0.867 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1260, ET: 0.1659, TC: 0.1233, WT: 0.0889
[0m
[0;33m2025-05-17 05:03:03,558  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 05:03:03,558  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-17 05:05:22,931  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-17 05:05:22,932  - INFO - - Train mean loss: 0.2099
- ET loss: 0.2585
- TC loss: 0.2187
- WT loss: 0.1524
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 05:05:22,932  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-17 05:05:53,698  - INFO - === [Epoch 49/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:30.7655s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.839 â”‚ 0.879 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.762 â”‚ 0.818 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.852 â”‚ 0.896 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.845 â”‚ 0.885 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1248, ET: 0.1631, TC: 0.1221, WT: 0.0892
[0m
[0;33m2025-05-17 05:05:53,699  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 05:05:53,699  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-17 05:08:12,350  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-17 05:08:12,351  - INFO - - Train mean loss: 0.2184
- ET loss: 0.2719
- TC loss: 0.2291
- WT loss: 0.1541
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 05:08:12,351  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-17 05:08:43,404  - INFO - === [Epoch 50/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:31.0526s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.836 â”‚ 0.879 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.76  â”‚ 0.819 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.855 â”‚ 0.899 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.838 â”‚ 0.88  â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1288, ET: 0.1656, TC: 0.1222, WT: 0.0988
[0m
[0;33m2025-05-17 05:08:43,405  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 05:08:43,405  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-17 05:11:02,533  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-17 05:11:02,534  - INFO - - Train mean loss: 0.2123
- ET loss: 0.2634
- TC loss: 0.2262
- WT loss: 0.1474
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 05:11:02,534  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-17 05:11:33,344  - INFO - === [Epoch 51/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:30.8088s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.838 â”‚ 0.877 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.761 â”‚ 0.818 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.842 â”‚ 0.893 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.853 â”‚ 0.887 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1256, ET: 0.1636, TC: 0.1234, WT: 0.0897
[0m
[0;33m2025-05-17 05:11:33,344  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 05:11:33,344  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-17 05:13:49,838  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-17 05:13:49,839  - INFO - - Train mean loss: 0.2237
- ET loss: 0.2754
- TC loss: 0.2407
- WT loss: 0.1550
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 05:13:49,839  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-17 05:14:20,568  - INFO - === [Epoch 52/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:30.7281s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.836 â”‚ 0.872 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.811 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.854 â”‚ 0.9   â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.837 â”‚ 0.867 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1284, ET: 0.1657, TC: 0.1288, WT: 0.0906
[0m
[0;33m2025-05-17 05:14:20,569  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 05:14:20,569  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-17 05:16:38,967  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-17 05:16:38,968  - INFO - - Train mean loss: 0.2092
- ET loss: 0.2598
- TC loss: 0.2206
- WT loss: 0.1473
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 05:16:38,968  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-17 05:17:09,829  - INFO - === [Epoch 53/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:30.8600s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.838 â”‚ 0.871 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.76  â”‚ 0.809 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.852 â”‚ 0.911 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.842 â”‚ 0.854 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1268, ET: 0.1637, TC: 0.1298, WT: 0.0868
[0m
[0;33m2025-05-17 05:17:09,829  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 05:17:09,830  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-17 05:19:26,623  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-17 05:19:26,624  - INFO - - Train mean loss: 0.2073
- ET loss: 0.2573
- TC loss: 0.2155
- WT loss: 0.1490
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 05:19:26,624  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-17 05:19:57,324  - INFO - === [Epoch 54/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:30.6993s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.837 â”‚ 0.878 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.761 â”‚ 0.818 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.876 â”‚ 0.836 â”‚ 0.89  â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.857 â”‚ 0.884 â”‚ 0.934 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1255, ET: 0.1639, TC: 0.1227, WT: 0.0900
[0m
[0;33m2025-05-17 05:19:57,325  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 05:19:57,325  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-17 05:22:15,645  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-17 05:22:15,646  - INFO - - Train mean loss: 0.2038
- ET loss: 0.2568
- TC loss: 0.2188
- WT loss: 0.1358
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 05:22:15,646  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-17 05:22:46,209  - INFO - === [Epoch 55/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:30.5621s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.878 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.764 â”‚ 0.819 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.841 â”‚ 0.896 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.858 â”‚ 0.88  â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1238, ET: 0.1614, TC: 0.1227, WT: 0.0872
[0m
[1;31m2025-05-17 05:22:46,211  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch47_loss0.1241_dice0.8774_20250517050014.pth[0m
[0;32m2025-05-17 05:22:46,253  - INFO - âœ¨ Saved checkpoint (epoch 55) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch55_loss0.1238_dice0.8777_20250517052246.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 05:22:46,254  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-17 05:25:04,191  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-17 05:25:04,192  - INFO - - Train mean loss: 0.2055
- ET loss: 0.2610
- TC loss: 0.2171
- WT loss: 0.1385
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 05:25:04,192  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-17 05:25:35,400  - INFO - === [Epoch 56/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:31.2068s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.839 â”‚ 0.881 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.762 â”‚ 0.821 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.878 â”‚ 0.826 â”‚ 0.885 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.872 â”‚ 0.899 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1222, ET: 0.1624, TC: 0.1203, WT: 0.0838
[0m
[1;31m2025-05-17 05:25:35,402  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch55_loss0.1238_dice0.8777_20250517052246.pth[0m
[0;32m2025-05-17 05:25:35,444  - INFO - âœ¨ Saved checkpoint (epoch 56) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch56_loss0.1222_dice0.8793_20250517052535.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 05:25:35,444  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-17 05:27:51,635  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-17 05:27:51,636  - INFO - - Train mean loss: 0.2115
- ET loss: 0.2638
- TC loss: 0.2183
- WT loss: 0.1525
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 05:27:51,636  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-17 05:28:22,651  - INFO - === [Epoch 57/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:31.0137s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.834 â”‚ 0.872 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.754 â”‚ 0.809 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.856 â”‚ 0.809 â”‚ 0.857 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.909 â”‚ 0.879 â”‚ 0.916 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1290, ET: 0.1677, TC: 0.1288, WT: 0.0904
[0m
[0;33m2025-05-17 05:28:22,651  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 05:28:22,651  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-17 05:30:43,578  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-17 05:30:43,579  - INFO - - Train mean loss: 0.2036
- ET loss: 0.2528
- TC loss: 0.2104
- WT loss: 0.1477
- Cost time: 2.35mins â±ï¸
[0m
[0;32m2025-05-17 05:30:43,579  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-17 05:31:14,197  - INFO - === [Epoch 58/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:30.6169s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.838 â”‚ 0.878 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.76  â”‚ 0.818 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.864 â”‚ 0.826 â”‚ 0.877 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.867 â”‚ 0.898 â”‚ 0.943 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1633, TC: 0.1224, WT: 0.0940
[0m
[0;33m2025-05-17 05:31:14,198  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 05:31:14,198  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-17 05:33:32,209  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-17 05:33:32,210  - INFO - - Train mean loss: 0.2104
- ET loss: 0.2662
- TC loss: 0.2229
- WT loss: 0.1423
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 05:33:32,210  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-17 05:34:02,676  - INFO - === [Epoch 59/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:30.4653s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.837 â”‚ 0.877 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.76  â”‚ 0.818 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.833 â”‚ 0.887 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.861 â”‚ 0.889 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1251, ET: 0.1639, TC: 0.1233, WT: 0.0882
[0m
[0;33m2025-05-17 05:34:02,677  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 05:34:02,677  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-17 05:36:22,026  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-17 05:36:22,027  - INFO - - Train mean loss: 0.2095
- ET loss: 0.2592
- TC loss: 0.2193
- WT loss: 0.1501
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 05:36:22,027  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-17 05:36:53,144  - INFO - === [Epoch 60/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:31.1162s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.878 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.762 â”‚ 0.816 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.824 â”‚ 0.865 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.873 â”‚ 0.914 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1246, ET: 0.1622, TC: 0.1235, WT: 0.0882
[0m
[0;33m2025-05-17 05:36:53,144  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 05:36:53,144  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-17 05:39:10,059  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-17 05:39:10,060  - INFO - - Train mean loss: 0.2146
- ET loss: 0.2700
- TC loss: 0.2279
- WT loss: 0.1458
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 05:39:10,060  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-17 05:39:40,786  - INFO - === [Epoch 61/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:30.7246s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.841 â”‚ 0.882 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.763 â”‚ 0.822 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.831 â”‚ 0.892 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.867 â”‚ 0.893 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1216, ET: 0.1611, TC: 0.1191, WT: 0.0845
[0m
[1;31m2025-05-17 05:39:40,788  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch56_loss0.1222_dice0.8793_20250517052535.pth[0m
[0;32m2025-05-17 05:39:40,829  - INFO - âœ¨ Saved checkpoint (epoch 61) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch61_loss0.1216_dice0.8797_20250517053940.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 05:39:40,829  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-17 05:41:57,768  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-17 05:41:57,769  - INFO - - Train mean loss: 0.2021
- ET loss: 0.2491
- TC loss: 0.2053
- WT loss: 0.1518
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 05:41:57,769  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-17 05:42:28,587  - INFO - === [Epoch 62/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:30.8164s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.878 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.764 â”‚ 0.818 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.828 â”‚ 0.895 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.873 â”‚ 0.881 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1222, ET: 0.1599, TC: 0.1224, WT: 0.0844
[0m
[0;33m2025-05-17 05:42:28,587  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 05:42:28,587  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-17 05:44:43,785  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-17 05:44:43,786  - INFO - - Train mean loss: 0.2042
- ET loss: 0.2606
- TC loss: 0.2148
- WT loss: 0.1370
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 05:44:43,786  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-17 05:45:14,484  - INFO - === [Epoch 63/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:30.6971s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.879 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.767 â”‚ 0.821 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.849 â”‚ 0.901 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.854 â”‚ 0.884 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1222, ET: 0.1598, TC: 0.1219, WT: 0.0850
[0m
[0;33m2025-05-17 05:45:14,485  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 05:45:14,485  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-17 05:47:30,122  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-17 05:47:30,124  - INFO - - Train mean loss: 0.2008
- ET loss: 0.2575
- TC loss: 0.2130
- WT loss: 0.1319
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 05:47:30,124  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-17 05:48:00,657  - INFO - === [Epoch 64/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:30.5321s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.877 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.764 â”‚ 0.818 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.842 â”‚ 0.899 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.858 â”‚ 0.876 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1233, ET: 0.1613, TC: 0.1238, WT: 0.0850
[0m
[0;33m2025-05-17 05:48:00,657  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 05:48:00,657  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-17 05:50:17,517  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-17 05:50:17,518  - INFO - - Train mean loss: 0.2003
- ET loss: 0.2494
- TC loss: 0.2129
- WT loss: 0.1387
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 05:50:17,518  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-17 05:50:48,534  - INFO - === [Epoch 65/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:31.0144s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.844 â”‚ 0.881 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.769 â”‚ 0.823 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.847 â”‚ 0.896 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.858 â”‚ 0.885 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1213, ET: 0.1578, TC: 0.1201, WT: 0.0859
[0m
[1;31m2025-05-17 05:50:48,535  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch61_loss0.1216_dice0.8797_20250517053940.pth[0m
[0;32m2025-05-17 05:50:48,577  - INFO - âœ¨ Saved checkpoint (epoch 65) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch65_loss0.1213_dice0.8801_20250517055048.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 05:50:48,577  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-17 05:53:05,575  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-17 05:53:05,576  - INFO - - Train mean loss: 0.2148
- ET loss: 0.2678
- TC loss: 0.2252
- WT loss: 0.1514
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 05:53:05,576  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-17 05:53:36,684  - INFO - === [Epoch 66/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:31.1069s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.842 â”‚ 0.88  â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.766 â”‚ 0.821 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.838 â”‚ 0.894 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.863 â”‚ 0.888 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1229, ET: 0.1596, TC: 0.1209, WT: 0.0884
[0m
[0;33m2025-05-17 05:53:36,685  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 05:53:36,685  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-17 05:55:53,385  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-17 05:55:53,386  - INFO - - Train mean loss: 0.2035
- ET loss: 0.2580
- TC loss: 0.2124
- WT loss: 0.1401
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 05:55:53,387  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-17 05:56:24,103  - INFO - === [Epoch 67/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:30.7151s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.841 â”‚ 0.879 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.766 â”‚ 0.821 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.854 â”‚ 0.902 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.847 â”‚ 0.883 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1226, ET: 0.1608, TC: 0.1219, WT: 0.0851
[0m
[0;33m2025-05-17 05:56:24,103  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 05:56:24,103  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-17 05:58:41,286  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-17 05:58:41,287  - INFO - - Train mean loss: 0.1977
- ET loss: 0.2487
- TC loss: 0.2059
- WT loss: 0.1385
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 05:58:41,287  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-17 05:59:11,770  - INFO - === [Epoch 68/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:30.4823s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.843 â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.767 â”‚ 0.824 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.834 â”‚ 0.887 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.869 â”‚ 0.902 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1215, ET: 0.1588, TC: 0.1183, WT: 0.0873
[0m
[0;33m2025-05-17 05:59:11,771  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 05:59:11,771  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-17 06:01:28,523  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-17 06:01:28,524  - INFO - - Train mean loss: 0.2125
- ET loss: 0.2653
- TC loss: 0.2221
- WT loss: 0.1502
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 06:01:28,524  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-17 06:01:59,377  - INFO - === [Epoch 69/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:30.8522s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.843 â”‚ 0.881 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.768 â”‚ 0.822 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.857 â”‚ 0.897 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.846 â”‚ 0.887 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1214, ET: 0.1588, TC: 0.1195, WT: 0.0858
[0m
[0;33m2025-05-17 06:01:59,377  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 06:01:59,377  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-17 06:04:17,047  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-17 06:04:17,049  - INFO - - Train mean loss: 0.2041
- ET loss: 0.2562
- TC loss: 0.2121
- WT loss: 0.1441
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 06:04:17,049  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-17 06:04:47,804  - INFO - === [Epoch 70/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:30.7540s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.843 â”‚ 0.881 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.768 â”‚ 0.823 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.843 â”‚ 0.891 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.86  â”‚ 0.896 â”‚ 0.934 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1220, ET: 0.1589, TC: 0.1195, WT: 0.0877
[0m
[0;33m2025-05-17 06:04:47,804  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 06:04:47,804  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-17 06:07:05,517  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-17 06:07:05,518  - INFO - - Train mean loss: 0.2070
- ET loss: 0.2616
- TC loss: 0.2158
- WT loss: 0.1436
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 06:07:05,518  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-17 06:07:36,206  - INFO - === [Epoch 71/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:30.6867s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.842 â”‚ 0.882 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.824 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.86  â”‚ 0.902 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.841 â”‚ 0.885 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1210, ET: 0.1594, TC: 0.1185, WT: 0.0851
[0m
[1;31m2025-05-17 06:07:36,208  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch65_loss0.1213_dice0.8801_20250517055048.pth[0m
[0;32m2025-05-17 06:07:36,250  - INFO - âœ¨ Saved checkpoint (epoch 71) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch71_loss0.1210_dice0.8803_20250517060736.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 06:07:36,250  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-17 06:09:55,870  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-17 06:09:55,872  - INFO - - Train mean loss: 0.2050
- ET loss: 0.2606
- TC loss: 0.2161
- WT loss: 0.1382
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 06:09:55,872  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-17 06:10:26,408  - INFO - === [Epoch 72/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:30.5355s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.84  â”‚ 0.88  â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.765 â”‚ 0.821 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.857 â”‚ 0.908 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.842 â”‚ 0.876 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1225, ET: 0.1617, TC: 0.1209, WT: 0.0849
[0m
[0;33m2025-05-17 06:10:26,409  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 06:10:26,409  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-17 06:12:46,565  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-17 06:12:46,566  - INFO - - Train mean loss: 0.1972
- ET loss: 0.2508
- TC loss: 0.2088
- WT loss: 0.1321
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-17 06:12:46,567  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-17 06:13:17,004  - INFO - === [Epoch 73/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:30.4362s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.839 â”‚ 0.88  â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.765 â”‚ 0.822 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.847 â”‚ 0.898 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.851 â”‚ 0.887 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1224, ET: 0.1619, TC: 0.1209, WT: 0.0846
[0m
[0;33m2025-05-17 06:13:17,004  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 06:13:17,004  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-17 06:15:38,736  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-17 06:15:38,737  - INFO - - Train mean loss: 0.2054
- ET loss: 0.2574
- TC loss: 0.2181
- WT loss: 0.1408
- Cost time: 2.36mins â±ï¸
[0m
[0;32m2025-05-17 06:15:38,737  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-17 06:16:09,121  - INFO - === [Epoch 74/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:30.3830s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.88  â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.822 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.859 â”‚ 0.911 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.845 â”‚ 0.874 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1217, ET: 0.1598, TC: 0.1210, WT: 0.0842
[0m
[0;33m2025-05-17 06:16:09,121  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 06:16:09,121  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-17 06:18:26,637  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-17 06:18:26,638  - INFO - - Train mean loss: 0.1995
- ET loss: 0.2519
- TC loss: 0.2090
- WT loss: 0.1375
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 06:18:26,638  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-17 06:18:57,270  - INFO - === [Epoch 75/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:30.6305s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.842 â”‚ 0.884 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.766 â”‚ 0.825 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.829 â”‚ 0.895 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.872 â”‚ 0.892 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1201, ET: 0.1590, TC: 0.1169, WT: 0.0844
[0m
[1;31m2025-05-17 06:18:57,272  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch71_loss0.1210_dice0.8803_20250517060736.pth[0m
[0;32m2025-05-17 06:18:57,313  - INFO - âœ¨ Saved checkpoint (epoch 75) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch75_loss0.1201_dice0.8809_20250517061857.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 06:18:57,313  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-17 06:21:13,986  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-17 06:21:13,987  - INFO - - Train mean loss: 0.2090
- ET loss: 0.2673
- TC loss: 0.2211
- WT loss: 0.1385
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 06:21:13,987  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-17 06:21:44,480  - INFO - === [Epoch 76/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:30.4922s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.842 â”‚ 0.883 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.767 â”‚ 0.824 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.844 â”‚ 0.895 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.857 â”‚ 0.892 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1202, ET: 0.1589, TC: 0.1180, WT: 0.0837
[0m
[0;33m2025-05-17 06:21:44,481  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 06:21:44,481  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-17 06:24:00,727  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-17 06:24:00,728  - INFO - - Train mean loss: 0.1951
- ET loss: 0.2449
- TC loss: 0.1994
- WT loss: 0.1409
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 06:24:00,728  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-17 06:24:31,098  - INFO - === [Epoch 77/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:30.3685s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.883 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.77  â”‚ 0.825 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.851 â”‚ 0.91  â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.853 â”‚ 0.879 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1198, ET: 0.1574, TC: 0.1178, WT: 0.0843
[0m
[1;31m2025-05-17 06:24:31,100  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch75_loss0.1201_dice0.8809_20250517061857.pth[0m
[0;32m2025-05-17 06:24:31,141  - INFO - âœ¨ Saved checkpoint (epoch 77) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch77_loss0.1198_dice0.8813_20250517062431.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 06:24:31,141  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-17 06:26:53,186  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-17 06:26:53,187  - INFO - - Train mean loss: 0.1989
- ET loss: 0.2505
- TC loss: 0.2061
- WT loss: 0.1400
- Cost time: 2.37mins â±ï¸
[0m
[0;32m2025-05-17 06:26:53,187  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-17 06:27:23,521  - INFO - === [Epoch 78/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:30.3333s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.844 â”‚ 0.883 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.824 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.852 â”‚ 0.906 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.852 â”‚ 0.883 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1193, ET: 0.1574, TC: 0.1180, WT: 0.0825
[0m
[1;31m2025-05-17 06:27:23,523  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch77_loss0.1198_dice0.8813_20250517062431.pth[0m
[0;32m2025-05-17 06:27:23,564  - INFO - âœ¨ Saved checkpoint (epoch 78) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch78_loss0.1193_dice0.8818_20250517062723.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 06:27:23,564  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-17 06:29:42,346  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-17 06:29:42,347  - INFO - - Train mean loss: 0.1944
- ET loss: 0.2474
- TC loss: 0.2007
- WT loss: 0.1352
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 06:29:42,347  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-17 06:30:12,809  - INFO - === [Epoch 79/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:30.4606s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.879 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.767 â”‚ 0.821 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.854 â”‚ 0.91  â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.848 â”‚ 0.874 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1216, ET: 0.1597, TC: 0.1215, WT: 0.0836
[0m
[0;33m2025-05-17 06:30:12,809  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 06:30:12,809  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-17 06:32:30,087  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-17 06:32:30,089  - INFO - - Train mean loss: 0.2041
- ET loss: 0.2570
- TC loss: 0.2116
- WT loss: 0.1437
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 06:32:30,089  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-17 06:33:00,757  - INFO - === [Epoch 80/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:30.6673s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.883 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.825 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.84  â”‚ 0.901 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.864 â”‚ 0.887 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1198, ET: 0.1575, TC: 0.1176, WT: 0.0844
[0m
[0;33m2025-05-17 06:33:00,758  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 06:33:00,758  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-17 06:35:18,522  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-17 06:35:18,523  - INFO - - Train mean loss: 0.2010
- ET loss: 0.2500
- TC loss: 0.2094
- WT loss: 0.1436
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 06:35:18,523  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-17 06:35:49,141  - INFO - === [Epoch 81/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:30.6168s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.842 â”‚ 0.88  â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.822 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.901 â”‚ 0.864 â”‚ 0.91  â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.839 â”‚ 0.874 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1209, ET: 0.1590, TC: 0.1206, WT: 0.0830
[0m
[0;33m2025-05-17 06:35:49,141  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 06:35:49,141  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-17 06:38:04,890  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-17 06:38:04,892  - INFO - - Train mean loss: 0.1958
- ET loss: 0.2486
- TC loss: 0.2040
- WT loss: 0.1349
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 06:38:04,892  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-17 06:38:36,161  - INFO - === [Epoch 82/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:31.2686s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.882 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.769 â”‚ 0.823 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.855 â”‚ 0.902 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.849 â”‚ 0.884 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1203, ET: 0.1576, TC: 0.1184, WT: 0.0850
[0m
[0;33m2025-05-17 06:38:36,161  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 06:38:36,161  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-17 06:40:52,686  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-17 06:40:52,688  - INFO - - Train mean loss: 0.1943
- ET loss: 0.2453
- TC loss: 0.2019
- WT loss: 0.1357
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 06:40:52,688  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-17 06:41:23,170  - INFO - === [Epoch 83/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:30.4805s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.881 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.824 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.851 â”‚ 0.906 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.854 â”‚ 0.883 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1199, ET: 0.1577, TC: 0.1196, WT: 0.0825
[0m
[0;33m2025-05-17 06:41:23,171  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 06:41:23,171  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-17 06:43:38,960  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-17 06:43:38,961  - INFO - - Train mean loss: 0.2019
- ET loss: 0.2571
- TC loss: 0.2137
- WT loss: 0.1349
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 06:43:38,961  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-17 06:44:09,318  - INFO - === [Epoch 84/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:30.3561s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.882 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.824 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.902 â”‚ 0.863 â”‚ 0.909 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.843 â”‚ 0.882 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1198, ET: 0.1580, TC: 0.1186, WT: 0.0828
[0m
[0;33m2025-05-17 06:44:09,318  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 06:44:09,318  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-17 06:46:25,309  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-17 06:46:25,310  - INFO - - Train mean loss: 0.1944
- ET loss: 0.2472
- TC loss: 0.2020
- WT loss: 0.1340
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 06:46:25,311  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-17 06:46:56,031  - INFO - === [Epoch 85/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:30.7190s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.881 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.823 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.854 â”‚ 0.907 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.85  â”‚ 0.88  â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1203, ET: 0.1580, TC: 0.1191, WT: 0.0840
[0m
[0;33m2025-05-17 06:46:56,031  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 06:46:56,031  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-17 06:49:12,104  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-17 06:49:12,105  - INFO - - Train mean loss: 0.1924
- ET loss: 0.2460
- TC loss: 0.1961
- WT loss: 0.1351
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 06:49:12,105  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-17 06:49:43,078  - INFO - === [Epoch 86/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:30.9723s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.881 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.77  â”‚ 0.823 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.855 â”‚ 0.909 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.85  â”‚ 0.879 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1201, ET: 0.1576, TC: 0.1199, WT: 0.0830
[0m
[0;33m2025-05-17 06:49:43,078  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-17 06:49:43,079  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-17 06:52:00,742  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-17 06:52:00,744  - INFO - - Train mean loss: 0.2087
- ET loss: 0.2637
- TC loss: 0.2178
- WT loss: 0.1446
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 06:52:00,744  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-17 06:52:31,213  - INFO - === [Epoch 87/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:30.4677s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.883 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.825 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.843 â”‚ 0.902 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.861 â”‚ 0.887 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1197, ET: 0.1570, TC: 0.1175, WT: 0.0845
[0m
[0;33m2025-05-17 06:52:31,213  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-17 06:52:31,213  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-17 06:54:47,769  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-17 06:54:47,770  - INFO - - Train mean loss: 0.1925
- ET loss: 0.2451
- TC loss: 0.2031
- WT loss: 0.1294
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 06:54:47,770  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-17 06:55:18,442  - INFO - === [Epoch 88/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:30.6707s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.884 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.772 â”‚ 0.827 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.846 â”‚ 0.902 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.861 â”‚ 0.889 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1183, ET: 0.1558, TC: 0.1162, WT: 0.0830
[0m
[1;31m2025-05-17 06:55:18,444  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch78_loss0.1193_dice0.8818_20250517062723.pth[0m
[0;32m2025-05-17 06:55:18,489  - INFO - âœ¨ Saved checkpoint (epoch 88) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch88_loss0.1183_dice0.8829_20250517065518.pth;             Size 12.43 MB[0m
[0;32m2025-05-17 06:55:18,489  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-17 06:57:34,792  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-17 06:57:34,793  - INFO - - Train mean loss: 0.1893
- ET loss: 0.2411
- TC loss: 0.1945
- WT loss: 0.1323
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 06:57:34,793  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-17 06:58:05,228  - INFO - === [Epoch 89/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:30.4336s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.846 â”‚ 0.884 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.772 â”‚ 0.826 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.851 â”‚ 0.906 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.856 â”‚ 0.886 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1189, ET: 0.1558, TC: 0.1171, WT: 0.0837
[0m
[0;33m2025-05-17 06:58:05,228  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 06:58:05,228  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-17 07:00:22,537  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-17 07:00:22,538  - INFO - - Train mean loss: 0.2230
- ET loss: 0.2785
- TC loss: 0.2334
- WT loss: 0.1572
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 07:00:22,538  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-17 07:00:53,129  - INFO - === [Epoch 90/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:30.5899s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.882 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.825 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.854 â”‚ 0.91  â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.851 â”‚ 0.88  â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1196, ET: 0.1568, TC: 0.1180, WT: 0.0841
[0m
[0;33m2025-05-17 07:00:53,129  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 07:00:53,130  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-17 07:03:10,536  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-17 07:03:10,537  - INFO - - Train mean loss: 0.1999
- ET loss: 0.2557
- TC loss: 0.2070
- WT loss: 0.1369
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 07:03:10,537  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-17 07:03:41,415  - INFO - === [Epoch 91/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:30.8774s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.827 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.849 â”‚ 0.899 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.858 â”‚ 0.892 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1193, ET: 0.1562, TC: 0.1167, WT: 0.0851
[0m
[0;33m2025-05-17 07:03:41,416  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 07:03:41,416  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-17 07:05:56,686  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-17 07:05:56,687  - INFO - - Train mean loss: 0.1900
- ET loss: 0.2470
- TC loss: 0.2010
- WT loss: 0.1219
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 07:05:56,688  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-17 07:06:26,973  - INFO - === [Epoch 92/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:30.2843s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.844 â”‚ 0.883 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.771 â”‚ 0.825 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.902 â”‚ 0.86  â”‚ 0.91  â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.846 â”‚ 0.88  â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1192, ET: 0.1571, TC: 0.1180, WT: 0.0826
[0m
[0;33m2025-05-17 07:06:26,973  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 07:06:26,973  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-17 07:08:47,258  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-17 07:08:47,259  - INFO - - Train mean loss: 0.2026
- ET loss: 0.2597
- TC loss: 0.2139
- WT loss: 0.1343
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-17 07:08:47,259  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-17 07:09:17,611  - INFO - === [Epoch 93/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:30.3512s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.772 â”‚ 0.826 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.851 â”‚ 0.903 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.855 â”‚ 0.887 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1189, ET: 0.1560, TC: 0.1168, WT: 0.0839
[0m
[0;33m2025-05-17 07:09:17,612  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 07:09:17,612  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-17 07:11:34,790  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-17 07:11:34,791  - INFO - - Train mean loss: 0.1982
- ET loss: 0.2509
- TC loss: 0.2103
- WT loss: 0.1335
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 07:11:34,791  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-17 07:12:05,498  - INFO - === [Epoch 94/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:30.7054s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.771 â”‚ 0.826 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.85  â”‚ 0.905 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.856 â”‚ 0.886 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1188, ET: 0.1563, TC: 0.1169, WT: 0.0832
[0m
[0;33m2025-05-17 07:12:05,498  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 07:12:05,498  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-17 07:14:19,214  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-17 07:14:19,215  - INFO - - Train mean loss: 0.1903
- ET loss: 0.2433
- TC loss: 0.1975
- WT loss: 0.1300
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 07:14:19,215  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-17 07:14:49,969  - INFO - === [Epoch 95/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:30.7532s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.771 â”‚ 0.826 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.848 â”‚ 0.903 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.857 â”‚ 0.888 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1189, ET: 0.1568, TC: 0.1168, WT: 0.0831
[0m
[0;33m2025-05-17 07:14:49,970  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 07:14:49,970  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-17 07:17:05,273  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-17 07:17:05,274  - INFO - - Train mean loss: 0.2084
- ET loss: 0.2632
- TC loss: 0.2181
- WT loss: 0.1440
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 07:17:05,274  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-17 07:17:36,008  - INFO - === [Epoch 96/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:30.7323s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.883 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.826 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.85  â”‚ 0.904 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.855 â”‚ 0.886 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1191, ET: 0.1568, TC: 0.1172, WT: 0.0833
[0m
[0;33m2025-05-17 07:17:36,008  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-17 07:17:36,008  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-17 07:19:53,257  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-17 07:19:53,258  - INFO - - Train mean loss: 0.1910
- ET loss: 0.2453
- TC loss: 0.1988
- WT loss: 0.1288
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 07:19:53,259  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-17 07:20:23,883  - INFO - === [Epoch 97/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:30.6238s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.847 â”‚ 0.904 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.86  â”‚ 0.889 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1192, ET: 0.1563, TC: 0.1170, WT: 0.0843
[0m
[0;33m2025-05-17 07:20:23,884  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-17 07:20:23,884  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-17 07:22:41,649  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-17 07:22:41,650  - INFO - - Train mean loss: 0.1970
- ET loss: 0.2481
- TC loss: 0.2047
- WT loss: 0.1383
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 07:22:41,651  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-17 07:23:12,096  - INFO - === [Epoch 98/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:30.4443s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.826 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.848 â”‚ 0.9   â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.858 â”‚ 0.891 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1189, ET: 0.1564, TC: 0.1164, WT: 0.0840
[0m
[0;33m2025-05-17 07:23:12,096  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-17 07:23:12,096  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-17 07:25:31,300  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-17 07:25:31,301  - INFO - - Train mean loss: 0.2123
- ET loss: 0.2694
- TC loss: 0.2263
- WT loss: 0.1412
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 07:25:31,301  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-17 07:26:02,068  - INFO - === [Epoch 99/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:30.7653s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.885 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.9   â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.857 â”‚ 0.89  â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1189, ET: 0.1565, TC: 0.1157, WT: 0.0845
[0m
[0;33m2025-05-17 07:26:02,068  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-17 07:26:02,068  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-17 07:28:18,570  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-17 07:28:18,571  - INFO - - Train mean loss: 0.1872
- ET loss: 0.2363
- TC loss: 0.1929
- WT loss: 0.1323
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 07:28:18,572  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-17 07:28:49,225  - INFO - === [Epoch 100/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:30.6527s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.844 â”‚ 0.883 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.825 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.857 â”‚ 0.908 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.848 â”‚ 0.88  â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1194, ET: 0.1570, TC: 0.1179, WT: 0.0833
[0m
[0;33m2025-05-17 07:28:49,226  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[1;31m2025-05-17 07:28:50,431  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1183 at epoch 88[0m
[0;32m2025-05-17 07:28:50,432  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 07:28:50,440  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 07:28:50,440  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 07:28:50,440  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 07:32:15,990  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚  0.816 â”‚ 0.878 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚  0.734 â”‚ 0.813 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚  0.819 â”‚ 0.913 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚  0.835 â”‚ 0.875 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  6.552 â”‚ 10.303 â”‚ 4.718 â”‚ 4.635 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1296;ET: 0.1861;ET: 0.1861;TC: 0.1222;WT: 0.0805
[0m
[0;32m2025-05-17 07:32:15,991  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 07:32:15,991  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-17.log[0m
[0;32m2025-05-17 07:32:22,189  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 07:32:25,415  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 07:32:25,418  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 07:32:25,418  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 07:32:25,418  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 07:32:25,418  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 07:32:25,418  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 07:32:25,425  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 07:32:25,425  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 07:32:25,425  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 07:32:25,429  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv1_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 07:32:28,361  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv1_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 07:32:28,361  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 07:34:48,234  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 07:34:48,236  - INFO - - Train mean loss: 0.5040
- ET loss: 0.5029
- TC loss: 0.4955
- WT loss: 0.5136
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 07:34:48,237  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 07:35:21,246  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:33.0086s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.762 â”‚ 0.731 â”‚ 0.746 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.655 â”‚ 0.62  â”‚ 0.639 â”‚ 0.705 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.827 â”‚ 0.792 â”‚ 0.822 â”‚ 0.868 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.741 â”‚ 0.711 â”‚ 0.725 â”‚ 0.786 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2443, ET: 0.2763, TC: 0.2594, WT: 0.1971
[0m
[0;32m2025-05-17 07:35:21,296  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.2443_dice0.7624_20250517073521.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:35:21,296  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 07:37:37,573  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 07:37:37,576  - INFO - - Train mean loss: 0.3359
- ET loss: 0.3760
- TC loss: 0.3626
- WT loss: 0.2689
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 07:37:37,577  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 07:38:10,485  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:32.9066s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.794 â”‚ 0.749 â”‚ 0.792 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.693 â”‚ 0.638 â”‚ 0.695 â”‚ 0.745 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.812 â”‚ 0.72  â”‚ 0.808 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.813 â”‚ 0.818 â”‚ 0.816 â”‚ 0.805 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2113, ET: 0.2557, TC: 0.2136, WT: 0.1647
[0m
[0;32m2025-05-17 07:38:10,545  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.2113_dice0.7939_20250517073810.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:38:10,546  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-17 07:40:26,922  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-17 07:40:26,923  - INFO - - Train mean loss: 0.3122
- ET loss: 0.3568
- TC loss: 0.3404
- WT loss: 0.2395
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 07:40:26,923  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-17 07:40:59,155  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:32.2313s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.812 â”‚ 0.772 â”‚ 0.806 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.722 â”‚ 0.675 â”‚ 0.721 â”‚ 0.77  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.843 â”‚ 0.787 â”‚ 0.839 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.813 â”‚ 0.792 â”‚ 0.81  â”‚ 0.837 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1921, ET: 0.2323, TC: 0.1971, WT: 0.1468
[0m
[1;31m2025-05-17 07:40:59,158  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.2113_dice0.7939_20250517073810.pth[0m
[0;32m2025-05-17 07:40:59,211  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.1921_dice0.8117_20250517074059.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:40:59,211  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-17 07:43:16,913  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-17 07:43:16,915  - INFO - - Train mean loss: 0.2975
- ET loss: 0.3418
- TC loss: 0.3213
- WT loss: 0.2295
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 07:43:16,915  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-17 07:43:49,077  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:32.1604s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.78  â”‚ 0.751 â”‚ 0.767 â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.678 â”‚ 0.647 â”‚ 0.668 â”‚ 0.718 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.727 â”‚ 0.706 â”‚ 0.711 â”‚ 0.763 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.853 â”‚ 0.898 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2265, ET: 0.2544, TC: 0.2388, WT: 0.1862
[0m
[0;33m2025-05-17 07:43:49,077  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 07:43:49,077  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-17 07:46:07,267  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-17 07:46:07,268  - INFO - - Train mean loss: 0.2819
- ET loss: 0.3309
- TC loss: 0.3037
- WT loss: 0.2112
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 07:46:07,269  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-17 07:46:39,501  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:32.2314s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.817 â”‚ 0.779 â”‚ 0.809 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.731 â”‚ 0.686 â”‚ 0.726 â”‚ 0.78  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.806 â”‚ 0.867 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.801 â”‚ 0.785 â”‚ 0.794 â”‚ 0.826 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1854, ET: 0.2230, TC: 0.1928, WT: 0.1403
[0m
[1;31m2025-05-17 07:46:39,503  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.1921_dice0.8117_20250517074059.pth[0m
[0;32m2025-05-17 07:46:39,549  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.1854_dice0.8171_20250517074639.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:46:39,550  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-17 07:48:56,492  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-17 07:48:56,494  - INFO - - Train mean loss: 0.2719
- ET loss: 0.3210
- TC loss: 0.2908
- WT loss: 0.2041
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 07:48:56,494  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-17 07:49:28,794  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:32.2980s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.828 â”‚ 0.785 â”‚ 0.823 â”‚ 0.875 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.744 â”‚ 0.693 â”‚ 0.744 â”‚ 0.795 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.813 â”‚ 0.769 â”‚ 0.806 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.841 â”‚ 0.884 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1762, ET: 0.2177, TC: 0.1803, WT: 0.1307
[0m
[1;31m2025-05-17 07:49:28,796  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.1854_dice0.8171_20250517074639.pth[0m
[0;32m2025-05-17 07:49:28,841  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.1762_dice0.8278_20250517074928.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:49:28,842  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-17 07:51:46,323  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-17 07:51:46,324  - INFO - - Train mean loss: 0.2803
- ET loss: 0.3319
- TC loss: 0.3020
- WT loss: 0.2070
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 07:51:46,324  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-17 07:52:18,351  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:32.0259s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.822 â”‚ 0.771 â”‚ 0.817 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.734 â”‚ 0.671 â”‚ 0.735 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.788 â”‚ 0.714 â”‚ 0.783 â”‚ 0.869 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.88  â”‚ 0.901 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1821, ET: 0.2317, TC: 0.1856, WT: 0.1291
[0m
[0;33m2025-05-17 07:52:18,352  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 07:52:18,352  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-17 07:54:34,463  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-17 07:54:34,465  - INFO - - Train mean loss: 0.2672
- ET loss: 0.3139
- TC loss: 0.2841
- WT loss: 0.2037
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 07:54:34,465  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-17 07:55:06,781  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:32.3153s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.833 â”‚ 0.793 â”‚ 0.837 â”‚ 0.871 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.75  â”‚ 0.702 â”‚ 0.764 â”‚ 0.785 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.814 â”‚ 0.774 â”‚ 0.832 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.847 â”‚ 0.878 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1716, ET: 0.2100, TC: 0.1656, WT: 0.1392
[0m
[1;31m2025-05-17 07:55:06,783  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.1762_dice0.8278_20250517074928.pth[0m
[0;32m2025-05-17 07:55:06,829  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch8_loss0.1716_dice0.8335_20250517075506.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:55:06,829  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-17 07:57:25,953  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-17 07:57:25,954  - INFO - - Train mean loss: 0.2715
- ET loss: 0.3235
- TC loss: 0.2941
- WT loss: 0.1969
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 07:57:25,954  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-17 07:57:57,977  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:32.0212s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.832 â”‚ 0.796 â”‚ 0.817 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.751 â”‚ 0.707 â”‚ 0.738 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.823 â”‚ 0.778 â”‚ 0.789 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.849 â”‚ 0.901 â”‚ 0.884 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1705, ET: 0.2070, TC: 0.1854, WT: 0.1191
[0m
[1;31m2025-05-17 07:57:57,979  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.1716_dice0.8335_20250517075506.pth[0m
[0;32m2025-05-17 07:57:58,033  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.1705_dice0.8320_20250517075757.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 07:57:58,033  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-17 08:00:17,890  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-17 08:00:17,891  - INFO - - Train mean loss: 0.2590
- ET loss: 0.3066
- TC loss: 0.2687
- WT loss: 0.2017
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 08:00:17,891  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-17 08:00:50,235  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:32.3430s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.84  â”‚ 0.796 â”‚ 0.843 â”‚ 0.879 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.762 â”‚ 0.709 â”‚ 0.775 â”‚ 0.802 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.838 â”‚ 0.867 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.788 â”‚ 0.851 â”‚ 0.847 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1625, ET: 0.2057, TC: 0.1583, WT: 0.1236
[0m
[1;31m2025-05-17 08:00:50,238  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.1705_dice0.8320_20250517075757.pth[0m
[0;32m2025-05-17 08:00:50,294  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.1625_dice0.8397_20250517080050.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:00:50,295  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-17 08:03:08,268  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-17 08:03:08,269  - INFO - - Train mean loss: 0.2488
- ET loss: 0.2943
- TC loss: 0.2626
- WT loss: 0.1895
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 08:03:08,269  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-17 08:03:40,645  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:32.3743s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.844 â”‚ 0.802 â”‚ 0.844 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.767 â”‚ 0.715 â”‚ 0.776 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.865 â”‚ 0.805 â”‚ 0.872 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.85  â”‚ 0.832 â”‚ 0.85  â”‚ 0.869 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1587, ET: 0.2001, TC: 0.1572, WT: 0.1188
[0m
[1;31m2025-05-17 08:03:40,646  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.1625_dice0.8397_20250517080050.pth[0m
[0;32m2025-05-17 08:03:40,695  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.1587_dice0.8436_20250517080340.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:03:40,695  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-17 08:05:55,733  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-17 08:05:55,735  - INFO - - Train mean loss: 0.2348
- ET loss: 0.2846
- TC loss: 0.2468
- WT loss: 0.1732
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 08:05:55,735  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-17 08:06:28,393  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:32.6562s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.847 â”‚ 0.806 â”‚ 0.847 â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.772 â”‚ 0.721 â”‚ 0.78  â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.823 â”‚ 0.885 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚ 0.823 â”‚ 0.841 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1551, ET: 0.1961, TC: 0.1549, WT: 0.1142
[0m
[1;31m2025-05-17 08:06:28,395  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.1587_dice0.8436_20250517080340.pth[0m
[0;32m2025-05-17 08:06:28,449  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.1551_dice0.8471_20250517080628.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:06:28,449  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-17 08:08:40,691  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-17 08:08:40,692  - INFO - - Train mean loss: 0.2516
- ET loss: 0.3050
- TC loss: 0.2716
- WT loss: 0.1781
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 08:08:40,693  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-17 08:09:13,157  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:32.4640s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.851 â”‚ 0.81  â”‚ 0.851 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.775 â”‚ 0.725 â”‚ 0.783 â”‚ 0.818 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.823 â”‚ 0.884 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.83  â”‚ 0.851 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1512, ET: 0.1917, TC: 0.1511, WT: 0.1109
[0m
[1;31m2025-05-17 08:09:13,159  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.1551_dice0.8471_20250517080628.pth[0m
[0;32m2025-05-17 08:09:13,204  - INFO - âœ¨ Saved checkpoint (epoch 13) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.1512_dice0.8509_20250517080913.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:09:13,205  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-17 08:11:27,026  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-17 08:11:27,027  - INFO - - Train mean loss: 0.2517
- ET loss: 0.3005
- TC loss: 0.2676
- WT loss: 0.1871
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 08:11:27,027  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-17 08:11:59,242  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:32.2133s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.846 â”‚ 0.807 â”‚ 0.844 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.77  â”‚ 0.722 â”‚ 0.775 â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.876 â”‚ 0.814 â”‚ 0.886 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.839 â”‚ 0.824 â”‚ 0.829 â”‚ 0.865 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1562, ET: 0.1952, TC: 0.1583, WT: 0.1150
[0m
[0;33m2025-05-17 08:11:59,242  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 08:11:59,242  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-17 08:14:11,509  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-17 08:14:11,511  - INFO - - Train mean loss: 0.2558
- ET loss: 0.3080
- TC loss: 0.2719
- WT loss: 0.1874
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 08:14:11,511  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-17 08:14:43,965  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:32.4533s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.852 â”‚ 0.812 â”‚ 0.851 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.779 â”‚ 0.73  â”‚ 0.786 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.828 â”‚ 0.886 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.854 â”‚ 0.824 â”‚ 0.845 â”‚ 0.893 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1504, ET: 0.1896, TC: 0.1505, WT: 0.1111
[0m
[1;31m2025-05-17 08:14:43,967  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch13_loss0.1512_dice0.8509_20250517080913.pth[0m
[0;32m2025-05-17 08:14:44,021  - INFO - âœ¨ Saved checkpoint (epoch 15) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch15_loss0.1504_dice0.8517_20250517081443.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:14:44,021  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-17 08:16:56,271  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-17 08:16:56,273  - INFO - - Train mean loss: 0.2453
- ET loss: 0.2958
- TC loss: 0.2619
- WT loss: 0.1782
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 08:16:56,273  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-17 08:17:28,701  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:32.4264s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.815 â”‚ 0.856 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.784 â”‚ 0.734 â”‚ 0.793 â”‚ 0.827 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.871 â”‚ 0.828 â”‚ 0.88  â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.833 â”‚ 0.862 â”‚ 0.901 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1467, ET: 0.1868, TC: 0.1460, WT: 0.1073
[0m
[1;31m2025-05-17 08:17:28,703  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch15_loss0.1504_dice0.8517_20250517081443.pth[0m
[0;32m2025-05-17 08:17:28,757  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.1467_dice0.8554_20250517081728.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:17:28,758  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-17 08:19:40,785  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-17 08:19:40,787  - INFO - - Train mean loss: 0.2388
- ET loss: 0.2885
- TC loss: 0.2528
- WT loss: 0.1752
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 08:19:40,787  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-17 08:20:13,268  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:32.4795s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.848 â”‚ 0.81  â”‚ 0.843 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.774 â”‚ 0.726 â”‚ 0.776 â”‚ 0.82  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.839 â”‚ 0.909 â”‚ 0.936 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.83  â”‚ 0.812 â”‚ 0.814 â”‚ 0.864 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1540, ET: 0.1917, TC: 0.1587, WT: 0.1117
[0m
[0;33m2025-05-17 08:20:13,268  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 08:20:13,268  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-17 08:22:24,424  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-17 08:22:24,426  - INFO - - Train mean loss: 0.2371
- ET loss: 0.2840
- TC loss: 0.2557
- WT loss: 0.1715
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 08:22:24,426  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-17 08:22:56,726  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:32.2991s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.857 â”‚ 0.818 â”‚ 0.857 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.787 â”‚ 0.738 â”‚ 0.795 â”‚ 0.83  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.818 â”‚ 0.869 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.869 â”‚ 0.841 â”‚ 0.87  â”‚ 0.897 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1451, ET: 0.1841, TC: 0.1448, WT: 0.1064
[0m
[1;31m2025-05-17 08:22:56,729  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.1467_dice0.8554_20250517081728.pth[0m
[0;32m2025-05-17 08:22:56,783  - INFO - âœ¨ Saved checkpoint (epoch 18) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch18_loss0.1451_dice0.8570_20250517082256.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:22:56,784  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-17 08:25:09,854  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-17 08:25:09,856  - INFO - - Train mean loss: 0.2427
- ET loss: 0.2944
- TC loss: 0.2551
- WT loss: 0.1786
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 08:25:09,856  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-17 08:25:41,974  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:32.1173s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.854 â”‚ 0.813 â”‚ 0.853 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.782 â”‚ 0.731 â”‚ 0.789 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.863 â”‚ 0.814 â”‚ 0.87  â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.844 â”‚ 0.869 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1485, ET: 0.1891, TC: 0.1484, WT: 0.1080
[0m
[0;33m2025-05-17 08:25:41,974  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 08:25:41,974  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-17 08:27:59,621  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-17 08:27:59,623  - INFO - - Train mean loss: 0.2330
- ET loss: 0.2806
- TC loss: 0.2456
- WT loss: 0.1726
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 08:27:59,623  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-17 08:28:31,899  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:32.2754s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.847 â”‚ 0.806 â”‚ 0.837 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.776 â”‚ 0.725 â”‚ 0.773 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.859 â”‚ 0.901 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.831 â”‚ 0.791 â”‚ 0.814 â”‚ 0.887 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1548, ET: 0.1953, TC: 0.1638, WT: 0.1054
[0m
[0;33m2025-05-17 08:28:31,900  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 08:28:31,900  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-17 08:30:44,626  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-17 08:30:44,628  - INFO - - Train mean loss: 0.2431
- ET loss: 0.2933
- TC loss: 0.2608
- WT loss: 0.1751
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 08:30:44,628  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-17 08:31:17,092  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:32.4628s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.854 â”‚ 0.817 â”‚ 0.855 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.78  â”‚ 0.735 â”‚ 0.79  â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.842 â”‚ 0.891 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.863 â”‚ 0.817 â”‚ 0.847 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1481, ET: 0.1849, TC: 0.1463, WT: 0.1129
[0m
[0;33m2025-05-17 08:31:17,092  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 08:31:17,092  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-17 08:33:32,440  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-17 08:33:32,441  - INFO - - Train mean loss: 0.2282
- ET loss: 0.2796
- TC loss: 0.2417
- WT loss: 0.1632
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 08:33:32,442  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-17 08:34:04,805  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:32.3628s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.86  â”‚ 0.821 â”‚ 0.861 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.741 â”‚ 0.799 â”‚ 0.83  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.831 â”‚ 0.888 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.859 â”‚ 0.836 â”‚ 0.858 â”‚ 0.884 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1419, ET: 0.1804, TC: 0.1405, WT: 0.1048
[0m
[1;31m2025-05-17 08:34:04,807  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch18_loss0.1451_dice0.8570_20250517082256.pth[0m
[0;32m2025-05-17 08:34:05,193  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.1419_dice0.8598_20250517083404.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:34:05,194  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-17 08:36:15,552  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-17 08:36:15,554  - INFO - - Train mean loss: 0.2280
- ET loss: 0.2778
- TC loss: 0.2390
- WT loss: 0.1671
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 08:36:15,555  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-17 08:36:47,975  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:32.4196s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.856 â”‚ 0.818 â”‚ 0.852 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.786 â”‚ 0.738 â”‚ 0.787 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.854 â”‚ 0.809 â”‚ 0.834 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.854 â”‚ 0.899 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1455, ET: 0.1833, TC: 0.1492, WT: 0.1039
[0m
[0;33m2025-05-17 08:36:47,975  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 08:36:47,975  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-17 08:39:00,305  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-17 08:39:00,306  - INFO - - Train mean loss: 0.2426
- ET loss: 0.2930
- TC loss: 0.2555
- WT loss: 0.1793
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 08:39:00,306  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-17 08:39:32,607  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:32.3002s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.86  â”‚ 0.82  â”‚ 0.859 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.791 â”‚ 0.742 â”‚ 0.799 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.85  â”‚ 0.902 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.857 â”‚ 0.821 â”‚ 0.846 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1418, ET: 0.1813, TC: 0.1419, WT: 0.1022
[0m
[1;31m2025-05-17 08:39:32,610  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.1419_dice0.8598_20250517083404.pth[0m
[0;32m2025-05-17 08:39:32,664  - INFO - âœ¨ Saved checkpoint (epoch 24) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch24_loss0.1418_dice0.8596_20250517083932.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:39:32,664  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-17 08:41:44,947  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-17 08:41:44,948  - INFO - - Train mean loss: 0.2275
- ET loss: 0.2735
- TC loss: 0.2364
- WT loss: 0.1726
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 08:41:44,948  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-17 08:42:17,452  - INFO - === [Epoch 25/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:32.5030s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.824 â”‚ 0.867 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.795 â”‚ 0.744 â”‚ 0.805 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.823 â”‚ 0.873 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.852 â”‚ 0.884 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1373, ET: 0.1778, TC: 0.1346, WT: 0.0996
[0m
[1;31m2025-05-17 08:42:17,454  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch24_loss0.1418_dice0.8596_20250517083932.pth[0m
[0;32m2025-05-17 08:42:17,500  - INFO - âœ¨ Saved checkpoint (epoch 25) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch25_loss0.1373_dice0.8644_20250517084217.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 08:42:17,500  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-17 08:44:28,212  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-17 08:44:28,213  - INFO - - Train mean loss: 0.2351
- ET loss: 0.2867
- TC loss: 0.2481
- WT loss: 0.1705
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 08:44:28,213  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-17 08:45:01,221  - INFO - === [Epoch 26/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:33.0070s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.825 â”‚ 0.864 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.745 â”‚ 0.802 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.863 â”‚ 0.819 â”‚ 0.869 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.859 â”‚ 0.884 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1384, ET: 0.1769, TC: 0.1374, WT: 0.1008
[0m
[0;33m2025-05-17 08:45:01,221  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 08:45:01,221  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-17 08:47:10,764  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-17 08:47:10,766  - INFO - - Train mean loss: 0.2320
- ET loss: 0.2821
- TC loss: 0.2454
- WT loss: 0.1685
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-17 08:47:10,766  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-17 08:47:43,459  - INFO - === [Epoch 27/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:32.6918s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.826 â”‚ 0.867 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.795 â”‚ 0.748 â”‚ 0.807 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.862 â”‚ 0.82  â”‚ 0.874 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.863 â”‚ 0.886 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1377, ET: 0.1752, TC: 0.1345, WT: 0.1035
[0m
[0;33m2025-05-17 08:47:43,459  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 08:47:43,459  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-17 08:49:55,050  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-17 08:49:55,051  - INFO - - Train mean loss: 0.2238
- ET loss: 0.2727
- TC loss: 0.2348
- WT loss: 0.1638
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 08:49:55,051  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-17 08:50:28,531  - INFO - === [Epoch 28/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:33.4787s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.825 â”‚ 0.862 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.796 â”‚ 0.748 â”‚ 0.802 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.82  â”‚ 0.861 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.856 â”‚ 0.89  â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1382, ET: 0.1760, TC: 0.1390, WT: 0.0996
[0m
[0;33m2025-05-17 08:50:28,531  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 08:50:28,531  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-17 08:52:39,757  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-17 08:52:39,759  - INFO - - Train mean loss: 0.2151
- ET loss: 0.2627
- TC loss: 0.2207
- WT loss: 0.1617
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 08:52:39,759  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-17 08:53:12,931  - INFO - === [Epoch 29/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:33.1708s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.862 â”‚ 0.824 â”‚ 0.86  â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.795 â”‚ 0.748 â”‚ 0.8   â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.878 â”‚ 0.831 â”‚ 0.871 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.873 â”‚ 0.848 â”‚ 0.881 â”‚ 0.889 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1390, ET: 0.1770, TC: 0.1411, WT: 0.0990
[0m
[0;33m2025-05-17 08:53:12,931  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 08:53:12,931  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-17 08:55:25,923  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-17 08:55:25,925  - INFO - - Train mean loss: 0.2222
- ET loss: 0.2745
- TC loss: 0.2329
- WT loss: 0.1593
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 08:55:25,925  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-17 08:55:58,704  - INFO - === [Epoch 30/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:32.7785s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.826 â”‚ 0.864 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.75  â”‚ 0.806 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.838 â”‚ 0.889 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.845 â”‚ 0.871 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1374, ET: 0.1757, TC: 0.1371, WT: 0.0994
[0m
[0;33m2025-05-17 08:55:58,705  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 08:55:58,705  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-17 08:58:12,373  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-17 08:58:12,374  - INFO - - Train mean loss: 0.2241
- ET loss: 0.2734
- TC loss: 0.2333
- WT loss: 0.1655
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 08:58:12,375  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-17 08:58:44,651  - INFO - === [Epoch 31/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:32.2751s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.821 â”‚ 0.865 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.74  â”‚ 0.803 â”‚ 0.827 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.849 â”‚ 0.802 â”‚ 0.864 â”‚ 0.879 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.869 â”‚ 0.893 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1405, ET: 0.1807, TC: 0.1357, WT: 0.1050
[0m
[0;33m2025-05-17 08:58:44,651  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 08:58:44,651  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-17 09:00:55,346  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-17 09:00:55,347  - INFO - - Train mean loss: 0.2249
- ET loss: 0.2751
- TC loss: 0.2340
- WT loss: 0.1655
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 09:00:55,347  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-17 09:01:27,710  - INFO - === [Epoch 32/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:32.3612s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.828 â”‚ 0.865 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.753 â”‚ 0.808 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.843 â”‚ 0.894 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.844 â”‚ 0.867 â”‚ 0.898 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1348, ET: 0.1733, TC: 0.1355, WT: 0.0957
[0m
[1;31m2025-05-17 09:01:27,712  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch25_loss0.1373_dice0.8644_20250517084217.pth[0m
[0;32m2025-05-17 09:01:27,766  - INFO - âœ¨ Saved checkpoint (epoch 32) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch32_loss0.1348_dice0.8665_20250517090127.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:01:27,766  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-17 09:03:41,020  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-17 09:03:41,021  - INFO - - Train mean loss: 0.2263
- ET loss: 0.2812
- TC loss: 0.2404
- WT loss: 0.1575
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 09:03:41,021  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-17 09:04:13,294  - INFO - === [Epoch 33/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:32.2716s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.828 â”‚ 0.871 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.749 â”‚ 0.813 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.818 â”‚ 0.888 â”‚ 0.936 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.866 â”‚ 0.878 â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1329, ET: 0.1731, TC: 0.1301, WT: 0.0955
[0m
[1;31m2025-05-17 09:04:13,296  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch32_loss0.1348_dice0.8665_20250517090127.pth[0m
[0;32m2025-05-17 09:04:13,351  - INFO - âœ¨ Saved checkpoint (epoch 33) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch33_loss0.1329_dice0.8684_20250517090413.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:04:13,351  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-17 09:06:25,647  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-17 09:06:25,649  - INFO - - Train mean loss: 0.2165
- ET loss: 0.2667
- TC loss: 0.2287
- WT loss: 0.1543
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 09:06:25,649  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-17 09:06:57,980  - INFO - === [Epoch 34/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:32.3299s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.829 â”‚ 0.868 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.753 â”‚ 0.812 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.829 â”‚ 0.896 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.857 â”‚ 0.869 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1334, ET: 0.1723, TC: 0.1327, WT: 0.0952
[0m
[0;33m2025-05-17 09:06:57,980  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 09:06:57,980  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-17 09:09:11,912  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-17 09:09:11,913  - INFO - - Train mean loss: 0.2144
- ET loss: 0.2634
- TC loss: 0.2228
- WT loss: 0.1571
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 09:09:11,913  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-17 09:09:44,351  - INFO - === [Epoch 35/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:32.4360s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.829 â”‚ 0.869 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.753 â”‚ 0.813 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.854 â”‚ 0.897 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.865 â”‚ 0.832 â”‚ 0.868 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1335, ET: 0.1723, TC: 0.1314, WT: 0.0967
[0m
[0;33m2025-05-17 09:09:44,351  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 09:09:44,351  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-17 09:11:58,838  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-17 09:11:58,839  - INFO - - Train mean loss: 0.2046
- ET loss: 0.2539
- TC loss: 0.2130
- WT loss: 0.1468
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 09:11:58,839  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-17 09:12:31,542  - INFO - === [Epoch 36/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:32.7017s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.828 â”‚ 0.867 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.753 â”‚ 0.811 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.902 â”‚ 0.862 â”‚ 0.907 â”‚ 0.939 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.859 â”‚ 0.827 â”‚ 0.858 â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1338, ET: 0.1731, TC: 0.1335, WT: 0.0946
[0m
[0;33m2025-05-17 09:12:31,542  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 09:12:31,542  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-17 09:14:46,801  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-17 09:14:46,803  - INFO - - Train mean loss: 0.2256
- ET loss: 0.2745
- TC loss: 0.2373
- WT loss: 0.1650
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 09:14:46,803  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-17 09:15:18,975  - INFO - === [Epoch 37/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:32.1708s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.832 â”‚ 0.869 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.756 â”‚ 0.811 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.871 â”‚ 0.834 â”‚ 0.88  â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.857 â”‚ 0.887 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1321, ET: 0.1693, TC: 0.1317, WT: 0.0953
[0m
[1;31m2025-05-17 09:15:18,977  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch33_loss0.1329_dice0.8684_20250517090413.pth[0m
[0;32m2025-05-17 09:15:19,032  - INFO - âœ¨ Saved checkpoint (epoch 37) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch37_loss0.1321_dice0.8693_20250517091518.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:15:19,032  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-17 09:17:33,349  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-17 09:17:33,351  - INFO - - Train mean loss: 0.2172
- ET loss: 0.2675
- TC loss: 0.2302
- WT loss: 0.1538
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 09:17:33,351  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-17 09:18:04,722  - INFO - === [Epoch 38/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:31.3698s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.83  â”‚ 0.866 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.755 â”‚ 0.811 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.844 â”‚ 0.897 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.845 â”‚ 0.869 â”‚ 0.887 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1351, ET: 0.1715, TC: 0.1342, WT: 0.0996
[0m
[0;33m2025-05-17 09:18:04,722  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 09:18:04,722  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-17 09:20:16,632  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-17 09:20:16,633  - INFO - - Train mean loss: 0.2327
- ET loss: 0.2834
- TC loss: 0.2447
- WT loss: 0.1698
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 09:20:16,633  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-17 09:20:48,497  - INFO - === [Epoch 39/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:31.8631s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.831 â”‚ 0.871 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.755 â”‚ 0.814 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.825 â”‚ 0.89  â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.863 â”‚ 0.877 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1319, ET: 0.1699, TC: 0.1298, WT: 0.0959
[0m
[1;31m2025-05-17 09:20:48,500  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch37_loss0.1321_dice0.8693_20250517091518.pth[0m
[0;32m2025-05-17 09:20:48,554  - INFO - âœ¨ Saved checkpoint (epoch 39) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch39_loss0.1319_dice0.8693_20250517092048.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:20:48,555  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-17 09:22:59,638  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-17 09:22:59,639  - INFO - - Train mean loss: 0.2012
- ET loss: 0.2454
- TC loss: 0.2049
- WT loss: 0.1534
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 09:22:59,639  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-17 09:23:30,806  - INFO - === [Epoch 40/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:31.1655s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.846 â”‚ 0.812 â”‚ 0.853 â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.769 â”‚ 0.727 â”‚ 0.787 â”‚ 0.793 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.823 â”‚ 0.793 â”‚ 0.842 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.863 â”‚ 0.897 â”‚ 0.941 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1559, ET: 0.1897, TC: 0.1483, WT: 0.1298
[0m
[0;33m2025-05-17 09:23:30,806  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 09:23:30,806  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-17 09:25:41,811  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-17 09:25:41,813  - INFO - - Train mean loss: 0.2176
- ET loss: 0.2684
- TC loss: 0.2293
- WT loss: 0.1551
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 09:25:41,813  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-17 09:26:13,235  - INFO - === [Epoch 41/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:31.4211s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.826 â”‚ 0.867 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.746 â”‚ 0.806 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.855 â”‚ 0.805 â”‚ 0.857 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.879 â”‚ 0.905 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1346, ET: 0.1751, TC: 0.1341, WT: 0.0946
[0m
[0;33m2025-05-17 09:26:13,235  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 09:26:13,236  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-17 09:28:27,112  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-17 09:28:27,113  - INFO - - Train mean loss: 0.2243
- ET loss: 0.2736
- TC loss: 0.2405
- WT loss: 0.1588
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 09:28:27,113  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-17 09:28:58,511  - INFO - === [Epoch 42/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:31.3971s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.828 â”‚ 0.87  â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.753 â”‚ 0.816 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.838 â”‚ 0.894 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.851 â”‚ 0.874 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1328, ET: 0.1732, TC: 0.1305, WT: 0.0948
[0m
[0;33m2025-05-17 09:28:58,512  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 09:28:58,512  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-17 09:31:12,496  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-17 09:31:12,497  - INFO - - Train mean loss: 0.2181
- ET loss: 0.2700
- TC loss: 0.2293
- WT loss: 0.1551
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 09:31:12,497  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-17 09:31:43,613  - INFO - === [Epoch 43/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:31.1142s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.828 â”‚ 0.866 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.798 â”‚ 0.751 â”‚ 0.807 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.856 â”‚ 0.814 â”‚ 0.861 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.872 â”‚ 0.903 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1353, ET: 0.1732, TC: 0.1348, WT: 0.0980
[0m
[0;33m2025-05-17 09:31:43,613  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 09:31:43,613  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-17 09:33:57,210  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-17 09:33:57,212  - INFO - - Train mean loss: 0.2083
- ET loss: 0.2548
- TC loss: 0.2142
- WT loss: 0.1560
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 09:33:57,212  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-17 09:34:28,732  - INFO - === [Epoch 44/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:31.5186s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.832 â”‚ 0.867 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.758 â”‚ 0.812 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.843 â”‚ 0.905 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.85  â”‚ 0.86  â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1316, ET: 0.1690, TC: 0.1332, WT: 0.0927
[0m
[1;31m2025-05-17 09:34:28,733  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch39_loss0.1319_dice0.8693_20250517092048.pth[0m
[0;32m2025-05-17 09:34:28,777  - INFO - âœ¨ Saved checkpoint (epoch 44) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch44_loss0.1316_dice0.8696_20250517093428.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:34:28,777  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-17 09:36:44,599  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-17 09:36:44,600  - INFO - - Train mean loss: 0.2089
- ET loss: 0.2569
- TC loss: 0.2191
- WT loss: 0.1508
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 09:36:44,600  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-17 09:37:15,987  - INFO - === [Epoch 45/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:31.3857s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.827 â”‚ 0.867 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.752 â”‚ 0.811 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.859 â”‚ 0.904 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.871 â”‚ 0.828 â”‚ 0.858 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1334, ET: 0.1740, TC: 0.1336, WT: 0.0927
[0m
[0;33m2025-05-17 09:37:15,987  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 09:37:15,987  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-17 09:39:27,037  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-17 09:39:27,039  - INFO - - Train mean loss: 0.2114
- ET loss: 0.2639
- TC loss: 0.2217
- WT loss: 0.1487
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 09:39:27,039  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-17 09:39:58,493  - INFO - === [Epoch 46/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:31.4530s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.825 â”‚ 0.868 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.749 â”‚ 0.811 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.82  â”‚ 0.871 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.864 â”‚ 0.892 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1345, ET: 0.1759, TC: 0.1328, WT: 0.0947
[0m
[0;33m2025-05-17 09:39:58,493  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 09:39:58,493  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-17 09:42:13,263  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-17 09:42:13,264  - INFO - - Train mean loss: 0.2173
- ET loss: 0.2707
- TC loss: 0.2318
- WT loss: 0.1494
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 09:42:13,264  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-17 09:42:45,091  - INFO - === [Epoch 47/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:31.8262s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.834 â”‚ 0.869 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.76  â”‚ 0.813 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.849 â”‚ 0.893 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.846 â”‚ 0.872 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1307, ET: 0.1676, TC: 0.1321, WT: 0.0923
[0m
[1;31m2025-05-17 09:42:45,093  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch44_loss0.1316_dice0.8696_20250517093428.pth[0m
[0;32m2025-05-17 09:42:45,138  - INFO - âœ¨ Saved checkpoint (epoch 47) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch47_loss0.1307_dice0.8706_20250517094245.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:42:45,139  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-17 09:44:59,597  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-17 09:44:59,598  - INFO - - Train mean loss: 0.2058
- ET loss: 0.2527
- TC loss: 0.2162
- WT loss: 0.1484
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 09:44:59,598  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-17 09:45:31,026  - INFO - === [Epoch 48/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:31.4268s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.836 â”‚ 0.873 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.762 â”‚ 0.818 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.847 â”‚ 0.893 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.849 â”‚ 0.88  â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1281, ET: 0.1656, TC: 0.1277, WT: 0.0909
[0m
[1;31m2025-05-17 09:45:31,028  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch47_loss0.1307_dice0.8706_20250517094245.pth[0m
[0;32m2025-05-17 09:45:31,073  - INFO - âœ¨ Saved checkpoint (epoch 48) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch48_loss0.1281_dice0.8733_20250517094531.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:45:31,073  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-17 09:47:46,332  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-17 09:47:46,333  - INFO - - Train mean loss: 0.2079
- ET loss: 0.2554
- TC loss: 0.2147
- WT loss: 0.1535
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 09:47:46,333  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-17 09:48:17,594  - INFO - === [Epoch 49/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:31.2600s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.834 â”‚ 0.872 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.761 â”‚ 0.819 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.847 â”‚ 0.899 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.847 â”‚ 0.873 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1292, ET: 0.1668, TC: 0.1283, WT: 0.0925
[0m
[0;33m2025-05-17 09:48:17,595  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 09:48:17,595  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-17 09:50:34,452  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-17 09:50:34,453  - INFO - - Train mean loss: 0.2157
- ET loss: 0.2676
- TC loss: 0.2240
- WT loss: 0.1555
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 09:50:34,454  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-17 09:51:05,466  - INFO - === [Epoch 50/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:31.0109s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.831 â”‚ 0.869 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.758 â”‚ 0.814 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.853 â”‚ 0.901 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.839 â”‚ 0.867 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1324, ET: 0.1704, TC: 0.1320, WT: 0.0948
[0m
[0;33m2025-05-17 09:51:05,466  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 09:51:05,466  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-17 09:53:19,943  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-17 09:53:19,945  - INFO - - Train mean loss: 0.2098
- ET loss: 0.2611
- TC loss: 0.2200
- WT loss: 0.1481
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 09:53:19,945  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-17 09:53:51,076  - INFO - === [Epoch 51/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:31.1305s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.835 â”‚ 0.876 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.761 â”‚ 0.822 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.829 â”‚ 0.888 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.867 â”‚ 0.889 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1285, ET: 0.1661, TC: 0.1244, WT: 0.0950
[0m
[0;33m2025-05-17 09:53:51,077  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 09:53:51,077  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-17 09:56:05,129  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-17 09:56:05,131  - INFO - - Train mean loss: 0.2206
- ET loss: 0.2701
- TC loss: 0.2370
- WT loss: 0.1548
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 09:56:05,131  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-17 09:56:36,961  - INFO - === [Epoch 52/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:31.8296s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.833 â”‚ 0.873 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.76  â”‚ 0.819 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.841 â”‚ 0.894 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.853 â”‚ 0.879 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1291, ET: 0.1683, TC: 0.1274, WT: 0.0916
[0m
[0;33m2025-05-17 09:56:36,962  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 09:56:36,962  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-17 09:58:51,841  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-17 09:58:51,843  - INFO - - Train mean loss: 0.2063
- ET loss: 0.2559
- TC loss: 0.2173
- WT loss: 0.1456
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 09:58:51,843  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-17 09:59:23,157  - INFO - === [Epoch 53/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:31.3130s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.836 â”‚ 0.874 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.763 â”‚ 0.821 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.854 â”‚ 0.904 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.843 â”‚ 0.871 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1270, ET: 0.1652, TC: 0.1263, WT: 0.0895
[0m
[1;31m2025-05-17 09:59:23,159  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch48_loss0.1281_dice0.8733_20250517094531.pth[0m
[0;32m2025-05-17 09:59:23,220  - INFO - âœ¨ Saved checkpoint (epoch 53) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch53_loss0.1270_dice0.8742_20250517095923.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 09:59:23,220  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-17 10:01:37,035  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-17 10:01:37,036  - INFO - - Train mean loss: 0.2052
- ET loss: 0.2530
- TC loss: 0.2135
- WT loss: 0.1491
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 10:01:37,037  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-17 10:02:08,529  - INFO - === [Epoch 54/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:31.4912s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.833 â”‚ 0.871 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.758 â”‚ 0.815 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.824 â”‚ 0.871 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.868 â”‚ 0.9   â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1292, ET: 0.1682, TC: 0.1295, WT: 0.0899
[0m
[0;33m2025-05-17 10:02:08,529  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 10:02:08,529  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-17 10:04:23,503  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-17 10:04:23,504  - INFO - - Train mean loss: 0.2007
- ET loss: 0.2527
- TC loss: 0.2132
- WT loss: 0.1363
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 10:04:23,505  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-17 10:04:54,717  - INFO - === [Epoch 55/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:31.2117s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.835 â”‚ 0.874 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.762 â”‚ 0.819 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.84  â”‚ 0.888 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.854 â”‚ 0.885 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1278, ET: 0.1663, TC: 0.1264, WT: 0.0907
[0m
[0;33m2025-05-17 10:04:54,717  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 10:04:54,717  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-17 10:07:08,767  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-17 10:07:08,768  - INFO - - Train mean loss: 0.2039
- ET loss: 0.2560
- TC loss: 0.2155
- WT loss: 0.1403
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 10:07:08,768  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-17 10:07:40,411  - INFO - === [Epoch 56/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:31.6420s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.835 â”‚ 0.873 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.76  â”‚ 0.818 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.836 â”‚ 0.893 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.858 â”‚ 0.879 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1290, ET: 0.1665, TC: 0.1278, WT: 0.0927
[0m
[0;33m2025-05-17 10:07:40,411  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 10:07:40,411  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-17 10:09:54,679  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-17 10:09:54,682  - INFO - - Train mean loss: 0.2059
- ET loss: 0.2569
- TC loss: 0.2130
- WT loss: 0.1480
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 10:09:54,682  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-17 10:10:26,286  - INFO - === [Epoch 57/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:31.6020s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.832 â”‚ 0.867 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.758 â”‚ 0.809 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.821 â”‚ 0.861 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.867 â”‚ 0.9   â”‚ 0.901 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1332, ET: 0.1692, TC: 0.1342, WT: 0.0962
[0m
[0;33m2025-05-17 10:10:26,286  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 10:10:26,287  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-17 10:12:39,796  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-17 10:12:39,798  - INFO - - Train mean loss: 0.2021
- ET loss: 0.2500
- TC loss: 0.2088
- WT loss: 0.1475
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 10:12:39,798  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-17 10:13:11,100  - INFO - === [Epoch 58/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:31.3010s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.835 â”‚ 0.873 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.762 â”‚ 0.819 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.878 â”‚ 0.843 â”‚ 0.892 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.857 â”‚ 0.885 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1285, ET: 0.1659, TC: 0.1274, WT: 0.0924
[0m
[0;33m2025-05-17 10:13:11,100  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 10:13:11,100  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-17 10:15:22,859  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-17 10:15:22,861  - INFO - - Train mean loss: 0.2094
- ET loss: 0.2626
- TC loss: 0.2208
- WT loss: 0.1448
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 10:15:22,861  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-17 10:15:54,374  - INFO - === [Epoch 59/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:31.5116s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.832 â”‚ 0.873 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.76  â”‚ 0.82  â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.839 â”‚ 0.891 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.852 â”‚ 0.879 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1286, ET: 0.1688, TC: 0.1274, WT: 0.0896
[0m
[0;33m2025-05-17 10:15:54,374  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 10:15:54,374  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-17 10:18:05,438  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-17 10:18:05,440  - INFO - - Train mean loss: 0.2073
- ET loss: 0.2552
- TC loss: 0.2148
- WT loss: 0.1518
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 10:18:05,440  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-17 10:18:35,655  - INFO - === [Epoch 60/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:30.2136s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.876 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.765 â”‚ 0.822 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.846 â”‚ 0.889 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.853 â”‚ 0.889 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1257, ET: 0.1638, TC: 0.1250, WT: 0.0883
[0m
[1;31m2025-05-17 10:18:35,658  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch53_loss0.1270_dice0.8742_20250517095923.pth[0m
[0;32m2025-05-17 10:18:35,713  - INFO - âœ¨ Saved checkpoint (epoch 60) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch60_loss0.1257_dice0.8753_20250517101835.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 10:18:35,714  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-17 10:20:47,186  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-17 10:20:47,187  - INFO - - Train mean loss: 0.2112
- ET loss: 0.2657
- TC loss: 0.2209
- WT loss: 0.1470
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 10:20:47,187  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-17 10:21:18,507  - INFO - === [Epoch 61/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:31.3190s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.835 â”‚ 0.875 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.764 â”‚ 0.821 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.846 â”‚ 0.896 â”‚ 0.936 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.851 â”‚ 0.879 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1272, ET: 0.1657, TC: 0.1262, WT: 0.0898
[0m
[0;33m2025-05-17 10:21:18,508  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 10:21:18,508  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-17 10:23:29,852  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-17 10:23:29,854  - INFO - - Train mean loss: 0.1993
- ET loss: 0.2444
- TC loss: 0.2008
- WT loss: 0.1526
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 10:23:29,854  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-17 10:24:00,655  - INFO - === [Epoch 62/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:30.7990s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.836 â”‚ 0.877 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.762 â”‚ 0.823 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.829 â”‚ 0.892 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.869 â”‚ 0.887 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1254, ET: 0.1649, TC: 0.1234, WT: 0.0880
[0m
[1;31m2025-05-17 10:24:00,657  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch60_loss0.1257_dice0.8753_20250517101835.pth[0m
[0;32m2025-05-17 10:24:00,711  - INFO - âœ¨ Saved checkpoint (epoch 62) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch62_loss0.1254_dice0.8755_20250517102400.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 10:24:00,712  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-17 10:26:12,650  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-17 10:26:12,652  - INFO - - Train mean loss: 0.2036
- ET loss: 0.2573
- TC loss: 0.2140
- WT loss: 0.1394
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 10:26:12,652  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-17 10:26:43,628  - INFO - === [Epoch 63/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:30.9744s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.834 â”‚ 0.875 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.761 â”‚ 0.821 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.837 â”‚ 0.893 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.859 â”‚ 0.882 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1268, ET: 0.1666, TC: 0.1257, WT: 0.0880
[0m
[0;33m2025-05-17 10:26:43,628  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 10:26:43,628  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-17 10:28:54,583  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-17 10:28:54,585  - INFO - - Train mean loss: 0.1990
- ET loss: 0.2543
- TC loss: 0.2092
- WT loss: 0.1335
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 10:28:54,585  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-17 10:29:24,882  - INFO - === [Epoch 64/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:30.2964s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.836 â”‚ 0.877 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.764 â”‚ 0.824 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.841 â”‚ 0.897 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.859 â”‚ 0.882 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1256, ET: 0.1646, TC: 0.1239, WT: 0.0882
[0m
[0;33m2025-05-17 10:29:24,883  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 10:29:24,883  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-17 10:31:36,206  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-17 10:31:36,209  - INFO - - Train mean loss: 0.1960
- ET loss: 0.2450
- TC loss: 0.2036
- WT loss: 0.1395
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 10:31:36,209  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-17 10:32:07,761  - INFO - === [Epoch 65/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:31.5505s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.838 â”‚ 0.877 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.766 â”‚ 0.825 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.844 â”‚ 0.896 â”‚ 0.94  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.853 â”‚ 0.88  â”‚ 0.901 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1251, ET: 0.1634, TC: 0.1236, WT: 0.0881
[0m
[1;31m2025-05-17 10:32:07,764  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch62_loss0.1254_dice0.8755_20250517102400.pth[0m
[0;32m2025-05-17 10:32:07,813  - INFO - âœ¨ Saved checkpoint (epoch 65) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch65_loss0.1251_dice0.8760_20250517103207.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 10:32:07,814  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-17 10:34:21,325  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-17 10:34:21,327  - INFO - - Train mean loss: 0.2099
- ET loss: 0.2614
- TC loss: 0.2181
- WT loss: 0.1502
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 10:34:21,327  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-17 10:34:53,049  - INFO - === [Epoch 66/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:31.7207s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.836 â”‚ 0.875 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.763 â”‚ 0.822 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.837 â”‚ 0.893 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.862 â”‚ 0.885 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1273, ET: 0.1654, TC: 0.1252, WT: 0.0913
[0m
[0;33m2025-05-17 10:34:53,049  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 10:34:53,049  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-17 10:37:08,268  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-17 10:37:08,271  - INFO - - Train mean loss: 0.2023
- ET loss: 0.2545
- TC loss: 0.2136
- WT loss: 0.1388
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 10:37:08,271  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-17 10:37:38,929  - INFO - === [Epoch 67/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:30.6565s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.836 â”‚ 0.877 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.764 â”‚ 0.824 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.838 â”‚ 0.891 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.862 â”‚ 0.889 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1251, ET: 0.1647, TC: 0.1231, WT: 0.0873
[0m
[1;31m2025-05-17 10:37:38,932  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch65_loss0.1251_dice0.8760_20250517103207.pth[0m
[0;32m2025-05-17 10:37:38,980  - INFO - âœ¨ Saved checkpoint (epoch 67) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch67_loss0.1251_dice0.8760_20250517103738.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 10:37:38,980  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-17 10:39:55,965  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-17 10:39:55,967  - INFO - - Train mean loss: 0.1953
- ET loss: 0.2435
- TC loss: 0.2041
- WT loss: 0.1384
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 10:39:55,967  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-17 10:40:27,186  - INFO - === [Epoch 68/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:31.2170s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.834 â”‚ 0.876 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.762 â”‚ 0.824 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.839 â”‚ 0.897 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.851 â”‚ 0.874 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1264, ET: 0.1667, TC: 0.1240, WT: 0.0884
[0m
[0;33m2025-05-17 10:40:27,186  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 10:40:27,186  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-17 10:42:40,054  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-17 10:42:40,055  - INFO - - Train mean loss: 0.2122
- ET loss: 0.2639
- TC loss: 0.2222
- WT loss: 0.1505
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 10:42:40,055  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-17 10:43:11,118  - INFO - === [Epoch 69/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:31.0626s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.839 â”‚ 0.874 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.767 â”‚ 0.819 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.85  â”‚ 0.88  â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.849 â”‚ 0.889 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1254, ET: 0.1625, TC: 0.1270, WT: 0.0867
[0m
[0;33m2025-05-17 10:43:11,119  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 10:43:11,119  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-17 10:45:22,894  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-17 10:45:22,895  - INFO - - Train mean loss: 0.2019
- ET loss: 0.2543
- TC loss: 0.2081
- WT loss: 0.1431
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 10:45:22,895  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-17 10:45:53,529  - INFO - === [Epoch 70/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:30.6324s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.875 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.763 â”‚ 0.82  â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.828 â”‚ 0.869 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.873 â”‚ 0.909 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1263, ET: 0.1639, TC: 0.1253, WT: 0.0897
[0m
[0;33m2025-05-17 10:45:53,529  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 10:45:53,529  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-17 10:48:03,384  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-17 10:48:03,385  - INFO - - Train mean loss: 0.2053
- ET loss: 0.2590
- TC loss: 0.2145
- WT loss: 0.1425
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-17 10:48:03,385  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-17 10:48:34,117  - INFO - === [Epoch 71/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:30.7290s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.871 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.764 â”‚ 0.815 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.871 â”‚ 0.832 â”‚ 0.863 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.865 â”‚ 0.903 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1272, ET: 0.1643, TC: 0.1296, WT: 0.0877
[0m
[0;33m2025-05-17 10:48:34,117  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 10:48:34,117  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-17 10:50:46,560  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-17 10:50:46,561  - INFO - - Train mean loss: 0.2037
- ET loss: 0.2575
- TC loss: 0.2125
- WT loss: 0.1410
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 10:50:46,561  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-17 10:51:17,611  - INFO - === [Epoch 72/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:31.0487s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.836 â”‚ 0.877 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.764 â”‚ 0.824 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.849 â”‚ 0.897 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.85  â”‚ 0.882 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1255, ET: 0.1651, TC: 0.1240, WT: 0.0874
[0m
[0;33m2025-05-17 10:51:17,611  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 10:51:17,611  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-17 10:53:28,449  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-17 10:53:28,450  - INFO - - Train mean loss: 0.1964
- ET loss: 0.2484
- TC loss: 0.2058
- WT loss: 0.1349
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 10:53:28,450  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-17 10:54:00,977  - INFO - === [Epoch 73/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:32.5256s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.835 â”‚ 0.875 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.763 â”‚ 0.822 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.835 â”‚ 0.879 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.86  â”‚ 0.893 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1259, ET: 0.1661, TC: 0.1257, WT: 0.0858
[0m
[0;33m2025-05-17 10:54:00,977  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 10:54:00,977  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-17 10:56:10,270  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-17 10:56:10,272  - INFO - - Train mean loss: 0.2010
- ET loss: 0.2515
- TC loss: 0.2113
- WT loss: 0.1402
- Cost time: 2.15mins â±ï¸
[0m
[0;32m2025-05-17 10:56:10,272  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-17 10:56:42,115  - INFO - === [Epoch 74/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:31.8420s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.872 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.765 â”‚ 0.818 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.849 â”‚ 0.888 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.85  â”‚ 0.887 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1263, ET: 0.1645, TC: 0.1289, WT: 0.0854
[0m
[0;33m2025-05-17 10:56:42,115  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 10:56:42,115  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-17 10:58:52,026  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-17 10:58:52,027  - INFO - - Train mean loss: 0.1987
- ET loss: 0.2489
- TC loss: 0.2070
- WT loss: 0.1402
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 10:58:52,027  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-17 10:59:24,222  - INFO - === [Epoch 75/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:32.1938s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.836 â”‚ 0.878 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.763 â”‚ 0.825 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.829 â”‚ 0.892 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.869 â”‚ 0.888 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1244, ET: 0.1645, TC: 0.1225, WT: 0.0863
[0m
[1;31m2025-05-17 10:59:24,225  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch67_loss0.1251_dice0.8760_20250517103738.pth[0m
[0;32m2025-05-17 10:59:24,280  - INFO - âœ¨ Saved checkpoint (epoch 75) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch75_loss0.1244_dice0.8766_20250517105924.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 10:59:24,280  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-17 11:01:32,267  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-17 11:01:32,269  - INFO - - Train mean loss: 0.2082
- ET loss: 0.2642
- TC loss: 0.2193
- WT loss: 0.1410
- Cost time: 2.13mins â±ï¸
[0m
[0;32m2025-05-17 11:01:32,269  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-17 11:02:03,847  - INFO - === [Epoch 76/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:31.5768s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.876 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.765 â”‚ 0.822 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.84  â”‚ 0.883 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.861 â”‚ 0.894 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1257, ET: 0.1638, TC: 0.1251, WT: 0.0882
[0m
[0;33m2025-05-17 11:02:03,847  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 11:02:03,847  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-17 11:04:14,652  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-17 11:04:14,654  - INFO - - Train mean loss: 0.1937
- ET loss: 0.2411
- TC loss: 0.1976
- WT loss: 0.1425
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 11:04:14,654  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-17 11:04:46,488  - INFO - === [Epoch 77/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:31.8335s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.836 â”‚ 0.877 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.765 â”‚ 0.825 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.848 â”‚ 0.9   â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.848 â”‚ 0.875 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1247, ET: 0.1649, TC: 0.1240, WT: 0.0853
[0m
[0;33m2025-05-17 11:04:46,488  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 11:04:46,488  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-17 11:06:56,431  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-17 11:06:56,433  - INFO - - Train mean loss: 0.1978
- ET loss: 0.2471
- TC loss: 0.2050
- WT loss: 0.1414
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 11:06:56,433  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-17 11:07:28,747  - INFO - === [Epoch 78/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:32.3134s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.838 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.767 â”‚ 0.826 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.845 â”‚ 0.898 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.857 â”‚ 0.883 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1236, ET: 0.1628, TC: 0.1226, WT: 0.0855
[0m
[1;31m2025-05-17 11:07:28,750  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch75_loss0.1244_dice0.8766_20250517105924.pth[0m
[0;32m2025-05-17 11:07:28,806  - INFO - âœ¨ Saved checkpoint (epoch 78) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch78_loss0.1236_dice0.8774_20250517110728.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:07:28,807  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-17 11:09:38,462  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-17 11:09:38,463  - INFO - - Train mean loss: 0.1923
- ET loss: 0.2440
- TC loss: 0.1994
- WT loss: 0.1336
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-17 11:09:38,463  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-17 11:10:10,808  - INFO - === [Epoch 79/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:32.3432s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.836 â”‚ 0.876 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.765 â”‚ 0.823 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.847 â”‚ 0.892 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.853 â”‚ 0.886 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1256, ET: 0.1652, TC: 0.1248, WT: 0.0868
[0m
[0;33m2025-05-17 11:10:10,808  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 11:10:10,808  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-17 11:12:17,976  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-17 11:12:17,978  - INFO - - Train mean loss: 0.2016
- ET loss: 0.2518
- TC loss: 0.2086
- WT loss: 0.1443
- Cost time: 2.12mins â±ï¸
[0m
[0;32m2025-05-17 11:12:17,978  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-17 11:12:50,058  - INFO - === [Epoch 80/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:32.0787s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.838 â”‚ 0.879 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.767 â”‚ 0.827 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.845 â”‚ 0.899 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.856 â”‚ 0.882 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1233, ET: 0.1625, TC: 0.1215, WT: 0.0860
[0m
[1;31m2025-05-17 11:12:50,060  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch78_loss0.1236_dice0.8774_20250517110728.pth[0m
[0;32m2025-05-17 11:12:50,108  - INFO - âœ¨ Saved checkpoint (epoch 80) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch80_loss0.1233_dice0.8777_20250517111250.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:12:50,109  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-17 11:15:01,573  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-17 11:15:01,575  - INFO - - Train mean loss: 0.1988
- ET loss: 0.2461
- TC loss: 0.2065
- WT loss: 0.1437
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 11:15:01,575  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-17 11:15:33,962  - INFO - === [Epoch 81/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:32.3869s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.879 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.848 â”‚ 0.898 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.855 â”‚ 0.884 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1230, ET: 0.1611, TC: 0.1215, WT: 0.0863
[0m
[1;31m2025-05-17 11:15:33,964  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch80_loss0.1233_dice0.8777_20250517111250.pth[0m
[0;32m2025-05-17 11:15:34,010  - INFO - âœ¨ Saved checkpoint (epoch 81) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch81_loss0.1230_dice0.8780_20250517111533.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:15:34,010  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-17 11:17:44,775  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-17 11:17:44,776  - INFO - - Train mean loss: 0.1928
- ET loss: 0.2444
- TC loss: 0.1986
- WT loss: 0.1355
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 11:17:44,776  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-17 11:18:16,635  - INFO - === [Epoch 82/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:31.8579s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.838 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.767 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.849 â”‚ 0.891 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.854 â”‚ 0.89  â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1233, ET: 0.1626, TC: 0.1221, WT: 0.0853
[0m
[0;33m2025-05-17 11:18:16,635  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 11:18:16,635  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-17 11:20:24,991  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-17 11:20:24,992  - INFO - - Train mean loss: 0.1925
- ET loss: 0.2425
- TC loss: 0.1983
- WT loss: 0.1367
- Cost time: 2.14mins â±ï¸
[0m
[0;32m2025-05-17 11:20:24,992  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-17 11:20:57,463  - INFO - === [Epoch 83/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:32.4700s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.839 â”‚ 0.879 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.827 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.844 â”‚ 0.897 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.859 â”‚ 0.885 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1234, ET: 0.1618, TC: 0.1217, WT: 0.0867
[0m
[0;33m2025-05-17 11:20:57,463  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 11:20:57,463  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-17 11:23:08,679  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-17 11:23:08,681  - INFO - - Train mean loss: 0.1987
- ET loss: 0.2509
- TC loss: 0.2060
- WT loss: 0.1394
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 11:23:08,681  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-17 11:23:41,524  - INFO - === [Epoch 84/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:32.8424s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.839 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.85  â”‚ 0.893 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.854 â”‚ 0.888 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1231, ET: 0.1616, TC: 0.1224, WT: 0.0852
[0m
[0;33m2025-05-17 11:23:41,524  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 11:23:41,525  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-17 11:25:51,201  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-17 11:25:51,202  - INFO - - Train mean loss: 0.1945
- ET loss: 0.2455
- TC loss: 0.2011
- WT loss: 0.1368
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-17 11:25:51,202  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-17 11:26:23,188  - INFO - === [Epoch 85/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:31.9850s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.839 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.846 â”‚ 0.895 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.856 â”‚ 0.886 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1232, ET: 0.1621, TC: 0.1223, WT: 0.0854
[0m
[0;33m2025-05-17 11:26:23,189  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 11:26:23,189  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-17 11:28:33,522  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-17 11:28:33,523  - INFO - - Train mean loss: 0.1932
- ET loss: 0.2453
- TC loss: 0.1957
- WT loss: 0.1387
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 11:28:33,523  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-17 11:29:05,845  - INFO - === [Epoch 86/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:32.3205s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.877 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.824 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.843 â”‚ 0.888 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.86  â”‚ 0.892 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1236, ET: 0.1617, TC: 0.1232, WT: 0.0859
[0m
[0;33m2025-05-17 11:29:05,845  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 11:29:05,845  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-17 11:31:15,206  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-17 11:31:15,208  - INFO - - Train mean loss: 0.2056
- ET loss: 0.2609
- TC loss: 0.2138
- WT loss: 0.1420
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-17 11:31:15,208  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-17 11:31:47,369  - INFO - === [Epoch 87/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:32.1602s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.845 â”‚ 0.895 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.859 â”‚ 0.886 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1232, ET: 0.1615, TC: 0.1224, WT: 0.0859
[0m
[0;33m2025-05-17 11:31:47,369  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 11:31:47,369  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-17 11:33:56,419  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-17 11:33:56,420  - INFO - - Train mean loss: 0.1913
- ET loss: 0.2429
- TC loss: 0.1986
- WT loss: 0.1323
- Cost time: 2.15mins â±ï¸
[0m
[0;32m2025-05-17 11:33:56,420  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-17 11:34:28,752  - INFO - === [Epoch 88/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:32.3305s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.826 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.84  â”‚ 0.889 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.863 â”‚ 0.892 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1230, ET: 0.1613, TC: 0.1222, WT: 0.0855
[0m
[1;31m2025-05-17 11:34:28,753  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch81_loss0.1230_dice0.8780_20250517111533.pth[0m
[0;32m2025-05-17 11:34:28,800  - INFO - âœ¨ Saved checkpoint (epoch 88) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch88_loss0.1230_dice0.8781_20250517113428.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:34:28,801  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-17 11:36:38,859  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-17 11:36:38,861  - INFO - - Train mean loss: 0.1872
- ET loss: 0.2369
- TC loss: 0.1909
- WT loss: 0.1338
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 11:36:38,861  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-17 11:37:11,286  - INFO - === [Epoch 89/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:32.4243s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.879 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.847 â”‚ 0.896 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.857 â”‚ 0.886 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1228, ET: 0.1612, TC: 0.1218, WT: 0.0855
[0m
[1;31m2025-05-17 11:37:11,289  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch88_loss0.1230_dice0.8781_20250517113428.pth[0m
[0;32m2025-05-17 11:37:11,344  - INFO - âœ¨ Saved checkpoint (epoch 89) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch89_loss0.1228_dice0.8782_20250517113711.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:37:11,344  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-17 11:39:21,498  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-17 11:39:21,500  - INFO - - Train mean loss: 0.2204
- ET loss: 0.2738
- TC loss: 0.2308
- WT loss: 0.1568
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 11:39:21,500  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-17 11:39:53,978  - INFO - === [Epoch 90/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:32.4775s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.879 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.896 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.856 â”‚ 0.886 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1228, ET: 0.1615, TC: 0.1220, WT: 0.0849
[0m
[1;31m2025-05-17 11:39:53,980  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch89_loss0.1228_dice0.8782_20250517113711.pth[0m
[0;32m2025-05-17 11:39:54,034  - INFO - âœ¨ Saved checkpoint (epoch 90) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch90_loss0.1228_dice0.8782_20250517113953.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:39:54,035  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-17 11:42:03,878  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-17 11:42:03,880  - INFO - - Train mean loss: 0.1999
- ET loss: 0.2539
- TC loss: 0.2078
- WT loss: 0.1379
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-17 11:42:03,880  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-17 11:42:36,144  - INFO - === [Epoch 91/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:32.2636s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.839 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.853 â”‚ 0.897 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.852 â”‚ 0.884 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1235, ET: 0.1618, TC: 0.1230, WT: 0.0858
[0m
[0;33m2025-05-17 11:42:36,145  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 11:42:36,145  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-17 11:44:45,179  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-17 11:44:45,181  - INFO - - Train mean loss: 0.1890
- ET loss: 0.2430
- TC loss: 0.1996
- WT loss: 0.1244
- Cost time: 2.15mins â±ï¸
[0m
[0;32m2025-05-17 11:44:45,181  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-17 11:45:17,597  - INFO - === [Epoch 92/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:32.4147s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.837 â”‚ 0.877 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.767 â”‚ 0.825 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.848 â”‚ 0.893 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.851 â”‚ 0.883 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1246, ET: 0.1637, TC: 0.1232, WT: 0.0869
[0m
[0;33m2025-05-17 11:45:17,597  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 11:45:17,597  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-17 11:47:27,974  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-17 11:47:27,975  - INFO - - Train mean loss: 0.2004
- ET loss: 0.2543
- TC loss: 0.2101
- WT loss: 0.1366
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 11:47:27,975  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-17 11:48:00,276  - INFO - === [Epoch 93/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:32.2993s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.839 â”‚ 0.879 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.769 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.845 â”‚ 0.892 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.856 â”‚ 0.887 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1229, ET: 0.1615, TC: 0.1215, WT: 0.0856
[0m
[0;33m2025-05-17 11:48:00,276  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 11:48:00,276  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-17 11:50:14,439  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-17 11:50:14,440  - INFO - - Train mean loss: 0.1971
- ET loss: 0.2484
- TC loss: 0.2071
- WT loss: 0.1358
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 11:50:14,440  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-17 11:50:46,866  - INFO - === [Epoch 94/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:32.4249s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.878 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.825 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.844 â”‚ 0.89  â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.86  â”‚ 0.89  â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1234, ET: 0.1614, TC: 0.1225, WT: 0.0862
[0m
[0;33m2025-05-17 11:50:46,866  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 11:50:46,866  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-17 11:52:59,989  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-17 11:52:59,991  - INFO - - Train mean loss: 0.1884
- ET loss: 0.2404
- TC loss: 0.1955
- WT loss: 0.1292
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 11:52:59,991  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-17 11:53:32,503  - INFO - === [Epoch 95/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:32.5113s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.839 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.825 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.84  â”‚ 0.889 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.863 â”‚ 0.892 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1233, ET: 0.1619, TC: 0.1224, WT: 0.0855
[0m
[0;33m2025-05-17 11:53:32,503  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 11:53:32,504  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-17 11:55:46,124  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-17 11:55:46,125  - INFO - - Train mean loss: 0.2078
- ET loss: 0.2611
- TC loss: 0.2172
- WT loss: 0.1453
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 11:55:46,125  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-17 11:56:18,279  - INFO - === [Epoch 96/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:32.1528s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.84  â”‚ 0.879 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.769 â”‚ 0.827 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.845 â”‚ 0.893 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.859 â”‚ 0.89  â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1225, ET: 0.1611, TC: 0.1214, WT: 0.0850
[0m
[1;31m2025-05-17 11:56:18,281  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch90_loss0.1228_dice0.8782_20250517113953.pth[0m
[0;32m2025-05-17 11:56:18,333  - INFO - âœ¨ Saved checkpoint (epoch 96) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch96_loss0.1225_dice0.8785_20250517115618.pth;             Size 12.49 MB[0m
[0;32m2025-05-17 11:56:18,333  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-17 11:58:31,513  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-17 11:58:31,515  - INFO - - Train mean loss: 0.1894
- ET loss: 0.2426
- TC loss: 0.1965
- WT loss: 0.1290
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 11:58:31,515  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-17 11:59:03,675  - INFO - === [Epoch 97/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:32.1595s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.843 â”‚ 0.891 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.861 â”‚ 0.891 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1231, ET: 0.1612, TC: 0.1222, WT: 0.0858
[0m
[0;33m2025-05-17 11:59:03,675  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 11:59:03,675  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-17 12:01:17,502  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-17 12:01:17,503  - INFO - - Train mean loss: 0.1958
- ET loss: 0.2448
- TC loss: 0.2031
- WT loss: 0.1395
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-17 12:01:17,503  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-17 12:01:49,714  - INFO - === [Epoch 98/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:32.2094s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.879 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.826 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.842 â”‚ 0.888 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.862 â”‚ 0.894 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1229, ET: 0.1613, TC: 0.1216, WT: 0.0859
[0m
[0;33m2025-05-17 12:01:49,714  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 12:01:49,714  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-17 12:04:01,130  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-17 12:04:01,131  - INFO - - Train mean loss: 0.2099
- ET loss: 0.2642
- TC loss: 0.2203
- WT loss: 0.1453
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 12:04:01,132  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-17 12:04:33,540  - INFO - === [Epoch 99/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:32.4073s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.879 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.846 â”‚ 0.893 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.858 â”‚ 0.889 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1226, ET: 0.1613, TC: 0.1214, WT: 0.0852
[0m
[0;33m2025-05-17 12:04:33,540  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 12:04:33,540  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-17 12:06:43,494  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-17 12:06:43,496  - INFO - - Train mean loss: 0.1858
- ET loss: 0.2330
- TC loss: 0.1902
- WT loss: 0.1343
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 12:06:43,496  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-17 12:07:15,947  - INFO - === [Epoch 100/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:32.4505s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.879 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.826 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.894 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.856 â”‚ 0.888 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1228, ET: 0.1615, TC: 0.1218, WT: 0.0851
[0m
[0;33m2025-05-17 12:07:15,947  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[1;31m2025-05-17 12:07:16,752  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1225 at epoch 96[0m
[0;32m2025-05-17 12:07:16,753  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 12:07:16,760  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/ResUNetBaseline_S_DCLA_SLKv1_v2_final_model.pth[0m
[1;31m2025-05-17 12:07:16,760  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 12:07:16,760  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 12:10:37,303  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚  0.82  â”‚ 0.876 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚  0.74  â”‚ 0.814 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚  0.814 â”‚ 0.911 â”‚ 0.937 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚  0.845 â”‚ 0.878 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  7.062 â”‚ 11.736 â”‚ 5.956 â”‚ 3.493 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1281;ET: 0.1816;ET: 0.1816;TC: 0.1239;WT: 0.0787
[0m
[0;32m2025-05-17 12:10:37,304  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 12:10:37,304  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-17.log[0m
[0;32m2025-05-17 12:10:44,028  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:10:47,245  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 12:10:47,248  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:10:47,248  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:10:47,248  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:10:47,248  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:10:47,248  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:10:47,255  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 12:10:47,255  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 12:10:47,255  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 12:10:47,259  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:14:37,655  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:14:40,892  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 12:14:40,895  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:14:40,895  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:14:40,895  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:14:40,895  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:14:40,895  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:14:40,902  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 12:14:40,902  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 12:14:40,902  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 12:14:40,905  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:14:43,929  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 12:14:43,929  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 12:17:05,423  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 12:17:05,425  - INFO - - Train mean loss: 0.6884
- ET loss: 0.5935
- TC loss: 0.5289
- WT loss: 0.9428
- Cost time: 2.36mins â±ï¸
[0m
[0;32m2025-05-17 12:17:05,425  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 12:17:37,393  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:31.9662s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.466 â”‚ 0.63  â”‚ 0.684 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.365 â”‚ 0.491 â”‚ 0.559 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.435 â”‚ 0.554 â”‚ 0.707 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.838 â”‚ 0.791 â”‚ 0.724 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5380, ET: 0.3758, TC: 0.3217, WT: 0.9164
[0m
[0;32m2025-05-17 12:17:37,454  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.5380_dice0.4661_20250517121737.pth;             Size 12.57 MB[0m
[0;32m2025-05-17 12:17:37,454  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 12:19:56,548  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 12:19:56,549  - INFO - - Train mean loss: 0.5986
- ET loss: 0.4398
- TC loss: 0.4135
- WT loss: 0.9426
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-17 12:19:56,549  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 12:20:40,744  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:20:44,008  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 12:20:44,011  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:20:44,011  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:20:44,011  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:20:44,011  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:20:44,011  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:20:44,017  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 12:20:44,017  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 12:20:44,017  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 12:20:44,021  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:20:46,809  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 12:20:46,810  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 12:23:08,537  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 12:23:08,539  - INFO - - Train mean loss: 0.6863
- ET loss: 0.5864
- TC loss: 0.5291
- WT loss: 0.9434
- Cost time: 2.36mins â±ï¸
[0m
[0;32m2025-05-17 12:23:08,539  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 12:23:42,039  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:33.4991s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.444 â”‚ 0.574 â”‚ 0.673 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.34  â”‚ 0.432 â”‚ 0.544 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.374 â”‚ 0.459 â”‚ 0.619 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.853 â”‚ 0.814 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5617, ET: 0.4332, TC: 0.3354, WT: 0.9164
[0m
[0;32m2025-05-17 12:23:42,346  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.5617_dice0.4435_20250517122342.pth;             Size 12.72 MB[0m
[0;32m2025-05-17 12:23:42,346  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 12:29:29,096  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:29:32,386  - INFO - Total number of parameters: 1.16 M[0m
[0;32m2025-05-17 12:29:32,389  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:29:32,389  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:29:32,389  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:29:32,389  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:29:32,389  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:29:32,396  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 12:29:32,396  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 12:29:32,396  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 12:29:32,400  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.16 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:29:35,128  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 12:29:35,128  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 12:32:00,848  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 12:32:00,852  - INFO - - Train mean loss: 0.5031
- ET loss: 0.5285
- TC loss: 0.5904
- WT loss: 0.3904
- Cost time: 2.43mins â±ï¸
[0m
[0;32m2025-05-17 12:32:00,852  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 12:32:32,704  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:31.8503s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.665 â”‚ 0.693 â”‚ 0.524 â”‚ 0.778 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.541 â”‚ 0.571 â”‚ 0.387 â”‚ 0.665 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.709 â”‚ 0.781 â”‚ 0.421 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.745 â”‚ 0.661 â”‚ 0.876 â”‚ 0.696 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3407, ET: 0.3151, TC: 0.4815, WT: 0.2254
[0m
[0;32m2025-05-17 12:32:32,795  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.3407_dice0.6654_20250517123232.pth;             Size 14.41 MB[0m
[0;32m2025-05-17 12:32:32,796  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 12:34:56,978  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 12:34:56,980  - INFO - - Train mean loss: 0.4163
- ET loss: 0.4078
- TC loss: 0.5440
- WT loss: 0.2973
- Cost time: 2.40mins â±ï¸
[0m
[0;32m2025-05-17 12:34:56,980  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 12:35:28,382  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:35:31,660  - INFO - Total number of parameters: 1.16 M[0m
[0;32m2025-05-17 12:35:31,663  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:35:31,663  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:35:31,663  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:35:31,663  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:35:31,663  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:35:31,669  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 12:35:31,670  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 12:35:31,670  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 12:35:31,673  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.16 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:35:34,606  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 12:35:34,606  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 12:35:55,144  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:35:58,456  - INFO - Total number of parameters: 1.16 M[0m
[0;32m2025-05-17 12:35:58,459  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:35:58,459  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:35:58,459  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:35:58,459  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:35:58,459  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:35:58,466  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 12:35:58,466  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 12:35:58,467  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 12:35:58,470  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.16 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:35:58,940  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 12:35:58,940  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 12:36:37,040  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 12:36:37,040  - INFO - - Train mean loss: 0.7316
- ET loss: 0.6390
- TC loss: 0.6514
- WT loss: 0.9042
- Cost time: 0.64mins â±ï¸
[0m
[0;32m2025-05-17 12:36:37,040  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 12:36:46,124  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.0828s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.448 â”‚ 0.63  â”‚ 0.61  â”‚ 0.105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.351 â”‚ 0.503 â”‚ 0.493 â”‚ 0.057 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.545 â”‚ 0.741 â”‚ 0.836 â”‚ 0.057 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.705 â”‚ 0.617 â”‚ 0.54  â”‚ 0.957 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5565, ET: 0.3763, TC: 0.3983, WT: 0.8949
[0m
[0;32m2025-05-17 12:36:46,193  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5565_dice0.4483_20250517123646.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:36:46,194  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 12:37:23,333  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 12:37:23,333  - INFO - - Train mean loss: 0.6158
- ET loss: 0.4781
- TC loss: 0.4835
- WT loss: 0.8858
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 12:37:23,333  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 12:37:31,999  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:8.6643s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.465 â”‚ 0.574 â”‚ 0.644 â”‚ 0.176 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.348 â”‚ 0.432 â”‚ 0.512 â”‚ 0.101 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.374 â”‚ 0.448 â”‚ 0.571 â”‚ 0.103 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.875 â”‚ 0.822 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5430, ET: 0.4359, TC: 0.3671, WT: 0.8261
[0m
[0;32m2025-05-17 12:37:32,065  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5430_dice0.4647_20250517123731.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:37:32,065  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 12:38:08,806  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 12:38:08,806  - INFO - - Train mean loss: 0.4770
- ET loss: 0.4362
- TC loss: 0.4512
- WT loss: 0.5435
- Cost time: 0.61mins â±ï¸
[0m
[0;32m2025-05-17 12:38:08,806  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 12:38:17,524  - INFO - === [Epoch 3/10] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:8.7167s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.677 â”‚ 0.61  â”‚ 0.671 â”‚ 0.748 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.473 â”‚ 0.545 â”‚ 0.622 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.597 â”‚ 0.487 â”‚ 0.612 â”‚ 0.69  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.855 â”‚ 0.884 â”‚ 0.82  â”‚ 0.862 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3315, ET: 0.3971, TC: 0.3357, WT: 0.2617
[0m
[1;31m2025-05-17 12:38:17,526  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5430_dice0.4647_20250517123731.pth[0m
[0;32m2025-05-17 12:38:17,591  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3315_dice0.6766_20250517123817.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:38:17,591  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-17 12:38:54,529  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-17 12:38:54,530  - INFO - - Train mean loss: 0.3682
- ET loss: 0.3959
- TC loss: 0.4190
- WT loss: 0.2896
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 12:38:54,530  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-17 12:39:03,218  - INFO - === [Epoch 4/10] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:8.6870s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.724 â”‚ 0.698 â”‚ 0.711 â”‚ 0.762 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.604 â”‚ 0.578 â”‚ 0.597 â”‚ 0.636 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.671 â”‚ 0.611 â”‚ 0.721 â”‚ 0.68  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.84  â”‚ 0.86  â”‚ 0.758 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2836, ET: 0.3073, TC: 0.2933, WT: 0.2503
[0m
[1;31m2025-05-17 12:39:03,220  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3315_dice0.6766_20250517123817.pth[0m
[0;32m2025-05-17 12:39:03,286  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.2836_dice0.7235_20250517123903.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:39:03,286  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-17 12:39:40,320  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-17 12:39:40,321  - INFO - - Train mean loss: 0.3623
- ET loss: 0.3961
- TC loss: 0.4178
- WT loss: 0.2730
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 12:39:40,321  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-17 12:39:49,060  - INFO - === [Epoch 5/10] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:8.7378s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.756 â”‚ 0.723 â”‚ 0.733 â”‚ 0.813 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.646 â”‚ 0.608 â”‚ 0.624 â”‚ 0.707 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.765 â”‚ 0.663 â”‚ 0.781 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.791 â”‚ 0.835 â”‚ 0.735 â”‚ 0.804 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2472, ET: 0.2802, TC: 0.2701, WT: 0.1912
[0m
[1;31m2025-05-17 12:39:49,061  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2836_dice0.7235_20250517123903.pth[0m
[0;32m2025-05-17 12:39:49,132  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.2472_dice0.7564_20250517123949.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:39:49,132  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;32m2025-05-17 12:41:15,436  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:41:18,709  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 12:41:18,712  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:41:18,712  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:41:18,712  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:41:18,712  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:41:18,712  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:41:18,719  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 12:41:18,719  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 12:41:18,719  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 12:41:18,722  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:41:19,100  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 12:41:19,100  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 12:41:54,614  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 12:41:54,615  - INFO - - Train mean loss: 0.6741
- ET loss: 0.7658
- TC loss: 0.6854
- WT loss: 0.5711
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 12:41:54,615  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 12:42:03,756  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.1386s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.484 â”‚ 0.324 â”‚ 0.427 â”‚ 0.701 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.357 â”‚ 0.203 â”‚ 0.291 â”‚ 0.576 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.405 â”‚ 0.21  â”‚ 0.306 â”‚ 0.7   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.826 â”‚ 0.859 â”‚ 0.876 â”‚ 0.742 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5355, ET: 0.6934, TC: 0.5930, WT: 0.3201
[0m
[0;32m2025-05-17 12:42:03,822  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5355_dice0.4838_20250517124203.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 12:42:03,822  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 12:42:38,715  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 12:42:38,715  - INFO - - Train mean loss: 0.5088
- ET loss: 0.6514
- TC loss: 0.5192
- WT loss: 0.3558
- Cost time: 0.58mins â±ï¸
[0m
[0;32m2025-05-17 12:42:38,716  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 12:42:47,376  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:8.6595s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.562 â”‚ 0.413 â”‚ 0.527 â”‚ 0.744 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.429 â”‚ 0.276 â”‚ 0.384 â”‚ 0.628 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.528 â”‚ 0.293 â”‚ 0.422 â”‚ 0.869 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.803 â”‚ 0.853 â”‚ 0.87  â”‚ 0.685 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4468, ET: 0.5964, TC: 0.4825, WT: 0.2614
[0m
[0;32m2025-05-17 12:42:47,439  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4468_dice0.5615_20250517124247.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 12:42:47,439  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 12:43:22,857  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 12:43:22,858  - INFO - - Train mean loss: 0.5324
- ET loss: 0.6557
- TC loss: 0.5392
- WT loss: 0.4022
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 12:43:22,858  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 12:43:31,454  - INFO - === [Epoch 3/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:8.5944s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.55  â”‚ 0.399 â”‚ 0.511 â”‚ 0.739 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.415 â”‚ 0.264 â”‚ 0.368 â”‚ 0.613 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.496 â”‚ 0.273 â”‚ 0.393 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.818 â”‚ 0.875 â”‚ 0.887 â”‚ 0.694 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4667, ET: 0.6167, TC: 0.5070, WT: 0.2763
[0m
[0;33m2025-05-17 12:43:31,455  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-17 12:43:31,455  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-17 12:44:06,924  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-17 12:44:06,925  - INFO - - Train mean loss: 0.4861
- ET loss: 0.6146
- TC loss: 0.4837
- WT loss: 0.3599
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 12:44:06,925  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-17 12:44:15,710  - INFO - === [Epoch 4/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:8.7843s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.584 â”‚ 0.487 â”‚ 0.597 â”‚ 0.668 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.445 â”‚ 0.344 â”‚ 0.457 â”‚ 0.534 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.634 â”‚ 0.391 â”‚ 0.55  â”‚ 0.96  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.717 â”‚ 0.799 â”‚ 0.809 â”‚ 0.542 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4180, ET: 0.5164, TC: 0.4060, WT: 0.3317
[0m
[1;31m2025-05-17 12:44:15,712  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4468_dice0.5615_20250517124247.pth[0m
[0;32m2025-05-17 12:44:15,779  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.4180_dice0.5838_20250517124415.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 12:44:15,780  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-17 12:44:51,003  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-17 12:44:51,003  - INFO - - Train mean loss: 0.4870
- ET loss: 0.6108
- TC loss: 0.4791
- WT loss: 0.3712
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 12:44:51,003  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-17 12:44:59,570  - INFO - === [Epoch 5/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:8.5656s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.588 â”‚ 0.522 â”‚ 0.63  â”‚ 0.613 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.449 â”‚ 0.379 â”‚ 0.497 â”‚ 0.47  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.665 â”‚ 0.432 â”‚ 0.606 â”‚ 0.956 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.69  â”‚ 0.794 â”‚ 0.8   â”‚ 0.476 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4134, ET: 0.4808, TC: 0.3728, WT: 0.3865
[0m
[1;31m2025-05-17 12:44:59,572  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.4180_dice0.5838_20250517124415.pth[0m
[0;32m2025-05-17 12:44:59,647  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.4134_dice0.5884_20250517124459.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 12:44:59,648  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;32m2025-05-17 12:45:43,971  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 12:45:47,289  - INFO - Total number of parameters: 1.16 M[0m
[0;32m2025-05-17 12:45:47,292  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 12:45:47,292  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:45:47,292  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:45:47,292  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 12:45:47,292  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 12:45:47,299  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 12:45:47,299  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 12:45:47,299  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 12:45:47,304  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.16 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 12:45:50,413  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 12:45:50,413  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 12:48:16,730  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 12:48:16,733  - INFO - - Train mean loss: 0.5477
- ET loss: 0.7000
- TC loss: 0.5452
- WT loss: 0.3978
- Cost time: 2.44mins â±ï¸
[0m
[0;32m2025-05-17 12:48:16,733  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 12:48:48,025  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:31.2910s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.537 â”‚ 0.442 â”‚ 0.524 â”‚ 0.644 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.402 â”‚ 0.311 â”‚ 0.392 â”‚ 0.503 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.416 â”‚ 0.32  â”‚ 0.409 â”‚ 0.52  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.912 â”‚ 0.889 â”‚ 0.908 â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4804, ET: 0.5693, TC: 0.4948, WT: 0.3772
[0m
[0;32m2025-05-17 12:48:48,096  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.4804_dice0.5366_20250517124848.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:48:48,096  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 12:51:13,248  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 12:51:13,250  - INFO - - Train mean loss: 0.3773
- ET loss: 0.4409
- TC loss: 0.4090
- WT loss: 0.2820
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 12:51:13,250  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 12:51:43,604  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:30.3525s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.763 â”‚ 0.711 â”‚ 0.755 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.654 â”‚ 0.592 â”‚ 0.651 â”‚ 0.719 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.754 â”‚ 0.683 â”‚ 0.746 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.823 â”‚ 0.799 â”‚ 0.824 â”‚ 0.845 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2463, ET: 0.2977, TC: 0.2536, WT: 0.1876
[0m
[1;31m2025-05-17 12:51:43,606  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.4804_dice0.5366_20250517124848.pth[0m
[0;32m2025-05-17 12:51:43,676  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.2463_dice0.7630_20250517125143.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:51:43,677  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-17 12:54:08,703  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-17 12:54:08,704  - INFO - - Train mean loss: 0.3304
- ET loss: 0.3858
- TC loss: 0.3519
- WT loss: 0.2535
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 12:54:08,704  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-17 12:54:39,235  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:30.5300s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.793 â”‚ 0.749 â”‚ 0.79  â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.693 â”‚ 0.64  â”‚ 0.697 â”‚ 0.743 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.799 â”‚ 0.749 â”‚ 0.796 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.826 â”‚ 0.791 â”‚ 0.834 â”‚ 0.854 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2140, ET: 0.2573, TC: 0.2156, WT: 0.1692
[0m
[1;31m2025-05-17 12:54:39,238  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.2463_dice0.7630_20250517125143.pth[0m
[0;32m2025-05-17 12:54:39,309  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.2140_dice0.7928_20250517125439.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:54:39,310  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-17 12:57:04,343  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-17 12:57:04,344  - INFO - - Train mean loss: 0.3067
- ET loss: 0.3593
- TC loss: 0.3260
- WT loss: 0.2348
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 12:57:04,344  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-17 12:57:34,779  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:30.4337s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.809 â”‚ 0.765 â”‚ 0.807 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.716 â”‚ 0.662 â”‚ 0.72  â”‚ 0.765 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.849 â”‚ 0.811 â”‚ 0.851 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.799 â”‚ 0.749 â”‚ 0.797 â”‚ 0.851 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1962, ET: 0.2395, TC: 0.1963, WT: 0.1529
[0m
[1;31m2025-05-17 12:57:34,781  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.2140_dice0.7928_20250517125439.pth[0m
[0;32m2025-05-17 12:57:34,848  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.1962_dice0.8087_20250517125734.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 12:57:34,848  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-17 12:59:59,654  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-17 12:59:59,655  - INFO - - Train mean loss: 0.2860
- ET loss: 0.3406
- TC loss: 0.3011
- WT loss: 0.2164
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 12:59:59,655  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-17 13:00:30,536  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:30.8796s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.808 â”‚ 0.766 â”‚ 0.805 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.714 â”‚ 0.663 â”‚ 0.717 â”‚ 0.762 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.815 â”‚ 0.765 â”‚ 0.832 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.838 â”‚ 0.804 â”‚ 0.825 â”‚ 0.886 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1973, ET: 0.2378, TC: 0.1995, WT: 0.1546
[0m
[0;33m2025-05-17 13:00:30,536  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 13:00:30,536  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-17 13:02:55,026  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-17 13:02:55,027  - INFO - - Train mean loss: 0.2871
- ET loss: 0.3401
- TC loss: 0.3007
- WT loss: 0.2204
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:02:55,027  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-17 13:03:26,385  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:31.3566s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.821 â”‚ 0.776 â”‚ 0.822 â”‚ 0.866 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.732 â”‚ 0.676 â”‚ 0.737 â”‚ 0.783 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.805 â”‚ 0.75  â”‚ 0.797 â”‚ 0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.834 â”‚ 0.876 â”‚ 0.889 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1823, ET: 0.2265, TC: 0.1815, WT: 0.1389
[0m
[1;31m2025-05-17 13:03:26,387  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.1962_dice0.8087_20250517125734.pth[0m
[0;32m2025-05-17 13:03:26,453  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.1823_dice0.8212_20250517130326.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:03:26,454  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-17 13:05:50,858  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-17 13:05:50,860  - INFO - - Train mean loss: 0.2855
- ET loss: 0.3404
- TC loss: 0.3006
- WT loss: 0.2155
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:05:50,860  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-17 13:06:22,448  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:31.5871s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.829 â”‚ 0.789 â”‚ 0.824 â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.744 â”‚ 0.694 â”‚ 0.744 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.844 â”‚ 0.814 â”‚ 0.821 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.841 â”‚ 0.788 â”‚ 0.86  â”‚ 0.874 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1744, ET: 0.2143, TC: 0.1791, WT: 0.1299
[0m
[1;31m2025-05-17 13:06:22,450  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.1823_dice0.8212_20250517130326.pth[0m
[0;32m2025-05-17 13:06:22,518  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.1744_dice0.8290_20250517130622.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:06:22,518  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-17 13:08:47,300  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-17 13:08:47,302  - INFO - - Train mean loss: 0.2673
- ET loss: 0.3242
- TC loss: 0.2846
- WT loss: 0.1929
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:08:47,302  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-17 13:09:18,712  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:31.4097s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.829 â”‚ 0.787 â”‚ 0.829 â”‚ 0.872 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.744 â”‚ 0.691 â”‚ 0.75  â”‚ 0.792 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.835 â”‚ 0.787 â”‚ 0.851 â”‚ 0.868 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚ 0.82  â”‚ 0.839 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1735, ET: 0.2146, TC: 0.1734, WT: 0.1325
[0m
[1;31m2025-05-17 13:09:18,714  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.1744_dice0.8290_20250517130622.pth[0m
[0;32m2025-05-17 13:09:18,784  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch8_loss0.1735_dice0.8295_20250517130918.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:09:18,785  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-17 13:11:43,211  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-17 13:11:43,212  - INFO - - Train mean loss: 0.2704
- ET loss: 0.3201
- TC loss: 0.2844
- WT loss: 0.2066
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:11:43,212  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-17 13:12:14,776  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:31.5633s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.832 â”‚ 0.79  â”‚ 0.835 â”‚ 0.871 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.749 â”‚ 0.696 â”‚ 0.76  â”‚ 0.792 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.842 â”‚ 0.865 â”‚ 0.941 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.808 â”‚ 0.765 â”‚ 0.831 â”‚ 0.829 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1707, ET: 0.2133, TC: 0.1667, WT: 0.1321
[0m
[1;31m2025-05-17 13:12:14,778  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.1735_dice0.8295_20250517130918.pth[0m
[0;32m2025-05-17 13:12:14,844  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.1707_dice0.8320_20250517131214.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:12:14,845  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-17 13:14:39,675  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-17 13:14:39,676  - INFO - - Train mean loss: 0.2755
- ET loss: 0.3252
- TC loss: 0.2906
- WT loss: 0.2106
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:14:39,676  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-17 13:15:11,146  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:31.4684s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.832 â”‚ 0.794 â”‚ 0.828 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.747 â”‚ 0.699 â”‚ 0.748 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.817 â”‚ 0.77  â”‚ 0.803 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.848 â”‚ 0.891 â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1719, ET: 0.2084, TC: 0.1739, WT: 0.1333
[0m
[0;33m2025-05-17 13:15:11,146  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 13:15:11,146  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-17 13:17:35,807  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-17 13:17:35,808  - INFO - - Train mean loss: 0.2516
- ET loss: 0.3058
- TC loss: 0.2654
- WT loss: 0.1836
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:17:35,808  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-17 13:18:07,667  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:31.8579s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.84  â”‚ 0.802 â”‚ 0.836 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.761 â”‚ 0.713 â”‚ 0.761 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.851 â”‚ 0.805 â”‚ 0.825 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.855 â”‚ 0.822 â”‚ 0.88  â”‚ 0.865 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1625, ET: 0.2002, TC: 0.1664, WT: 0.1208
[0m
[1;31m2025-05-17 13:18:07,669  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.1707_dice0.8320_20250517131214.pth[0m
[0;32m2025-05-17 13:18:07,738  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.1625_dice0.8403_20250517131807.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:18:07,739  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-17 13:20:32,457  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-17 13:20:32,458  - INFO - - Train mean loss: 0.2736
- ET loss: 0.3232
- TC loss: 0.2893
- WT loss: 0.2083
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:20:32,458  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-17 13:21:03,715  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:31.2561s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.843 â”‚ 0.802 â”‚ 0.844 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.761 â”‚ 0.709 â”‚ 0.77  â”‚ 0.805 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.819 â”‚ 0.771 â”‚ 0.823 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.86  â”‚ 0.898 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1607, ET: 0.2005, TC: 0.1580, WT: 0.1235
[0m
[1;31m2025-05-17 13:21:03,717  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.1625_dice0.8403_20250517131807.pth[0m
[0;32m2025-05-17 13:21:03,786  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.1607_dice0.8427_20250517132103.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:21:03,786  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-17 13:23:28,305  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-17 13:23:28,306  - INFO - - Train mean loss: 0.2531
- ET loss: 0.3083
- TC loss: 0.2667
- WT loss: 0.1842
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:23:28,306  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-17 13:23:59,592  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:31.2858s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.844 â”‚ 0.8   â”‚ 0.847 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.763 â”‚ 0.706 â”‚ 0.773 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.821 â”‚ 0.759 â”‚ 0.825 â”‚ 0.881 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.872 â”‚ 0.901 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1588, ET: 0.2022, TC: 0.1554, WT: 0.1189
[0m
[1;31m2025-05-17 13:23:59,595  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.1607_dice0.8427_20250517132103.pth[0m
[0;32m2025-05-17 13:23:59,661  - INFO - âœ¨ Saved checkpoint (epoch 13) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.1588_dice0.8437_20250517132359.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:23:59,662  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-17 13:26:24,193  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-17 13:26:24,194  - INFO - - Train mean loss: 0.2558
- ET loss: 0.3057
- TC loss: 0.2667
- WT loss: 0.1949
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:26:24,195  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-17 13:26:55,673  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:31.4777s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.842 â”‚ 0.807 â”‚ 0.846 â”‚ 0.872 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.761 â”‚ 0.717 â”‚ 0.775 â”‚ 0.791 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.833 â”‚ 0.794 â”‚ 0.855 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.844 â”‚ 0.864 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1618, ET: 0.1952, TC: 0.1554, WT: 0.1349
[0m
[0;33m2025-05-17 13:26:55,673  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 13:26:55,673  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-17 13:29:20,568  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-17 13:29:20,570  - INFO - - Train mean loss: 0.2497
- ET loss: 0.3051
- TC loss: 0.2643
- WT loss: 0.1797
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:29:20,570  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-17 13:29:52,017  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:31.4461s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.851 â”‚ 0.812 â”‚ 0.847 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.773 â”‚ 0.723 â”‚ 0.774 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.842 â”‚ 0.782 â”‚ 0.825 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.868 â”‚ 0.908 â”‚ 0.881 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1516, ET: 0.1897, TC: 0.1547, WT: 0.1105
[0m
[1;31m2025-05-17 13:29:52,019  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch13_loss0.1588_dice0.8437_20250517132359.pth[0m
[0;32m2025-05-17 13:29:52,086  - INFO - âœ¨ Saved checkpoint (epoch 15) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch15_loss0.1516_dice0.8506_20250517132952.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:29:52,087  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-17 13:32:17,217  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-17 13:32:17,219  - INFO - - Train mean loss: 0.2569
- ET loss: 0.3097
- TC loss: 0.2704
- WT loss: 0.1905
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 13:32:17,219  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-17 13:32:48,469  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:31.2497s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.852 â”‚ 0.813 â”‚ 0.854 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.775 â”‚ 0.726 â”‚ 0.785 â”‚ 0.814 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.872 â”‚ 0.848 â”‚ 0.883 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.857 â”‚ 0.804 â”‚ 0.853 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1506, ET: 0.1888, TC: 0.1469, WT: 0.1161
[0m
[1;31m2025-05-17 13:32:48,471  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch15_loss0.1516_dice0.8506_20250517132952.pth[0m
[0;32m2025-05-17 13:32:48,537  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.1506_dice0.8518_20250517133248.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:32:48,537  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-17 13:35:13,007  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-17 13:35:13,009  - INFO - - Train mean loss: 0.2428
- ET loss: 0.2920
- TC loss: 0.2512
- WT loss: 0.1852
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:35:13,009  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-17 13:35:44,781  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:31.7710s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.819 â”‚ 0.854 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.782 â”‚ 0.735 â”‚ 0.788 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.821 â”‚ 0.859 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.839 â”‚ 0.88  â”‚ 0.883 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1468, ET: 0.1827, TC: 0.1471, WT: 0.1106
[0m
[1;31m2025-05-17 13:35:44,783  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.1506_dice0.8518_20250517133248.pth[0m
[0;32m2025-05-17 13:35:44,850  - INFO - âœ¨ Saved checkpoint (epoch 17) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch17_loss0.1468_dice0.8553_20250517133544.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:35:44,851  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-17 13:38:09,826  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-17 13:38:09,827  - INFO - - Train mean loss: 0.2414
- ET loss: 0.2949
- TC loss: 0.2522
- WT loss: 0.1771
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 13:38:09,827  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-17 13:38:41,045  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:31.2165s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.86  â”‚ 0.819 â”‚ 0.86  â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.785 â”‚ 0.733 â”‚ 0.791 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.865 â”‚ 0.819 â”‚ 0.852 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.843 â”‚ 0.892 â”‚ 0.893 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1427, ET: 0.1829, TC: 0.1411, WT: 0.1042
[0m
[1;31m2025-05-17 13:38:41,047  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch17_loss0.1468_dice0.8553_20250517133544.pth[0m
[0;32m2025-05-17 13:38:41,345  - INFO - âœ¨ Saved checkpoint (epoch 18) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch18_loss0.1427_dice0.8595_20250517133841.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:38:41,346  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-17 13:41:06,077  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-17 13:41:06,079  - INFO - - Train mean loss: 0.2338
- ET loss: 0.2851
- TC loss: 0.2454
- WT loss: 0.1708
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:41:06,079  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-17 13:41:37,982  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:31.9025s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.847 â”‚ 0.813 â”‚ 0.84  â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.771 â”‚ 0.728 â”‚ 0.769 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.843 â”‚ 0.812 â”‚ 0.831 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.846 â”‚ 0.886 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1547, ET: 0.1884, TC: 0.1615, WT: 0.1141
[0m
[0;33m2025-05-17 13:41:37,982  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 13:41:37,982  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-17 13:44:02,796  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-17 13:44:02,797  - INFO - - Train mean loss: 0.2393
- ET loss: 0.2892
- TC loss: 0.2528
- WT loss: 0.1760
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:44:02,797  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-17 13:44:33,787  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:30.9866s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.824 â”‚ 0.864 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.789 â”‚ 0.74  â”‚ 0.798 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.848 â”‚ 0.9   â”‚ 0.939 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.85  â”‚ 0.823 â”‚ 0.852 â”‚ 0.876 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1403, ET: 0.1777, TC: 0.1370, WT: 0.1061
[0m
[1;31m2025-05-17 13:44:33,789  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch18_loss0.1427_dice0.8595_20250517133841.pth[0m
[0;32m2025-05-17 13:44:33,860  - INFO - âœ¨ Saved checkpoint (epoch 20) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch20_loss0.1403_dice0.8614_20250517134433.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:44:33,860  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-17 13:46:58,785  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-17 13:46:58,787  - INFO - - Train mean loss: 0.2356
- ET loss: 0.2832
- TC loss: 0.2446
- WT loss: 0.1790
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 13:46:58,787  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-17 13:47:30,089  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:31.3014s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.823 â”‚ 0.864 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.787 â”‚ 0.738 â”‚ 0.798 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.816 â”‚ 0.873 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.851 â”‚ 0.881 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1412, ET: 0.1790, TC: 0.1373, WT: 0.1073
[0m
[0;33m2025-05-17 13:47:30,089  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 13:47:30,089  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-17 13:49:54,902  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-17 13:49:54,903  - INFO - - Train mean loss: 0.2256
- ET loss: 0.2741
- TC loss: 0.2359
- WT loss: 0.1668
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:49:54,903  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-17 13:50:26,101  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:31.1978s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.827 â”‚ 0.872 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.742 â”‚ 0.807 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.872 â”‚ 0.817 â”‚ 0.888 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.86  â”‚ 0.877 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1359, ET: 0.1749, TC: 0.1293, WT: 0.1035
[0m
[1;31m2025-05-17 13:50:26,103  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch20_loss0.1403_dice0.8614_20250517134433.pth[0m
[0;32m2025-05-17 13:50:26,171  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.1359_dice0.8660_20250517135026.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 13:50:26,171  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-17 13:52:50,816  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-17 13:52:50,817  - INFO - - Train mean loss: 0.2356
- ET loss: 0.2847
- TC loss: 0.2429
- WT loss: 0.1791
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:52:50,817  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-17 13:53:21,866  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:31.0478s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.862 â”‚ 0.825 â”‚ 0.866 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.789 â”‚ 0.741 â”‚ 0.801 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.849 â”‚ 0.806 â”‚ 0.854 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.866 â”‚ 0.902 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1397, ET: 0.1769, TC: 0.1349, WT: 0.1072
[0m
[0;33m2025-05-17 13:53:21,866  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 13:53:21,866  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-17 13:55:46,403  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-17 13:55:46,405  - INFO - - Train mean loss: 0.2354
- ET loss: 0.2875
- TC loss: 0.2449
- WT loss: 0.1739
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:55:46,405  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-17 13:56:17,526  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:31.1202s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.827 â”‚ 0.866 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.792 â”‚ 0.744 â”‚ 0.8   â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.873 â”‚ 0.841 â”‚ 0.875 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.832 â”‚ 0.88  â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1381, ET: 0.1746, TC: 0.1354, WT: 0.1042
[0m
[0;33m2025-05-17 13:56:17,526  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 13:56:17,526  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-17 13:58:42,418  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-17 13:58:42,420  - INFO - - Train mean loss: 0.2355
- ET loss: 0.2853
- TC loss: 0.2430
- WT loss: 0.1783
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 13:58:42,420  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-17 13:59:13,544  - INFO - === [Epoch 25/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:31.1227s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.818 â”‚ 0.863 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.784 â”‚ 0.731 â”‚ 0.795 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.855 â”‚ 0.792 â”‚ 0.856 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.87  â”‚ 0.895 â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1426, ET: 0.1830, TC: 0.1384, WT: 0.1064
[0m
[0;33m2025-05-17 13:59:13,544  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 13:59:13,544  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-17 14:01:38,430  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-17 14:01:38,431  - INFO - - Train mean loss: 0.2308
- ET loss: 0.2841
- TC loss: 0.2389
- WT loss: 0.1694
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:01:38,431  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-17 14:02:09,624  - INFO - === [Epoch 26/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:31.1918s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.824 â”‚ 0.868 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.741 â”‚ 0.801 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.85  â”‚ 0.801 â”‚ 0.856 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.872 â”‚ 0.907 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1391, ET: 0.1771, TC: 0.1336, WT: 0.1064
[0m
[0;33m2025-05-17 14:02:09,624  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 14:02:09,624  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-17 14:04:34,201  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-17 14:04:34,202  - INFO - - Train mean loss: 0.2452
- ET loss: 0.3002
- TC loss: 0.2588
- WT loss: 0.1765
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:04:34,203  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-17 14:05:05,289  - INFO - === [Epoch 27/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:31.0853s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.821 â”‚ 0.865 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.786 â”‚ 0.735 â”‚ 0.797 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.843 â”‚ 0.797 â”‚ 0.847 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.873 â”‚ 0.909 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1411, ET: 0.1804, TC: 0.1366, WT: 0.1063
[0m
[0;33m2025-05-17 14:05:05,289  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 14:05:05,289  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-17 14:07:29,955  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-17 14:07:29,956  - INFO - - Train mean loss: 0.2334
- ET loss: 0.2881
- TC loss: 0.2446
- WT loss: 0.1675
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:07:29,956  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-17 14:08:01,167  - INFO - === [Epoch 28/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:31.2098s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.828 â”‚ 0.873 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.746 â”‚ 0.811 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.876 â”‚ 0.822 â”‚ 0.882 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.857 â”‚ 0.885 â”‚ 0.898 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1330, ET: 0.1733, TC: 0.1281, WT: 0.0977
[0m
[1;31m2025-05-17 14:08:01,169  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.1359_dice0.8660_20250517135026.pth[0m
[0;32m2025-05-17 14:08:01,239  - INFO - âœ¨ Saved checkpoint (epoch 28) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch28_loss0.1330_dice0.8686_20250517140801.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:08:01,239  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-17 14:10:26,010  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-17 14:10:26,011  - INFO - - Train mean loss: 0.2230
- ET loss: 0.2760
- TC loss: 0.2329
- WT loss: 0.1603
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:10:26,011  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-17 14:10:57,248  - INFO - === [Epoch 29/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:31.2352s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.825 â”‚ 0.864 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.793 â”‚ 0.744 â”‚ 0.797 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.876 â”‚ 0.841 â”‚ 0.867 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.835 â”‚ 0.889 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1383, ET: 0.1771, TC: 0.1374, WT: 0.1003
[0m
[0;33m2025-05-17 14:10:57,248  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 14:10:57,248  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-17 14:13:22,123  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-17 14:13:22,125  - INFO - - Train mean loss: 0.2206
- ET loss: 0.2720
- TC loss: 0.2298
- WT loss: 0.1600
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:13:22,125  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-17 14:13:53,169  - INFO - === [Epoch 30/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:31.0435s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.832 â”‚ 0.876 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.751 â”‚ 0.814 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.826 â”‚ 0.876 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.857 â”‚ 0.895 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1308, ET: 0.1695, TC: 0.1248, WT: 0.0980
[0m
[1;31m2025-05-17 14:13:53,171  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch28_loss0.1330_dice0.8686_20250517140801.pth[0m
[0;32m2025-05-17 14:13:53,242  - INFO - âœ¨ Saved checkpoint (epoch 30) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch30_loss0.1308_dice0.8709_20250517141353.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:13:53,243  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-17 14:16:17,774  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-17 14:16:17,776  - INFO - - Train mean loss: 0.2325
- ET loss: 0.2830
- TC loss: 0.2430
- WT loss: 0.1717
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:16:17,776  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-17 14:16:49,070  - INFO - === [Epoch 31/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:31.2937s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.834 â”‚ 0.876 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.754 â”‚ 0.815 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.872 â”‚ 0.836 â”‚ 0.889 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.85  â”‚ 0.882 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1308, ET: 0.1679, TC: 0.1252, WT: 0.0992
[0m
[1;31m2025-05-17 14:16:49,073  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch30_loss0.1308_dice0.8709_20250517141353.pth[0m
[0;32m2025-05-17 14:16:49,140  - INFO - âœ¨ Saved checkpoint (epoch 31) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch31_loss0.1308_dice0.8711_20250517141649.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:16:49,140  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-17 14:19:13,809  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-17 14:19:13,811  - INFO - - Train mean loss: 0.2163
- ET loss: 0.2690
- TC loss: 0.2266
- WT loss: 0.1534
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:19:13,811  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-17 14:19:45,340  - INFO - === [Epoch 32/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:31.5289s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.829 â”‚ 0.871 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.798 â”‚ 0.75  â”‚ 0.81  â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.848 â”‚ 0.899 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.834 â”‚ 0.865 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1343, ET: 0.1721, TC: 0.1300, WT: 0.1008
[0m
[0;33m2025-05-17 14:19:45,341  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 14:19:45,341  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-17 14:22:10,107  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-17 14:22:10,108  - INFO - - Train mean loss: 0.2178
- ET loss: 0.2697
- TC loss: 0.2280
- WT loss: 0.1559
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:22:10,108  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-17 14:22:41,162  - INFO - === [Epoch 33/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:31.0526s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.833 â”‚ 0.877 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.754 â”‚ 0.816 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.834 â”‚ 0.883 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.854 â”‚ 0.891 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1306, ET: 0.1687, TC: 0.1242, WT: 0.0989
[0m
[1;31m2025-05-17 14:22:41,164  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch31_loss0.1308_dice0.8711_20250517141649.pth[0m
[0;32m2025-05-17 14:22:41,230  - INFO - âœ¨ Saved checkpoint (epoch 33) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch33_loss0.1306_dice0.8710_20250517142241.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:22:41,231  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-17 14:25:06,105  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-17 14:25:06,106  - INFO - - Train mean loss: 0.2293
- ET loss: 0.2826
- TC loss: 0.2396
- WT loss: 0.1657
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:25:06,106  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-17 14:25:37,474  - INFO - === [Epoch 34/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:31.3667s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.832 â”‚ 0.87  â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.753 â”‚ 0.808 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.835 â”‚ 0.88  â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.85  â”‚ 0.883 â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1321, ET: 0.1690, TC: 0.1305, WT: 0.0967
[0m
[0;33m2025-05-17 14:25:37,474  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 14:25:37,474  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-17 14:28:02,057  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-17 14:28:02,058  - INFO - - Train mean loss: 0.2178
- ET loss: 0.2671
- TC loss: 0.2307
- WT loss: 0.1557
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:28:02,058  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-17 14:28:33,241  - INFO - === [Epoch 35/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:31.1821s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.836 â”‚ 0.873 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.813 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.848 â”‚ 0.889 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.847 â”‚ 0.885 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1296, ET: 0.1655, TC: 0.1283, WT: 0.0951
[0m
[1;31m2025-05-17 14:28:33,243  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch33_loss0.1306_dice0.8710_20250517142241.pth[0m
[0;32m2025-05-17 14:28:33,311  - INFO - âœ¨ Saved checkpoint (epoch 35) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch35_loss0.1296_dice0.8720_20250517142833.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:28:33,312  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-17 14:30:58,160  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-17 14:30:58,161  - INFO - - Train mean loss: 0.2180
- ET loss: 0.2693
- TC loss: 0.2276
- WT loss: 0.1572
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:30:58,162  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-17 14:31:29,581  - INFO - === [Epoch 36/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:31.4181s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.834 â”‚ 0.874 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.756 â”‚ 0.813 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.828 â”‚ 0.874 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.862 â”‚ 0.898 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1311, ET: 0.1674, TC: 0.1275, WT: 0.0983
[0m
[0;33m2025-05-17 14:31:29,581  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 14:31:29,581  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-17 14:33:54,254  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-17 14:33:54,255  - INFO - - Train mean loss: 0.2056
- ET loss: 0.2564
- TC loss: 0.2135
- WT loss: 0.1471
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:33:54,255  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-17 14:34:25,617  - INFO - === [Epoch 37/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:31.3610s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.831 â”‚ 0.874 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.793 â”‚ 0.749 â”‚ 0.811 â”‚ 0.82  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.845 â”‚ 0.804 â”‚ 0.865 â”‚ 0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.907 â”‚ 0.88  â”‚ 0.904 â”‚ 0.937 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1357, ET: 0.1704, TC: 0.1274, WT: 0.1094
[0m
[0;33m2025-05-17 14:34:25,618  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 14:34:25,618  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-17 14:36:49,857  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-17 14:36:49,859  - INFO - - Train mean loss: 0.2213
- ET loss: 0.2723
- TC loss: 0.2334
- WT loss: 0.1582
- Cost time: 2.40mins â±ï¸
[0m
[0;32m2025-05-17 14:36:49,859  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-17 14:37:21,194  - INFO - === [Epoch 38/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:31.3335s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.825 â”‚ 0.861 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.795 â”‚ 0.745 â”‚ 0.799 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.906 â”‚ 0.871 â”‚ 0.912 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.847 â”‚ 0.808 â”‚ 0.838 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1375, ET: 0.1762, TC: 0.1396, WT: 0.0966
[0m
[0;33m2025-05-17 14:37:21,194  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 14:37:21,194  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-17 14:39:45,657  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-17 14:39:45,659  - INFO - - Train mean loss: 0.2241
- ET loss: 0.2766
- TC loss: 0.2357
- WT loss: 0.1600
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:39:45,659  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-17 14:40:16,961  - INFO - === [Epoch 39/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:31.3016s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.833 â”‚ 0.869 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.753 â”‚ 0.805 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.859 â”‚ 0.821 â”‚ 0.858 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.866 â”‚ 0.905 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1318, ET: 0.1683, TC: 0.1316, WT: 0.0954
[0m
[0;33m2025-05-17 14:40:16,962  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 14:40:16,962  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-17 14:42:41,274  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-17 14:42:41,275  - INFO - - Train mean loss: 0.2099
- ET loss: 0.2665
- TC loss: 0.2223
- WT loss: 0.1408
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:42:41,275  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-17 14:43:12,806  - INFO - === [Epoch 40/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:31.5295s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.877 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.76  â”‚ 0.818 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.845 â”‚ 0.894 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.849 â”‚ 0.88  â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1263, ET: 0.1641, TC: 0.1235, WT: 0.0912
[0m
[1;31m2025-05-17 14:43:12,808  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch35_loss0.1296_dice0.8720_20250517142833.pth[0m
[0;32m2025-05-17 14:43:12,880  - INFO - âœ¨ Saved checkpoint (epoch 40) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch40_loss0.1263_dice0.8753_20250517144312.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:43:12,880  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-17 14:45:37,800  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-17 14:45:37,802  - INFO - - Train mean loss: 0.2146
- ET loss: 0.2653
- TC loss: 0.2262
- WT loss: 0.1522
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 14:45:37,802  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-17 14:46:10,254  - INFO - === [Epoch 41/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:32.4511s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.837 â”‚ 0.879 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.76  â”‚ 0.821 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.839 â”‚ 0.894 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.856 â”‚ 0.885 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1254, ET: 0.1640, TC: 0.1216, WT: 0.0906
[0m
[1;31m2025-05-17 14:46:10,256  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch40_loss0.1263_dice0.8753_20250517144312.pth[0m
[0;32m2025-05-17 14:46:10,322  - INFO - âœ¨ Saved checkpoint (epoch 41) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch41_loss0.1254_dice0.8760_20250517144610.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 14:46:10,323  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-17 14:48:35,056  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-17 14:48:35,057  - INFO - - Train mean loss: 0.2011
- ET loss: 0.2518
- TC loss: 0.2088
- WT loss: 0.1427
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:48:35,057  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-17 14:49:07,294  - INFO - === [Epoch 42/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:32.2355s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.836 â”‚ 0.879 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.757 â”‚ 0.819 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.821 â”‚ 0.878 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.869 â”‚ 0.897 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1271, ET: 0.1653, TC: 0.1221, WT: 0.0938
[0m
[0;33m2025-05-17 14:49:07,294  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 14:49:07,294  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-17 14:51:32,069  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-17 14:51:32,070  - INFO - - Train mean loss: 0.2227
- ET loss: 0.2790
- TC loss: 0.2336
- WT loss: 0.1555
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 14:51:32,071  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-17 14:52:04,084  - INFO - === [Epoch 43/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:32.0129s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.834 â”‚ 0.871 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.752 â”‚ 0.808 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.814 â”‚ 0.889 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.874 â”‚ 0.876 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1308, ET: 0.1677, TC: 0.1295, WT: 0.0952
[0m
[0;33m2025-05-17 14:52:04,085  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 14:52:04,085  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-17 14:54:29,014  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-17 14:54:29,015  - INFO - - Train mean loss: 0.2237
- ET loss: 0.2731
- TC loss: 0.2345
- WT loss: 0.1636
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 14:54:29,015  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-17 14:55:01,077  - INFO - === [Epoch 44/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:32.0615s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.832 â”‚ 0.871 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.754 â”‚ 0.813 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.833 â”‚ 0.881 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.853 â”‚ 0.885 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1327, ET: 0.1697, TC: 0.1293, WT: 0.0990
[0m
[0;33m2025-05-17 14:55:01,078  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 14:55:01,078  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-17 14:57:25,983  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-17 14:57:25,984  - INFO - - Train mean loss: 0.2225
- ET loss: 0.2750
- TC loss: 0.2321
- WT loss: 0.1603
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 14:57:25,984  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-17 14:57:58,003  - INFO - === [Epoch 45/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:32.0183s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.879 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.821 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.827 â”‚ 0.888 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.869 â”‚ 0.886 â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1267, ET: 0.1621, TC: 0.1214, WT: 0.0966
[0m
[0;33m2025-05-17 14:57:58,004  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 14:57:58,004  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-17 15:00:22,319  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-17 15:00:22,321  - INFO - - Train mean loss: 0.2183
- ET loss: 0.2723
- TC loss: 0.2318
- WT loss: 0.1507
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:00:22,321  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-17 15:00:55,098  - INFO - === [Epoch 46/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:32.7767s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.841 â”‚ 0.882 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.763 â”‚ 0.823 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.874 â”‚ 0.831 â”‚ 0.881 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.87  â”‚ 0.904 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1240, ET: 0.1606, TC: 0.1184, WT: 0.0931
[0m
[1;31m2025-05-17 15:00:55,100  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch41_loss0.1254_dice0.8760_20250517144610.pth[0m
[0;32m2025-05-17 15:00:55,166  - INFO - âœ¨ Saved checkpoint (epoch 46) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch46_loss0.1240_dice0.8773_20250517150055.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 15:00:55,167  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-17 15:03:19,941  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-17 15:03:19,942  - INFO - - Train mean loss: 0.2128
- ET loss: 0.2631
- TC loss: 0.2208
- WT loss: 0.1545
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:03:19,942  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-17 15:03:52,197  - INFO - === [Epoch 47/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:32.2539s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.88  â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.765 â”‚ 0.823 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.859 â”‚ 0.903 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.846 â”‚ 0.882 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1245, ET: 0.1611, TC: 0.1205, WT: 0.0918
[0m
[0;33m2025-05-17 15:03:52,197  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 15:03:52,197  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-17 15:06:16,919  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-17 15:06:16,920  - INFO - - Train mean loss: 0.2161
- ET loss: 0.2677
- TC loss: 0.2262
- WT loss: 0.1545
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:06:16,920  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-17 15:06:49,790  - INFO - === [Epoch 48/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:32.8689s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.841 â”‚ 0.883 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.764 â”‚ 0.823 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.833 â”‚ 0.878 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.869 â”‚ 0.908 â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1231, ET: 0.1600, TC: 0.1178, WT: 0.0916
[0m
[1;31m2025-05-17 15:06:49,792  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch46_loss0.1240_dice0.8773_20250517150055.pth[0m
[0;32m2025-05-17 15:06:49,863  - INFO - âœ¨ Saved checkpoint (epoch 48) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch48_loss0.1231_dice0.8781_20250517150649.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 15:06:49,864  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-17 15:09:14,647  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-17 15:09:14,648  - INFO - - Train mean loss: 0.2023
- ET loss: 0.2523
- TC loss: 0.2119
- WT loss: 0.1428
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:09:14,648  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-17 15:09:47,199  - INFO - === [Epoch 49/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:32.5498s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.84  â”‚ 0.882 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.764 â”‚ 0.823 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.848 â”‚ 0.898 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.852 â”‚ 0.885 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1236, ET: 0.1610, TC: 0.1189, WT: 0.0909
[0m
[0;33m2025-05-17 15:09:47,199  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 15:09:47,199  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-17 15:12:11,868  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-17 15:12:11,869  - INFO - - Train mean loss: 0.2200
- ET loss: 0.2751
- TC loss: 0.2293
- WT loss: 0.1557
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:12:11,869  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-17 15:12:44,054  - INFO - === [Epoch 50/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:32.1836s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.876 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.83  â”‚ 0.871 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.868 â”‚ 0.906 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1622, TC: 0.1245, WT: 0.0931
[0m
[0;33m2025-05-17 15:12:44,054  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 15:12:44,054  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-17 15:15:08,537  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-17 15:15:08,539  - INFO - - Train mean loss: 0.2028
- ET loss: 0.2529
- TC loss: 0.2091
- WT loss: 0.1463
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:15:08,539  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-17 15:15:40,400  - INFO - === [Epoch 51/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:31.8602s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.881 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.764 â”‚ 0.823 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.864 â”‚ 0.903 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.837 â”‚ 0.881 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1245, ET: 0.1616, TC: 0.1194, WT: 0.0926
[0m
[0;33m2025-05-17 15:15:40,400  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 15:15:40,400  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-17 15:18:04,957  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-17 15:18:04,959  - INFO - - Train mean loss: 0.2172
- ET loss: 0.2668
- TC loss: 0.2300
- WT loss: 0.1547
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:18:04,959  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-17 15:18:36,860  - INFO - === [Epoch 52/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:31.9009s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.88  â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.763 â”‚ 0.821 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.831 â”‚ 0.879 â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.868 â”‚ 0.904 â”‚ 0.943 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1256, ET: 0.1617, TC: 0.1203, WT: 0.0948
[0m
[0;33m2025-05-17 15:18:36,861  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 15:18:36,861  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-17 15:21:01,619  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-17 15:21:01,620  - INFO - - Train mean loss: 0.2007
- ET loss: 0.2539
- TC loss: 0.2126
- WT loss: 0.1355
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:21:01,620  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-17 15:21:33,591  - INFO - === [Epoch 53/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:31.9699s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.842 â”‚ 0.883 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.765 â”‚ 0.825 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.834 â”‚ 0.892 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.868 â”‚ 0.896 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1230, ET: 0.1594, TC: 0.1179, WT: 0.0915
[0m
[1;31m2025-05-17 15:21:33,593  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch48_loss0.1231_dice0.8781_20250517150649.pth[0m
[0;32m2025-05-17 15:21:33,663  - INFO - âœ¨ Saved checkpoint (epoch 53) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch53_loss0.1230_dice0.8783_20250517152133.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 15:21:33,663  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-17 15:23:58,221  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-17 15:23:58,222  - INFO - - Train mean loss: 0.2111
- ET loss: 0.2601
- TC loss: 0.2203
- WT loss: 0.1527
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:23:58,223  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-17 15:24:30,241  - INFO - === [Epoch 54/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:32.0171s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.841 â”‚ 0.88  â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.766 â”‚ 0.823 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.858 â”‚ 0.899 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.845 â”‚ 0.879 â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1249, ET: 0.1601, TC: 0.1204, WT: 0.0941
[0m
[0;33m2025-05-17 15:24:30,241  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 15:24:30,241  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-17 15:26:54,863  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-17 15:26:54,865  - INFO - - Train mean loss: 0.2099
- ET loss: 0.2622
- TC loss: 0.2166
- WT loss: 0.1509
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:26:54,865  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-17 15:27:27,303  - INFO - === [Epoch 55/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:32.4370s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.884 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.827 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.851 â”‚ 0.899 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.854 â”‚ 0.891 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1202, ET: 0.1570, TC: 0.1165, WT: 0.0869
[0m
[1;31m2025-05-17 15:27:27,305  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch53_loss0.1230_dice0.8783_20250517152133.pth[0m
[0;32m2025-05-17 15:27:27,374  - INFO - âœ¨ Saved checkpoint (epoch 55) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch55_loss0.1202_dice0.8810_20250517152727.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 15:27:27,374  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-17 15:29:51,960  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-17 15:29:51,962  - INFO - - Train mean loss: 0.1988
- ET loss: 0.2471
- TC loss: 0.2104
- WT loss: 0.1388
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:29:51,962  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-17 15:30:24,274  - INFO - === [Epoch 56/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:32.3111s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.766 â”‚ 0.825 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.856 â”‚ 0.897 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.847 â”‚ 0.886 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1219, ET: 0.1596, TC: 0.1181, WT: 0.0879
[0m
[0;33m2025-05-17 15:30:24,274  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 15:30:24,274  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-17 15:32:49,140  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-17 15:32:49,142  - INFO - - Train mean loss: 0.2011
- ET loss: 0.2532
- TC loss: 0.2079
- WT loss: 0.1423
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:32:49,142  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-17 15:33:21,010  - INFO - === [Epoch 57/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:31.8676s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.835 â”‚ 0.87  â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.758 â”‚ 0.808 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.874 â”‚ 0.896 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.871 â”‚ 0.819 â”‚ 0.87  â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1292, ET: 0.1660, TC: 0.1300, WT: 0.0915
[0m
[0;33m2025-05-17 15:33:21,010  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 15:33:21,011  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-17 15:35:45,715  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-17 15:35:45,716  - INFO - - Train mean loss: 0.2024
- ET loss: 0.2550
- TC loss: 0.2097
- WT loss: 0.1426
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:35:45,717  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-17 15:36:17,702  - INFO - === [Epoch 58/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:31.9846s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.844 â”‚ 0.889 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.767 â”‚ 0.831 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.835 â”‚ 0.893 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.869 â”‚ 0.899 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1194, ET: 0.1577, TC: 0.1116, WT: 0.0888
[0m
[1;31m2025-05-17 15:36:17,704  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch55_loss0.1202_dice0.8810_20250517152727.pth[0m
[0;32m2025-05-17 15:36:17,771  - INFO - âœ¨ Saved checkpoint (epoch 58) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch58_loss0.1194_dice0.8818_20250517153617.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 15:36:17,771  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-17 15:38:42,387  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-17 15:38:42,388  - INFO - - Train mean loss: 0.2004
- ET loss: 0.2498
- TC loss: 0.2052
- WT loss: 0.1463
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:38:42,388  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-17 15:39:14,378  - INFO - === [Epoch 59/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:31.9889s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.885 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.827 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.845 â”‚ 0.887 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.861 â”‚ 0.9   â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1207, ET: 0.1586, TC: 0.1161, WT: 0.0873
[0m
[0;33m2025-05-17 15:39:14,378  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 15:39:14,378  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-17 15:41:38,863  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-17 15:41:38,865  - INFO - - Train mean loss: 0.2167
- ET loss: 0.2711
- TC loss: 0.2272
- WT loss: 0.1519
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:41:38,865  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-17 15:42:10,701  - INFO - === [Epoch 60/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:31.8354s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.84  â”‚ 0.882 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.813 â”‚ 0.764 â”‚ 0.823 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.898 â”‚ 0.859 â”‚ 0.913 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.844 â”‚ 0.87  â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1227, ET: 0.1613, TC: 0.1185, WT: 0.0882
[0m
[0;33m2025-05-17 15:42:10,701  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 15:42:10,701  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-17 15:44:35,416  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-17 15:44:35,418  - INFO - - Train mean loss: 0.1871
- ET loss: 0.2343
- TC loss: 0.1944
- WT loss: 0.1326
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:44:35,418  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-17 15:45:07,298  - INFO - === [Epoch 61/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:31.8789s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.843 â”‚ 0.886 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.768 â”‚ 0.829 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.878 â”‚ 0.838 â”‚ 0.891 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.867 â”‚ 0.896 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1212, ET: 0.1578, TC: 0.1149, WT: 0.0910
[0m
[0;33m2025-05-17 15:45:07,298  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 15:45:07,298  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-17 15:47:33,010  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-17 15:47:33,012  - INFO - - Train mean loss: 0.2080
- ET loss: 0.2620
- TC loss: 0.2191
- WT loss: 0.1429
- Cost time: 2.43mins â±ï¸
[0m
[0;32m2025-05-17 15:47:33,013  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-17 15:48:04,802  - INFO - === [Epoch 62/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:31.7885s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.841 â”‚ 0.885 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.767 â”‚ 0.827 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.85  â”‚ 0.904 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.854 â”‚ 0.882 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1216, ET: 0.1599, TC: 0.1158, WT: 0.0890
[0m
[0;33m2025-05-17 15:48:04,802  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 15:48:04,802  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-17 15:50:29,527  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-17 15:50:29,529  - INFO - - Train mean loss: 0.2061
- ET loss: 0.2583
- TC loss: 0.2162
- WT loss: 0.1440
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:50:29,529  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-17 15:51:01,654  - INFO - === [Epoch 63/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:32.1243s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.841 â”‚ 0.882 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.767 â”‚ 0.824 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.851 â”‚ 0.9   â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.854 â”‚ 0.885 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1217, ET: 0.1598, TC: 0.1184, WT: 0.0868
[0m
[0;33m2025-05-17 15:51:01,654  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 15:51:01,654  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-17 15:53:26,445  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-17 15:53:26,446  - INFO - - Train mean loss: 0.1946
- ET loss: 0.2442
- TC loss: 0.1996
- WT loss: 0.1399
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:53:26,446  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-17 15:53:58,240  - INFO - === [Epoch 64/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:31.7930s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.884 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.828 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.857 â”‚ 0.908 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.849 â”‚ 0.881 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1201, ET: 0.1578, TC: 0.1163, WT: 0.0862
[0m
[0;33m2025-05-17 15:53:58,240  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 15:53:58,240  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-17 15:56:22,878  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-17 15:56:22,879  - INFO - - Train mean loss: 0.2020
- ET loss: 0.2536
- TC loss: 0.2061
- WT loss: 0.1462
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:56:22,880  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-17 15:56:54,994  - INFO - === [Epoch 65/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:32.1134s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.884 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.826 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.841 â”‚ 0.887 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.865 â”‚ 0.901 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1197, ET: 0.1571, TC: 0.1163, WT: 0.0857
[0m
[0;33m2025-05-17 15:56:54,994  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 15:56:54,994  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-17 15:59:19,543  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-17 15:59:19,544  - INFO - - Train mean loss: 0.2069
- ET loss: 0.2542
- TC loss: 0.2130
- WT loss: 0.1535
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 15:59:19,544  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-17 15:59:52,545  - INFO - === [Epoch 66/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:33.0003s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.845 â”‚ 0.886 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.77  â”‚ 0.829 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.898 â”‚ 0.857 â”‚ 0.903 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.851 â”‚ 0.887 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1184, ET: 0.1566, TC: 0.1149, WT: 0.0837
[0m
[1;31m2025-05-17 15:59:52,547  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch58_loss0.1194_dice0.8818_20250517153617.pth[0m
[0;32m2025-05-17 15:59:52,619  - INFO - âœ¨ Saved checkpoint (epoch 66) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch66_loss0.1184_dice0.8827_20250517155952.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 15:59:52,619  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-17 16:02:17,248  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-17 16:02:17,250  - INFO - - Train mean loss: 0.1990
- ET loss: 0.2533
- TC loss: 0.2034
- WT loss: 0.1403
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:02:17,250  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-17 16:02:48,874  - INFO - === [Epoch 67/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:31.6231s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.844 â”‚ 0.884 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.77  â”‚ 0.826 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.853 â”‚ 0.891 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.856 â”‚ 0.896 â”‚ 0.936 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1212, ET: 0.1574, TC: 0.1166, WT: 0.0896
[0m
[0;33m2025-05-17 16:02:48,874  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 16:02:48,874  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-17 16:05:13,334  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-17 16:05:13,335  - INFO - - Train mean loss: 0.1925
- ET loss: 0.2428
- TC loss: 0.1974
- WT loss: 0.1374
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:05:13,335  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-17 16:05:45,088  - INFO - === [Epoch 68/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:31.7519s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.886 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.77  â”‚ 0.83  â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.85  â”‚ 0.905 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.859 â”‚ 0.887 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1187, ET: 0.1564, TC: 0.1141, WT: 0.0856
[0m
[0;33m2025-05-17 16:05:45,088  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 16:05:45,088  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-17 16:08:09,824  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-17 16:08:09,825  - INFO - - Train mean loss: 0.1923
- ET loss: 0.2433
- TC loss: 0.1985
- WT loss: 0.1351
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:08:09,825  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-17 16:08:41,464  - INFO - === [Epoch 69/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:31.6375s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.843 â”‚ 0.887 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.767 â”‚ 0.829 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.832 â”‚ 0.885 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.902 â”‚ 0.876 â”‚ 0.906 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1193, ET: 0.1583, TC: 0.1134, WT: 0.0861
[0m
[0;33m2025-05-17 16:08:41,464  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 16:08:41,464  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-17 16:11:06,601  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-17 16:11:06,603  - INFO - - Train mean loss: 0.1936
- ET loss: 0.2435
- TC loss: 0.1967
- WT loss: 0.1406
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 16:11:06,603  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-17 16:11:38,404  - INFO - === [Epoch 70/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:31.8004s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.845 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.77  â”‚ 0.831 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.835 â”‚ 0.899 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.873 â”‚ 0.891 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1176, ET: 0.1560, TC: 0.1120, WT: 0.0846
[0m
[1;31m2025-05-17 16:11:38,406  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch66_loss0.1184_dice0.8827_20250517155952.pth[0m
[0;32m2025-05-17 16:11:38,664  - INFO - âœ¨ Saved checkpoint (epoch 70) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch70_loss0.1176_dice0.8835_20250517161138.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 16:11:38,665  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-17 16:14:03,356  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-17 16:14:03,357  - INFO - - Train mean loss: 0.2047
- ET loss: 0.2587
- TC loss: 0.2124
- WT loss: 0.1431
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:14:03,357  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-17 16:14:35,063  - INFO - === [Epoch 71/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:31.7049s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.884 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.851 â”‚ 0.898 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.857 â”‚ 0.891 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1199, ET: 0.1576, TC: 0.1168, WT: 0.0853
[0m
[0;33m2025-05-17 16:14:35,063  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 16:14:35,064  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-17 16:16:59,418  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-17 16:16:59,419  - INFO - - Train mean loss: 0.1970
- ET loss: 0.2502
- TC loss: 0.2046
- WT loss: 0.1361
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:16:59,419  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-17 16:17:31,001  - INFO - === [Epoch 72/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:31.5808s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.845 â”‚ 0.889 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.77  â”‚ 0.831 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.841 â”‚ 0.897 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.867 â”‚ 0.896 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1183, ET: 0.1561, TC: 0.1121, WT: 0.0868
[0m
[0;33m2025-05-17 16:17:31,001  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 16:17:31,001  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-17 16:19:55,920  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-17 16:19:55,921  - INFO - - Train mean loss: 0.1900
- ET loss: 0.2433
- TC loss: 0.1958
- WT loss: 0.1308
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 16:19:55,921  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-17 16:20:26,668  - INFO - === [Epoch 73/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:30.7458s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.846 â”‚ 0.888 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.772 â”‚ 0.832 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.846 â”‚ 0.896 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.864 â”‚ 0.898 â”‚ 0.934 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1186, ET: 0.1551, TC: 0.1122, WT: 0.0887
[0m
[0;33m2025-05-17 16:20:26,668  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 16:20:26,668  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-17 16:22:51,248  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-17 16:22:51,250  - INFO - - Train mean loss: 0.1973
- ET loss: 0.2472
- TC loss: 0.2031
- WT loss: 0.1417
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:22:51,250  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-17 16:23:22,864  - INFO - === [Epoch 74/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:31.6133s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.886 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.771 â”‚ 0.83  â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.847 â”‚ 0.897 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.862 â”‚ 0.894 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1186, ET: 0.1557, TC: 0.1143, WT: 0.0859
[0m
[0;33m2025-05-17 16:23:22,864  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 16:23:22,864  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-17 16:25:47,256  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-17 16:25:47,257  - INFO - - Train mean loss: 0.2055
- ET loss: 0.2563
- TC loss: 0.2149
- WT loss: 0.1454
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:25:47,257  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-17 16:26:19,100  - INFO - === [Epoch 75/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:31.8424s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.847 â”‚ 0.887 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.773 â”‚ 0.831 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.848 â”‚ 0.897 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.863 â”‚ 0.896 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1186, ET: 0.1542, TC: 0.1134, WT: 0.0884
[0m
[0;33m2025-05-17 16:26:19,101  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 16:26:19,101  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-17 16:28:43,856  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-17 16:28:43,858  - INFO - - Train mean loss: 0.1960
- ET loss: 0.2501
- TC loss: 0.1997
- WT loss: 0.1381
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:28:43,858  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-17 16:29:15,652  - INFO - === [Epoch 76/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:31.7931s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.887 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.773 â”‚ 0.831 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.847 â”‚ 0.897 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.864 â”‚ 0.896 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1177, ET: 0.1545, TC: 0.1137, WT: 0.0848
[0m
[0;33m2025-05-17 16:29:15,652  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 16:29:15,652  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-17 16:31:40,290  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-17 16:31:40,291  - INFO - - Train mean loss: 0.1844
- ET loss: 0.2348
- TC loss: 0.1872
- WT loss: 0.1312
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:31:40,292  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-17 16:32:12,049  - INFO - === [Epoch 77/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:31.7565s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.885 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.772 â”‚ 0.831 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.855 â”‚ 0.905 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.855 â”‚ 0.883 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1179, ET: 0.1550, TC: 0.1151, WT: 0.0836
[0m
[0;33m2025-05-17 16:32:12,049  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-17 16:32:12,049  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-17 16:34:36,588  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-17 16:34:36,589  - INFO - - Train mean loss: 0.2032
- ET loss: 0.2596
- TC loss: 0.2137
- WT loss: 0.1363
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:34:36,589  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-17 16:35:08,280  - INFO - === [Epoch 78/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:31.6902s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.887 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.773 â”‚ 0.831 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.85  â”‚ 0.898 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.862 â”‚ 0.896 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1179, ET: 0.1549, TC: 0.1140, WT: 0.0848
[0m
[0;33m2025-05-17 16:35:08,281  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-17 16:35:08,281  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-17 16:37:32,817  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-17 16:37:32,818  - INFO - - Train mean loss: 0.1933
- ET loss: 0.2424
- TC loss: 0.1958
- WT loss: 0.1418
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:37:32,818  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-17 16:38:04,500  - INFO - === [Epoch 79/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:31.6802s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.885 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.772 â”‚ 0.829 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.861 â”‚ 0.906 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.848 â”‚ 0.885 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1190, ET: 0.1556, TC: 0.1156, WT: 0.0859
[0m
[0;33m2025-05-17 16:38:04,500  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-17 16:38:04,500  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-17 16:40:29,298  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-17 16:40:29,299  - INFO - - Train mean loss: 0.1919
- ET loss: 0.2437
- TC loss: 0.2001
- WT loss: 0.1319
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:40:29,299  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-17 16:41:01,338  - INFO - === [Epoch 80/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:32.0379s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.771 â”‚ 0.829 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.904 â”‚ 0.865 â”‚ 0.915 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.849 â”‚ 0.88  â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1191, ET: 0.1566, TC: 0.1165, WT: 0.0842
[0m
[0;33m2025-05-17 16:41:01,339  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-17 16:41:01,339  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-17 16:43:26,118  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-17 16:43:26,120  - INFO - - Train mean loss: 0.1959
- ET loss: 0.2481
- TC loss: 0.2038
- WT loss: 0.1359
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:43:26,120  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-17 16:43:57,711  - INFO - === [Epoch 81/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:31.5902s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.887 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.772 â”‚ 0.832 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.843 â”‚ 0.894 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.868 â”‚ 0.896 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1180, ET: 0.1549, TC: 0.1137, WT: 0.0852
[0m
[0;33m2025-05-17 16:43:57,711  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-17 16:43:57,711  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-17 16:46:22,503  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-17 16:46:22,504  - INFO - - Train mean loss: 0.2085
- ET loss: 0.2627
- TC loss: 0.2163
- WT loss: 0.1465
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:46:22,504  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-17 16:46:54,118  - INFO - === [Epoch 82/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:31.6124s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.845 â”‚ 0.885 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.771 â”‚ 0.829 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.844 â”‚ 0.894 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.867 â”‚ 0.897 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1184, ET: 0.1561, TC: 0.1152, WT: 0.0838
[0m
[0;33m2025-05-17 16:46:54,118  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[0;32m2025-05-17 16:46:54,119  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-17 16:49:18,494  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-17 16:49:18,495  - INFO - - Train mean loss: 0.1922
- ET loss: 0.2419
- TC loss: 0.1971
- WT loss: 0.1378
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:49:18,495  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-17 16:49:49,972  - INFO - === [Epoch 83/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:31.4760s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.888 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.773 â”‚ 0.831 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.844 â”‚ 0.893 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.868 â”‚ 0.901 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1177, ET: 0.1538, TC: 0.1131, WT: 0.0862
[0m
[0;33m2025-05-17 16:49:49,972  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 13/100[0m
[0;32m2025-05-17 16:49:49,972  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-17 16:52:14,973  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-17 16:52:14,974  - INFO - - Train mean loss: 0.1957
- ET loss: 0.2486
- TC loss: 0.1995
- WT loss: 0.1392
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 16:52:14,974  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-17 16:52:46,848  - INFO - === [Epoch 84/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:31.8732s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.888 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.774 â”‚ 0.832 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.851 â”‚ 0.899 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.862 â”‚ 0.894 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1176, ET: 0.1536, TC: 0.1126, WT: 0.0866
[0m
[0;33m2025-05-17 16:52:46,848  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 14/100[0m
[0;32m2025-05-17 16:52:46,848  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-17 16:55:11,336  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-17 16:55:11,337  - INFO - - Train mean loss: 0.1871
- ET loss: 0.2401
- TC loss: 0.1922
- WT loss: 0.1290
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:55:11,338  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-17 16:55:42,948  - INFO - === [Epoch 85/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:31.6100s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.848 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.774 â”‚ 0.832 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.854 â”‚ 0.904 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.861 â”‚ 0.892 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1171, ET: 0.1533, TC: 0.1131, WT: 0.0849
[0m
[1;31m2025-05-17 16:55:42,951  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch70_loss0.1176_dice0.8835_20250517161138.pth[0m
[0;32m2025-05-17 16:55:43,017  - INFO - âœ¨ Saved checkpoint (epoch 85) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch85_loss0.1171_dice0.8841_20250517165542.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 16:55:43,018  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-17 16:58:07,370  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-17 16:58:07,371  - INFO - - Train mean loss: 0.1841
- ET loss: 0.2330
- TC loss: 0.1870
- WT loss: 0.1322
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 16:58:07,372  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-17 16:58:39,305  - INFO - === [Epoch 86/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:31.9329s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.887 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.773 â”‚ 0.831 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.852 â”‚ 0.898 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.861 â”‚ 0.894 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1181, ET: 0.1546, TC: 0.1139, WT: 0.0857
[0m
[0;33m2025-05-17 16:58:39,306  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 16:58:39,306  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-17 17:01:04,029  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-17 17:01:04,030  - INFO - - Train mean loss: 0.2022
- ET loss: 0.2531
- TC loss: 0.2091
- WT loss: 0.1443
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:01:04,030  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-17 17:01:35,488  - INFO - === [Epoch 87/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:31.4571s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.888 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.773 â”‚ 0.832 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.849 â”‚ 0.9   â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.863 â”‚ 0.893 â”‚ 0.937 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1182, ET: 0.1544, TC: 0.1127, WT: 0.0875
[0m
[0;33m2025-05-17 17:01:35,488  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 17:01:35,488  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-17 17:03:59,897  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-17 17:03:59,899  - INFO - - Train mean loss: 0.1752
- ET loss: 0.2237
- TC loss: 0.1782
- WT loss: 0.1236
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:03:59,899  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-17 17:04:32,163  - INFO - === [Epoch 88/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:32.2634s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.887 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.774 â”‚ 0.831 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.898 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.864 â”‚ 0.895 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1539, TC: 0.1134, WT: 0.0843
[0m
[0;33m2025-05-17 17:04:32,163  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 17:04:32,163  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-17 17:06:56,732  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-17 17:06:56,733  - INFO - - Train mean loss: 0.2008
- ET loss: 0.2515
- TC loss: 0.2080
- WT loss: 0.1431
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:06:56,733  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-17 17:07:28,648  - INFO - === [Epoch 89/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:31.9139s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.774 â”‚ 0.832 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.854 â”‚ 0.899 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.859 â”‚ 0.895 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1542, TC: 0.1128, WT: 0.0848
[0m
[0;33m2025-05-17 17:07:28,648  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 17:07:28,648  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-17 17:09:53,403  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-17 17:09:53,404  - INFO - - Train mean loss: 0.2084
- ET loss: 0.2612
- TC loss: 0.2191
- WT loss: 0.1450
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:09:53,404  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-17 17:10:25,030  - INFO - === [Epoch 90/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:31.6244s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.886 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.773 â”‚ 0.83  â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.854 â”‚ 0.898 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.858 â”‚ 0.891 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1178, ET: 0.1546, TC: 0.1147, WT: 0.0841
[0m
[0;33m2025-05-17 17:10:25,030  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 17:10:25,030  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-17 17:12:49,968  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-17 17:12:49,969  - INFO - - Train mean loss: 0.1932
- ET loss: 0.2453
- TC loss: 0.1990
- WT loss: 0.1353
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 17:12:49,969  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-17 17:13:21,317  - INFO - === [Epoch 91/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:31.3464s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.846 â”‚ 0.887 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.831 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.846 â”‚ 0.897 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.866 â”‚ 0.896 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1173, ET: 0.1547, TC: 0.1135, WT: 0.0838
[0m
[0;33m2025-05-17 17:13:21,317  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 17:13:21,317  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-17 17:15:46,094  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-17 17:15:46,095  - INFO - - Train mean loss: 0.1911
- ET loss: 0.2437
- TC loss: 0.1965
- WT loss: 0.1330
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:15:46,095  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-17 17:16:17,813  - INFO - === [Epoch 92/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:31.7165s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.885 â”‚ 0.847 â”‚ 0.889 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.833 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.85  â”‚ 0.9   â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.863 â”‚ 0.894 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1164, ET: 0.1537, TC: 0.1121, WT: 0.0834
[0m
[1;31m2025-05-17 17:16:17,815  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch85_loss0.1171_dice0.8841_20250517165542.pth[0m
[0;32m2025-05-17 17:16:17,882  - INFO - âœ¨ Saved checkpoint (epoch 92) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch92_loss0.1164_dice0.8847_20250517171617.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 17:16:17,883  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-17 17:18:42,386  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-17 17:18:42,387  - INFO - - Train mean loss: 0.2020
- ET loss: 0.2567
- TC loss: 0.2107
- WT loss: 0.1386
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:18:42,387  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-17 17:19:13,894  - INFO - === [Epoch 93/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:31.5052s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.885 â”‚ 0.847 â”‚ 0.89  â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.833 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.898 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.865 â”‚ 0.898 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1162, ET: 0.1536, TC: 0.1110, WT: 0.0840
[0m
[1;31m2025-05-17 17:19:13,896  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch92_loss0.1164_dice0.8847_20250517171617.pth[0m
[0;32m2025-05-17 17:19:13,976  - INFO - âœ¨ Saved checkpoint (epoch 93) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch93_loss0.1162_dice0.8849_20250517171913.pth;             Size 14.39 MB[0m
[0;32m2025-05-17 17:19:13,976  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-17 17:21:38,851  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-17 17:21:38,852  - INFO - - Train mean loss: 0.1935
- ET loss: 0.2473
- TC loss: 0.2011
- WT loss: 0.1320
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:21:38,852  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-17 17:22:10,915  - INFO - === [Epoch 94/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:32.0625s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.888 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.832 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.854 â”‚ 0.9   â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.86  â”‚ 0.894 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1167, ET: 0.1537, TC: 0.1128, WT: 0.0835
[0m
[0;33m2025-05-17 17:22:10,916  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 17:22:10,916  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-17 17:24:35,373  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-17 17:24:35,374  - INFO - - Train mean loss: 0.2072
- ET loss: 0.2610
- TC loss: 0.2153
- WT loss: 0.1453
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:24:35,374  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-17 17:25:06,965  - INFO - === [Epoch 95/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:31.5893s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.889 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.832 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.847 â”‚ 0.896 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.865 â”‚ 0.898 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1166, ET: 0.1542, TC: 0.1121, WT: 0.0837
[0m
[0;33m2025-05-17 17:25:06,965  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 17:25:06,965  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-17 17:27:31,715  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-17 17:27:31,717  - INFO - - Train mean loss: 0.1975
- ET loss: 0.2552
- TC loss: 0.2071
- WT loss: 0.1303
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:27:31,717  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-17 17:28:03,386  - INFO - === [Epoch 96/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:31.6685s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.889 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.833 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.848 â”‚ 0.898 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.865 â”‚ 0.896 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1167, ET: 0.1542, TC: 0.1117, WT: 0.0841
[0m
[0;33m2025-05-17 17:28:03,386  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 17:28:03,386  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-17 17:30:28,098  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-17 17:30:28,100  - INFO - - Train mean loss: 0.1910
- ET loss: 0.2421
- TC loss: 0.1980
- WT loss: 0.1329
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:30:28,100  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-17 17:31:00,287  - INFO - === [Epoch 97/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:32.1863s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.832 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.854 â”‚ 0.903 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.861 â”‚ 0.892 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1542, TC: 0.1126, WT: 0.0846
[0m
[0;33m2025-05-17 17:31:00,287  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 17:31:00,287  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-17 17:33:25,523  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-17 17:33:25,525  - INFO - - Train mean loss: 0.1914
- ET loss: 0.2425
- TC loss: 0.1977
- WT loss: 0.1341
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 17:33:25,525  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-17 17:33:57,495  - INFO - === [Epoch 98/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:31.9693s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.888 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.832 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.849 â”‚ 0.901 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.864 â”‚ 0.893 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1170, ET: 0.1542, TC: 0.1127, WT: 0.0840
[0m
[0;33m2025-05-17 17:33:57,495  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-17 17:33:57,495  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-17 17:36:21,958  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-17 17:36:21,960  - INFO - - Train mean loss: 0.1957
- ET loss: 0.2508
- TC loss: 0.2026
- WT loss: 0.1337
- Cost time: 2.41mins â±ï¸
[0m
[0;32m2025-05-17 17:36:21,960  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-17 17:36:53,688  - INFO - === [Epoch 99/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:31.7268s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.774 â”‚ 0.831 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.849 â”‚ 0.895 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.864 â”‚ 0.898 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1170, ET: 0.1538, TC: 0.1127, WT: 0.0844
[0m
[0;33m2025-05-17 17:36:53,688  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-17 17:36:53,688  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-17 17:39:18,814  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-17 17:39:18,815  - INFO - - Train mean loss: 0.1931
- ET loss: 0.2476
- TC loss: 0.2014
- WT loss: 0.1302
- Cost time: 2.42mins â±ï¸
[0m
[0;32m2025-05-17 17:39:18,815  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-17 17:39:50,642  - INFO - === [Epoch 100/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:31.8255s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.888 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.774 â”‚ 0.832 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.854 â”‚ 0.9   â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.859 â”‚ 0.894 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1168, ET: 0.1539, TC: 0.1124, WT: 0.0839
[0m
[0;33m2025-05-17 17:39:50,642  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[1;31m2025-05-17 17:39:51,849  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1162 at epoch 93[0m
[0;32m2025-05-17 17:39:51,849  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 17:39:51,859  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/ResUNetBaseline_S_DCLAv1_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 17:39:51,859  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 17:39:51,859  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 17:43:20,120  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚  0.82  â”‚ 0.883 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚  0.741 â”‚ 0.82  â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚  0.82  â”‚ 0.91  â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚  0.839 â”‚ 0.884 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  6.727 â”‚ 10.242 â”‚ 4.499 â”‚ 5.442 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1257;ET: 0.1813;ET: 0.1813;TC: 0.1176;WT: 0.0783
[0m
[0;32m2025-05-17 17:43:20,120  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 17:43:20,120  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-17.log[0m
[0;32m2025-05-17 17:46:29,312  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 17:46:32,558  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 17:46:32,561  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 17:46:32,561  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 17:46:32,561  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 17:46:32,561  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 17:46:32,561  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 17:46:32,568  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 17:46:32,568  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 17:46:32,568  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 17:46:32,571  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv1_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 17:46:32,790  - INFO - 
model: ResUNetBaseline_S_SLKv1_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 17:46:32,790  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 17:47:09,283  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 17:47:09,284  - INFO - - Train mean loss: 0.7318
- ET loss: 0.6673
- TC loss: 0.7251
- WT loss: 0.8031
- Cost time: 0.61mins â±ï¸
[0m
[0;32m2025-05-17 17:47:09,284  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 17:47:18,172  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.8868s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.636 â”‚ 0.635 â”‚ 0.601 â”‚ 0.671 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.505 â”‚ 0.503 â”‚ 0.463 â”‚ 0.547 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.678 â”‚ 0.612 â”‚ 0.569 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.713 â”‚ 0.739 â”‚ 0.787 â”‚ 0.612 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3718, ET: 0.3743, TC: 0.4032, WT: 0.3378
[0m
[0;32m2025-05-17 17:47:18,208  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3718_dice0.6359_20250517174718.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:47:18,208  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 17:47:52,588  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 17:47:52,589  - INFO - - Train mean loss: 0.4369
- ET loss: 0.4746
- TC loss: 0.4770
- WT loss: 0.3590
- Cost time: 0.57mins â±ï¸
[0m
[0;32m2025-05-17 17:47:52,589  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 17:48:00,991  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:8.4011s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.706 â”‚ 0.687 â”‚ 0.678 â”‚ 0.754 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.589 â”‚ 0.57  â”‚ 0.558 â”‚ 0.638 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.771 â”‚ 0.695 â”‚ 0.714 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.728 â”‚ 0.738 â”‚ 0.757 â”‚ 0.687 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3023, ET: 0.3211, TC: 0.3297, WT: 0.2563
[0m
[0;32m2025-05-17 17:48:01,026  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3023_dice0.7062_20250517174800.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:48:01,027  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 17:48:35,442  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 17:48:35,442  - INFO - - Train mean loss: 0.3758
- ET loss: 0.4185
- TC loss: 0.4150
- WT loss: 0.2940
- Cost time: 0.57mins â±ï¸
[0m
[0;32m2025-05-17 17:48:35,442  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 17:48:43,632  - INFO - === [Epoch 3/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:8.1886s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.709 â”‚ 0.714 â”‚ 0.706 â”‚ 0.706 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.588 â”‚ 0.601 â”‚ 0.596 â”‚ 0.567 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.706 â”‚ 0.723 â”‚ 0.784 â”‚ 0.611 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.781 â”‚ 0.75  â”‚ 0.703 â”‚ 0.889 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3003, ET: 0.2912, TC: 0.2976, WT: 0.3121
[0m
[1;31m2025-05-17 17:48:43,633  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3023_dice0.7062_20250517174800.pth[0m
[0;32m2025-05-17 17:48:43,674  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3003_dice0.7086_20250517174843.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:48:43,675  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-17 17:49:18,681  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-17 17:49:18,681  - INFO - - Train mean loss: 0.3546
- ET loss: 0.3880
- TC loss: 0.3886
- WT loss: 0.2871
- Cost time: 0.58mins â±ï¸
[0m
[0;32m2025-05-17 17:49:18,681  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-17 17:49:26,843  - INFO - === [Epoch 4/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:8.1576s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.745 â”‚ 0.728 â”‚ 0.698 â”‚ 0.81  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.634 â”‚ 0.619 â”‚ 0.577 â”‚ 0.706 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.741 â”‚ 0.685 â”‚ 0.658 â”‚ 0.88  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.813 â”‚ 0.816 â”‚ 0.844 â”‚ 0.779 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2612, ET: 0.2768, TC: 0.3077, WT: 0.1991
[0m
[1;31m2025-05-17 17:49:26,845  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3003_dice0.7086_20250517174843.pth[0m
[0;32m2025-05-17 17:49:26,889  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.2612_dice0.7454_20250517174926.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:49:26,889  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-17 17:50:02,900  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-17 17:50:02,900  - INFO - - Train mean loss: 0.3502
- ET loss: 0.3946
- TC loss: 0.3972
- WT loss: 0.2590
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 17:50:02,900  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-17 17:50:11,209  - INFO - === [Epoch 5/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:8.3073s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.744 â”‚ 0.729 â”‚ 0.724 â”‚ 0.78  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.633 â”‚ 0.623 â”‚ 0.614 â”‚ 0.661 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.693 â”‚ 0.684 â”‚ 0.691 â”‚ 0.705 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.857 â”‚ 0.83  â”‚ 0.841 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2696, ET: 0.2802, TC: 0.2844, WT: 0.2441
[0m
[0;33m2025-05-17 17:50:11,209  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-17 17:50:11,209  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-17 17:50:46,604  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-17 17:50:46,604  - INFO - - Train mean loss: 0.3667
- ET loss: 0.4110
- TC loss: 0.4042
- WT loss: 0.2849
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 17:50:46,605  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-17 17:50:54,870  - INFO - === [Epoch 6/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:8.2639s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.763 â”‚ 0.737 â”‚ 0.735 â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.661 â”‚ 0.635 â”‚ 0.634 â”‚ 0.715 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.84  â”‚ 0.811 â”‚ 0.825 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.749 â”‚ 0.727 â”‚ 0.74  â”‚ 0.782 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2425, ET: 0.2678, TC: 0.2682, WT: 0.1916
[0m
[1;31m2025-05-17 17:50:54,872  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2612_dice0.7454_20250517174926.pth[0m
[0;32m2025-05-17 17:50:54,917  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch6_loss0.2425_dice0.7628_20250517175054.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:50:54,917  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-17 17:51:30,956  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-17 17:51:30,956  - INFO - - Train mean loss: 0.3420
- ET loss: 0.3815
- TC loss: 0.3812
- WT loss: 0.2632
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 17:51:30,956  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-17 17:51:39,009  - INFO - === [Epoch 7/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:8.0521s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.769 â”‚ 0.748 â”‚ 0.742 â”‚ 0.818 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.667 â”‚ 0.648 â”‚ 0.639 â”‚ 0.714 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.77  â”‚ 0.744 â”‚ 0.756 â”‚ 0.81  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.824 â”‚ 0.809 â”‚ 0.813 â”‚ 0.849 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2382, ET: 0.2569, TC: 0.2631, WT: 0.1947
[0m
[1;31m2025-05-17 17:51:39,011  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.2425_dice0.7628_20250517175054.pth[0m
[0;32m2025-05-17 17:51:39,053  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch7_loss0.2382_dice0.7693_20250517175139.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:51:39,053  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-17 17:52:13,000  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-17 17:52:13,000  - INFO - - Train mean loss: 0.3238
- ET loss: 0.3642
- TC loss: 0.3646
- WT loss: 0.2425
- Cost time: 0.57mins â±ï¸
[0m
[0;32m2025-05-17 17:52:13,001  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-17 17:52:21,209  - INFO - === [Epoch 8/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:8.2071s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.783 â”‚ 0.759 â”‚ 0.753 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.684 â”‚ 0.662 â”‚ 0.651 â”‚ 0.738 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.756 â”‚ 0.733 â”‚ 0.714 â”‚ 0.82  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚ 0.824 â”‚ 0.863 â”‚ 0.872 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2254, ET: 0.2465, TC: 0.2537, WT: 0.1760
[0m
[1;31m2025-05-17 17:52:21,210  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.2382_dice0.7693_20250517175139.pth[0m
[0;32m2025-05-17 17:52:21,251  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch8_loss0.2254_dice0.7827_20250517175221.pth;             Size 12.35 MB[0m
[0;32m2025-05-17 17:52:21,252  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-17 17:52:55,982  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-17 17:52:55,982  - INFO - - Train mean loss: 0.3150
- ET loss: 0.3653
- TC loss: 0.3563
- WT loss: 0.2233
- Cost time: 0.58mins â±ï¸
[0m
[0;32m2025-05-17 17:52:55,982  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-17 17:53:04,206  - INFO - === [Epoch 9/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:8.2221s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.777 â”‚ 0.75  â”‚ 0.739 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.677 â”‚ 0.651 â”‚ 0.632 â”‚ 0.749 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.749 â”‚ 0.705 â”‚ 0.685 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.858 â”‚ 0.842 â”‚ 0.878 â”‚ 0.853 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2280, ET: 0.2546, TC: 0.2661, WT: 0.1632
[0m
[0;33m2025-05-17 17:53:04,206  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-17 17:53:04,206  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-17 17:53:39,745  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-17 17:53:39,745  - INFO - - Train mean loss: 0.3083
- ET loss: 0.3485
- TC loss: 0.3472
- WT loss: 0.2291
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 17:53:39,745  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-17 17:53:47,762  - INFO - === [Epoch 10/10] ===
- Model:    ResUNetBaseline_S_SLKv1_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:8.0163s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.777 â”‚ 0.757 â”‚ 0.766 â”‚ 0.808 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.684 â”‚ 0.661 â”‚ 0.677 â”‚ 0.713 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.86  â”‚ 0.806 â”‚ 0.847 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.755 â”‚ 0.75  â”‚ 0.759 â”‚ 0.755 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2266, ET: 0.2471, TC: 0.2380, WT: 0.1946
[0m
[0;33m2025-05-17 17:53:47,763  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/5[0m
[1;31m2025-05-17 17:53:47,763  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.2254 at epoch 8[0m
[0;32m2025-05-17 17:53:47,763  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 17:53:47,771  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/ResUNetBaseline_S_SLKv1_v2_final_model.pth[0m
[1;31m2025-05-17 17:53:47,771  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 17:53:47,771  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 17:54:40,110  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.803 â”‚  0.765 â”‚  0.772 â”‚  0.871 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.697 â”‚  0.652 â”‚  0.659 â”‚  0.78  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.805 â”‚  0.741 â”‚  0.791 â”‚  0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.847 â”‚  0.825 â”‚  0.843 â”‚  0.872 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 13.784 â”‚ 13.318 â”‚ 13.275 â”‚ 14.76  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.2060;ET: 0.2420;ET: 0.2420;TC: 0.2354;WT: 0.1406
[0m
[0;32m2025-05-17 17:54:40,111  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 17:54:40,111  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv1_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 17:54:46,333  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 17:54:49,657  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 17:54:49,659  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 17:54:49,659  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 17:54:49,659  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 17:54:49,660  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 17:54:49,660  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 17:54:49,666  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 17:54:49,667  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 17:54:49,667  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 17:54:49,670  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 17:54:50,069  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 17:54:50,070  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 17:55:26,279  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 17:55:26,279  - INFO - - Train mean loss: 0.7264
- ET loss: 0.8457
- TC loss: 0.7684
- WT loss: 0.5650
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 17:55:26,279  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 17:55:35,101  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.8204s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.482 â”‚ 0.305 â”‚ 0.423 â”‚ 0.716 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.361 â”‚ 0.192 â”‚ 0.293 â”‚ 0.597 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.498 â”‚ 0.228 â”‚ 0.371 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.652 â”‚ 0.633 â”‚ 0.683 â”‚ 0.64  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5198, ET: 0.6960, TC: 0.5787, WT: 0.2847
[0m
[1;31m2025-05-17 17:55:35,103  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.4134_dice0.5884_20250517124459.pth[0m
[0;32m2025-05-17 17:55:35,170  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5198_dice0.4817_20250517175535.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 17:55:35,170  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 17:56:11,246  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 17:56:11,247  - INFO - - Train mean loss: 0.5519
- ET loss: 0.7238
- TC loss: 0.5932
- WT loss: 0.3388
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 17:56:11,247  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 17:56:19,773  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:8.5251s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.532 â”‚ 0.374 â”‚ 0.495 â”‚ 0.728 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.406 â”‚ 0.245 â”‚ 0.356 â”‚ 0.616 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.55  â”‚ 0.286 â”‚ 0.435 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.711 â”‚ 0.728 â”‚ 0.764 â”‚ 0.641 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4681, ET: 0.6270, TC: 0.5060, WT: 0.2713
[0m
[1;31m2025-05-17 17:56:19,775  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.5198_dice0.4817_20250517175535.pth[0m
[0;32m2025-05-17 17:56:19,838  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4681_dice0.5325_20250517175619.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 17:56:19,839  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 17:56:55,094  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 17:56:55,095  - INFO - - Train mean loss: 0.4759
- ET loss: 0.6053
- TC loss: 0.5185
- WT loss: 0.3038
- Cost time: 0.59mins â±ï¸
[0m
[0;32m2025-05-17 17:56:55,095  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 17:57:03,460  - INFO - === [Epoch 3/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:8.3637s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.611 â”‚ 0.482 â”‚ 0.586 â”‚ 0.764 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.485 â”‚ 0.343 â”‚ 0.451 â”‚ 0.66  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.637 â”‚ 0.42  â”‚ 0.58  â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.751 â”‚ 0.771 â”‚ 0.776 â”‚ 0.705 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3925, ET: 0.5223, TC: 0.4186, WT: 0.2366
[0m
[1;31m2025-05-17 17:57:03,462  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4681_dice0.5325_20250517175619.pth[0m
[0;32m2025-05-17 17:57:03,535  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3925_dice0.6108_20250517175703.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 17:57:03,535  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-17 17:57:39,320  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-17 17:57:39,320  - INFO - - Train mean loss: 0.4291
- ET loss: 0.5319
- TC loss: 0.4722
- WT loss: 0.2833
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 17:57:39,320  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-17 17:57:47,849  - INFO - === [Epoch 4/10] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:8.5280s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.703 â”‚ 0.612 â”‚ 0.681 â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.581 â”‚ 0.473 â”‚ 0.558 â”‚ 0.714 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.694 â”‚ 0.549 â”‚ 0.698 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.791 â”‚ 0.796 â”‚ 0.753 â”‚ 0.823 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3053, ET: 0.3964, TC: 0.3278, WT: 0.1917
[0m
[1;31m2025-05-17 17:57:47,851  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3925_dice0.6108_20250517175703.pth[0m
[0;32m2025-05-17 17:57:47,913  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.3053_dice0.7030_20250517175747.pth;             Size 12.68 MB[0m
[0;32m2025-05-17 17:57:47,913  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;32m2025-05-17 18:00:41,142  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 18:00:44,466  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 18:00:44,469  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 18:00:44,469  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 18:00:44,469  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 18:00:44,469  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 18:00:44,469  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 18:00:44,476  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 18:00:44,476  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 18:00:44,476  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 18:00:44,479  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 18:00:47,657  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 18:00:47,657  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 19:11:46,955  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:11:50,246  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 19:11:50,249  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:11:50,249  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:11:50,249  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:11:50,249  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:11:50,249  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:11:50,256  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:11:50,256  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:11:50,256  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:11:50,259  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:11:50,624  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 19:11:50,625  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 19:12:58,905  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:12:58,905  - INFO - - Train mean loss: 0.6979
- ET loss: 0.7407
- TC loss: 0.7585
- WT loss: 0.5946
- Cost time: 1.14mins â±ï¸
[0m
[0;32m2025-05-17 19:12:58,906  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 19:13:09,417  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.5094s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚   0.59 â”‚ 0.572 â”‚ 0.484 â”‚ 0.714 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚   0.46 â”‚ 0.439 â”‚ 0.344 â”‚ 0.596 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚   0.64 â”‚ 0.632 â”‚ 0.412 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚   0.69 â”‚ 0.64  â”‚ 0.781 â”‚ 0.649 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4193, ET: 0.4492, TC: 0.5200, WT: 0.2887
[0m
[0;32m2025-05-17 19:13:09,480  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4193_dice0.5901_20250517191309.pth;             Size 8.66 MB[0m
[0;32m2025-05-17 19:13:09,481  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 19:14:16,515  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 19:14:16,515  - INFO - - Train mean loss: 0.4760
- ET loss: 0.5076
- TC loss: 0.5698
- WT loss: 0.3507
- Cost time: 1.12mins â±ï¸
[0m
[0;32m2025-05-17 19:14:16,515  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 19:14:26,553  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.0364s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.618 â”‚ 0.64  â”‚ 0.452 â”‚ 0.761 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.49  â”‚ 0.511 â”‚ 0.313 â”‚ 0.645 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.598 â”‚ 0.674 â”‚ 0.336 â”‚ 0.785 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.78  â”‚ 0.691 â”‚ 0.867 â”‚ 0.781 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3896, ET: 0.3765, TC: 0.5508, WT: 0.2416
[0m
[0;32m2025-05-17 19:14:26,612  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3896_dice0.6180_20250517191426.pth;             Size 8.66 MB[0m
[0;32m2025-05-17 19:14:26,612  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 19:15:33,471  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 19:15:33,472  - INFO - - Train mean loss: 0.4409
- ET loss: 0.4666
- TC loss: 0.5570
- WT loss: 0.2991
- Cost time: 1.11mins â±ï¸
[0m
[0;32m2025-05-17 19:15:33,472  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 19:17:04,175  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:17:07,482  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 19:17:07,485  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:17:07,485  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:17:07,485  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:17:07,485  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:17:07,485  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:17:07,492  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:17:07,492  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:17:07,492  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:17:07,495  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:17:07,960  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 19:17:07,960  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 19:18:20,724  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:18:20,725  - INFO - - Train mean loss: 0.8699
- ET loss: 0.8530
- TC loss: 0.8206
- WT loss: 0.9362
- Cost time: 1.21mins â±ï¸
[0m
[0;32m2025-05-17 19:18:20,725  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 19:18:31,761  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.0351s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.378 â”‚ 0.482 â”‚ 0.571 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.277 â”‚ 0.347 â”‚ 0.441 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.374 â”‚ 0.456 â”‚ 0.622 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.78  â”‚ 0.669 â”‚ 0.671 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6287, ET: 0.5271, TC: 0.4396, WT: 0.9194
[0m
[1;31m2025-05-17 19:18:31,763  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.3910_dice0.6095_20250517190205.pth[0m
[0;32m2025-05-17 19:18:31,851  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.6287_dice0.3781_20250517191831.pth;             Size 10.61 MB[0m
[0;32m2025-05-17 19:18:31,852  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 19:19:43,699  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 19:19:43,700  - INFO - - Train mean loss: 0.6686
- ET loss: 0.5635
- TC loss: 0.5031
- WT loss: 0.9391
- Cost time: 1.20mins â±ï¸
[0m
[0;32m2025-05-17 19:19:43,700  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 19:19:54,508  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.8057s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.45  â”‚ 0.601 â”‚ 0.669 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.347 â”‚ 0.459 â”‚ 0.54  â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.439 â”‚ 0.566 â”‚ 0.709 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.817 â”‚ 0.73  â”‚ 0.721 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5555, ET: 0.4070, TC: 0.3400, WT: 0.9195
[0m
[1;31m2025-05-17 19:19:54,510  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_3_final_model.pth[0m
[0;32m2025-05-17 19:19:54,600  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5555_dice0.4501_20250517191954.pth;             Size 10.61 MB[0m
[0;32m2025-05-17 19:19:54,600  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 19:21:06,369  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 19:21:06,370  - INFO - - Train mean loss: 0.6199
- ET loss: 0.4839
- TC loss: 0.4365
- WT loss: 0.9392
- Cost time: 1.20mins â±ï¸
[0m
[0;32m2025-05-17 19:21:06,370  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 19:21:49,078  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:21:52,450  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 19:21:52,453  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:21:52,453  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:21:52,453  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:21:52,453  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:21:52,453  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:21:52,460  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:21:52,460  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:21:52,460  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:21:52,463  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 10                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:21:52,917  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-17 19:21:52,917  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-17 19:23:05,616  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:23:05,616  - INFO - - Train mean loss: 0.6760
- ET loss: 0.7498
- TC loss: 0.6868
- WT loss: 0.5913
- Cost time: 1.21mins â±ï¸
[0m
[0;32m2025-05-17 19:23:05,616  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-17 19:23:16,563  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.9457s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.509 â”‚ 0.366 â”‚ 0.474 â”‚ 0.687 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.379 â”‚ 0.239 â”‚ 0.338 â”‚ 0.559 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.464 â”‚ 0.255 â”‚ 0.375 â”‚ 0.762 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.802 â”‚ 0.85  â”‚ 0.864 â”‚ 0.694 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5008, ET: 0.6446, TC: 0.5369, WT: 0.3210
[0m
[1;31m2025-05-17 19:23:16,565  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.6287_dice0.3781_20250517191831.pth[0m
[0;32m2025-05-17 19:23:16,640  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5008_dice0.5091_20250517192316.pth;             Size 10.49 MB[0m
[0;32m2025-05-17 19:23:16,640  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-17 19:24:27,724  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-17 19:24:27,724  - INFO - - Train mean loss: 0.5661
- ET loss: 0.6720
- TC loss: 0.5806
- WT loss: 0.4456
- Cost time: 1.18mins â±ï¸
[0m
[0;32m2025-05-17 19:24:27,724  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-17 19:24:38,424  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.6989s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.542 â”‚ 0.445 â”‚ 0.547 â”‚ 0.635 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.407 â”‚ 0.307 â”‚ 0.409 â”‚ 0.505 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.599 â”‚ 0.367 â”‚ 0.526 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.69  â”‚ 0.762 â”‚ 0.774 â”‚ 0.534 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4602, ET: 0.5580, TC: 0.4564, WT: 0.3663
[0m
[1;31m2025-05-17 19:24:38,426  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5555_dice0.4501_20250517191954.pth[0m
[0;32m2025-05-17 19:24:38,499  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4602_dice0.5425_20250517192438.pth;             Size 10.49 MB[0m
[0;32m2025-05-17 19:24:38,499  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-17 19:25:50,272  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-17 19:25:50,273  - INFO - - Train mean loss: 0.5373
- ET loss: 0.6494
- TC loss: 0.5492
- WT loss: 0.4132
- Cost time: 1.20mins â±ï¸
[0m
[0;32m2025-05-17 19:25:50,273  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-17 19:26:01,164  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:10.8905s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.532 â”‚ 0.384 â”‚ 0.494 â”‚ 0.717 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.401 â”‚ 0.254 â”‚ 0.354 â”‚ 0.597 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.483 â”‚ 0.265 â”‚ 0.387 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.815 â”‚ 0.865 â”‚ 0.88  â”‚ 0.701 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4752, ET: 0.6236, TC: 0.5144, WT: 0.2877
[0m
[0;33m2025-05-17 19:26:01,165  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/5[0m
[0;32m2025-05-17 19:26:01,165  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-17 19:27:12,349  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-17 19:27:12,349  - INFO - - Train mean loss: 0.5076
- ET loss: 0.6222
- TC loss: 0.5126
- WT loss: 0.3880
- Cost time: 1.19mins â±ï¸
[0m
[0;32m2025-05-17 19:27:12,349  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-17 19:27:22,917  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:10.5664s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.556 â”‚ 0.445 â”‚ 0.554 â”‚ 0.669 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.42  â”‚ 0.306 â”‚ 0.414 â”‚ 0.539 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.563 â”‚ 0.336 â”‚ 0.484 â”‚ 0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.746 â”‚ 0.821 â”‚ 0.834 â”‚ 0.583 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4463, ET: 0.5572, TC: 0.4492, WT: 0.3325
[0m
[1;31m2025-05-17 19:27:22,918  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.5008_dice0.5091_20250517192316.pth[0m
[0;32m2025-05-17 19:27:22,990  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.4463_dice0.5560_20250517192722.pth;             Size 10.49 MB[0m
[0;32m2025-05-17 19:27:22,990  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-17 19:28:34,181  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-17 19:28:34,181  - INFO - - Train mean loss: 0.5178
- ET loss: 0.6345
- TC loss: 0.5240
- WT loss: 0.3948
- Cost time: 1.19mins â±ï¸
[0m
[0;32m2025-05-17 19:28:34,181  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-17 19:28:44,958  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:10.7759s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.56  â”‚ 0.435 â”‚ 0.546 â”‚ 0.7   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.425 â”‚ 0.297 â”‚ 0.405 â”‚ 0.574 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.538 â”‚ 0.314 â”‚ 0.452 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.79  â”‚ 0.859 â”‚ 0.871 â”‚ 0.64  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4439, ET: 0.5705, TC: 0.4591, WT: 0.3022
[0m
[1;31m2025-05-17 19:28:44,960  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.4602_dice0.5425_20250517192438.pth[0m
[0;32m2025-05-17 19:28:45,035  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.4439_dice0.5604_20250517192844.pth;             Size 10.49 MB[0m
[0;32m2025-05-17 19:28:45,036  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;32m2025-05-17 19:30:01,143  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:30:04,426  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-17 19:30:04,429  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:30:04,429  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:30:04,429  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:30:04,429  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:30:04,429  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:30:04,436  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:30:04,436  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:30:04,436  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:30:04,440  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:30:04,824  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 19:30:04,824  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 19:31:13,801  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:31:13,801  - INFO - - Train mean loss: 0.7258
- ET loss: 0.9998
- TC loss: 0.6909
- WT loss: 0.4867
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-17 19:31:13,801  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 19:31:24,495  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.6922s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.35  â”‚    0 â”‚ 0.354 â”‚ 0.697 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.266 â”‚    0 â”‚ 0.231 â”‚ 0.567 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.284 â”‚    0 â”‚ 0.236 â”‚ 0.616 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.588 â”‚    0 â”‚ 0.901 â”‚ 0.863 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6548, ET: 1.0000, TC: 0.6514, WT: 0.3129
[0m
[0;32m2025-05-17 19:31:24,565  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.6548_dice0.3503_20250517193124.pth;             Size 8.78 MB[0m
[1;31m2025-05-17 19:31:24,566  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.6548 at epoch 1[0m
[0;32m2025-05-17 19:31:24,566  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 19:31:24,570  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 19:31:24,570  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 19:31:24,571  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 19:32:06,299  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚    MEAN â”‚      ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚   0.399 â”‚   0     â”‚  0.452 â”‚  0.746 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚   0.309 â”‚   0     â”‚  0.316 â”‚  0.611 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚   0.337 â”‚   0     â”‚  0.331 â”‚  0.679 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚   0.598 â”‚   0     â”‚  0.929 â”‚  0.866 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 107.476 â”‚ 221.702 â”‚ 57.457 â”‚ 43.267 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.6055;ET: 1.0000;ET: 1.0000;TC: 0.5535;WT: 0.2631
[0m
[0;32m2025-05-17 19:32:06,299  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 19:32:06,300  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 19:32:12,087  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:32:15,369  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 19:32:15,371  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:32:15,372  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:32:15,372  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:32:15,372  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:32:15,372  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:32:15,378  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:32:15,378  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:32:15,379  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:32:15,382  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:32:15,827  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 19:32:15,827  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 19:33:28,332  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:33:28,333  - INFO - - Train mean loss: 0.6760
- ET loss: 0.7500
- TC loss: 0.6869
- WT loss: 0.5912
- Cost time: 1.21mins â±ï¸
[0m
[0;32m2025-05-17 19:33:28,333  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 19:33:39,384  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.0505s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.509 â”‚ 0.366 â”‚ 0.474 â”‚ 0.686 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.379 â”‚ 0.24  â”‚ 0.338 â”‚ 0.559 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.464 â”‚ 0.255 â”‚ 0.375 â”‚ 0.761 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.802 â”‚ 0.849 â”‚ 0.864 â”‚ 0.693 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5011, ET: 0.6446, TC: 0.5370, WT: 0.3217
[0m
[0;32m2025-05-17 19:33:39,461  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.5011_dice0.5088_20250517193339.pth;             Size 10.49 MB[0m
[1;31m2025-05-17 19:33:39,461  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.5011 at epoch 1[0m
[0;32m2025-05-17 19:33:39,461  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 19:33:39,467  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-17 19:33:39,467  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 19:33:39,467  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 19:34:35,200  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.55  â”‚  0.394 â”‚  0.56  â”‚  0.697 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.417 â”‚  0.264 â”‚  0.419 â”‚  0.57  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.528 â”‚  0.282 â”‚  0.489 â”‚  0.814 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.792 â”‚  0.853 â”‚  0.855 â”‚  0.668 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 38.116 â”‚ 43.797 â”‚ 41.134 â”‚ 29.416 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4580;ET: 0.6146;ET: 0.6146;TC: 0.4493;WT: 0.3102
[0m
[0;32m2025-05-17 19:34:35,201  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 19:34:35,201  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 19:35:11,784  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:35:15,056  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 19:35:15,058  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:35:15,059  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:35:15,059  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:35:15,059  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:35:15,059  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:35:15,065  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:35:15,066  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:35:15,066  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:35:15,069  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:35:15,450  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 19:35:15,450  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 19:36:24,571  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:36:24,572  - INFO - - Train mean loss: 0.7327
- ET loss: 0.7515
- TC loss: 0.7416
- WT loss: 0.7051
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-17 19:36:24,572  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 19:36:35,273  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.6998s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.571 â”‚ 0.571 â”‚ 0.488 â”‚ 0.655 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.432 â”‚ 0.425 â”‚ 0.348 â”‚ 0.523 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.537 â”‚ 0.483 â”‚ 0.379 â”‚ 0.749 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.746 â”‚ 0.775 â”‚ 0.843 â”‚ 0.62  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4588, ET: 0.4627, TC: 0.5460, WT: 0.3675
[0m
[1;31m2025-05-17 19:36:35,275  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-17 19:36:35,351  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4588_dice0.5714_20250517193635.pth;             Size 8.75 MB[0m
[1;31m2025-05-17 19:36:35,351  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4588 at epoch 1[0m
[0;32m2025-05-17 19:36:35,351  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 19:36:35,358  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 19:36:35,358  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 19:36:35,358  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 19:37:32,524  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.602 â”‚  0.556 â”‚  0.563 â”‚  0.686 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.46  â”‚  0.412 â”‚  0.413 â”‚  0.554 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.598 â”‚  0.495 â”‚  0.475 â”‚  0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.734 â”‚  0.719 â”‚  0.848 â”‚  0.637 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 38.839 â”‚ 33.847 â”‚ 48.676 â”‚ 33.994 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4258;ET: 0.4705;ET: 0.4705;TC: 0.4725;WT: 0.3345
[0m
[0;32m2025-05-17 19:37:32,524  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 19:37:32,524  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 19:37:38,962  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:37:42,241  - INFO - Total number of parameters: 0.82 M[0m
[0;32m2025-05-17 19:37:42,244  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:37:42,244  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:37:42,244  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:37:42,244  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:37:42,244  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:37:42,251  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 19:37:42,251  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 19:37:42,251  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 19:37:42,255  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.82 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:37:42,721  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 19:37:42,721  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 19:38:54,694  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 19:38:54,695  - INFO - - Train mean loss: 0.7893
- ET loss: 0.8281
- TC loss: 0.8030
- WT loss: 0.7368
- Cost time: 1.20mins â±ï¸
[0m
[0;32m2025-05-17 19:38:54,695  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 19:39:05,673  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.9770s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.535 â”‚ 0.42  â”‚ 0.52  â”‚ 0.667 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.402 â”‚ 0.284 â”‚ 0.378 â”‚ 0.543 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.546 â”‚ 0.324 â”‚ 0.453 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.732 â”‚ 0.793 â”‚ 0.801 â”‚ 0.602 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4715, ET: 0.5863, TC: 0.4912, WT: 0.3370
[0m
[1;31m2025-05-17 19:39:05,674  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_3_final_model.pth[0m
[0;32m2025-05-17 19:39:05,749  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4715_dice0.5354_20250517193905.pth;             Size 10.45 MB[0m
[1;31m2025-05-17 19:39:05,749  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4715 at epoch 1[0m
[0;32m2025-05-17 19:39:05,750  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 19:39:05,757  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-17 19:39:05,757  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 19:39:05,757  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 19:40:01,256  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.557 â”‚  0.421 â”‚  0.561 â”‚  0.687 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.419 â”‚  0.283 â”‚  0.411 â”‚  0.563 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.558 â”‚  0.314 â”‚  0.504 â”‚  0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.756 â”‚  0.821 â”‚  0.819 â”‚  0.627 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 38.27  â”‚ 43.886 â”‚ 43.173 â”‚ 27.75  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4498;ET: 0.5845;ET: 0.5845;TC: 0.4481;WT: 0.3167
[0m
[0;32m2025-05-17 19:40:01,257  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 19:40:01,257  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 19:45:30,274  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:45:33,796  - INFO - Total number of parameters: 0.82 M[0m
[0;32m2025-05-17 19:45:33,799  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:45:33,799  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:45:33,800  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:45:33,800  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:45:33,800  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:45:33,808  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 19:45:33,808  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 19:45:33,808  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 19:45:33,813  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.82 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:45:37,068  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 19:45:37,069  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 19:50:25,508  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 19:50:25,509  - INFO - - Train mean loss: 0.5909
- ET loss: 0.6969
- TC loss: 0.6127
- WT loss: 0.4631
- Cost time: 4.81mins â±ï¸
[0m
[0;32m2025-05-17 19:50:25,509  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 19:51:03,669  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:38.1592s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.538 â”‚ 0.451 â”‚ 0.552 â”‚ 0.611 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.402 â”‚ 0.314 â”‚ 0.416 â”‚ 0.475 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.623 â”‚ 0.381 â”‚ 0.536 â”‚ 0.952 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.656 â”‚ 0.745 â”‚ 0.74  â”‚ 0.483 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4622, ET: 0.5495, TC: 0.4493, WT: 0.3878
[0m
[1;31m2025-05-17 19:51:03,671  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.5198_dice0.4821_20250517181147.pth[0m
[0;32m2025-05-17 19:51:03,745  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.4622_dice0.5381_20250517195103.pth;             Size 10.45 MB[0m
[0;32m2025-05-17 19:51:03,745  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 19:55:50,740  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 19:55:50,742  - INFO - - Train mean loss: 0.4578
- ET loss: 0.5016
- TC loss: 0.5490
- WT loss: 0.3229
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-17 19:55:50,742  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 19:56:28,498  - INFO - === [Epoch 2/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:37.7551s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.634 â”‚ 0.634 â”‚ 0.468 â”‚ 0.799 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.504 â”‚ 0.496 â”‚ 0.331 â”‚ 0.686 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.568 â”‚ 0.54  â”‚ 0.342 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚ 0.83  â”‚ 0.928 â”‚ 0.802 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3685, ET: 0.3693, TC: 0.5335, WT: 0.2028
[0m
[1;31m2025-05-17 19:56:28,500  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.4622_dice0.5381_20250517195103.pth[0m
[0;32m2025-05-17 19:56:28,576  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.3685_dice0.6339_20250517195628.pth;             Size 10.45 MB[0m
[0;32m2025-05-17 19:56:28,576  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;32m2025-05-17 19:58:15,106  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 19:58:18,349  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 19:58:18,352  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 19:58:18,352  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:58:18,352  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:58:18,352  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 19:58:18,352  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 19:58:18,359  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 19:58:18,359  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 19:58:18,359  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 19:58:18,362  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 19:58:21,401  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 19:58:21,402  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 20:03:11,386  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 20:03:11,387  - INFO - - Train mean loss: 0.8123
- ET loss: 0.5171
- TC loss: 0.9775
- WT loss: 0.9422
- Cost time: 4.83mins â±ï¸
[0m
[0;32m2025-05-17 20:03:11,388  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 20:03:49,488  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:38.0989s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.271 â”‚ 0.699 â”‚ 0.031 â”‚ 0.084 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.211 â”‚ 0.574 â”‚ 0.016 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.249 â”‚ 0.687 â”‚ 0.016 â”‚ 0.044 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.915 â”‚ 0.76  â”‚ 0.984 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7311, ET: 0.3076, TC: 0.9694, WT: 0.9163
[0m
[1;31m2025-05-17 20:03:49,489  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3685_dice0.6339_20250517195628.pth[0m
[0;32m2025-05-17 20:03:49,563  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.7311_dice0.2712_20250517200349.pth;             Size 10.49 MB[0m
[0;32m2025-05-17 20:03:49,563  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 20:05:03,347  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:05:06,691  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-17 20:05:06,693  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:05:06,693  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:05:06,694  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:05:06,694  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:05:06,694  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:05:06,700  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:05:06,700  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:05:06,700  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:05:06,704  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:05:07,103  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:05:07,103  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:06:16,959  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:06:16,960  - INFO - - Train mean loss: 0.7351
- ET loss: 0.7525
- TC loss: 0.7656
- WT loss: 0.6872
- Cost time: 1.16mins â±ï¸
[0m
[0;32m2025-05-17 20:06:16,960  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:06:27,469  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.5081s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.569 â”‚ 0.533 â”‚ 0.503 â”‚ 0.672 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.433 â”‚ 0.387 â”‚ 0.362 â”‚ 0.55  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.573 â”‚ 0.481 â”‚ 0.415 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.707 â”‚ 0.713 â”‚ 0.808 â”‚ 0.601 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4393, ET: 0.4807, TC: 0.5063, WT: 0.3309
[0m
[1;31m2025-05-17 20:06:27,470  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-17 20:06:27,554  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4393_dice0.5692_20250517200627.pth;             Size 8.91 MB[0m
[1;31m2025-05-17 20:06:27,554  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4393 at epoch 1[0m
[0;32m2025-05-17 20:06:27,554  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:06:27,561  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 20:06:27,561  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:06:27,561  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:07:23,845  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.591 â”‚  0.525 â”‚  0.559 â”‚  0.688 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.455 â”‚  0.377 â”‚  0.418 â”‚  0.571 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.618 â”‚  0.501 â”‚  0.497 â”‚  0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.709 â”‚  0.685 â”‚  0.817 â”‚  0.625 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 30.25  â”‚ 25.909 â”‚ 38.198 â”‚ 26.642 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4158;ET: 0.4858;ET: 0.4858;TC: 0.4479;WT: 0.3136
[0m
[0;32m2025-05-17 20:07:23,845  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:07:23,846  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:07:29,813  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:07:33,135  - INFO - Total number of parameters: 0.82 M[0m
[0;32m2025-05-17 20:07:33,137  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:07:33,137  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:07:33,137  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:07:33,138  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:07:33,138  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:07:33,145  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:07:33,146  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:07:33,146  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:07:33,150  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.82 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:07:33,591  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:07:33,591  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:08:45,854  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:08:45,854  - INFO - - Train mean loss: 0.8457
- ET loss: 0.6213
- TC loss: 0.9761
- WT loss: 0.9398
- Cost time: 1.20mins â±ï¸
[0m
[0;32m2025-05-17 20:08:45,855  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:08:57,103  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.2475s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.245 â”‚ 0.624 â”‚ 0.031 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.184 â”‚ 0.493 â”‚ 0.016 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.259 â”‚ 0.717 â”‚ 0.016 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.855 â”‚ 0.617 â”‚ 0.95  â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7589, ET: 0.3886, TC: 0.9686, WT: 0.9195
[0m
[1;31m2025-05-17 20:08:57,104  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_3_final_model.pth[0m
[0;32m2025-05-17 20:08:57,180  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.7589_dice0.2452_20250517200857.pth;             Size 10.45 MB[0m
[1;31m2025-05-17 20:08:57,180  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.7589 at epoch 1[0m
[0;32m2025-05-17 20:08:57,180  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:08:57,187  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-17 20:08:57,187  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:08:57,187  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:09:55,844  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚      TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.239 â”‚  0.586 â”‚   0.042 â”‚  0.089 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.174 â”‚  0.453 â”‚   0.022 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.25  â”‚  0.681 â”‚   0.022 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚  0.565 â”‚   0.995 â”‚  1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 74.173 â”‚ 24.264 â”‚ 105.54  â”‚ 92.715 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.7630;ET: 0.4193;ET: 0.4193;TC: 0.9584;WT: 0.9112
[0m
[0;32m2025-05-17 20:09:55,845  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:09:55,845  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:21:49,994  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:21:53,291  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:21:53,294  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:21:53,294  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:21:53,294  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:21:53,294  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:21:53,295  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:21:53,301  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:21:53,302  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:21:53,302  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:21:53,305  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:21:53,644  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:21:53,644  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:22:29,403  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:22:29,403  - INFO - - Train mean loss: 0.7266
- ET loss: 0.7193
- TC loss: 0.7984
- WT loss: 0.6622
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 20:22:29,404  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:22:38,444  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.0394s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.587 â”‚ 0.608 â”‚ 0.45  â”‚ 0.702 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.458 â”‚ 0.476 â”‚ 0.313 â”‚ 0.586 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.594 â”‚ 0.653 â”‚ 0.35  â”‚ 0.778 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.707 â”‚ 0.612 â”‚ 0.808 â”‚ 0.701 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4258, ET: 0.4104, TC: 0.5613, WT: 0.3058
[0m
[0;32m2025-05-17 20:22:38,490  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4258_dice0.5867_20250517202238.pth;             Size 12.43 MB[0m
[1;31m2025-05-17 20:22:38,491  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4258 at epoch 1[0m
[0;32m2025-05-17 20:22:38,491  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:22:38,497  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:22:38,497  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:22:38,497  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[0;32m2025-05-17 20:23:22,965  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:23:26,239  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:23:26,241  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:23:26,241  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:23:26,241  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:23:26,241  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:23:26,241  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:23:26,248  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:23:26,248  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:23:26,248  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:23:26,251  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:23:26,590  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:23:26,590  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:24:04,277  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:24:04,277  - INFO - - Train mean loss: 0.7266
- ET loss: 0.7191
- TC loss: 0.7985
- WT loss: 0.6622
- Cost time: 0.63mins â±ï¸
[0m
[0;32m2025-05-17 20:24:04,277  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:24:13,343  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.0643s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.586 â”‚ 0.607 â”‚ 0.45  â”‚ 0.702 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.458 â”‚ 0.476 â”‚ 0.312 â”‚ 0.586 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.592 â”‚ 0.651 â”‚ 0.349 â”‚ 0.777 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.708 â”‚ 0.612 â”‚ 0.809 â”‚ 0.702 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4262, ET: 0.4109, TC: 0.5617, WT: 0.3059
[0m
[1;31m2025-05-17 20:24:13,344  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:24:13,388  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4262_dice0.5864_20250517202413.pth;             Size 12.43 MB[0m
[1;31m2025-05-17 20:24:13,388  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4262 at epoch 1[0m
[0;32m2025-05-17 20:24:13,388  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:24:13,397  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:24:13,397  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:24:13,397  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:25:06,375  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.615 â”‚  0.581 â”‚  0.523 â”‚  0.741 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.48  â”‚  0.443 â”‚  0.377 â”‚  0.62  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.622 â”‚  0.632 â”‚  0.426 â”‚  0.808 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.716 â”‚  0.574 â”‚  0.853 â”‚  0.722 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 28.739 â”‚ 25.642 â”‚ 35.276 â”‚ 25.297 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.3977;ET: 0.4367;ET: 0.4367;TC: 0.4878;WT: 0.2684
[0m
[0;32m2025-05-17 20:25:06,375  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:25:06,375  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:25:11,870  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:25:19,704  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:25:23,199  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 20:25:23,202  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:25:23,202  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:25:23,202  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:25:23,202  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:25:23,202  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:25:23,210  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:25:23,210  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:25:23,211  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:25:23,214  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:25:23,578  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:25:23,578  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:26:00,031  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:26:00,031  - INFO - - Train mean loss: 0.8219
- ET loss: 0.7927
- TC loss: 0.7331
- WT loss: 0.9400
- Cost time: 0.61mins â±ï¸
[0m
[0;32m2025-05-17 20:26:00,031  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:26:09,148  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.1154s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.369 â”‚ 0.463 â”‚ 0.564 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.266 â”‚ 0.326 â”‚ 0.429 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.331 â”‚ 0.401 â”‚ 0.551 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.827 â”‚ 0.736 â”‚ 0.745 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6411, ET: 0.5518, TC: 0.4520, WT: 0.9195
[0m
[0;32m2025-05-17 20:26:09,201  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.6411_dice0.3689_20250517202609.pth;             Size 12.56 MB[0m
[1;31m2025-05-17 20:26:09,201  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.6411 at epoch 1[0m
[0;32m2025-05-17 20:26:09,201  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:26:09,208  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:26:09,208  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:26:09,208  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:27:04,522  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.386 â”‚  0.459 â”‚  0.609 â”‚  0.089 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.281 â”‚  0.321 â”‚  0.475 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.342 â”‚  0.369 â”‚  0.609 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.831 â”‚  0.747 â”‚  0.745 â”‚  1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 49.09  â”‚ 28.948 â”‚ 25.606 â”‚ 92.715 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.6240;ET: 0.5551;ET: 0.5551;TC: 0.4058;WT: 0.9112
[0m
[0;32m2025-05-17 20:27:04,523  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:27:04,523  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:27:10,169  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:27:13,432  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:27:13,435  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:27:13,435  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:27:13,435  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:27:13,435  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:27:13,435  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:27:13,442  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:27:13,442  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:27:13,442  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:27:13,445  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:27:13,803  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:27:13,803  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:28:21,902  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:28:21,903  - INFO - - Train mean loss: 0.7324
- ET loss: 0.8326
- TC loss: 0.7781
- WT loss: 0.5867
- Cost time: 1.13mins â±ï¸
[0m
[0;32m2025-05-17 20:28:21,903  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:28:32,405  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.5011s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.533 â”‚ 0.453 â”‚ 0.418 â”‚ 0.728 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.411 â”‚ 0.336 â”‚ 0.285 â”‚ 0.61  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.651 â”‚ 0.758 â”‚ 0.35  â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.594 â”‚ 0.378 â”‚ 0.717 â”‚ 0.686 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4761, ET: 0.5539, TC: 0.5932, WT: 0.2813
[0m
[0;32m2025-05-17 20:28:32,469  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4761_dice0.5332_20250517202832.pth;             Size 8.66 MB[0m
[1;31m2025-05-17 20:28:32,470  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4761 at epoch 1[0m
[0;32m2025-05-17 20:28:32,470  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:28:32,475  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 20:28:32,475  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:28:32,475  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:29:27,223  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.554 â”‚  0.398 â”‚  0.501 â”‚  0.762 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.433 â”‚  0.291 â”‚  0.361 â”‚  0.648 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.673 â”‚  0.711 â”‚  0.427 â”‚  0.881 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.607 â”‚  0.335 â”‚  0.769 â”‚  0.715 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 20.073 â”‚ 14.141 â”‚ 29.282 â”‚ 16.796 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4538;ET: 0.6027;ET: 0.6027;TC: 0.5115;WT: 0.2472
[0m
[0;32m2025-05-17 20:29:27,223  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:29:27,223  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:29:33,090  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:29:36,369  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-17 20:29:36,371  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:29:36,371  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:29:36,371  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:29:36,371  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:29:36,371  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:29:36,378  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:29:36,378  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:29:36,379  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:29:36,382  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:29:36,771  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:29:36,771  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:30:46,062  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:30:46,062  - INFO - - Train mean loss: 0.7274
- ET loss: 0.9997
- TC loss: 0.6994
- WT loss: 0.4831
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-17 20:30:46,062  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:30:56,778  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.7141s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.374 â”‚    0 â”‚ 0.39  â”‚ 0.733 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.289 â”‚    0 â”‚ 0.259 â”‚ 0.608 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.318 â”‚    0 â”‚ 0.27  â”‚ 0.684 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.571 â”‚    0 â”‚ 0.882 â”‚ 0.83  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6309, ET: 0.9999, TC: 0.6165, WT: 0.2762
[0m
[1;31m2025-05-17 20:30:56,779  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-17 20:30:56,848  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.6309_dice0.3743_20250517203056.pth;             Size 8.78 MB[0m
[1;31m2025-05-17 20:30:56,848  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.6309 at epoch 1[0m
[0;32m2025-05-17 20:30:56,848  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:30:56,854  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 20:30:56,854  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:30:56,854  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:31:39,861  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚      ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.417 â”‚   0     â”‚  0.478 â”‚  0.774 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.329 â”‚   0     â”‚  0.339 â”‚  0.648 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.368 â”‚   0     â”‚  0.36  â”‚  0.744 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.581 â”‚   0     â”‚  0.905 â”‚  0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 96.276 â”‚ 208.634 â”‚ 47.775 â”‚ 32.419 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5866;ET: 1.0000;ET: 1.0000;TC: 0.5265;WT: 0.2333
[0m
[0;32m2025-05-17 20:31:39,862  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:31:39,862  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:34:04,219  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:34:07,449  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 20:34:07,452  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:34:07,452  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:34:07,452  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:34:07,452  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:34:07,452  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:34:07,459  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:34:07,459  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:34:07,459  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:34:07,463  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:34:07,832  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:34:07,832  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:34:44,617  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:34:44,618  - INFO - - Train mean loss: 0.8522
- ET loss: 0.8390
- TC loss: 0.7786
- WT loss: 0.9389
- Cost time: 0.61mins â±ï¸
[0m
[0;32m2025-05-17 20:34:44,618  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:34:53,671  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.0519s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.315 â”‚ 0.376 â”‚ 0.489 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.22  â”‚ 0.254 â”‚ 0.363 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.293 â”‚ 0.341 â”‚ 0.496 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.75  â”‚ 0.606 â”‚ 0.645 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6867, ET: 0.6251, TC: 0.5153, WT: 0.9195
[0m
[1;31m2025-05-17 20:34:53,673  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:34:53,744  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.6867_dice0.3153_20250517203453.pth;             Size 12.59 MB[0m
[1;31m2025-05-17 20:34:53,744  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.6867 at epoch 1[0m
[0;32m2025-05-17 20:34:53,744  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:34:53,753  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:34:53,753  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:34:53,754  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[0;32m2025-05-17 20:35:49,217  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:35:52,553  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:35:52,555  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:35:52,556  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:35:52,556  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:35:52,556  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:35:52,556  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:35:52,563  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:35:52,563  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:35:52,563  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:35:52,566  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:35:52,939  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:35:52,939  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:36:29,158  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:36:29,159  - INFO - - Train mean loss: 0.8361
- ET loss: 0.6981
- TC loss: 0.9147
- WT loss: 0.8954
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 20:36:29,159  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:36:38,304  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.1446s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.389 â”‚ 0.472 â”‚ 0.545 â”‚ 0.148 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.274 â”‚ 0.332 â”‚ 0.407 â”‚ 0.085 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.312 â”‚ 0.382 â”‚ 0.467 â”‚ 0.085 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.827 â”‚ 0.799 â”‚ 0.795 â”‚ 0.888 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6689, ET: 0.5510, TC: 0.6018, WT: 0.8538
[0m
[1;31m2025-05-17 20:36:38,306  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:36:38,358  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.6689_dice0.3886_20250517203638.pth;             Size 12.52 MB[0m
[1;31m2025-05-17 20:36:38,358  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.6689 at epoch 1[0m
[0;32m2025-05-17 20:36:38,358  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:36:38,367  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:36:38,367  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:36:38,367  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:37:36,346  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.387 â”‚  0.44  â”‚  0.563 â”‚  0.16  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.272 â”‚  0.304 â”‚  0.422 â”‚  0.091 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.312 â”‚  0.335 â”‚  0.509 â”‚  0.092 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.826 â”‚  0.791 â”‚  0.773 â”‚  0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 55.546 â”‚ 35.041 â”‚ 54.027 â”‚ 77.569 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.6617;ET: 0.5768;ET: 0.5768;TC: 0.5664;WT: 0.8420
[0m
[0;32m2025-05-17 20:37:36,347  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:37:36,347  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:37:41,812  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:37:45,122  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:37:45,125  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:37:45,125  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:37:45,125  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:37:45,125  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:37:45,125  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:37:45,132  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:37:45,132  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:37:45,132  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:37:45,136  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:37:45,509  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:37:45,509  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:38:53,668  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:38:53,668  - INFO - - Train mean loss: 0.8584
- ET loss: 1.0000
- TC loss: 0.6370
- WT loss: 0.9382
- Cost time: 1.14mins â±ï¸
[0m
[0;32m2025-05-17 20:38:53,669  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:39:04,256  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.5859s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚   ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.22  â”‚    0 â”‚ 0.58  â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.161 â”‚    0 â”‚ 0.441 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.191 â”‚    0 â”‚ 0.532 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.59  â”‚    0 â”‚ 0.771 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7817, ET: 1.0000, TC: 0.4255, WT: 0.9195
[0m
[1;31m2025-05-17 20:39:04,257  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 20:39:04,318  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.7817_dice0.2202_20250517203904.pth;             Size 8.66 MB[0m
[1;31m2025-05-17 20:39:04,318  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.7817 at epoch 1[0m
[0;32m2025-05-17 20:39:04,318  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:39:04,324  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 20:39:04,324  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:39:04,324  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:39:45,572  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚    MEAN â”‚      ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚   0.228 â”‚   0     â”‚  0.596 â”‚  0.089 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚   0.168 â”‚   0     â”‚  0.456 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚   0.215 â”‚   0     â”‚  0.597 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚   0.575 â”‚   0     â”‚  0.724 â”‚  1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 116.688 â”‚ 221.702 â”‚ 35.645 â”‚ 92.715 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.7732;ET: 1.0000;ET: 1.0000;TC: 0.4083;WT: 0.9112
[0m
[0;32m2025-05-17 20:39:45,572  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:39:45,572  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:39:51,480  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:39:54,791  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:39:54,794  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:39:54,794  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:39:54,794  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:39:54,794  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:39:54,794  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:39:54,801  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:39:54,801  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:39:54,801  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:39:54,805  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:39:55,200  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:39:55,200  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:41:04,063  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:41:04,064  - INFO - - Train mean loss: 0.7108
- ET loss: 0.7254
- TC loss: 0.7029
- WT loss: 0.7040
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-17 20:41:04,064  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:42:27,181  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:42:30,493  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:42:30,496  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:42:30,496  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:42:30,496  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:42:30,496  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:42:30,496  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:42:30,503  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:42:30,503  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:42:30,503  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:42:30,507  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:42:30,755  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:42:30,755  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:43:06,806  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:43:06,806  - INFO - - Train mean loss: 0.7135
- ET loss: 0.9991
- TC loss: 0.6692
- WT loss: 0.4722
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 20:43:06,806  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:43:15,419  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.6115s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.38  â”‚ 0     â”‚ 0.45  â”‚ 0.691 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.3   â”‚ 0     â”‚ 0.317 â”‚ 0.582 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.478 â”‚ 0.125 â”‚ 0.414 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.439 â”‚ 0     â”‚ 0.695 â”‚ 0.622 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.6186, ET: 0.9993, TC: 0.5482, WT: 0.3083
[0m
[1;31m2025-05-17 20:43:15,421  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:43:15,471  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.6186_dice0.3801_20250517204315.pth;             Size 12.42 MB[0m
[1;31m2025-05-17 20:43:15,472  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.6186 at epoch 1[0m
[0;32m2025-05-17 20:43:15,472  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:43:15,481  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:43:15,481  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:43:15,481  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:43:59,790  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚      ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.422 â”‚   0     â”‚  0.535 â”‚  0.731 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.337 â”‚   0     â”‚  0.399 â”‚  0.613 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.506 â”‚   0.077 â”‚  0.491 â”‚  0.949 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.456 â”‚   0     â”‚  0.731 â”‚  0.638 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 52.495 â”‚ 124.417 â”‚ 19.193 â”‚ 13.875 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5778;ET: 0.9991;ET: 0.9991;TC: 0.4667;WT: 0.2677
[0m
[0;32m2025-05-17 20:43:59,791  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:43:59,791  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:44:38,942  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:44:42,205  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:44:42,207  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:44:42,207  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:44:42,207  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:44:42,208  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:44:42,208  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:44:42,214  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:44:42,214  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:44:42,214  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:44:42,218  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:44:42,460  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:44:42,460  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:45:20,661  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:45:20,661  - INFO - - Train mean loss: 0.6337
- ET loss: 0.6942
- TC loss: 0.6082
- WT loss: 0.5986
- Cost time: 0.64mins â±ï¸
[0m
[0;32m2025-05-17 20:45:20,661  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:45:29,447  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.7847s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.576 â”‚ 0.513 â”‚ 0.626 â”‚ 0.588 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.435 â”‚ 0.37  â”‚ 0.488 â”‚ 0.446 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.622 â”‚ 0.419 â”‚ 0.571 â”‚ 0.875 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.691 â”‚ 0.796 â”‚ 0.805 â”‚ 0.472 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4284, ET: 0.4927, TC: 0.3804, WT: 0.4120
[0m
[1;31m2025-05-17 20:45:29,448  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:45:29,491  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4284_dice0.5756_20250517204529.pth;             Size 12.39 MB[0m
[1;31m2025-05-17 20:45:29,491  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4284 at epoch 1[0m
[0;32m2025-05-17 20:45:29,491  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:45:29,499  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:45:29,499  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:45:29,499  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:46:20,465  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.593 â”‚  0.496 â”‚  0.662 â”‚  0.622 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.455 â”‚  0.353 â”‚  0.523 â”‚  0.489 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.667 â”‚  0.408 â”‚  0.653 â”‚  0.939 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.699 â”‚  0.794 â”‚  0.791 â”‚  0.51  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 21.225 â”‚ 24.528 â”‚ 20.506 â”‚ 18.641 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4103;ET: 0.5085;ET: 0.5085;TC: 0.3433;WT: 0.3790
[0m
[0;32m2025-05-17 20:46:20,465  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:46:20,466  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:46:26,214  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:46:29,464  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:46:29,467  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:46:29,467  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:46:29,467  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:46:29,467  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:46:29,467  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:46:29,474  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:46:29,474  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:46:29,474  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:46:29,477  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:46:29,766  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:46:29,767  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:47:08,051  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:47:08,052  - INFO - - Train mean loss: 0.7154
- ET loss: 0.6224
- TC loss: 0.5825
- WT loss: 0.9412
- Cost time: 0.64mins â±ï¸
[0m
[0;32m2025-05-17 20:47:08,052  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:47:16,821  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.7675s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.46  â”‚ 0.616 â”‚ 0.683 â”‚ 0.08  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.359 â”‚ 0.477 â”‚ 0.559 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.429 â”‚ 0.55  â”‚ 0.694 â”‚ 0.043 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.842 â”‚ 0.782 â”‚ 0.745 â”‚ 1     â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5434, ET: 0.3883, TC: 0.3223, WT: 0.9196
[0m
[1;31m2025-05-17 20:47:16,822  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:47:16,884  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.5434_dice0.4597_20250517204716.pth;             Size 12.51 MB[0m
[1;31m2025-05-17 20:47:16,885  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.5434 at epoch 1[0m
[0;32m2025-05-17 20:47:16,885  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:47:16,894  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:47:16,894  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:47:16,894  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:48:10,521  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.442 â”‚  0.583 â”‚  0.654 â”‚  0.089 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.334 â”‚  0.433 â”‚  0.522 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.435 â”‚  0.536 â”‚  0.723 â”‚  0.047 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.821 â”‚  0.763 â”‚  0.701 â”‚  1     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 41.895 â”‚ 16.544 â”‚ 16.43  â”‚ 92.712 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5608;ET: 0.4211;ET: 0.4211;TC: 0.3499;WT: 0.9113
[0m
[0;32m2025-05-17 20:48:10,522  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:48:10,522  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:48:16,051  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:48:19,477  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:48:19,480  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:48:19,480  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:48:19,480  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:48:19,480  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:48:19,480  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:48:19,487  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:48:19,487  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:48:19,487  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:48:19,490  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:48:19,785  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:48:19,785  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:49:20,883  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:49:20,883  - INFO - - Train mean loss: 0.6369
- ET loss: 0.7056
- TC loss: 0.6474
- WT loss: 0.5576
- Cost time: 1.02mins â±ï¸
[0m
[0;32m2025-05-17 20:49:20,883  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:49:30,259  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.3749s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.537 â”‚ 0.425 â”‚ 0.531 â”‚ 0.655 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.4   â”‚ 0.288 â”‚ 0.387 â”‚ 0.525 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.519 â”‚ 0.308 â”‚ 0.436 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.76  â”‚ 0.843 â”‚ 0.843 â”‚ 0.595 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4654, ET: 0.5774, TC: 0.4724, WT: 0.3465
[0m
[1;31m2025-05-17 20:49:30,261  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 20:49:30,323  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4654_dice0.5370_20250517204930.pth;             Size 8.61 MB[0m
[1;31m2025-05-17 20:49:30,323  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4654 at epoch 1[0m
[0;32m2025-05-17 20:49:30,324  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:49:30,330  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 20:49:30,330  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:49:30,330  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:50:25,322  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.574 â”‚  0.454 â”‚  0.6   â”‚  0.669 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.434 â”‚  0.312 â”‚  0.451 â”‚  0.539 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.579 â”‚  0.332 â”‚  0.537 â”‚  0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.776 â”‚  0.867 â”‚  0.856 â”‚  0.606 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 28.617 â”‚ 31.926 â”‚ 30.357 â”‚ 23.569 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4286;ET: 0.5497;ET: 0.5497;TC: 0.4039;WT: 0.3321
[0m
[0;32m2025-05-17 20:50:25,322  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:50:25,323  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:50:32,127  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:50:35,427  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:50:35,430  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:50:35,430  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:50:35,430  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:50:35,430  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:50:35,430  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:50:35,437  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:50:35,437  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:50:35,437  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:50:35,441  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:50:35,783  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:50:35,784  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:51:37,946  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:51:37,947  - INFO - - Train mean loss: 0.6776
- ET loss: 0.6281
- TC loss: 0.7196
- WT loss: 0.6851
- Cost time: 1.04mins â±ï¸
[0m
[0;32m2025-05-17 20:51:37,947  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:51:47,691  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.7417s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.665 â”‚ 0.675 â”‚ 0.571 â”‚ 0.75  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.534 â”‚ 0.552 â”‚ 0.426 â”‚ 0.624 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.662 â”‚ 0.686 â”‚ 0.535 â”‚ 0.764 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.762 â”‚ 0.734 â”‚ 0.778 â”‚ 0.773 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3427, ET: 0.3298, TC: 0.4339, WT: 0.2644
[0m
[1;31m2025-05-17 20:51:47,693  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-17 20:51:47,768  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.3427_dice0.6654_20250517205147.pth;             Size 8.74 MB[0m
[1;31m2025-05-17 20:51:47,769  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.3427 at epoch 1[0m
[0;32m2025-05-17 20:51:47,769  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:51:47,776  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 20:51:47,776  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:51:47,777  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:52:41,824  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.688 â”‚  0.685 â”‚  0.614 â”‚  0.765 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.557 â”‚  0.556 â”‚  0.472 â”‚  0.642 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.716 â”‚  0.736 â”‚  0.608 â”‚  0.804 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.745 â”‚  0.704 â”‚  0.761 â”‚  0.77  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 19.639 â”‚ 12.908 â”‚ 24.35  â”‚ 21.658 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.3204;ET: 0.3228;ET: 0.3228;TC: 0.3928;WT: 0.2455
[0m
[0;32m2025-05-17 20:52:41,825  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:52:41,825  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:53:11,554  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:53:15,046  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:53:15,049  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:53:15,049  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:53:15,049  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:53:15,049  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:53:15,049  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:53:15,057  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:53:15,057  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:53:15,057  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:53:15,061  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:53:15,420  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:53:15,421  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:53:52,671  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:53:52,672  - INFO - - Train mean loss: 0.7339
- ET loss: 0.6774
- TC loss: 0.6130
- WT loss: 0.9113
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 20:53:52,672  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:54:01,875  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.2015s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.427 â”‚ 0.55  â”‚ 0.63  â”‚ 0.099 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.319 â”‚ 0.407 â”‚ 0.497 â”‚ 0.054 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.396 â”‚ 0.491 â”‚ 0.644 â”‚ 0.054 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.822 â”‚ 0.748 â”‚ 0.723 â”‚ 0.994 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5826, ET: 0.4620, TC: 0.3843, WT: 0.9014
[0m
[1;31m2025-05-17 20:54:01,876  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:54:01,921  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.5826_dice0.4266_20250517205401.pth;             Size 12.40 MB[0m
[1;31m2025-05-17 20:54:01,922  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.5826 at epoch 1[0m
[0;32m2025-05-17 20:54:01,922  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:54:01,930  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:54:01,930  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:54:01,930  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:54:57,759  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.43  â”‚  0.525 â”‚  0.646 â”‚  0.119 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.325 â”‚  0.385 â”‚  0.526 â”‚  0.066 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.397 â”‚  0.442 â”‚  0.684 â”‚  0.067 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.822 â”‚  0.752 â”‚  0.727 â”‚  0.988 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 44.436 â”‚ 24.496 â”‚ 22.82  â”‚ 85.992 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5773;ET: 0.4841;ET: 0.4841;TC: 0.3647;WT: 0.8830
[0m
[0;32m2025-05-17 20:54:57,759  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:54:57,760  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:55:03,882  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:55:07,296  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 20:55:07,298  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:55:07,298  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:55:07,299  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:55:07,299  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:55:07,299  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:55:07,305  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:55:07,306  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:55:07,306  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:55:07,309  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:55:07,748  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:55:07,749  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:55:43,815  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:55:43,816  - INFO - - Train mean loss: 0.8608
- ET loss: 0.6970
- TC loss: 0.9647
- WT loss: 0.9207
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 20:55:43,816  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:55:52,747  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.9300s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.263 â”‚ 0.634 â”‚ 0.045 â”‚ 0.11  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.195 â”‚ 0.503 â”‚ 0.024 â”‚ 0.06  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.251 â”‚ 0.668 â”‚ 0.024 â”‚ 0.06  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.869 â”‚ 0.686 â”‚ 0.945 â”‚ 0.977 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7487, ET: 0.3955, TC: 0.9556, WT: 0.8951
[0m
[1;31m2025-05-17 20:55:52,750  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 20:55:52,803  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.7487_dice0.2629_20250517205552.pth;             Size 12.53 MB[0m
[1;31m2025-05-17 20:55:52,803  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.7487 at epoch 1[0m
[0;32m2025-05-17 20:55:52,803  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:55:52,812  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 20:55:52,812  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:55:52,813  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:56:52,441  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚      TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.247 â”‚  0.567 â”‚   0.058 â”‚  0.117 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.179 â”‚  0.442 â”‚   0.031 â”‚  0.063 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.227 â”‚  0.588 â”‚   0.031 â”‚  0.064 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚  0.665 â”‚   0.988 â”‚  0.973 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 73.963 â”‚ 27.57  â”‚ 103.43  â”‚ 90.89  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.7595;ET: 0.4488;ET: 0.4488;TC: 0.9424;WT: 0.8874
[0m
[0;32m2025-05-17 20:56:52,441  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:56:52,442  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:56:58,165  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:57:01,347  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:57:01,350  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:57:01,350  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:57:01,350  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:57:01,350  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:57:01,350  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:57:01,361  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:57:01,361  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:57:01,361  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:57:01,364  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:57:01,734  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:57:01,734  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 20:58:09,482  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 20:58:09,483  - INFO - - Train mean loss: 0.6007
- ET loss: 0.7003
- TC loss: 0.6118
- WT loss: 0.4899
- Cost time: 1.13mins â±ï¸
[0m
[0;32m2025-05-17 20:58:09,483  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 20:58:20,153  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.6688s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.557 â”‚ 0.457 â”‚ 0.557 â”‚ 0.658 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.421 â”‚ 0.316 â”‚ 0.416 â”‚ 0.53  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.6   â”‚ 0.367 â”‚ 0.514 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.707 â”‚ 0.783 â”‚ 0.786 â”‚ 0.551 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4492, ET: 0.5536, TC: 0.4518, WT: 0.3421
[0m
[1;31m2025-05-17 20:58:20,154  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 20:58:20,221  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4492_dice0.5573_20250517205820.pth;             Size 8.62 MB[0m
[1;31m2025-05-17 20:58:20,221  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4492 at epoch 1[0m
[0;32m2025-05-17 20:58:20,221  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 20:58:20,229  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 20:58:20,229  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 20:58:20,229  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 20:59:14,968  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.577 â”‚  0.466 â”‚  0.607 â”‚  0.656 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.444 â”‚  0.326 â”‚  0.471 â”‚  0.535 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.648 â”‚  0.381 â”‚  0.606 â”‚  0.958 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.699 â”‚  0.777 â”‚  0.769 â”‚  0.549 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 21.558 â”‚ 25.357 â”‚ 22.171 â”‚ 17.145 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4292;ET: 0.5425;ET: 0.5425;TC: 0.4014;WT: 0.3438
[0m
[0;32m2025-05-17 20:59:14,969  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 20:59:14,969  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 20:59:21,362  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 20:59:24,662  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 20:59:24,665  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 20:59:24,665  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:59:24,665  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:59:24,665  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 20:59:24,665  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 20:59:24,672  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 20:59:24,672  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 20:59:24,672  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 20:59:24,675  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 20:59:25,072  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 20:59:25,073  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:00:34,235  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:00:34,236  - INFO - - Train mean loss: 0.6334
- ET loss: 0.7267
- TC loss: 0.6456
- WT loss: 0.5278
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-17 21:00:34,236  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:00:44,933  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.6948s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.538 â”‚ 0.399 â”‚ 0.506 â”‚ 0.709 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.407 â”‚ 0.265 â”‚ 0.365 â”‚ 0.59  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.519 â”‚ 0.293 â”‚ 0.417 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.778 â”‚ 0.831 â”‚ 0.847 â”‚ 0.658 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4712, ET: 0.6106, TC: 0.5041, WT: 0.2988
[0m
[1;31m2025-05-17 21:00:44,934  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-17 21:00:45,030  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4712_dice0.5380_20250517210044.pth;             Size 8.75 MB[0m
[1;31m2025-05-17 21:00:45,030  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4712 at epoch 1[0m
[0;32m2025-05-17 21:00:45,030  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:00:45,038  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 21:00:45,038  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:00:45,038  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[0;32m2025-05-17 21:05:03,718  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:05:07,033  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 21:05:07,036  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:05:07,036  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:05:07,036  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:05:07,036  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:05:07,036  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:05:07,043  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:05:07,043  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:05:07,043  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:05:07,046  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:05:07,367  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:05:07,367  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:05:43,460  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:05:43,460  - INFO - - Train mean loss: 0.7473
- ET loss: 0.7841
- TC loss: 0.7013
- WT loss: 0.7564
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 21:05:43,460  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:05:52,842  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.3803s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.546 â”‚ 0.412 â”‚ 0.52  â”‚ 0.705 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.412 â”‚ 0.276 â”‚ 0.377 â”‚ 0.583 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.513 â”‚ 0.315 â”‚ 0.446 â”‚ 0.778 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.778 â”‚ 0.802 â”‚ 0.82  â”‚ 0.712 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4692, ET: 0.5981, TC: 0.4919, WT: 0.3177
[0m
[1;31m2025-05-17 21:05:52,843  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 21:05:52,889  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4692_dice0.5459_20250517210552.pth;             Size 12.46 MB[0m
[1;31m2025-05-17 21:05:52,889  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4692 at epoch 1[0m
[0;32m2025-05-17 21:05:52,889  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:05:52,898  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 21:05:52,898  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:05:52,898  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:06:46,909  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.586 â”‚  0.407 â”‚  0.593 â”‚  0.759 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.453 â”‚  0.275 â”‚  0.451 â”‚  0.634 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.539 â”‚  0.298 â”‚  0.503 â”‚  0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.814 â”‚  0.842 â”‚  0.852 â”‚  0.749 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 33.855 â”‚ 37.738 â”‚ 34.547 â”‚ 29.279 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4295;ET: 0.6020;ET: 0.6020;TC: 0.4190;WT: 0.2675
[0m
[0;32m2025-05-17 21:06:46,910  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:06:46,910  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:06:52,768  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:06:56,069  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 21:06:56,071  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:06:56,072  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:06:56,072  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:06:56,072  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:06:56,072  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:06:56,078  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:06:56,078  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:06:56,078  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:06:56,082  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLA_SLKv2_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:06:56,462  - INFO - 
model: ResUNetBaseline_S_DCLA_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:06:56,462  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:07:32,611  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:07:32,612  - INFO - - Train mean loss: 0.8718
- ET loss: 0.7242
- TC loss: 0.9725
- WT loss: 0.9187
- Cost time: 0.60mins â±ï¸
[0m
[0;32m2025-05-17 21:07:32,612  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:07:42,187  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLA_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.5738s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.227 â”‚ 0.558 â”‚ 0.028 â”‚ 0.096 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.163 â”‚ 0.425 â”‚ 0.014 â”‚ 0.051 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.214 â”‚ 0.575 â”‚ 0.014 â”‚ 0.052 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.753 â”‚ 0.641 â”‚ 0.67  â”‚ 0.949 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.7881, ET: 0.4873, TC: 0.9719, WT: 0.9052
[0m
[1;31m2025-05-17 21:07:42,188  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 21:07:42,240  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.7881_dice0.2271_20250517210742.pth;             Size 12.59 MB[0m
[1;31m2025-05-17 21:07:42,241  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.7881 at epoch 1[0m
[0;32m2025-05-17 21:07:42,241  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:07:42,249  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLA_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 21:07:42,249  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:07:42,249  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:08:42,834  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.242 â”‚  0.579 â”‚  0.035 â”‚  0.111 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.173 â”‚  0.44  â”‚  0.018 â”‚  0.06  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.209 â”‚  0.55  â”‚  0.018 â”‚  0.06  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.783 â”‚  0.669 â”‚  0.681 â”‚  0.997 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 71.461 â”‚ 36.896 â”‚ 92.636 â”‚ 84.85  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.7744;ET: 0.4686;ET: 0.4686;TC: 0.9641;WT: 0.8905
[0m
[0;32m2025-05-17 21:08:42,835  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:08:42,835  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLA_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:08:48,663  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:08:51,959  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-17 21:08:51,962  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:08:51,962  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:08:51,962  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:08:51,962  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:08:51,962  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:08:51,969  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:08:51,969  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:08:51,969  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:08:51,973  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_2                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.69 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:08:52,355  - INFO - 
model: DCLA_UNet_v2_2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:08:52,356  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:10:02,075  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:10:02,075  - INFO - - Train mean loss: 0.7935
- ET loss: 0.8542
- TC loss: 0.8015
- WT loss: 0.7246
- Cost time: 1.16mins â±ï¸
[0m
[0;32m2025-05-17 21:10:02,075  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:10:12,597  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.5209s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.5   â”‚ 0.34  â”‚ 0.447 â”‚ 0.713 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.369 â”‚ 0.215 â”‚ 0.306 â”‚ 0.586 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.441 â”‚ 0.232 â”‚ 0.337 â”‚ 0.755 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.79  â”‚ 0.817 â”‚ 0.836 â”‚ 0.717 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5204, ET: 0.6775, TC: 0.5736, WT: 0.3099
[0m
[1;31m2025-05-17 21:10:12,599  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_2_final_model.pth[0m
[0;32m2025-05-17 21:10:12,670  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.5204_dice0.4997_20250517211012.pth;             Size 8.82 MB[0m
[1;31m2025-05-17 21:10:12,671  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.5204 at epoch 1[0m
[0;32m2025-05-17 21:10:12,671  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:10:12,677  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_2_final_model.pth[0m
[1;31m2025-05-17 21:10:12,677  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:10:12,677  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:11:09,184  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.541 â”‚  0.368 â”‚  0.531 â”‚  0.726 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.402 â”‚  0.236 â”‚  0.379 â”‚  0.591 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.489 â”‚  0.243 â”‚  0.422 â”‚  0.802 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.823 â”‚  0.867 â”‚  0.886 â”‚  0.715 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 41.08  â”‚ 49.387 â”‚ 45.175 â”‚ 28.678 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4782;ET: 0.6500;ET: 0.6500;TC: 0.4906;WT: 0.2940
[0m
[0;32m2025-05-17 21:11:09,185  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:11:09,185  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:11:14,948  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:11:18,202  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 21:11:18,205  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:11:18,205  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:11:18,205  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:11:18,205  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:11:18,205  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:11:18,212  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:11:18,212  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:11:18,212  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:11:18,215  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:11:18,566  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:11:18,566  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:12:27,105  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:12:27,106  - INFO - - Train mean loss: 0.6916
- ET loss: 0.7536
- TC loss: 0.7396
- WT loss: 0.5817
- Cost time: 1.14mins â±ï¸
[0m
[0;32m2025-05-17 21:12:27,106  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:12:37,675  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.5678s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.519 â”‚ 0.364 â”‚ 0.443 â”‚ 0.75  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.387 â”‚ 0.235 â”‚ 0.304 â”‚ 0.623 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.447 â”‚ 0.254 â”‚ 0.328 â”‚ 0.758 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.83  â”‚ 0.838 â”‚ 0.874 â”‚ 0.777 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4854, ET: 0.6372, TC: 0.5634, WT: 0.2556
[0m
[1;31m2025-05-17 21:12:37,676  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 21:12:37,739  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4854_dice0.5187_20250517211237.pth;             Size 8.69 MB[0m
[1;31m2025-05-17 21:12:37,740  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4854 at epoch 1[0m
[0;32m2025-05-17 21:12:37,740  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:12:37,747  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 21:12:37,747  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:12:37,747  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:13:33,565  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.564 â”‚  0.389 â”‚  0.526 â”‚  0.776 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.431 â”‚  0.257 â”‚  0.382 â”‚  0.655 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.505 â”‚  0.279 â”‚  0.413 â”‚  0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.837 â”‚  0.848 â”‚  0.891 â”‚  0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 28.299 â”‚ 33.119 â”‚ 33.783 â”‚ 17.995 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4396;ET: 0.6136;ET: 0.6136;TC: 0.4781;WT: 0.2270
[0m
[0;32m2025-05-17 21:13:33,565  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:13:33,565  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:13:39,386  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:13:42,684  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 21:13:42,686  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:13:42,686  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:13:42,687  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:13:42,687  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:13:42,687  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:13:42,693  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:13:42,693  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:13:42,694  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:13:42,697  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:13:43,156  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:13:43,157  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:14:56,045  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:14:56,046  - INFO - - Train mean loss: 0.6540
- ET loss: 0.7701
- TC loss: 0.6938
- WT loss: 0.4982
- Cost time: 1.21mins â±ï¸
[0m
[0;32m2025-05-17 21:14:56,046  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:15:07,048  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.0013s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.52  â”‚ 0.341 â”‚ 0.452 â”‚ 0.768 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.393 â”‚ 0.216 â”‚ 0.313 â”‚ 0.65  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.442 â”‚ 0.224 â”‚ 0.331 â”‚ 0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.854 â”‚ 0.878 â”‚ 0.893 â”‚ 0.791 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4838, ET: 0.6627, TC: 0.5522, WT: 0.2364
[0m
[1;31m2025-05-17 21:15:07,049  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_3_final_model.pth[0m
[0;32m2025-05-17 21:15:07,123  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4838_dice0.5203_20250517211507.pth;             Size 10.52 MB[0m
[1;31m2025-05-17 21:15:07,124  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4838 at epoch 1[0m
[0;32m2025-05-17 21:15:07,124  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:15:07,131  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-17 21:15:07,131  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:15:07,131  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:16:04,179  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.554 â”‚  0.355 â”‚  0.527 â”‚  0.779 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.423 â”‚  0.229 â”‚  0.38  â”‚  0.661 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.488 â”‚  0.234 â”‚  0.413 â”‚  0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚  0.896 â”‚  0.909 â”‚  0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 35.76  â”‚ 42.649 â”‚ 38.716 â”‚ 25.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4499;ET: 0.6479;ET: 0.6479;TC: 0.4772;WT: 0.2245
[0m
[0;32m2025-05-17 21:16:04,179  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:16:04,179  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:18:27,267  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:18:30,644  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 21:18:30,647  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:18:30,647  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:18:30,647  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:18:30,647  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:18:30,647  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:18:30,654  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:18:30,654  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:18:30,654  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:18:30,658  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:18:30,982  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:18:30,982  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:19:08,181  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:19:08,182  - INFO - - Train mean loss: 0.7476
- ET loss: 0.7843
- TC loss: 0.7015
- WT loss: 0.7570
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 21:19:08,182  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:19:17,583  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.4002s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.542 â”‚ 0.406 â”‚ 0.514 â”‚ 0.706 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.408 â”‚ 0.271 â”‚ 0.371 â”‚ 0.583 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.503 â”‚ 0.306 â”‚ 0.434 â”‚ 0.77  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.784 â”‚ 0.809 â”‚ 0.826 â”‚ 0.717 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4730, ET: 0.6036, TC: 0.4976, WT: 0.3177
[0m
[1;31m2025-05-17 21:19:17,585  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 21:19:17,639  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4730_dice0.5422_20250517211917.pth;             Size 12.46 MB[0m
[1;31m2025-05-17 21:19:17,640  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4730 at epoch 1[0m
[0;32m2025-05-17 21:19:17,640  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:19:17,649  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 21:19:17,649  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:19:17,649  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:20:11,959  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.583 â”‚  0.402 â”‚  0.588 â”‚  0.759 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.45  â”‚  0.27  â”‚  0.446 â”‚  0.634 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.531 â”‚  0.291 â”‚  0.493 â”‚  0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.82  â”‚  0.848 â”‚  0.859 â”‚  0.753 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 35.443 â”‚ 39.774 â”‚ 36.384 â”‚ 30.171 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4332;ET: 0.6065;ET: 0.6065;TC: 0.4238;WT: 0.2693
[0m
[0;32m2025-05-17 21:20:11,959  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:20:11,960  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:20:17,920  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:20:21,456  - INFO - Total number of parameters: 1.16 M[0m
[0;32m2025-05-17 21:20:21,459  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:20:21,459  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:20:21,459  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:20:21,459  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:20:21,459  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:20:21,466  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:20:21,466  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:20:21,466  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:20:21,470  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.16 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:20:21,931  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:20:21,931  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:20:59,228  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:20:59,229  - INFO - - Train mean loss: 0.6237
- ET loss: 0.7333
- TC loss: 0.6608
- WT loss: 0.4770
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 21:20:59,229  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:21:08,335  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.1048s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.556 â”‚ 0.409 â”‚ 0.522 â”‚ 0.738 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.424 â”‚ 0.272 â”‚ 0.378 â”‚ 0.621 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.547 â”‚ 0.301 â”‚ 0.438 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.762 â”‚ 0.805 â”‚ 0.824 â”‚ 0.657 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4482, ET: 0.5953, TC: 0.4838, WT: 0.2656
[0m
[0;32m2025-05-17 21:21:08,417  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4482_dice0.5562_20250517212108.pth;             Size 14.29 MB[0m
[1;31m2025-05-17 21:21:08,417  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4482 at epoch 1[0m
[0;32m2025-05-17 21:21:08,417  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:21:08,428  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLAv1_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 21:21:08,429  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:21:08,429  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:22:02,213  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.588 â”‚  0.424 â”‚  0.592 â”‚  0.747 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.46  â”‚  0.291 â”‚  0.453 â”‚  0.635 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.591 â”‚  0.309 â”‚  0.515 â”‚  0.948 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.783 â”‚  0.847 â”‚  0.839 â”‚  0.663 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 17.68  â”‚ 22.932 â”‚ 18.666 â”‚ 11.443 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4158;ET: 0.5799;ET: 0.5799;TC: 0.4128;WT: 0.2546
[0m
[0;32m2025-05-17 21:22:02,214  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:22:02,214  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:22:07,744  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:22:11,166  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 21:22:11,168  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:22:11,168  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:22:11,168  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:22:11,168  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:22:11,168  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:22:11,175  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:22:11,175  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:22:11,175  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:22:11,179  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:22:11,547  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:22:11,547  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:23:20,374  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:23:20,374  - INFO - - Train mean loss: 0.6916
- ET loss: 0.7536
- TC loss: 0.7397
- WT loss: 0.5816
- Cost time: 1.15mins â±ï¸
[0m
[0;32m2025-05-17 21:23:20,374  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:23:30,824  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.4481s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.519 â”‚ 0.365 â”‚ 0.443 â”‚ 0.749 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.388 â”‚ 0.236 â”‚ 0.304 â”‚ 0.623 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.447 â”‚ 0.255 â”‚ 0.328 â”‚ 0.758 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.829 â”‚ 0.836 â”‚ 0.874 â”‚ 0.777 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4851, ET: 0.6361, TC: 0.5635, WT: 0.2557
[0m
[1;31m2025-05-17 21:23:30,825  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 21:23:30,888  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4851_dice0.5190_20250517212330.pth;             Size 8.69 MB[0m
[1;31m2025-05-17 21:23:30,888  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4851 at epoch 1[0m
[0;32m2025-05-17 21:23:30,888  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:23:30,894  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 21:23:30,894  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:23:30,894  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:24:26,558  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.564 â”‚  0.39  â”‚  0.526 â”‚  0.776 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.432 â”‚  0.258 â”‚  0.382 â”‚  0.656 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.506 â”‚  0.281 â”‚  0.413 â”‚  0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.836 â”‚  0.846 â”‚  0.891 â”‚  0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 28.279 â”‚ 33.021 â”‚ 33.811 â”‚ 18.005 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4393;ET: 0.6127;ET: 0.6127;TC: 0.4782;WT: 0.2269
[0m
[0;32m2025-05-17 21:24:26,559  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:24:26,559  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:24:32,362  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:24:35,644  - INFO - Total number of parameters: 2.89 M[0m
[0;32m2025-05-17 21:24:35,647  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:24:35,647  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:24:35,647  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:24:35,647  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:24:35,647  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:24:35,653  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:24:35,653  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:24:35,654  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:24:35,657  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_MSF_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 2.89 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:24:36,024  - INFO - 
model: ResUNetBaseline_S_DCLAv1_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:24:36,024  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:25:32,041  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:25:32,041  - INFO - - Train mean loss: 0.8668
- ET loss: 0.8398
- TC loss: 0.8508
- WT loss: 0.9099
- Cost time: 0.93mins â±ï¸
[0m
[0;32m2025-05-17 21:25:32,041  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:25:41,447  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLAv1_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.4042s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.49  â”‚ 0.611 â”‚ 0.647 â”‚ 0.211 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.372 â”‚ 0.473 â”‚ 0.521 â”‚ 0.123 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.439 â”‚ 0.538 â”‚ 0.655 â”‚ 0.124 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.814 â”‚ 0.793 â”‚ 0.728 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5383, ET: 0.4084, TC: 0.3913, WT: 0.8153
[0m
[0;32m2025-05-17 21:25:41,531  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.5383_dice0.4897_20250517212541.pth;             Size 35.06 MB[0m
[1;31m2025-05-17 21:25:41,532  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.5383 at epoch 1[0m
[0;32m2025-05-17 21:25:41,532  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:25:41,551  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLAv1_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 21:25:41,551  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:25:41,551  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:26:38,999  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.494 â”‚  0.612 â”‚  0.637 â”‚  0.232 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.372 â”‚  0.472 â”‚  0.509 â”‚  0.136 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.457 â”‚  0.54  â”‚  0.693 â”‚  0.138 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.777 â”‚  0.764 â”‚  0.663 â”‚  0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 53.823 â”‚ 35.752 â”‚ 37.341 â”‚ 88.376 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5344;ET: 0.4078;ET: 0.4078;TC: 0.3965;WT: 0.7987
[0m
[0;32m2025-05-17 21:26:39,000  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:26:39,000  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:26:44,896  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:26:48,281  - INFO - Total number of parameters: 0.83 M[0m
[0;32m2025-05-17 21:26:48,284  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:26:48,284  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:26:48,285  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:26:48,285  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:26:48,285  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:26:48,293  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:26:48,293  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:26:48,293  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:26:48,297  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.83 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:26:48,807  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:26:48,808  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:28:01,771  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:28:01,772  - INFO - - Train mean loss: 0.6532
- ET loss: 0.7694
- TC loss: 0.6931
- WT loss: 0.4971
- Cost time: 1.22mins â±ï¸
[0m
[0;32m2025-05-17 21:28:01,772  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:28:12,801  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.0281s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.521 â”‚ 0.341 â”‚ 0.452 â”‚ 0.769 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.394 â”‚ 0.217 â”‚ 0.313 â”‚ 0.651 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.443 â”‚ 0.224 â”‚ 0.331 â”‚ 0.775 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚ 0.877 â”‚ 0.892 â”‚ 0.791 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4832, ET: 0.6622, TC: 0.5519, WT: 0.2355
[0m
[1;31m2025-05-17 21:28:12,803  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_3_final_model.pth[0m
[0;32m2025-05-17 21:28:12,878  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4832_dice0.5209_20250517212812.pth;             Size 10.52 MB[0m
[1;31m2025-05-17 21:28:12,879  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4832 at epoch 1[0m
[0;32m2025-05-17 21:28:12,879  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:28:12,886  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-17 21:28:12,886  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:28:12,886  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:29:10,546  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.555 â”‚  0.356 â”‚  0.527 â”‚  0.78  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.424 â”‚  0.23  â”‚  0.38  â”‚  0.662 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.489 â”‚  0.235 â”‚  0.413 â”‚  0.818 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚  0.896 â”‚  0.908 â”‚  0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 35.811 â”‚ 42.72  â”‚ 38.758 â”‚ 25.957 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4493;ET: 0.6472;ET: 0.6472;TC: 0.4767;WT: 0.2239
[0m
[0;32m2025-05-17 21:29:10,547  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:29:10,547  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:30:21,841  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:30:25,308  - INFO - Total number of parameters: 1.02 M[0m
[0;32m2025-05-17 21:30:25,311  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:30:25,311  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:30:25,311  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:30:25,311  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:30:25,311  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:30:25,318  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 21:30:25,318  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 21:30:25,318  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 21:30:25,321  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.02 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:30:28,101  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 21:30:28,101  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 21:32:46,908  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 21:32:46,910  - INFO - - Train mean loss: 0.5443
- ET loss: 0.6367
- TC loss: 0.5574
- WT loss: 0.4387
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 21:32:46,910  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 21:33:20,234  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:33.3230s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.675 â”‚ 0.578 â”‚ 0.67  â”‚ 0.777 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.544 â”‚ 0.434 â”‚ 0.539 â”‚ 0.659 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.615 â”‚ 0.47  â”‚ 0.627 â”‚ 0.748 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.84  â”‚ 0.853 â”‚ 0.81  â”‚ 0.856 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3415, ET: 0.4410, TC: 0.3494, WT: 0.2341
[0m
[1;31m2025-05-17 21:33:20,236  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch88_loss0.1183_dice0.8829_20250517065518.pth[0m
[0;32m2025-05-17 21:33:20,282  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.3415_dice0.6749_20250517213320.pth;             Size 12.46 MB[0m
[0;32m2025-05-17 21:33:20,282  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 21:35:39,142  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 21:35:39,143  - INFO - - Train mean loss: 0.3805
- ET loss: 0.4367
- TC loss: 0.4271
- WT loss: 0.2779
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 21:35:39,143  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 21:36:10,627  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:31.4826s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.75  â”‚ 0.712 â”‚ 0.711 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.638 â”‚ 0.592 â”‚ 0.593 â”‚ 0.728 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.795 â”‚ 0.688 â”‚ 0.824 â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.758 â”‚ 0.787 â”‚ 0.673 â”‚ 0.814 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2575, ET: 0.2990, TC: 0.2952, WT: 0.1783
[0m
[1;31m2025-05-17 21:36:10,629  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 21:36:10,676  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.2575_dice0.7504_20250517213610.pth;             Size 12.46 MB[0m
[0;32m2025-05-17 21:36:10,676  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-17 21:38:25,703  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-17 21:38:25,704  - INFO - - Train mean loss: 0.3592
- ET loss: 0.4133
- TC loss: 0.4127
- WT loss: 0.2516
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-17 21:38:25,704  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-17 21:38:58,838  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:33.1334s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.759 â”‚ 0.72  â”‚ 0.714 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.649 â”‚ 0.601 â”‚ 0.598 â”‚ 0.749 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.761 â”‚ 0.653 â”‚ 0.77  â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.803 â”‚ 0.843 â”‚ 0.714 â”‚ 0.852 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2467, ET: 0.2872, TC: 0.2904, WT: 0.1626
[0m
[1;31m2025-05-17 21:38:58,840  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.3415_dice0.6749_20250517213320.pth[0m
[0;32m2025-05-17 21:38:58,882  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.2467_dice0.7593_20250517213858.pth;             Size 12.46 MB[0m
[0;32m2025-05-17 21:38:58,883  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-17 21:41:17,123  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-17 21:41:17,125  - INFO - - Train mean loss: 0.3380
- ET loss: 0.3808
- TC loss: 0.4036
- WT loss: 0.2297
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 21:41:17,125  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-17 21:41:48,967  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:31.8418s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.767 â”‚ 0.726 â”‚ 0.72  â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.66  â”‚ 0.608 â”‚ 0.605 â”‚ 0.766 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.773 â”‚ 0.658 â”‚ 0.774 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.807 â”‚ 0.851 â”‚ 0.72  â”‚ 0.849 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2382, ET: 0.2810, TC: 0.2841, WT: 0.1494
[0m
[1;31m2025-05-17 21:41:48,969  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.2575_dice0.7504_20250517213610.pth[0m
[0;32m2025-05-17 21:41:49,011  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.2382_dice0.7675_20250517214148.pth;             Size 12.46 MB[0m
[0;32m2025-05-17 21:41:49,012  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-17 21:44:07,292  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-17 21:44:07,293  - INFO - - Train mean loss: 0.3322
- ET loss: 0.3752
- TC loss: 0.4009
- WT loss: 0.2205
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-17 21:44:07,293  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-17 21:44:38,125  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:30.8311s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.771 â”‚ 0.738 â”‚ 0.716 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.666 â”‚ 0.625 â”‚ 0.6   â”‚ 0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.778 â”‚ 0.675 â”‚ 0.775 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.813 â”‚ 0.865 â”‚ 0.719 â”‚ 0.856 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2342, ET: 0.2684, TC: 0.2885, WT: 0.1456
[0m
[1;31m2025-05-17 21:44:38,127  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.2467_dice0.7593_20250517213858.pth[0m
[0;32m2025-05-17 21:44:38,178  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.2342_dice0.7708_20250517214438.pth;             Size 12.46 MB[0m
[0;32m2025-05-17 21:44:38,178  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-17 21:46:56,936  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-17 21:46:56,937  - INFO - - Train mean loss: 0.3249
- ET loss: 0.3600
- TC loss: 0.3922
- WT loss: 0.2225
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 21:46:56,937  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-17 21:47:28,137  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:31.1989s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.756 â”‚ 0.747 â”‚ 0.7   â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.651 â”‚ 0.639 â”‚ 0.586 â”‚ 0.728 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.85  â”‚ 0.759 â”‚ 0.858 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.722 â”‚ 0.771 â”‚ 0.633 â”‚ 0.761 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2465, ET: 0.2568, TC: 0.3017, WT: 0.1811
[0m
[0;33m2025-05-17 21:47:28,137  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 21:47:28,137  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;32m2025-05-17 21:47:45,934  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:47:49,246  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 21:47:49,249  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:47:49,249  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:47:49,249  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:47:49,249  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:47:49,249  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:47:49,256  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:47:49,256  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:47:49,256  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:47:49,260  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:47:49,624  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:47:49,624  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:48:26,671  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:48:26,672  - INFO - - Train mean loss: 0.7339
- ET loss: 0.6773
- TC loss: 0.6131
- WT loss: 0.9113
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 21:48:26,672  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:48:35,361  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.6878s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.425 â”‚ 0.546 â”‚ 0.629 â”‚ 0.1   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.317 â”‚ 0.402 â”‚ 0.495 â”‚ 0.054 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.388 â”‚ 0.478 â”‚ 0.63  â”‚ 0.054 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.757 â”‚ 0.734 â”‚ 0.994 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.5844, ET: 0.4662, TC: 0.3857, WT: 0.9012
[0m
[1;31m2025-05-17 21:48:35,363  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 21:48:35,409  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.5844_dice0.4247_20250517214835.pth;             Size 12.40 MB[0m
[1;31m2025-05-17 21:48:35,410  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.5844 at epoch 1[0m
[0;32m2025-05-17 21:48:35,410  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:48:35,419  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 21:48:35,419  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:48:35,419  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:49:31,237  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.428 â”‚  0.52  â”‚  0.644 â”‚  0.119 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.323 â”‚  0.379 â”‚  0.523 â”‚  0.066 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.39  â”‚  0.432 â”‚  0.672 â”‚  0.067 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.829 â”‚  0.761 â”‚  0.739 â”‚  0.988 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 45.2   â”‚ 25.392 â”‚ 24.308 â”‚ 85.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.5794;ET: 0.4891;ET: 0.4891;TC: 0.3664;WT: 0.8827
[0m
[0;32m2025-05-17 21:49:31,237  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:49:31,238  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:49:37,435  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:49:40,739  - INFO - Total number of parameters: 1.15 M[0m
[0;32m2025-05-17 21:49:40,742  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:49:40,742  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:49:40,742  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:49:40,742  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:49:40,743  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:49:40,751  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:49:40,751  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:49:40,751  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:49:40,755  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.15 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:49:41,197  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:49:41,198  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:50:18,193  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:50:18,193  - INFO - - Train mean loss: 0.6175
- ET loss: 0.6413
- TC loss: 0.6656
- WT loss: 0.5455
- Cost time: 0.62mins â±ï¸
[0m
[0;32m2025-05-17 21:50:18,193  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:50:27,387  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.1924s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.673 â”‚ 0.664 â”‚ 0.633 â”‚ 0.72  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.536 â”‚ 0.5   â”‚ 0.605 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.729 â”‚ 0.662 â”‚ 0.638 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.712 â”‚ 0.726 â”‚ 0.748 â”‚ 0.661 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3390, ET: 0.3448, TC: 0.3922, WT: 0.2798
[0m
[1;31m2025-05-17 21:50:27,388  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLAv1_SLKv2_v2_final_model.pth[0m
[0;32m2025-05-17 21:50:27,448  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.3390_dice0.6725_20250517215027.pth;             Size 14.23 MB[0m
[1;31m2025-05-17 21:50:27,448  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.3390 at epoch 1[0m
[0;32m2025-05-17 21:50:27,448  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:50:27,458  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLAv1_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-17 21:50:27,458  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:50:27,458  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:51:19,814  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.676 â”‚ 0.644 â”‚  0.649 â”‚  0.737 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.549 â”‚ 0.509 â”‚  0.517 â”‚  0.622 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.759 â”‚ 0.684 â”‚  0.692 â”‚  0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.68  â”‚ 0.668 â”‚  0.698 â”‚  0.675 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 13.997 â”‚ 6.328 â”‚ 19.115 â”‚ 16.548 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.3331;ET: 0.3663;ET: 0.3663;TC: 0.3706;WT: 0.2624
[0m
[0;32m2025-05-17 21:51:19,814  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:51:19,815  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:51:25,777  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:51:29,060  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-17 21:51:29,062  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:51:29,062  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:51:29,063  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:51:29,063  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:51:29,063  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:51:29,069  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:51:29,070  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:51:29,070  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:51:29,073  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:51:29,444  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:51:29,444  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:52:37,032  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:52:37,033  - INFO - - Train mean loss: 0.6007
- ET loss: 0.7003
- TC loss: 0.6118
- WT loss: 0.4900
- Cost time: 1.13mins â±ï¸
[0m
[0;32m2025-05-17 21:52:37,033  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:52:47,638  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.6045s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.557 â”‚ 0.457 â”‚ 0.558 â”‚ 0.656 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.421 â”‚ 0.316 â”‚ 0.417 â”‚ 0.528 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.601 â”‚ 0.368 â”‚ 0.516 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.706 â”‚ 0.782 â”‚ 0.786 â”‚ 0.549 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4492, ET: 0.5529, TC: 0.4512, WT: 0.3434
[0m
[1;31m2025-05-17 21:52:47,639  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 21:52:47,703  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4492_dice0.5571_20250517215247.pth;             Size 8.62 MB[0m
[1;31m2025-05-17 21:52:47,703  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4492 at epoch 1[0m
[0;32m2025-05-17 21:52:47,703  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:52:47,709  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_SLKv2_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 21:52:47,709  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:52:47,709  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:53:43,152  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.576 â”‚  0.466 â”‚  0.607 â”‚  0.654 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.443 â”‚  0.326 â”‚  0.47  â”‚  0.533 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.65  â”‚  0.383 â”‚  0.609 â”‚  0.958 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.697 â”‚  0.775 â”‚  0.767 â”‚  0.547 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 21.587 â”‚ 25.536 â”‚ 22.097 â”‚ 17.128 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4300;ET: 0.5424;ET: 0.5424;TC: 0.4018;WT: 0.3458
[0m
[0;32m2025-05-17 21:53:43,153  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:53:43,153  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:53:49,179  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:53:52,505  - INFO - Total number of parameters: 2.89 M[0m
[0;32m2025-05-17 21:53:52,508  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:53:52,508  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:53:52,508  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:53:52,508  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:53:52,508  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:53:52,516  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:53:52,516  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:53:52,516  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:53:52,521  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_MSF_v2                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 2.89 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:53:52,906  - INFO - 
model: ResUNetBaseline_S_DCLAv1_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:53:52,906  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:54:48,847  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:54:48,848  - INFO - - Train mean loss: 0.8216
- ET loss: 0.7758
- TC loss: 0.8568
- WT loss: 0.8323
- Cost time: 0.93mins â±ï¸
[0m
[0;32m2025-05-17 21:54:48,848  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:54:58,879  - INFO - === [Epoch 1/1] ===
- Model:    ResUNetBaseline_S_DCLAv1_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.0307s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.671 â”‚ 0.612 â”‚ 0.656 â”‚ 0.746 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.542 â”‚ 0.472 â”‚ 0.527 â”‚ 0.626 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.619 â”‚ 0.523 â”‚ 0.644 â”‚ 0.69  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.817 â”‚ 0.822 â”‚ 0.767 â”‚ 0.862 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3957, ET: 0.4013, TC: 0.4384, WT: 0.3475
[0m
[1;31m2025-05-17 21:54:58,883  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed ResUNetBaseline_S_DCLAv1_MSF_v2_final_model.pth[0m
[0;32m2025-05-17 21:54:58,967  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.3957_dice0.6713_20250517215458.pth;             Size 35.06 MB[0m
[1;31m2025-05-17 21:54:58,967  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.3957 at epoch 1[0m
[0;32m2025-05-17 21:54:58,967  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:54:58,991  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/ResUNetBaseline_S_DCLAv1_MSF_v2_final_model.pth[0m
[1;31m2025-05-17 21:54:58,991  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:54:58,991  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:55:53,354  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.68  â”‚  0.604 â”‚  0.659 â”‚  0.777 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.548 â”‚  0.456 â”‚  0.53  â”‚  0.659 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.646 â”‚  0.51  â”‚  0.672 â”‚  0.756 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.794 â”‚  0.812 â”‚  0.727 â”‚  0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 27.151 â”‚ 22.019 â”‚ 26.981 â”‚ 32.452 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.3775;ET: 0.4089;ET: 0.4089;TC: 0.4158;WT: 0.3077
[0m
[0;32m2025-05-17 21:55:53,354  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:55:53,355  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_MSF_v2_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:55:59,305  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:56:02,606  - INFO - Total number of parameters: 0.82 M[0m
[0;32m2025-05-17 21:56:02,608  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:56:02,608  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:56:02,608  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:56:02,608  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:56:02,609  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:56:02,615  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š210[0m
[0;33m2025-05-17 21:56:02,615  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š60[0m
[0;33m2025-05-17 21:56:02,615  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š30[0m
[0;32m2025-05-17 21:56:02,619  - INFO - ğŸ§  é¡¹ç›®åï¼šlr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 5                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 210                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 60                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 30                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.82 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:56:03,054  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 1
early_stopping: 5
[0m
[0;32m2025-05-17 21:56:03,054  - INFO - === Training on [Epoch 1/1] ===:[0m
[0;33m2025-05-17 21:57:15,206  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-17 21:57:15,206  - INFO - - Train mean loss: 0.7207
- ET loss: 0.7344
- TC loss: 0.7237
- WT loss: 0.7040
- Cost time: 1.20mins â±ï¸
[0m
[0;32m2025-05-17 21:57:15,206  - INFO - === Validating on [Epoch 1/1] ===:[0m
[0;32m2025-05-17 21:57:26,309  - INFO - === [Epoch 1/1] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:11.1020s â±ï¸
- early_stopping: 5
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.564 â”‚ 0.533 â”‚ 0.46  â”‚ 0.7   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.429 â”‚ 0.393 â”‚ 0.32  â”‚ 0.574 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.554 â”‚ 0.513 â”‚ 0.365 â”‚ 0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.726 â”‚ 0.696 â”‚ 0.812 â”‚ 0.668 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4574, ET: 0.4903, TC: 0.5595, WT: 0.3225
[0m
[1;31m2025-05-17 21:57:26,311  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed DCLA_UNet_v2_3_final_model.pth[0m
[0;32m2025-05-17 21:57:26,385  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/best_epoch1_loss0.4574_dice0.5644_20250517215726.pth;             Size 10.45 MB[0m
[1;31m2025-05-17 21:57:26,385  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.4574 at epoch 1[0m
[0;32m2025-05-17 21:57:26,385  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-17 21:57:26,393  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-17 21:57:26,393  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-17 21:57:26,393  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-17 21:58:22,327  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚     TC â”‚     WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.561 â”‚  0.489 â”‚  0.515 â”‚  0.681 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.427 â”‚  0.356 â”‚  0.372 â”‚  0.553 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.598 â”‚  0.504 â”‚  0.454 â”‚  0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.665 â”‚  0.614 â”‚  0.757 â”‚  0.626 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚ 35.716 â”‚ 33.441 â”‚ 43.677 â”‚ 30.029 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•›
Mean Loss: 0.4538;ET: 0.5260;ET: 0.5260;TC: 0.4992;WT: 0.3363
[0m
[0;32m2025-05-17 21:58:22,327  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-17 21:58:22,327  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-17_lr0.0001_mlr1e-05_Tmax100_1_5/logs/2025-05-17.log[0m
[0;32m2025-05-17 21:59:10,425  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-17 21:59:13,709  - INFO - Total number of parameters: 1.01 M[0m
[0;32m2025-05-17 21:59:13,711  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-17 21:59:13,711  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:59:13,711  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:59:13,711  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-17 21:59:13,712  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-17 21:59:13,718  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-17 21:59:13,718  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-17 21:59:13,718  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-17 21:59:13,722  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_v2                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.01 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-17 21:59:16,545  - INFO - 
model: ResUNetBaseline_S_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-17 21:59:16,545  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-17 22:01:38,697  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-17 22:01:38,699  - INFO - - Train mean loss: 0.5833
- ET loss: 0.5533
- TC loss: 0.5092
- WT loss: 0.6873
- Cost time: 2.37mins â±ï¸
[0m
[0;32m2025-05-17 22:01:38,700  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-17 22:02:10,812  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:32.1098s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.694 â”‚ 0.664 â”‚ 0.687 â”‚ 0.73  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.566 â”‚ 0.534 â”‚ 0.566 â”‚ 0.598 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.671 â”‚ 0.617 â”‚ 0.754 â”‚ 0.641 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.808 â”‚ 0.804 â”‚ 0.712 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3109, ET: 0.3406, TC: 0.3171, WT: 0.2751
[0m
[1;31m2025-05-17 22:02:10,814  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2382_dice0.7675_20250517214148.pth[0m
[0;32m2025-05-17 22:02:10,870  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.3109_dice0.6941_20250517220210.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:02:10,870  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-17 22:04:31,806  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-17 22:04:31,807  - INFO - - Train mean loss: 0.3880
- ET loss: 0.4335
- TC loss: 0.4370
- WT loss: 0.2935
- Cost time: 2.35mins â±ï¸
[0m
[0;32m2025-05-17 22:04:31,807  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-17 22:05:03,634  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:31.8261s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.703 â”‚ 0.625 â”‚ 0.682 â”‚ 0.801 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.58  â”‚ 0.49  â”‚ 0.558 â”‚ 0.691 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.635 â”‚ 0.515 â”‚ 0.652 â”‚ 0.737 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.895 â”‚ 0.809 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3046, ET: 0.3813, TC: 0.3245, WT: 0.2081
[0m
[1;31m2025-05-17 22:05:03,636  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.2342_dice0.7708_20250517214438.pth[0m
[0;32m2025-05-17 22:05:03,680  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.3046_dice0.7025_20250517220503.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:05:03,680  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-17 22:07:23,804  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-17 22:07:23,806  - INFO - - Train mean loss: 0.3528
- ET loss: 0.4014
- TC loss: 0.4102
- WT loss: 0.2467
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-17 22:07:23,806  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-17 22:07:55,767  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:31.9588s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.7   â”‚ 0.621 â”‚ 0.667 â”‚ 0.812 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.578 â”‚ 0.488 â”‚ 0.539 â”‚ 0.707 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.622 â”‚ 0.502 â”‚ 0.624 â”‚ 0.74  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.914 â”‚ 0.81  â”‚ 0.942 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3074, ET: 0.3859, TC: 0.3396, WT: 0.1967
[0m
[0;33m2025-05-17 22:07:55,767  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 22:07:55,767  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-17 22:10:13,337  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-17 22:10:13,339  - INFO - - Train mean loss: 0.3421
- ET loss: 0.3974
- TC loss: 0.3943
- WT loss: 0.2346
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-17 22:10:13,339  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-17 22:10:45,099  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:31.7591s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.782 â”‚ 0.761 â”‚ 0.715 â”‚ 0.869 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.68  â”‚ 0.658 â”‚ 0.597 â”‚ 0.785 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.815 â”‚ 0.747 â”‚ 0.84  â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.794 â”‚ 0.818 â”‚ 0.664 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2217, ET: 0.2418, TC: 0.2874, WT: 0.1361
[0m
[1;31m2025-05-17 22:10:45,101  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch1_loss0.3109_dice0.6941_20250517220210.pth[0m
[0;32m2025-05-17 22:10:45,146  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.2217_dice0.7815_20250517221045.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:10:45,147  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-17 22:13:04,853  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-17 22:13:04,854  - INFO - - Train mean loss: 0.3034
- ET loss: 0.3445
- TC loss: 0.3623
- WT loss: 0.2034
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 22:13:04,854  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-17 22:13:35,116  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:30.2613s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.777 â”‚ 0.717 â”‚ 0.74  â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.673 â”‚ 0.6   â”‚ 0.626 â”‚ 0.795 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.754 â”‚ 0.626 â”‚ 0.758 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.854 â”‚ 0.897 â”‚ 0.773 â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2260, ET: 0.2859, TC: 0.2624, WT: 0.1299
[0m
[0;33m2025-05-17 22:13:35,116  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 22:13:35,116  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-17 22:15:56,061  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-17 22:15:56,063  - INFO - - Train mean loss: 0.3096
- ET loss: 0.3575
- TC loss: 0.3653
- WT loss: 0.2059
- Cost time: 2.35mins â±ï¸
[0m
[0;32m2025-05-17 22:15:56,063  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-17 22:16:26,288  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:30.2231s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.8   â”‚ 0.759 â”‚ 0.758 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.703 â”‚ 0.652 â”‚ 0.652 â”‚ 0.806 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.813 â”‚ 0.707 â”‚ 0.839 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.863 â”‚ 0.73  â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2025, ET: 0.2428, TC: 0.2432, WT: 0.1215
[0m
[1;31m2025-05-17 22:16:26,290  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3046_dice0.7025_20250517220503.pth[0m
[0;32m2025-05-17 22:16:26,335  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.2025_dice0.7997_20250517221626.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:16:26,335  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-17 22:18:45,906  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-17 22:18:45,908  - INFO - - Train mean loss: 0.2929
- ET loss: 0.3325
- TC loss: 0.3543
- WT loss: 0.1919
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-17 22:18:45,908  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-17 22:19:16,362  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:30.4527s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.803 â”‚ 0.757 â”‚ 0.77  â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.708 â”‚ 0.648 â”‚ 0.668 â”‚ 0.807 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.81  â”‚ 0.699 â”‚ 0.842 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.836 â”‚ 0.868 â”‚ 0.747 â”‚ 0.893 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1989, ET: 0.2448, TC: 0.2319, WT: 0.1201
[0m
[1;31m2025-05-17 22:19:16,364  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2217_dice0.7815_20250517221045.pth[0m
[0;32m2025-05-17 22:19:16,409  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.1989_dice0.8032_20250517221916.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:19:16,409  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-17 22:21:33,143  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-17 22:21:33,145  - INFO - - Train mean loss: 0.3070
- ET loss: 0.3653
- TC loss: 0.3653
- WT loss: 0.1904
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 22:21:33,145  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-17 22:22:03,432  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:30.2865s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.807 â”‚ 0.74  â”‚ 0.798 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.713 â”‚ 0.624 â”‚ 0.706 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.791 â”‚ 0.662 â”‚ 0.836 â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.884 â”‚ 0.796 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1945, ET: 0.2619, TC: 0.2035, WT: 0.1182
[0m
[1;31m2025-05-17 22:22:03,434  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.2025_dice0.7997_20250517221626.pth[0m
[0;32m2025-05-17 22:22:03,478  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch8_loss0.1945_dice0.8074_20250517222203.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:22:03,479  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-17 22:24:22,001  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-17 22:24:22,003  - INFO - - Train mean loss: 0.2821
- ET loss: 0.3422
- TC loss: 0.3230
- WT loss: 0.1811
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 22:24:22,003  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-17 22:24:52,149  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:30.1449s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.821 â”‚ 0.776 â”‚ 0.801 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.735 â”‚ 0.678 â”‚ 0.718 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.865 â”‚ 0.82  â”‚ 0.861 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.812 â”‚ 0.773 â”‚ 0.791 â”‚ 0.871 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1813, ET: 0.2260, TC: 0.2000, WT: 0.1179
[0m
[1;31m2025-05-17 22:24:52,151  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.1989_dice0.8032_20250517221916.pth[0m
[0;32m2025-05-17 22:24:52,193  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.1813_dice0.8207_20250517222452.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:24:52,193  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-17 22:27:12,842  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-17 22:27:12,844  - INFO - - Train mean loss: 0.2623
- ET loss: 0.3121
- TC loss: 0.2874
- WT loss: 0.1873
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-17 22:27:12,844  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-17 22:27:42,878  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:30.0330s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.836 â”‚ 0.792 â”‚ 0.83  â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.754 â”‚ 0.698 â”‚ 0.752 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.852 â”‚ 0.808 â”‚ 0.877 â”‚ 0.871 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.848 â”‚ 0.806 â”‚ 0.82  â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1663, ET: 0.2102, TC: 0.1712, WT: 0.1174
[0m
[1;31m2025-05-17 22:27:42,881  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.1945_dice0.8074_20250517222203.pth[0m
[0;32m2025-05-17 22:27:42,932  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.1663_dice0.8359_20250517222742.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:27:42,932  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-17 22:30:04,407  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-17 22:30:04,409  - INFO - - Train mean loss: 0.2555
- ET loss: 0.3064
- TC loss: 0.2793
- WT loss: 0.1808
- Cost time: 2.36mins â±ï¸
[0m
[0;32m2025-05-17 22:30:04,409  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-17 22:30:34,789  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:30.3790s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.844 â”‚ 0.801 â”‚ 0.843 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.766 â”‚ 0.712 â”‚ 0.771 â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.834 â”‚ 0.875 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.846 â”‚ 0.798 â”‚ 0.844 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1581, ET: 0.2013, TC: 0.1584, WT: 0.1146
[0m
[1;31m2025-05-17 22:30:34,791  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.1813_dice0.8207_20250517222452.pth[0m
[0;32m2025-05-17 22:30:34,833  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.1581_dice0.8439_20250517223034.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:30:34,833  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-17 22:32:50,484  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-17 22:32:50,485  - INFO - - Train mean loss: 0.2741
- ET loss: 0.3275
- TC loss: 0.2964
- WT loss: 0.1983
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 22:32:50,485  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-17 22:33:20,643  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:30.1574s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.838 â”‚ 0.798 â”‚ 0.83  â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.758 â”‚ 0.705 â”‚ 0.754 â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.832 â”‚ 0.778 â”‚ 0.834 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.848 â”‚ 0.875 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1638, ET: 0.2045, TC: 0.1718, WT: 0.1151
[0m
[0;33m2025-05-17 22:33:20,643  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 22:33:20,643  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-17 22:35:37,150  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-17 22:35:37,153  - INFO - - Train mean loss: 0.2558
- ET loss: 0.3098
- TC loss: 0.2794
- WT loss: 0.1782
- Cost time: 2.28mins â±ï¸
[0m
[0;32m2025-05-17 22:35:37,153  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-17 22:36:07,360  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:30.2056s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.85  â”‚ 0.811 â”‚ 0.847 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.773 â”‚ 0.722 â”‚ 0.776 â”‚ 0.821 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.857 â”‚ 0.801 â”‚ 0.856 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.844 â”‚ 0.868 â”‚ 0.886 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1519, ET: 0.1914, TC: 0.1543, WT: 0.1101
[0m
[1;31m2025-05-17 22:36:07,362  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.1663_dice0.8359_20250517222742.pth[0m
[0;32m2025-05-17 22:36:07,404  - INFO - âœ¨ Saved checkpoint (epoch 13) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.1519_dice0.8497_20250517223607.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:36:07,404  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-17 22:38:25,794  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-17 22:38:25,796  - INFO - - Train mean loss: 0.2503
- ET loss: 0.3003
- TC loss: 0.2667
- WT loss: 0.1839
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-17 22:38:25,796  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-17 22:38:55,998  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:30.2009s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.851 â”‚ 0.81  â”‚ 0.849 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.774 â”‚ 0.722 â”‚ 0.777 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.843 â”‚ 0.798 â”‚ 0.848 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.848 â”‚ 0.88  â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1507, ET: 0.1922, TC: 0.1519, WT: 0.1079
[0m
[1;31m2025-05-17 22:38:56,000  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.1581_dice0.8439_20250517223034.pth[0m
[0;32m2025-05-17 22:38:56,043  - INFO - âœ¨ Saved checkpoint (epoch 14) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch14_loss0.1507_dice0.8512_20250517223856.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:38:56,043  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-17 22:41:10,529  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-17 22:41:10,531  - INFO - - Train mean loss: 0.2463
- ET loss: 0.2990
- TC loss: 0.2654
- WT loss: 0.1744
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 22:41:10,531  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-17 22:41:40,912  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:30.3803s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.853 â”‚ 0.812 â”‚ 0.855 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.779 â”‚ 0.726 â”‚ 0.786 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.865 â”‚ 0.812 â”‚ 0.883 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.835 â”‚ 0.855 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1481, ET: 0.1896, TC: 0.1467, WT: 0.1081
[0m
[1;31m2025-05-17 22:41:40,914  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch13_loss0.1519_dice0.8497_20250517223607.pth[0m
[0;32m2025-05-17 22:41:40,964  - INFO - âœ¨ Saved checkpoint (epoch 15) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch15_loss0.1481_dice0.8534_20250517224140.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:41:40,964  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-17 22:43:55,301  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-17 22:43:55,302  - INFO - - Train mean loss: 0.2512
- ET loss: 0.3023
- TC loss: 0.2730
- WT loss: 0.1782
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 22:43:55,302  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-17 22:44:25,379  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:30.0756s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.814 â”‚ 0.854 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.781 â”‚ 0.729 â”‚ 0.786 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.828 â”‚ 0.879 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.859 â”‚ 0.823 â”‚ 0.859 â”‚ 0.894 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1466, ET: 0.1875, TC: 0.1473, WT: 0.1049
[0m
[1;31m2025-05-17 22:44:25,380  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch14_loss0.1507_dice0.8512_20250517223856.pth[0m
[0;32m2025-05-17 22:44:25,423  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.1466_dice0.8550_20250517224425.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:44:25,423  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-17 22:46:37,220  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-17 22:46:37,222  - INFO - - Train mean loss: 0.2422
- ET loss: 0.2923
- TC loss: 0.2573
- WT loss: 0.1770
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 22:46:37,222  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-17 22:47:07,432  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:30.2094s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.848 â”‚ 0.807 â”‚ 0.85  â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.771 â”‚ 0.719 â”‚ 0.779 â”‚ 0.813 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.829 â”‚ 0.787 â”‚ 0.836 â”‚ 0.865 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.859 â”‚ 0.9   â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1543, ET: 0.1956, TC: 0.1518, WT: 0.1155
[0m
[0;33m2025-05-17 22:47:07,432  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 22:47:07,432  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-17 22:49:19,122  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-17 22:49:19,124  - INFO - - Train mean loss: 0.2495
- ET loss: 0.3033
- TC loss: 0.2676
- WT loss: 0.1776
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 22:49:19,124  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-17 22:49:49,202  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:30.0768s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.842 â”‚ 0.803 â”‚ 0.849 â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.761 â”‚ 0.713 â”‚ 0.777 â”‚ 0.794 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.808 â”‚ 0.764 â”‚ 0.827 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.908 â”‚ 0.878 â”‚ 0.903 â”‚ 0.944 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1602, ET: 0.1992, TC: 0.1529, WT: 0.1284
[0m
[0;33m2025-05-17 22:49:49,202  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 22:49:49,202  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-17 22:52:01,438  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-17 22:52:01,439  - INFO - - Train mean loss: 0.2454
- ET loss: 0.2960
- TC loss: 0.2598
- WT loss: 0.1804
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 22:52:01,439  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-17 22:52:31,520  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:30.0803s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.817 â”‚ 0.856 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.78  â”‚ 0.734 â”‚ 0.788 â”‚ 0.818 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.86  â”‚ 0.836 â”‚ 0.871 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.824 â”‚ 0.875 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1466, ET: 0.1845, TC: 0.1451, WT: 0.1102
[0m
[0;33m2025-05-17 22:52:31,521  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 22:52:31,521  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-17 22:54:44,190  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-17 22:54:44,191  - INFO - - Train mean loss: 0.2340
- ET loss: 0.2830
- TC loss: 0.2481
- WT loss: 0.1708
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 22:54:44,191  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-17 22:55:14,764  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:30.5715s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.848 â”‚ 0.804 â”‚ 0.849 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.772 â”‚ 0.714 â”‚ 0.78  â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.834 â”‚ 0.763 â”‚ 0.844 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.878 â”‚ 0.883 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1529, ET: 0.1979, TC: 0.1522, WT: 0.1088
[0m
[0;33m2025-05-17 22:55:14,764  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 22:55:14,764  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-17 22:57:26,740  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-17 22:57:26,742  - INFO - - Train mean loss: 0.2449
- ET loss: 0.2965
- TC loss: 0.2655
- WT loss: 0.1726
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 22:57:26,742  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-17 22:57:56,918  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:30.1746s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.815 â”‚ 0.866 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.786 â”‚ 0.728 â”‚ 0.801 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.845 â”‚ 0.782 â”‚ 0.863 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.878 â”‚ 0.894 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1421, ET: 0.1864, TC: 0.1353, WT: 0.1047
[0m
[1;31m2025-05-17 22:57:56,920  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch15_loss0.1481_dice0.8534_20250517224140.pth[0m
[0;32m2025-05-17 22:57:56,962  - INFO - âœ¨ Saved checkpoint (epoch 21) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.1421_dice0.8593_20250517225756.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 22:57:56,962  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-17 23:00:07,710  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-17 23:00:07,712  - INFO - - Train mean loss: 0.2470
- ET loss: 0.2971
- TC loss: 0.2673
- WT loss: 0.1767
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 23:00:07,712  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-17 23:00:38,141  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:30.4276s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.823 â”‚ 0.867 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.792 â”‚ 0.741 â”‚ 0.803 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.862 â”‚ 0.808 â”‚ 0.871 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.863 â”‚ 0.889 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1383, ET: 0.1780, TC: 0.1338, WT: 0.1030
[0m
[1;31m2025-05-17 23:00:38,143  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.1466_dice0.8550_20250517224425.pth[0m
[0;32m2025-05-17 23:00:38,185  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.1383_dice0.8629_20250517230038.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:00:38,185  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-17 23:02:50,587  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-17 23:02:50,589  - INFO - - Train mean loss: 0.2211
- ET loss: 0.2707
- TC loss: 0.2326
- WT loss: 0.1600
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 23:02:50,589  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-17 23:03:20,984  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:30.3938s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.856 â”‚ 0.821 â”‚ 0.852 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.784 â”‚ 0.74  â”‚ 0.787 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.864 â”‚ 0.809 â”‚ 0.85  â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.858 â”‚ 0.891 â”‚ 0.873 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1454, ET: 0.1801, TC: 0.1486, WT: 0.1074
[0m
[0;33m2025-05-17 23:03:20,984  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 23:03:20,984  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-17 23:05:35,290  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-17 23:05:35,293  - INFO - - Train mean loss: 0.2229
- ET loss: 0.2727
- TC loss: 0.2347
- WT loss: 0.1614
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 23:05:35,293  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-17 23:06:05,282  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:29.9886s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.856 â”‚ 0.82  â”‚ 0.864 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.78  â”‚ 0.736 â”‚ 0.798 â”‚ 0.806 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.841 â”‚ 0.809 â”‚ 0.867 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.857 â”‚ 0.883 â”‚ 0.943 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1458, ET: 0.1814, TC: 0.1375, WT: 0.1186
[0m
[0;33m2025-05-17 23:06:05,283  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 23:06:05,283  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-17 23:08:16,783  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-17 23:08:16,785  - INFO - - Train mean loss: 0.2368
- ET loss: 0.2916
- TC loss: 0.2512
- WT loss: 0.1675
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 23:08:16,785  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-17 23:08:47,260  - INFO - === [Epoch 25/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:30.4741s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.86  â”‚ 0.819 â”‚ 0.864 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.789 â”‚ 0.738 â”‚ 0.803 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.86  â”‚ 0.814 â”‚ 0.865 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.851 â”‚ 0.888 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1420, ET: 0.1822, TC: 0.1371, WT: 0.1066
[0m
[0;33m2025-05-17 23:08:47,260  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-17 23:08:47,260  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-17 23:10:57,166  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-17 23:10:57,167  - INFO - - Train mean loss: 0.2269
- ET loss: 0.2767
- TC loss: 0.2393
- WT loss: 0.1646
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-17 23:10:57,167  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-17 23:11:27,699  - INFO - === [Epoch 26/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:30.5310s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.862 â”‚ 0.829 â”‚ 0.86  â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.748 â”‚ 0.793 â”‚ 0.83  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.861 â”‚ 0.837 â”‚ 0.853 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.844 â”‚ 0.9   â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1392, ET: 0.1732, TC: 0.1414, WT: 0.1031
[0m
[0;33m2025-05-17 23:11:27,699  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-17 23:11:27,699  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-17 23:13:38,667  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-17 23:13:38,669  - INFO - - Train mean loss: 0.2272
- ET loss: 0.2770
- TC loss: 0.2400
- WT loss: 0.1645
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 23:13:38,669  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-17 23:14:09,220  - INFO - === [Epoch 27/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:30.5506s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.823 â”‚ 0.866 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.793 â”‚ 0.742 â”‚ 0.804 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.809 â”‚ 0.869 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.866 â”‚ 0.889 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1378, ET: 0.1781, TC: 0.1350, WT: 0.1004
[0m
[1;31m2025-05-17 23:14:09,222  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch21_loss0.1421_dice0.8593_20250517225756.pth[0m
[0;32m2025-05-17 23:14:09,266  - INFO - âœ¨ Saved checkpoint (epoch 27) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch27_loss0.1378_dice0.8637_20250517231409.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:14:09,266  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-17 23:16:20,577  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-17 23:16:20,578  - INFO - - Train mean loss: 0.2315
- ET loss: 0.2855
- TC loss: 0.2416
- WT loss: 0.1673
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 23:16:20,578  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-17 23:16:50,555  - INFO - === [Epoch 28/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:29.9753s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.83  â”‚ 0.869 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.752 â”‚ 0.808 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.873 â”‚ 0.842 â”‚ 0.881 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.843 â”‚ 0.882 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1347, ET: 0.1712, TC: 0.1317, WT: 0.1011
[0m
[1;31m2025-05-17 23:16:50,557  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.1383_dice0.8629_20250517230038.pth[0m
[0;32m2025-05-17 23:16:50,606  - INFO - âœ¨ Saved checkpoint (epoch 28) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch28_loss0.1347_dice0.8669_20250517231650.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:16:50,607  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-17 23:19:02,167  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-17 23:19:02,169  - INFO - - Train mean loss: 0.2232
- ET loss: 0.2721
- TC loss: 0.2365
- WT loss: 0.1611
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 23:19:02,169  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-17 23:19:32,536  - INFO - === [Epoch 29/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:30.3661s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.827 â”‚ 0.868 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.796 â”‚ 0.748 â”‚ 0.806 â”‚ 0.835 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.843 â”‚ 0.894 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.871 â”‚ 0.835 â”‚ 0.863 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1356, ET: 0.1742, TC: 0.1330, WT: 0.0996
[0m
[0;33m2025-05-17 23:19:32,536  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 23:19:32,536  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-17 23:21:45,700  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-17 23:21:45,701  - INFO - - Train mean loss: 0.2110
- ET loss: 0.2611
- TC loss: 0.2206
- WT loss: 0.1514
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 23:21:45,701  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-17 23:22:16,085  - INFO - === [Epoch 30/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:30.3825s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.828 â”‚ 0.866 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.749 â”‚ 0.804 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.857 â”‚ 0.9   â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.86  â”‚ 0.824 â”‚ 0.856 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1342, ET: 0.1737, TC: 0.1352, WT: 0.0937
[0m
[1;31m2025-05-17 23:22:16,087  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch27_loss0.1378_dice0.8637_20250517231409.pth[0m
[0;32m2025-05-17 23:22:16,128  - INFO - âœ¨ Saved checkpoint (epoch 30) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch30_loss0.1342_dice0.8669_20250517232216.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:22:16,129  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-17 23:24:27,881  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-17 23:24:27,883  - INFO - - Train mean loss: 0.2258
- ET loss: 0.2770
- TC loss: 0.2373
- WT loss: 0.1630
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-17 23:24:27,883  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-17 23:24:58,050  - INFO - === [Epoch 31/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:30.1664s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.828 â”‚ 0.87  â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.747 â”‚ 0.809 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.814 â”‚ 0.883 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.865 â”‚ 0.883 â”‚ 0.891 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1336, ET: 0.1735, TC: 0.1310, WT: 0.0962
[0m
[1;31m2025-05-17 23:24:58,053  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch28_loss0.1347_dice0.8669_20250517231650.pth[0m
[0;32m2025-05-17 23:24:58,095  - INFO - âœ¨ Saved checkpoint (epoch 31) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch31_loss0.1336_dice0.8675_20250517232458.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:24:58,095  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-17 23:27:09,206  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-17 23:27:09,207  - INFO - - Train mean loss: 0.2200
- ET loss: 0.2710
- TC loss: 0.2308
- WT loss: 0.1581
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 23:27:09,207  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-17 23:27:39,367  - INFO - === [Epoch 32/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:30.1584s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.827 â”‚ 0.863 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.795 â”‚ 0.747 â”‚ 0.797 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.856 â”‚ 0.89  â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.82  â”‚ 0.862 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1363, ET: 0.1744, TC: 0.1380, WT: 0.0964
[0m
[0;33m2025-05-17 23:27:39,367  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 23:27:39,367  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-17 23:29:55,083  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-17 23:29:55,084  - INFO - - Train mean loss: 0.2339
- ET loss: 0.2849
- TC loss: 0.2453
- WT loss: 0.1715
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 23:29:55,084  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-17 23:30:25,422  - INFO - === [Epoch 33/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:30.3370s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.831 â”‚ 0.872 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.751 â”‚ 0.81  â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.833 â”‚ 0.897 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.854 â”‚ 0.869 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1316, ET: 0.1704, TC: 0.1289, WT: 0.0956
[0m
[1;31m2025-05-17 23:30:25,424  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch30_loss0.1342_dice0.8669_20250517232216.pth[0m
[0;32m2025-05-17 23:30:25,467  - INFO - âœ¨ Saved checkpoint (epoch 33) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch33_loss0.1316_dice0.8695_20250517233025.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:30:25,468  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-17 23:32:40,049  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-17 23:32:40,051  - INFO - - Train mean loss: 0.2286
- ET loss: 0.2833
- TC loss: 0.2423
- WT loss: 0.1601
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-17 23:32:40,051  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-17 23:33:10,149  - INFO - === [Epoch 34/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:30.0976s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.83  â”‚ 0.867 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.752 â”‚ 0.806 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.853 â”‚ 0.895 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.856 â”‚ 0.829 â”‚ 0.86  â”‚ 0.88  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1357, ET: 0.1710, TC: 0.1341, WT: 0.1021
[0m
[0;33m2025-05-17 23:33:10,150  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 23:33:10,150  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-17 23:35:25,717  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-17 23:35:25,720  - INFO - - Train mean loss: 0.2193
- ET loss: 0.2709
- TC loss: 0.2282
- WT loss: 0.1587
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 23:35:25,720  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-17 23:35:55,832  - INFO - === [Epoch 35/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:30.1115s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.826 â”‚ 0.862 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.748 â”‚ 0.799 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.859 â”‚ 0.894 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.863 â”‚ 0.821 â”‚ 0.859 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1353, ET: 0.1751, TC: 0.1388, WT: 0.0921
[0m
[0;33m2025-05-17 23:35:55,833  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 23:35:55,833  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-17 23:38:06,563  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-17 23:38:06,566  - INFO - - Train mean loss: 0.2259
- ET loss: 0.2775
- TC loss: 0.2386
- WT loss: 0.1615
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 23:38:06,566  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-17 23:38:36,638  - INFO - === [Epoch 36/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:30.0711s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.831 â”‚ 0.872 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.754 â”‚ 0.813 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.85  â”‚ 0.894 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.835 â”‚ 0.872 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1308, ET: 0.1698, TC: 0.1289, WT: 0.0938
[0m
[1;31m2025-05-17 23:38:36,640  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch31_loss0.1336_dice0.8675_20250517232458.pth[0m
[0;32m2025-05-17 23:38:36,682  - INFO - âœ¨ Saved checkpoint (epoch 36) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch36_loss0.1308_dice0.8702_20250517233836.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:38:36,682  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-17 23:40:47,517  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-17 23:40:47,519  - INFO - - Train mean loss: 0.2194
- ET loss: 0.2726
- TC loss: 0.2295
- WT loss: 0.1560
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 23:40:47,519  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-17 23:41:17,661  - INFO - === [Epoch 37/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:30.1408s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.827 â”‚ 0.865 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.748 â”‚ 0.802 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.868 â”‚ 0.911 â”‚ 0.879 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.865 â”‚ 0.812 â”‚ 0.843 â”‚ 0.94  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1366, ET: 0.1738, TC: 0.1359, WT: 0.1002
[0m
[0;33m2025-05-17 23:41:17,661  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 23:41:17,661  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-17 23:43:34,144  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-17 23:43:34,145  - INFO - - Train mean loss: 0.2069
- ET loss: 0.2588
- TC loss: 0.2171
- WT loss: 0.1448
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-17 23:43:34,146  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-17 23:44:04,569  - INFO - === [Epoch 38/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:30.4225s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.835 â”‚ 0.873 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.758 â”‚ 0.814 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.854 â”‚ 0.898 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.842 â”‚ 0.872 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1285, ET: 0.1667, TC: 0.1280, WT: 0.0910
[0m
[1;31m2025-05-17 23:44:04,571  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch33_loss0.1316_dice0.8695_20250517233025.pth[0m
[0;32m2025-05-17 23:44:04,612  - INFO - âœ¨ Saved checkpoint (epoch 38) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch38_loss0.1285_dice0.8725_20250517234404.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:44:04,613  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-17 23:46:17,796  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-17 23:46:17,797  - INFO - - Train mean loss: 0.2276
- ET loss: 0.2785
- TC loss: 0.2409
- WT loss: 0.1634
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-17 23:46:17,798  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-17 23:46:47,929  - INFO - === [Epoch 39/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:30.1301s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.867 â”‚ 0.831 â”‚ 0.861 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.798 â”‚ 0.752 â”‚ 0.797 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.825 â”‚ 0.847 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.863 â”‚ 0.912 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1340, ET: 0.1703, TC: 0.1395, WT: 0.0923
[0m
[0;33m2025-05-17 23:46:47,929  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-17 23:46:47,929  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-17 23:48:59,333  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-17 23:48:59,335  - INFO - - Train mean loss: 0.2107
- ET loss: 0.2616
- TC loss: 0.2190
- WT loss: 0.1514
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-17 23:48:59,335  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-17 23:49:31,383  - INFO - === [Epoch 40/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:32.0477s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.835 â”‚ 0.873 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.758 â”‚ 0.815 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.863 â”‚ 0.83  â”‚ 0.876 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.864 â”‚ 0.898 â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1307, ET: 0.1661, TC: 0.1273, WT: 0.0986
[0m
[0;33m2025-05-17 23:49:31,383  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-17 23:49:31,384  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-17 23:51:42,457  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-17 23:51:42,458  - INFO - - Train mean loss: 0.2198
- ET loss: 0.2698
- TC loss: 0.2313
- WT loss: 0.1584
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-17 23:51:42,458  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-17 23:52:14,263  - INFO - === [Epoch 41/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:31.8038s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.833 â”‚ 0.875 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.753 â”‚ 0.815 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.812 â”‚ 0.878 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.877 â”‚ 0.893 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1282, ET: 0.1687, TC: 0.1255, WT: 0.0905
[0m
[1;31m2025-05-17 23:52:14,264  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch36_loss0.1308_dice0.8702_20250517233836.pth[0m
[0;32m2025-05-17 23:52:14,306  - INFO - âœ¨ Saved checkpoint (epoch 41) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch41_loss0.1282_dice0.8728_20250517235214.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:52:14,307  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-17 23:54:27,075  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-17 23:54:27,076  - INFO - - Train mean loss: 0.2115
- ET loss: 0.2617
- TC loss: 0.2204
- WT loss: 0.1522
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-17 23:54:27,076  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-17 23:54:58,885  - INFO - === [Epoch 42/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:31.8081s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.836 â”‚ 0.877 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.759 â”‚ 0.817 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.841 â”‚ 0.886 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.854 â”‚ 0.894 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1273, ET: 0.1654, TC: 0.1237, WT: 0.0929
[0m
[1;31m2025-05-17 23:54:58,887  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch38_loss0.1285_dice0.8725_20250517234404.pth[0m
[0;32m2025-05-17 23:54:58,928  - INFO - âœ¨ Saved checkpoint (epoch 42) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch42_loss0.1273_dice0.8737_20250517235458.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:54:58,929  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-17 23:57:14,495  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-17 23:57:14,496  - INFO - - Train mean loss: 0.2084
- ET loss: 0.2543
- TC loss: 0.2129
- WT loss: 0.1582
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-17 23:57:14,496  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-17 23:57:46,555  - INFO - === [Epoch 43/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:32.0580s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.836 â”‚ 0.876 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.76  â”‚ 0.818 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.853 â”‚ 0.901 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.842 â”‚ 0.874 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1648, TC: 0.1247, WT: 0.0904
[0m
[1;31m2025-05-17 23:57:46,557  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch41_loss0.1282_dice0.8728_20250517235214.pth[0m
[0;32m2025-05-17 23:57:46,598  - INFO - âœ¨ Saved checkpoint (epoch 43) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch43_loss0.1266_dice0.8744_20250517235746.pth;             Size 12.40 MB[0m
[0;32m2025-05-17 23:57:46,599  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-18 00:00:01,760  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-18 00:00:01,761  - INFO - - Train mean loss: 0.2066
- ET loss: 0.2562
- TC loss: 0.2152
- WT loss: 0.1483
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 00:00:01,761  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-18 00:00:33,600  - INFO - === [Epoch 44/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:31.8380s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.836 â”‚ 0.875 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.759 â”‚ 0.816 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.852 â”‚ 0.897 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.843 â”‚ 0.872 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1260, ET: 0.1651, TC: 0.1255, WT: 0.0873
[0m
[1;31m2025-05-18 00:00:33,602  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch42_loss0.1273_dice0.8737_20250517235458.pth[0m
[0;32m2025-05-18 00:00:33,644  - INFO - âœ¨ Saved checkpoint (epoch 44) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch44_loss0.1260_dice0.8750_20250518000033.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:00:33,645  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-18 00:02:48,688  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-18 00:02:48,691  - INFO - - Train mean loss: 0.1955
- ET loss: 0.2462
- TC loss: 0.2068
- WT loss: 0.1336
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 00:02:48,691  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-18 00:03:20,228  - INFO - === [Epoch 45/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:31.5365s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.876 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.76  â”‚ 0.817 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.853 â”‚ 0.895 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.844 â”‚ 0.877 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1259, ET: 0.1641, TC: 0.1246, WT: 0.0890
[0m
[1;31m2025-05-18 00:03:20,230  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch43_loss0.1266_dice0.8744_20250517235746.pth[0m
[0;32m2025-05-18 00:03:20,273  - INFO - âœ¨ Saved checkpoint (epoch 45) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch45_loss0.1259_dice0.8752_20250518000320.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:03:20,273  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-18 00:05:37,401  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-18 00:05:37,403  - INFO - - Train mean loss: 0.2032
- ET loss: 0.2559
- TC loss: 0.2122
- WT loss: 0.1414
- Cost time: 2.29mins â±ï¸
[0m
[0;32m2025-05-18 00:05:37,403  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-18 00:06:09,388  - INFO - === [Epoch 46/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:31.9840s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.837 â”‚ 0.873 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.814 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.862 â”‚ 0.909 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.837 â”‚ 0.862 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1279, ET: 0.1641, TC: 0.1274, WT: 0.0921
[0m
[0;33m2025-05-18 00:06:09,389  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 00:06:09,389  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-18 00:08:25,322  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-18 00:08:25,323  - INFO - - Train mean loss: 0.2135
- ET loss: 0.2648
- TC loss: 0.2260
- WT loss: 0.1498
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-18 00:08:25,323  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-18 00:08:57,268  - INFO - === [Epoch 47/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:31.9433s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.838 â”‚ 0.876 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.763 â”‚ 0.82  â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.839 â”‚ 0.886 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.861 â”‚ 0.89  â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1254, ET: 0.1634, TC: 0.1246, WT: 0.0881
[0m
[1;31m2025-05-18 00:08:57,269  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch44_loss0.1260_dice0.8750_20250518000033.pth[0m
[0;32m2025-05-18 00:08:57,315  - INFO - âœ¨ Saved checkpoint (epoch 47) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch47_loss0.1254_dice0.8756_20250518000857.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:08:57,315  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-18 00:11:13,586  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-18 00:11:13,587  - INFO - - Train mean loss: 0.2151
- ET loss: 0.2708
- TC loss: 0.2289
- WT loss: 0.1456
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-18 00:11:13,587  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-18 00:11:45,322  - INFO - === [Epoch 48/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:31.7339s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.837 â”‚ 0.871 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.811 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.846 â”‚ 0.876 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.852 â”‚ 0.896 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1282, ET: 0.1644, TC: 0.1301, WT: 0.0902
[0m
[0;33m2025-05-18 00:11:45,323  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 00:11:45,323  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-18 00:14:03,896  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-18 00:14:03,898  - INFO - - Train mean loss: 0.2103
- ET loss: 0.2640
- TC loss: 0.2159
- WT loss: 0.1510
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 00:14:03,898  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-18 00:14:35,447  - INFO - === [Epoch 49/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:31.5480s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.837 â”‚ 0.876 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.762 â”‚ 0.819 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.844 â”‚ 0.888 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.853 â”‚ 0.885 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1253, ET: 0.1642, TC: 0.1249, WT: 0.0868
[0m
[1;31m2025-05-18 00:14:35,449  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch45_loss0.1259_dice0.8752_20250518000320.pth[0m
[0;32m2025-05-18 00:14:35,491  - INFO - âœ¨ Saved checkpoint (epoch 49) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch49_loss0.1253_dice0.8757_20250518001435.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:14:35,492  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-18 00:16:48,583  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-18 00:16:48,585  - INFO - - Train mean loss: 0.2017
- ET loss: 0.2553
- TC loss: 0.2135
- WT loss: 0.1364
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-18 00:16:48,585  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-18 00:17:20,195  - INFO - === [Epoch 50/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:31.6092s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.836 â”‚ 0.878 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.76  â”‚ 0.821 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.874 â”‚ 0.822 â”‚ 0.873 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.874 â”‚ 0.907 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1249, ET: 0.1649, TC: 0.1225, WT: 0.0873
[0m
[1;31m2025-05-18 00:17:20,197  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch47_loss0.1254_dice0.8756_20250518000857.pth[0m
[0;32m2025-05-18 00:17:20,240  - INFO - âœ¨ Saved checkpoint (epoch 50) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch50_loss0.1249_dice0.8761_20250518001720.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:17:20,240  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-18 00:19:32,332  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-18 00:19:32,333  - INFO - - Train mean loss: 0.2069
- ET loss: 0.2602
- TC loss: 0.2142
- WT loss: 0.1461
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-18 00:19:32,333  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-18 00:20:04,334  - INFO - === [Epoch 51/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:31.9993s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.839 â”‚ 0.877 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.763 â”‚ 0.819 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.86  â”‚ 0.903 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.839 â”‚ 0.874 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1244, ET: 0.1621, TC: 0.1234, WT: 0.0876
[0m
[1;31m2025-05-18 00:20:04,336  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch49_loss0.1253_dice0.8757_20250518001435.pth[0m
[0;32m2025-05-18 00:20:04,381  - INFO - âœ¨ Saved checkpoint (epoch 51) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch51_loss0.1244_dice0.8765_20250518002004.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:20:04,381  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-18 00:22:16,809  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-18 00:22:16,811  - INFO - - Train mean loss: 0.2047
- ET loss: 0.2578
- TC loss: 0.2150
- WT loss: 0.1412
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-18 00:22:16,811  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-18 00:22:48,534  - INFO - === [Epoch 52/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:31.7225s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.839 â”‚ 0.878 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.764 â”‚ 0.821 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.851 â”‚ 0.892 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.85  â”‚ 0.886 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1245, ET: 0.1620, TC: 0.1229, WT: 0.0885
[0m
[0;33m2025-05-18 00:22:48,534  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 00:22:48,535  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-18 00:25:01,484  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-18 00:25:01,485  - INFO - - Train mean loss: 0.2002
- ET loss: 0.2485
- TC loss: 0.2095
- WT loss: 0.1426
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-18 00:25:01,485  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-18 00:25:33,505  - INFO - === [Epoch 53/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:32.0189s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.874 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.762 â”‚ 0.817 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.903 â”‚ 0.865 â”‚ 0.902 â”‚ 0.942 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.834 â”‚ 0.869 â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1262, ET: 0.1645, TC: 0.1262, WT: 0.0877
[0m
[0;33m2025-05-18 00:25:33,505  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 00:25:33,505  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-18 00:27:46,760  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-18 00:27:46,761  - INFO - - Train mean loss: 0.1928
- ET loss: 0.2422
- TC loss: 0.2003
- WT loss: 0.1359
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-18 00:27:46,761  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-18 00:28:19,112  - INFO - === [Epoch 54/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:32.3500s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.835 â”‚ 0.874 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.758 â”‚ 0.816 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.855 â”‚ 0.817 â”‚ 0.863 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.91  â”‚ 0.877 â”‚ 0.913 â”‚ 0.939 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1295, ET: 0.1663, TC: 0.1265, WT: 0.0957
[0m
[0;33m2025-05-18 00:28:19,112  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 00:28:19,112  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-18 00:30:32,780  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-18 00:30:32,782  - INFO - - Train mean loss: 0.2084
- ET loss: 0.2593
- TC loss: 0.2212
- WT loss: 0.1447
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-18 00:30:32,782  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-18 00:31:04,661  - INFO - === [Epoch 55/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:31.8782s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.841 â”‚ 0.879 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.766 â”‚ 0.822 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.842 â”‚ 0.888 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.859 â”‚ 0.89  â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1230, ET: 0.1598, TC: 0.1212, WT: 0.0881
[0m
[1;31m2025-05-18 00:31:04,663  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch50_loss0.1249_dice0.8761_20250518001720.pth[0m
[0;32m2025-05-18 00:31:04,705  - INFO - âœ¨ Saved checkpoint (epoch 55) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch55_loss0.1230_dice0.8779_20250518003104.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:31:04,705  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-18 00:33:19,648  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-18 00:33:19,650  - INFO - - Train mean loss: 0.2026
- ET loss: 0.2545
- TC loss: 0.2123
- WT loss: 0.1410
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 00:33:19,650  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-18 00:33:51,459  - INFO - === [Epoch 56/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:31.8079s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.875 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.764 â”‚ 0.816 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.83  â”‚ 0.863 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.867 â”‚ 0.913 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1259, ET: 0.1616, TC: 0.1262, WT: 0.0898
[0m
[0;33m2025-05-18 00:33:51,459  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 00:33:51,459  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-18 00:36:07,242  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-18 00:36:07,243  - INFO - - Train mean loss: 0.1978
- ET loss: 0.2498
- TC loss: 0.2076
- WT loss: 0.1359
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-18 00:36:07,243  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-18 00:36:38,885  - INFO - === [Epoch 57/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:31.6408s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.88  â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.768 â”‚ 0.823 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.847 â”‚ 0.883 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.855 â”‚ 0.9   â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1219, ET: 0.1590, TC: 0.1203, WT: 0.0864
[0m
[1;31m2025-05-18 00:36:38,887  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch51_loss0.1244_dice0.8765_20250518002004.pth[0m
[0;32m2025-05-18 00:36:38,928  - INFO - âœ¨ Saved checkpoint (epoch 57) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch57_loss0.1219_dice0.8791_20250518003638.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:36:38,929  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-18 00:38:53,559  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-18 00:38:53,560  - INFO - - Train mean loss: 0.2084
- ET loss: 0.2641
- TC loss: 0.2205
- WT loss: 0.1406
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-18 00:38:53,560  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-18 00:39:25,019  - INFO - === [Epoch 58/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:31.4576s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.879 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.768 â”‚ 0.824 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.845 â”‚ 0.883 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.858 â”‚ 0.897 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1222, ET: 0.1590, TC: 0.1214, WT: 0.0861
[0m
[0;33m2025-05-18 00:39:25,019  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 00:39:25,019  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-18 00:41:36,475  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-18 00:41:36,477  - INFO - - Train mean loss: 0.1993
- ET loss: 0.2487
- TC loss: 0.2054
- WT loss: 0.1437
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-18 00:41:36,478  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-18 00:42:07,950  - INFO - === [Epoch 59/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:31.4716s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.841 â”‚ 0.876 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.812 â”‚ 0.766 â”‚ 0.82  â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.873 â”‚ 0.841 â”‚ 0.881 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.861 â”‚ 0.897 â”‚ 0.937 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1249, ET: 0.1605, TC: 0.1242, WT: 0.0900
[0m
[0;33m2025-05-18 00:42:07,951  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 00:42:07,951  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-18 00:44:18,617  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-18 00:44:18,618  - INFO - - Train mean loss: 0.2085
- ET loss: 0.2578
- TC loss: 0.2182
- WT loss: 0.1496
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-18 00:44:18,618  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-18 00:44:50,124  - INFO - === [Epoch 60/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:31.5042s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.843 â”‚ 0.878 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.769 â”‚ 0.823 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.849 â”‚ 0.898 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.856 â”‚ 0.879 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1218, ET: 0.1583, TC: 0.1222, WT: 0.0848
[0m
[1;31m2025-05-18 00:44:50,126  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch55_loss0.1230_dice0.8779_20250518003104.pth[0m
[0;32m2025-05-18 00:44:50,174  - INFO - âœ¨ Saved checkpoint (epoch 60) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch60_loss0.1218_dice0.8791_20250518004450.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:44:50,174  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-18 00:47:01,376  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-18 00:47:01,377  - INFO - - Train mean loss: 0.1977
- ET loss: 0.2509
- TC loss: 0.2067
- WT loss: 0.1356
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-18 00:47:01,377  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-18 00:47:32,906  - INFO - === [Epoch 61/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:31.5281s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.845 â”‚ 0.881 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.771 â”‚ 0.826 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.847 â”‚ 0.897 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.861 â”‚ 0.886 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1198, ET: 0.1565, TC: 0.1193, WT: 0.0836
[0m
[1;31m2025-05-18 00:47:32,908  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch57_loss0.1219_dice0.8791_20250518003638.pth[0m
[0;32m2025-05-18 00:47:32,954  - INFO - âœ¨ Saved checkpoint (epoch 61) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch61_loss0.1198_dice0.8811_20250518004732.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 00:47:32,954  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-18 00:49:41,747  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-18 00:49:41,748  - INFO - - Train mean loss: 0.1961
- ET loss: 0.2461
- TC loss: 0.2025
- WT loss: 0.1399
- Cost time: 2.15mins â±ï¸
[0m
[0;32m2025-05-18 00:49:41,748  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-18 00:50:13,396  - INFO - === [Epoch 62/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:31.6474s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.838 â”‚ 0.878 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.76  â”‚ 0.82  â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.819 â”‚ 0.877 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.881 â”‚ 0.904 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1238, ET: 0.1633, TC: 0.1222, WT: 0.0860
[0m
[0;33m2025-05-18 00:50:13,397  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 00:50:13,397  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-18 00:52:24,314  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-18 00:52:24,316  - INFO - - Train mean loss: 0.1951
- ET loss: 0.2474
- TC loss: 0.2035
- WT loss: 0.1343
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-18 00:52:24,316  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-18 00:52:56,219  - INFO - === [Epoch 63/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:31.9024s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.844 â”‚ 0.881 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.769 â”‚ 0.824 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.845 â”‚ 0.887 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.863 â”‚ 0.897 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1206, ET: 0.1568, TC: 0.1197, WT: 0.0852
[0m
[0;33m2025-05-18 00:52:56,219  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 00:52:56,219  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-18 00:55:07,766  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-18 00:55:07,767  - INFO - - Train mean loss: 0.1939
- ET loss: 0.2442
- TC loss: 0.1992
- WT loss: 0.1382
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-18 00:55:07,767  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-18 00:55:39,608  - INFO - === [Epoch 64/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:31.8407s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.883 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.768 â”‚ 0.828 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.842 â”‚ 0.896 â”‚ 0.941 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.863 â”‚ 0.89  â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1204, ET: 0.1585, TC: 0.1180, WT: 0.0847
[0m
[0;33m2025-05-18 00:55:39,609  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 00:55:39,609  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-18 00:57:53,914  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-18 00:57:53,915  - INFO - - Train mean loss: 0.2000
- ET loss: 0.2550
- TC loss: 0.2101
- WT loss: 0.1348
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-18 00:57:53,915  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-18 00:58:25,245  - INFO - === [Epoch 65/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:31.3290s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.842 â”‚ 0.877 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.769 â”‚ 0.821 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.903 â”‚ 0.864 â”‚ 0.912 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.841 â”‚ 0.867 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1224, ET: 0.1589, TC: 0.1234, WT: 0.0848
[0m
[0;33m2025-05-18 00:58:25,245  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 00:58:25,245  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-18 01:00:36,168  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-18 01:00:36,170  - INFO - - Train mean loss: 0.2114
- ET loss: 0.2668
- TC loss: 0.2200
- WT loss: 0.1472
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-18 01:00:36,170  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-18 01:01:07,962  - INFO - === [Epoch 66/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:31.7913s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.879 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.823 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.903 â”‚ 0.866 â”‚ 0.907 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.841 â”‚ 0.874 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1214, ET: 0.1588, TC: 0.1213, WT: 0.0841
[0m
[0;33m2025-05-18 01:01:07,962  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 01:01:07,962  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-18 01:03:17,579  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-18 01:03:17,580  - INFO - - Train mean loss: 0.1903
- ET loss: 0.2431
- TC loss: 0.1964
- WT loss: 0.1314
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-18 01:03:17,581  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-18 01:03:49,291  - INFO - === [Epoch 67/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:31.7093s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.883 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.767 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.827 â”‚ 0.883 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.877 â”‚ 0.903 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1201, ET: 0.1584, TC: 0.1175, WT: 0.0842
[0m
[0;33m2025-05-18 01:03:49,291  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 01:03:49,291  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-18 01:06:00,579  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-18 01:06:00,580  - INFO - - Train mean loss: 0.2015
- ET loss: 0.2561
- TC loss: 0.2095
- WT loss: 0.1389
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-18 01:06:00,580  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-18 01:06:32,379  - INFO - === [Epoch 68/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:31.7983s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.883 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.828 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.834 â”‚ 0.885 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.871 â”‚ 0.9   â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1203, ET: 0.1576, TC: 0.1175, WT: 0.0858
[0m
[0;33m2025-05-18 01:06:32,380  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 01:06:32,380  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-18 01:08:44,506  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-18 01:08:44,507  - INFO - - Train mean loss: 0.2030
- ET loss: 0.2566
- TC loss: 0.2125
- WT loss: 0.1398
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-18 01:08:44,507  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-18 01:09:16,017  - INFO - === [Epoch 69/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:31.5091s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.845 â”‚ 0.882 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.771 â”‚ 0.827 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.85  â”‚ 0.899 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.859 â”‚ 0.887 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1195, ET: 0.1564, TC: 0.1184, WT: 0.0837
[0m
[1;31m2025-05-18 01:09:16,019  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch60_loss0.1218_dice0.8791_20250518004450.pth[0m
[0;32m2025-05-18 01:09:16,061  - INFO - âœ¨ Saved checkpoint (epoch 69) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch69_loss0.1195_dice0.8814_20250518010916.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 01:09:16,061  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-18 01:11:32,311  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-18 01:11:32,312  - INFO - - Train mean loss: 0.1954
- ET loss: 0.2470
- TC loss: 0.2025
- WT loss: 0.1367
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-18 01:11:32,312  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-18 01:12:03,784  - INFO - === [Epoch 70/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:31.4709s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.843 â”‚ 0.881 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.769 â”‚ 0.826 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.853 â”‚ 0.901 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.853 â”‚ 0.884 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1200, ET: 0.1584, TC: 0.1193, WT: 0.0824
[0m
[0;33m2025-05-18 01:12:03,784  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 01:12:03,784  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-18 01:14:20,140  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-18 01:14:20,141  - INFO - - Train mean loss: 0.2015
- ET loss: 0.2567
- TC loss: 0.2095
- WT loss: 0.1383
- Cost time: 2.27mins â±ï¸
[0m
[0;32m2025-05-18 01:14:20,141  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-18 01:14:51,402  - INFO - === [Epoch 71/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:31.2597s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.842 â”‚ 0.878 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.823 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.861 â”‚ 0.908 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.843 â”‚ 0.874 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1216, ET: 0.1594, TC: 0.1220, WT: 0.0835
[0m
[0;33m2025-05-18 01:14:51,402  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 01:14:51,402  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-18 01:17:10,414  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-18 01:17:10,415  - INFO - - Train mean loss: 0.1924
- ET loss: 0.2440
- TC loss: 0.1977
- WT loss: 0.1356
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 01:17:10,416  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-18 01:17:41,647  - INFO - === [Epoch 72/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:31.2307s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.879 â”‚ 0.843 â”‚ 0.88  â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.769 â”‚ 0.826 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.844 â”‚ 0.891 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.861 â”‚ 0.892 â”‚ 0.934 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1217, ET: 0.1585, TC: 0.1204, WT: 0.0864
[0m
[0;33m2025-05-18 01:17:41,647  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 01:17:41,647  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-18 01:19:52,440  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-18 01:19:52,441  - INFO - - Train mean loss: 0.1982
- ET loss: 0.2524
- TC loss: 0.2072
- WT loss: 0.1350
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-18 01:19:52,441  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-18 01:20:22,970  - INFO - === [Epoch 73/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:30.5277s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.886 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.831 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.841 â”‚ 0.895 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.871 â”‚ 0.897 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1541, TC: 0.1145, WT: 0.0831
[0m
[1;31m2025-05-18 01:20:22,972  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch61_loss0.1198_dice0.8811_20250518004732.pth[0m
[0;32m2025-05-18 01:20:23,014  - INFO - âœ¨ Saved checkpoint (epoch 73) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch73_loss0.1172_dice0.8836_20250518012022.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 01:20:23,014  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-18 01:22:34,724  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-18 01:22:34,726  - INFO - - Train mean loss: 0.1952
- ET loss: 0.2514
- TC loss: 0.2047
- WT loss: 0.1296
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-18 01:22:34,727  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-18 01:23:04,647  - INFO - === [Epoch 74/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:29.9189s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.881 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.77  â”‚ 0.825 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.9   â”‚ 0.863 â”‚ 0.913 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.846 â”‚ 0.873 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1193, ET: 0.1571, TC: 0.1194, WT: 0.0814
[0m
[0;33m2025-05-18 01:23:04,647  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 01:23:04,647  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-18 01:25:17,781  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-18 01:25:17,783  - INFO - - Train mean loss: 0.1931
- ET loss: 0.2429
- TC loss: 0.1991
- WT loss: 0.1374
- Cost time: 2.22mins â±ï¸
[0m
[0;32m2025-05-18 01:25:17,783  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-18 01:25:48,123  - INFO - === [Epoch 75/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:30.3381s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.829 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.857 â”‚ 0.908 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.854 â”‚ 0.884 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1175, ET: 0.1549, TC: 0.1165, WT: 0.0812
[0m
[0;33m2025-05-18 01:25:48,123  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 01:25:48,123  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-18 01:28:02,196  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-18 01:28:02,197  - INFO - - Train mean loss: 0.2050
- ET loss: 0.2608
- TC loss: 0.2165
- WT loss: 0.1377
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-18 01:28:02,197  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-18 01:28:32,318  - INFO - === [Epoch 76/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:30.1194s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.883 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.771 â”‚ 0.828 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.848 â”‚ 0.902 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.862 â”‚ 0.886 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1184, ET: 0.1556, TC: 0.1173, WT: 0.0822
[0m
[0;33m2025-05-18 01:28:32,318  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 01:28:32,318  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-18 01:30:44,473  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-18 01:30:44,474  - INFO - - Train mean loss: 0.1946
- ET loss: 0.2457
- TC loss: 0.2046
- WT loss: 0.1334
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-18 01:30:44,474  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-18 01:31:14,344  - INFO - === [Epoch 77/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:29.8685s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.77  â”‚ 0.829 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.843 â”‚ 0.899 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.866 â”‚ 0.891 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1185, ET: 0.1564, TC: 0.1161, WT: 0.0829
[0m
[0;33m2025-05-18 01:31:14,344  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 01:31:14,344  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-18 01:33:28,171  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-18 01:33:28,172  - INFO - - Train mean loss: 0.1888
- ET loss: 0.2431
- TC loss: 0.1969
- WT loss: 0.1264
- Cost time: 2.23mins â±ï¸
[0m
[0;32m2025-05-18 01:33:28,172  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-18 01:33:58,765  - INFO - === [Epoch 78/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:30.5913s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.883 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.771 â”‚ 0.828 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.849 â”‚ 0.897 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.861 â”‚ 0.89  â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1186, ET: 0.1565, TC: 0.1179, WT: 0.0813
[0m
[0;33m2025-05-18 01:33:58,765  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 01:33:58,765  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-18 01:36:13,867  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-18 01:36:13,868  - INFO - - Train mean loss: 0.1939
- ET loss: 0.2462
- TC loss: 0.2002
- WT loss: 0.1353
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 01:36:13,868  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-18 01:36:43,826  - INFO - === [Epoch 79/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:29.9562s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.845 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.772 â”‚ 0.829 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.847 â”‚ 0.899 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.866 â”‚ 0.891 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1178, ET: 0.1555, TC: 0.1166, WT: 0.0813
[0m
[0;33m2025-05-18 01:36:43,826  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 01:36:43,826  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-18 01:38:58,842  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-18 01:38:58,843  - INFO - - Train mean loss: 0.2026
- ET loss: 0.2539
- TC loss: 0.2100
- WT loss: 0.1440
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 01:38:58,843  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-18 01:39:29,301  - INFO - === [Epoch 80/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:30.4569s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.884 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.829 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.843 â”‚ 0.895 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.865 â”‚ 0.894 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1181, ET: 0.1555, TC: 0.1167, WT: 0.0822
[0m
[0;33m2025-05-18 01:39:29,301  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 01:39:29,302  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-18 01:41:39,394  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-18 01:41:39,395  - INFO - - Train mean loss: 0.1908
- ET loss: 0.2428
- TC loss: 0.1981
- WT loss: 0.1314
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-18 01:41:39,395  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-18 01:42:09,883  - INFO - === [Epoch 81/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:30.4862s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.884 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.772 â”‚ 0.829 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.848 â”‚ 0.892 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.862 â”‚ 0.897 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1183, ET: 0.1557, TC: 0.1168, WT: 0.0825
[0m
[0;33m2025-05-18 01:42:09,883  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-18 01:42:09,883  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-18 01:44:15,324  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-18 01:44:15,325  - INFO - - Train mean loss: 0.1874
- ET loss: 0.2373
- TC loss: 0.1909
- WT loss: 0.1341
- Cost time: 2.09mins â±ï¸
[0m
[0;32m2025-05-18 01:44:15,325  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-18 01:44:45,309  - INFO - === [Epoch 82/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:29.9826s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.845 â”‚ 0.885 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.771 â”‚ 0.83  â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.838 â”‚ 0.892 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.871 â”‚ 0.899 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1176, ET: 0.1559, TC: 0.1158, WT: 0.0813
[0m
[0;33m2025-05-18 01:44:45,309  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-18 01:44:45,309  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-18 01:46:49,854  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-18 01:46:49,856  - INFO - - Train mean loss: 0.2146
- ET loss: 0.2687
- TC loss: 0.2240
- WT loss: 0.1510
- Cost time: 2.08mins â±ï¸
[0m
[0;32m2025-05-18 01:46:49,856  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-18 01:47:20,262  - INFO - === [Epoch 83/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:30.4051s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.882 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.773 â”‚ 0.827 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.853 â”‚ 0.902 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.854 â”‚ 0.885 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1186, ET: 0.1559, TC: 0.1185, WT: 0.0815
[0m
[0;33m2025-05-18 01:47:20,262  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-18 01:47:20,262  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-18 01:49:24,813  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-18 01:49:24,814  - INFO - - Train mean loss: 0.1920
- ET loss: 0.2442
- TC loss: 0.1961
- WT loss: 0.1358
- Cost time: 2.08mins â±ï¸
[0m
[0;32m2025-05-18 01:49:24,814  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-18 01:49:54,933  - INFO - === [Epoch 84/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:30.1179s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.883 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.828 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.854 â”‚ 0.901 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.857 â”‚ 0.888 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1183, ET: 0.1561, TC: 0.1179, WT: 0.0810
[0m
[0;33m2025-05-18 01:49:54,934  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-18 01:49:54,934  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-18 01:52:09,316  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-18 01:52:09,317  - INFO - - Train mean loss: 0.1887
- ET loss: 0.2411
- TC loss: 0.1921
- WT loss: 0.1330
- Cost time: 2.24mins â±ï¸
[0m
[0;32m2025-05-18 01:52:09,317  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-18 01:52:39,580  - INFO - === [Epoch 85/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:30.2627s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.773 â”‚ 0.829 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.852 â”‚ 0.898 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.86  â”‚ 0.892 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1175, ET: 0.1550, TC: 0.1166, WT: 0.0808
[0m
[0;33m2025-05-18 01:52:39,581  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[0;32m2025-05-18 01:52:39,581  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-18 01:54:57,562  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-18 01:54:57,565  - INFO - - Train mean loss: 0.1906
- ET loss: 0.2462
- TC loss: 0.1972
- WT loss: 0.1284
- Cost time: 2.30mins â±ï¸
[0m
[0;32m2025-05-18 01:54:57,565  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-18 01:55:27,640  - INFO - === [Epoch 86/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:30.0740s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.882 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.771 â”‚ 0.827 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.855 â”‚ 0.906 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.855 â”‚ 0.881 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1193, ET: 0.1571, TC: 0.1188, WT: 0.0821
[0m
[0;33m2025-05-18 01:55:27,640  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 13/100[0m
[0;32m2025-05-18 01:55:27,640  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-18 01:57:42,894  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-18 01:57:42,895  - INFO - - Train mean loss: 0.1976
- ET loss: 0.2484
- TC loss: 0.2059
- WT loss: 0.1384
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 01:57:42,896  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-18 01:58:12,815  - INFO - === [Epoch 87/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:29.9184s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.884 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.829 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.855 â”‚ 0.905 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.857 â”‚ 0.885 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1180, ET: 0.1550, TC: 0.1169, WT: 0.0820
[0m
[0;33m2025-05-18 01:58:12,815  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 14/100[0m
[0;32m2025-05-18 01:58:12,815  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-18 02:00:27,880  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-18 02:00:27,881  - INFO - - Train mean loss: 0.1981
- ET loss: 0.2518
- TC loss: 0.2067
- WT loss: 0.1359
- Cost time: 2.25mins â±ï¸
[0m
[0;32m2025-05-18 02:00:27,881  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-18 02:00:58,117  - INFO - === [Epoch 88/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:30.2345s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.846 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.773 â”‚ 0.83  â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.846 â”‚ 0.894 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.865 â”‚ 0.895 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1549, TC: 0.1162, WT: 0.0806
[0m
[0;33m2025-05-18 02:00:58,117  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 15/100[0m
[0;32m2025-05-18 02:00:58,117  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-18 02:03:10,846  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-18 02:03:10,848  - INFO - - Train mean loss: 0.1985
- ET loss: 0.2510
- TC loss: 0.2045
- WT loss: 0.1399
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-18 02:03:10,848  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-18 02:03:40,865  - INFO - === [Epoch 89/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:30.0166s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.83  â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.853 â”‚ 0.9   â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.861 â”‚ 0.89  â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1173, ET: 0.1543, TC: 0.1162, WT: 0.0813
[0m
[0;33m2025-05-18 02:03:40,866  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 16/100[0m
[0;32m2025-05-18 02:03:40,866  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-18 02:05:56,522  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-18 02:05:56,523  - INFO - - Train mean loss: 0.1930
- ET loss: 0.2490
- TC loss: 0.2030
- WT loss: 0.1270
- Cost time: 2.26mins â±ï¸
[0m
[0;32m2025-05-18 02:05:56,524  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-18 02:06:26,715  - INFO - === [Epoch 90/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:30.1905s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.885 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.823 â”‚ 0.775 â”‚ 0.831 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.855 â”‚ 0.904 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.859 â”‚ 0.888 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1165, ET: 0.1538, TC: 0.1155, WT: 0.0801
[0m
[1;31m2025-05-18 02:06:26,717  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch69_loss0.1195_dice0.8814_20250518010916.pth[0m
[0;32m2025-05-18 02:06:26,760  - INFO - âœ¨ Saved checkpoint (epoch 90) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch90_loss0.1165_dice0.8845_20250518020626.pth;             Size 12.40 MB[0m
[0;32m2025-05-18 02:06:26,760  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-18 02:08:39,360  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-18 02:08:39,361  - INFO - - Train mean loss: 0.1981
- ET loss: 0.2499
- TC loss: 0.2057
- WT loss: 0.1388
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-18 02:08:39,361  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-18 02:09:09,821  - INFO - === [Epoch 91/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:30.4589s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.885 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.83  â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.851 â”‚ 0.901 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.862 â”‚ 0.89  â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1170, ET: 0.1541, TC: 0.1157, WT: 0.0813
[0m
[0;33m2025-05-18 02:09:09,821  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 02:09:09,821  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-18 02:11:20,082  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-18 02:11:20,084  - INFO - - Train mean loss: 0.2100
- ET loss: 0.2649
- TC loss: 0.2191
- WT loss: 0.1459
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-18 02:11:20,084  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-18 02:11:50,063  - INFO - === [Epoch 92/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:29.9782s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.884 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.83  â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.854 â”‚ 0.901 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.859 â”‚ 0.888 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1173, ET: 0.1547, TC: 0.1168, WT: 0.0805
[0m
[0;33m2025-05-18 02:11:50,063  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 02:11:50,063  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-18 02:14:02,436  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-18 02:14:02,438  - INFO - - Train mean loss: 0.2008
- ET loss: 0.2540
- TC loss: 0.2090
- WT loss: 0.1393
- Cost time: 2.21mins â±ï¸
[0m
[0;32m2025-05-18 02:14:02,438  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-18 02:14:32,693  - INFO - === [Epoch 93/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:30.2550s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.846 â”‚ 0.883 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.829 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.855 â”‚ 0.903 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.857 â”‚ 0.887 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1175, ET: 0.1549, TC: 0.1170, WT: 0.0807
[0m
[0;33m2025-05-18 02:14:32,694  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 02:14:32,694  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-18 02:16:43,692  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-18 02:16:43,693  - INFO - - Train mean loss: 0.1961
- ET loss: 0.2480
- TC loss: 0.2029
- WT loss: 0.1375
- Cost time: 2.18mins â±ï¸
[0m
[0;32m2025-05-18 02:16:43,693  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-18 02:17:13,750  - INFO - === [Epoch 94/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:30.0556s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.846 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.83  â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.855 â”‚ 0.899 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.858 â”‚ 0.891 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1544, TC: 0.1160, WT: 0.0812
[0m
[0;33m2025-05-18 02:17:13,750  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 02:17:13,750  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-18 02:19:25,673  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-18 02:19:25,675  - INFO - - Train mean loss: 0.1957
- ET loss: 0.2486
- TC loss: 0.2025
- WT loss: 0.1361
- Cost time: 2.20mins â±ï¸
[0m
[0;32m2025-05-18 02:19:25,675  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-18 02:19:55,801  - INFO - === [Epoch 95/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:30.1247s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.846 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.773 â”‚ 0.83  â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.849 â”‚ 0.898 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.864 â”‚ 0.893 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1545, TC: 0.1160, WT: 0.0811
[0m
[0;33m2025-05-18 02:19:55,801  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 02:19:55,801  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-18 02:22:05,170  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-18 02:22:05,171  - INFO - - Train mean loss: 0.2034
- ET loss: 0.2602
- TC loss: 0.2120
- WT loss: 0.1381
- Cost time: 2.16mins â±ï¸
[0m
[0;32m2025-05-18 02:22:05,171  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-18 02:22:35,191  - INFO - === [Epoch 96/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:30.0191s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.885 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.83  â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.855 â”‚ 0.903 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.859 â”‚ 0.89  â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1167, ET: 0.1537, TC: 0.1157, WT: 0.0806
[0m
[0;33m2025-05-18 02:22:35,192  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 02:22:35,192  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-18 02:24:46,455  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-18 02:24:46,456  - INFO - - Train mean loss: 0.1860
- ET loss: 0.2369
- TC loss: 0.1891
- WT loss: 0.1320
- Cost time: 2.19mins â±ï¸
[0m
[0;32m2025-05-18 02:24:46,456  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-18 02:25:16,428  - INFO - === [Epoch 97/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:29.9710s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.885 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.823 â”‚ 0.774 â”‚ 0.831 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.853 â”‚ 0.9   â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.862 â”‚ 0.893 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1165, ET: 0.1538, TC: 0.1153, WT: 0.0804
[0m
[0;33m2025-05-18 02:25:16,428  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 02:25:16,428  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-18 02:27:26,384  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-18 02:27:26,385  - INFO - - Train mean loss: 0.2031
- ET loss: 0.2592
- TC loss: 0.2090
- WT loss: 0.1412
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-18 02:27:26,385  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-18 02:27:56,429  - INFO - === [Epoch 98/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:30.0431s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.885 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.83  â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.853 â”‚ 0.899 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.861 â”‚ 0.892 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1168, ET: 0.1540, TC: 0.1158, WT: 0.0807
[0m
[0;33m2025-05-18 02:27:56,429  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-18 02:27:56,429  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-18 02:30:06,466  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-18 02:30:06,467  - INFO - - Train mean loss: 0.1878
- ET loss: 0.2378
- TC loss: 0.1932
- WT loss: 0.1325
- Cost time: 2.17mins â±ï¸
[0m
[0;32m2025-05-18 02:30:06,467  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-18 02:30:36,405  - INFO - === [Epoch 99/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:29.9370s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.775 â”‚ 0.83  â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.856 â”‚ 0.903 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.858 â”‚ 0.888 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1171, ET: 0.1542, TC: 0.1163, WT: 0.0807
[0m
[0;33m2025-05-18 02:30:36,406  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-18 02:30:36,406  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-18 02:32:45,346  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-18 02:32:45,347  - INFO - - Train mean loss: 0.1962
- ET loss: 0.2500
- TC loss: 0.2014
- WT loss: 0.1374
- Cost time: 2.15mins â±ï¸
[0m
[0;32m2025-05-18 02:32:45,347  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-18 02:33:15,791  - INFO - === [Epoch 100/100] ===
- Model:    ResUNetBaseline_S_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:30.4433s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.846 â”‚ 0.884 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.829 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.852 â”‚ 0.898 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.861 â”‚ 0.891 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1173, ET: 0.1545, TC: 0.1163, WT: 0.0810
[0m
[0;33m2025-05-18 02:33:15,792  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[1;31m2025-05-18 02:33:16,998  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1165 at epoch 90[0m
[0;32m2025-05-18 02:33:16,998  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-18 02:33:17,010  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/ResUNetBaseline_S_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-18 02:33:17,010  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-18 02:33:17,010  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-18 02:36:44,986  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚  0.819 â”‚ 0.877 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚  0.739 â”‚ 0.815 â”‚ 0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚  0.827 â”‚ 0.919 â”‚ 0.942 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.873 â”‚  0.832 â”‚ 0.871 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  7.076 â”‚ 11.1   â”‚ 5.658 â”‚ 4.47  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1274;ET: 0.1826;ET: 0.1826;TC: 0.1234;WT: 0.0761
[0m
[0;32m2025-05-18 02:36:44,987  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-18 02:36:44,987  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_v2_2025-05-17_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-17.log[0m
[0;32m2025-05-18 02:36:51,264  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-18 02:36:54,502  - INFO - Total number of parameters: 1.15 M[0m
[0;32m2025-05-18 02:36:54,504  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-18 02:36:54,505  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-18 02:36:54,505  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-18 02:36:54,505  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-18 02:36:54,505  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-18 02:36:54,511  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-18 02:36:54,512  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-18 02:36:54,512  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-18 02:36:54,515  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_DCLAv1_SLKv2_v2                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 1.15 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-18 02:36:57,637  - INFO - 
model: ResUNetBaseline_S_DCLAv1_SLKv2_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-18 02:36:57,638  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-18 02:39:17,962  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-18 02:39:17,963  - INFO - - Train mean loss: 0.4464
- ET loss: 0.4998
- TC loss: 0.4773
- WT loss: 0.3620
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-18 02:39:17,964  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-18 02:39:51,057  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:33.0922s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.739 â”‚ 0.701 â”‚ 0.709 â”‚ 0.808 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.622 â”‚ 0.58  â”‚ 0.59  â”‚ 0.697 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.698 â”‚ 0.693 â”‚ 0.637 â”‚ 0.764 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.843 â”‚ 0.764 â”‚ 0.881 â”‚ 0.884 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2679, ET: 0.3058, TC: 0.2988, WT: 0.1991
[0m
[0;32m2025-05-18 02:39:51,354  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.2679_dice0.7394_20250518023951.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:39:51,354  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-18 02:42:10,737  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-18 02:42:10,739  - INFO - - Train mean loss: 0.3405
- ET loss: 0.3867
- TC loss: 0.3661
- WT loss: 0.2686
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 02:42:10,740  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-18 02:42:43,261  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:32.5207s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.727 â”‚ 0.696 â”‚ 0.674 â”‚ 0.812 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.61  â”‚ 0.576 â”‚ 0.55  â”‚ 0.704 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.646 â”‚ 0.615 â”‚ 0.568 â”‚ 0.756 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.869 â”‚ 0.931 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2788, ET: 0.3102, TC: 0.3327, WT: 0.1935
[0m
[0;33m2025-05-18 02:42:43,261  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 02:42:43,262  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-18 02:45:02,518  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-18 02:45:02,519  - INFO - - Train mean loss: 0.3129
- ET loss: 0.3630
- TC loss: 0.3321
- WT loss: 0.2435
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 02:45:02,519  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-18 02:45:35,060  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:32.5400s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.763 â”‚ 0.724 â”‚ 0.755 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.662 â”‚ 0.616 â”‚ 0.659 â”‚ 0.71  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.719 â”‚ 0.676 â”‚ 0.708 â”‚ 0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.84  â”‚ 0.882 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2429, ET: 0.2809, TC: 0.2505, WT: 0.1973
[0m
[0;32m2025-05-18 02:45:35,115  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.2429_dice0.7634_20250518024535.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:45:35,115  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-18 02:47:54,509  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-18 02:47:54,511  - INFO - - Train mean loss: 0.3051
- ET loss: 0.3585
- TC loss: 0.3241
- WT loss: 0.2328
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 02:47:54,511  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-18 02:48:26,728  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:32.2160s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.816 â”‚ 0.773 â”‚ 0.806 â”‚ 0.87  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.728 â”‚ 0.676 â”‚ 0.722 â”‚ 0.786 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.809 â”‚ 0.757 â”‚ 0.782 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.862 â”‚ 0.831 â”‚ 0.882 â”‚ 0.872 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1872, ET: 0.2305, TC: 0.1974, WT: 0.1338
[0m
[1;31m2025-05-18 02:48:26,730  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.2429_dice0.7634_20250518024535.pth[0m
[0;32m2025-05-18 02:48:26,786  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.1872_dice0.8161_20250518024826.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:48:26,786  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-18 02:50:47,015  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-18 02:50:47,017  - INFO - - Train mean loss: 0.2634
- ET loss: 0.3130
- TC loss: 0.2757
- WT loss: 0.2014
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-18 02:50:47,017  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-18 02:51:19,475  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:32.4567s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.821 â”‚ 0.779 â”‚ 0.812 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.733 â”‚ 0.682 â”‚ 0.729 â”‚ 0.789 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.815 â”‚ 0.761 â”‚ 0.799 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.858 â”‚ 0.832 â”‚ 0.864 â”‚ 0.878 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1819, ET: 0.2237, TC: 0.1905, WT: 0.1315
[0m
[1;31m2025-05-18 02:51:19,476  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.1872_dice0.8161_20250518024826.pth[0m
[0;32m2025-05-18 02:51:19,531  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.1819_dice0.8211_20250518025119.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:51:19,531  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-18 02:53:39,751  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-18 02:53:39,753  - INFO - - Train mean loss: 0.2720
- ET loss: 0.3211
- TC loss: 0.2870
- WT loss: 0.2078
- Cost time: 2.34mins â±ï¸
[0m
[0;32m2025-05-18 02:53:39,753  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-18 02:54:12,102  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:32.3481s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.831 â”‚ 0.789 â”‚ 0.827 â”‚ 0.878 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.749 â”‚ 0.696 â”‚ 0.751 â”‚ 0.799 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.823 â”‚ 0.775 â”‚ 0.823 â”‚ 0.872 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.842 â”‚ 0.875 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1716, ET: 0.2140, TC: 0.1752, WT: 0.1257
[0m
[1;31m2025-05-18 02:54:12,104  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.1819_dice0.8211_20250518025119.pth[0m
[0;32m2025-05-18 02:54:12,162  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.1716_dice0.8314_20250518025412.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:54:12,162  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-18 02:56:31,809  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-18 02:56:31,812  - INFO - - Train mean loss: 0.2561
- ET loss: 0.3030
- TC loss: 0.2718
- WT loss: 0.1934
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 02:56:31,812  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-18 02:57:04,389  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:32.5765s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.839 â”‚ 0.8   â”‚ 0.84  â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.758 â”‚ 0.71  â”‚ 0.768 â”‚ 0.797 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.839 â”‚ 0.804 â”‚ 0.853 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.826 â”‚ 0.862 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1637, ET: 0.2024, TC: 0.1616, WT: 0.1272
[0m
[1;31m2025-05-18 02:57:04,391  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.1716_dice0.8314_20250518025412.pth[0m
[0;32m2025-05-18 02:57:04,454  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.1637_dice0.8393_20250518025704.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:57:04,454  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-18 02:59:23,314  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-18 02:59:23,315  - INFO - - Train mean loss: 0.2710
- ET loss: 0.3256
- TC loss: 0.2942
- WT loss: 0.1932
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 02:59:23,315  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-18 02:59:55,747  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:32.4305s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.842 â”‚ 0.806 â”‚ 0.84  â”‚ 0.88  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.763 â”‚ 0.716 â”‚ 0.767 â”‚ 0.806 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.859 â”‚ 0.801 â”‚ 0.849 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.853 â”‚ 0.837 â”‚ 0.865 â”‚ 0.856 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1607, ET: 0.1973, TC: 0.1627, WT: 0.1221
[0m
[1;31m2025-05-18 02:59:55,749  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.1637_dice0.8393_20250518025704.pth[0m
[0;32m2025-05-18 02:59:55,809  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch8_loss0.1607_dice0.8420_20250518025955.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 02:59:55,809  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-18 03:02:15,544  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-18 03:02:15,546  - INFO - - Train mean loss: 0.2453
- ET loss: 0.2987
- TC loss: 0.2587
- WT loss: 0.1784
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 03:02:15,546  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-18 03:02:47,924  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:32.3772s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.845 â”‚ 0.81  â”‚ 0.838 â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.766 â”‚ 0.721 â”‚ 0.764 â”‚ 0.813 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.842 â”‚ 0.812 â”‚ 0.832 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.833 â”‚ 0.881 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1571, ET: 0.1926, TC: 0.1645, WT: 0.1141
[0m
[1;31m2025-05-18 03:02:47,926  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.1607_dice0.8420_20250518025955.pth[0m
[0;32m2025-05-18 03:02:47,985  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.1571_dice0.8455_20250518030247.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:02:47,985  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-18 03:05:07,405  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-18 03:05:07,407  - INFO - - Train mean loss: 0.2467
- ET loss: 0.2947
- TC loss: 0.2557
- WT loss: 0.1898
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:05:07,407  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-18 03:05:39,796  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:32.3882s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.851 â”‚ 0.813 â”‚ 0.852 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.775 â”‚ 0.726 â”‚ 0.783 â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.855 â”‚ 0.822 â”‚ 0.861 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.826 â”‚ 0.87  â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1509, ET: 0.1897, TC: 0.1502, WT: 0.1128
[0m
[1;31m2025-05-18 03:05:39,798  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.1571_dice0.8455_20250518030247.pth[0m
[0;32m2025-05-18 03:05:39,863  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.1509_dice0.8515_20250518030539.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:05:39,863  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-18 03:07:59,442  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-18 03:07:59,444  - INFO - - Train mean loss: 0.2455
- ET loss: 0.2956
- TC loss: 0.2571
- WT loss: 0.1839
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 03:07:59,444  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-18 03:08:31,601  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:32.1562s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.847 â”‚ 0.809 â”‚ 0.848 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.772 â”‚ 0.722 â”‚ 0.781 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.835 â”‚ 0.888 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.844 â”‚ 0.811 â”‚ 0.839 â”‚ 0.883 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1551, ET: 0.1931, TC: 0.1535, WT: 0.1187
[0m
[0;33m2025-05-18 03:08:31,601  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 03:08:31,601  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-18 03:10:51,441  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-18 03:10:51,443  - INFO - - Train mean loss: 0.2658
- ET loss: 0.3201
- TC loss: 0.2797
- WT loss: 0.1976
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 03:10:51,443  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-18 03:11:23,734  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:32.2895s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.84  â”‚ 0.807 â”‚ 0.829 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.759 â”‚ 0.718 â”‚ 0.752 â”‚ 0.808 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.823 â”‚ 0.787 â”‚ 0.821 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.855 â”‚ 0.88  â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1623, ET: 0.1949, TC: 0.1738, WT: 0.1182
[0m
[0;33m2025-05-18 03:11:23,734  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 03:11:23,734  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-18 03:13:42,982  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-18 03:13:42,983  - INFO - - Train mean loss: 0.2468
- ET loss: 0.2992
- TC loss: 0.2634
- WT loss: 0.1777
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:13:42,983  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-18 03:14:15,013  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:32.0290s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.85  â”‚ 0.814 â”‚ 0.853 â”‚ 0.884 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.774 â”‚ 0.727 â”‚ 0.783 â”‚ 0.812 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.851 â”‚ 0.794 â”‚ 0.849 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.86  â”‚ 0.887 â”‚ 0.879 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1517, ET: 0.1886, TC: 0.1489, WT: 0.1176
[0m
[0;33m2025-05-18 03:14:15,014  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 03:14:15,014  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-18 03:16:33,790  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-18 03:16:33,792  - INFO - - Train mean loss: 0.2416
- ET loss: 0.2912
- TC loss: 0.2497
- WT loss: 0.1839
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:16:33,792  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-18 03:17:06,018  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:32.2248s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.857 â”‚ 0.818 â”‚ 0.859 â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.783 â”‚ 0.733 â”‚ 0.793 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.815 â”‚ 0.863 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.844 â”‚ 0.878 â”‚ 0.877 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1452, ET: 0.1838, TC: 0.1425, WT: 0.1094
[0m
[1;31m2025-05-18 03:17:06,020  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.1509_dice0.8515_20250518030539.pth[0m
[0;32m2025-05-18 03:17:06,075  - INFO - âœ¨ Saved checkpoint (epoch 14) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch14_loss0.1452_dice0.8566_20250518031706.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:17:06,075  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-18 03:19:24,796  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-18 03:19:24,798  - INFO - - Train mean loss: 0.2374
- ET loss: 0.2889
- TC loss: 0.2511
- WT loss: 0.1721
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:19:24,798  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-18 03:19:56,796  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:31.9977s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.818 â”‚ 0.861 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.786 â”‚ 0.733 â”‚ 0.797 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.86  â”‚ 0.805 â”‚ 0.87  â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.856 â”‚ 0.874 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1431, ET: 0.1843, TC: 0.1404, WT: 0.1045
[0m
[1;31m2025-05-18 03:19:56,798  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch14_loss0.1452_dice0.8566_20250518031706.pth[0m
[0;32m2025-05-18 03:19:56,855  - INFO - âœ¨ Saved checkpoint (epoch 15) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch15_loss0.1431_dice0.8591_20250518031956.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:19:56,855  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-18 03:22:15,835  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-18 03:22:15,837  - INFO - - Train mean loss: 0.2441
- ET loss: 0.2929
- TC loss: 0.2583
- WT loss: 0.1810
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:22:15,837  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-18 03:22:48,034  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:32.1957s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.82  â”‚ 0.858 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.787 â”‚ 0.737 â”‚ 0.793 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.872 â”‚ 0.832 â”‚ 0.868 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.869 â”‚ 0.834 â”‚ 0.876 â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1428, ET: 0.1822, TC: 0.1437, WT: 0.1024
[0m
[1;31m2025-05-18 03:22:48,036  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch15_loss0.1431_dice0.8591_20250518031956.pth[0m
[0;32m2025-05-18 03:22:48,091  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.1428_dice0.8592_20250518032248.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:22:48,091  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-18 03:25:07,063  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-18 03:25:07,065  - INFO - - Train mean loss: 0.2369
- ET loss: 0.2853
- TC loss: 0.2473
- WT loss: 0.1780
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:25:07,066  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-18 03:25:39,551  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:32.4848s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.821 â”‚ 0.863 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.788 â”‚ 0.738 â”‚ 0.798 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.851 â”‚ 0.804 â”‚ 0.86  â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.86  â”‚ 0.888 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1416, ET: 0.1809, TC: 0.1388, WT: 0.1050
[0m
[1;31m2025-05-18 03:25:39,553  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.1428_dice0.8592_20250518032248.pth[0m
[0;32m2025-05-18 03:25:39,608  - INFO - âœ¨ Saved checkpoint (epoch 17) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch17_loss0.1416_dice0.8608_20250518032539.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:25:39,608  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-18 03:27:59,163  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-18 03:27:59,164  - INFO - - Train mean loss: 0.2425
- ET loss: 0.2943
- TC loss: 0.2581
- WT loss: 0.1752
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 03:27:59,164  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-18 03:28:31,731  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:32.5654s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.824 â”‚ 0.859 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.785 â”‚ 0.74  â”‚ 0.792 â”‚ 0.822 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.846 â”‚ 0.812 â”‚ 0.85  â”‚ 0.874 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.857 â”‚ 0.894 â”‚ 0.93  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1436, ET: 0.1783, TC: 0.1429, WT: 0.1095
[0m
[0;33m2025-05-18 03:28:31,732  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 03:28:31,732  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-18 03:30:51,004  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-18 03:30:51,006  - INFO - - Train mean loss: 0.2409
- ET loss: 0.2917
- TC loss: 0.2538
- WT loss: 0.1771
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:30:51,006  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-18 03:31:23,207  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:32.2008s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.858 â”‚ 0.822 â”‚ 0.861 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.783 â”‚ 0.739 â”‚ 0.795 â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.836 â”‚ 0.804 â”‚ 0.847 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.867 â”‚ 0.909 â”‚ 0.941 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1443, ET: 0.1802, TC: 0.1405, WT: 0.1121
[0m
[0;33m2025-05-18 03:31:23,208  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 03:31:23,208  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-18 03:33:41,987  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-18 03:33:41,988  - INFO - - Train mean loss: 0.2275
- ET loss: 0.2773
- TC loss: 0.2383
- WT loss: 0.1668
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:33:41,988  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-18 03:34:14,440  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:32.4513s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.849 â”‚ 0.811 â”‚ 0.846 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.773 â”‚ 0.724 â”‚ 0.775 â”‚ 0.819 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.828 â”‚ 0.78  â”‚ 0.822 â”‚ 0.881 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.871 â”‚ 0.909 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1530, ET: 0.1912, TC: 0.1559, WT: 0.1118
[0m
[0;33m2025-05-18 03:34:14,441  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 03:34:14,441  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-18 03:36:33,308  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-18 03:36:33,310  - INFO - - Train mean loss: 0.2377
- ET loss: 0.2922
- TC loss: 0.2525
- WT loss: 0.1684
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:36:33,310  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-18 03:37:05,526  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:32.2146s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.824 â”‚ 0.863 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.789 â”‚ 0.743 â”‚ 0.799 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.845 â”‚ 0.805 â”‚ 0.851 â”‚ 0.879 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.871 â”‚ 0.905 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1414, ET: 0.1773, TC: 0.1383, WT: 0.1085
[0m
[1;31m2025-05-18 03:37:05,528  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch17_loss0.1416_dice0.8608_20250518032539.pth[0m
[0;32m2025-05-18 03:37:05,582  - INFO - âœ¨ Saved checkpoint (epoch 21) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.1414_dice0.8605_20250518033705.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:37:05,582  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-18 03:39:24,476  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-18 03:39:24,478  - INFO - - Train mean loss: 0.2376
- ET loss: 0.2896
- TC loss: 0.2525
- WT loss: 0.1708
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:39:24,478  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-18 03:39:56,547  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:32.0687s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.829 â”‚ 0.866 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.795 â”‚ 0.747 â”‚ 0.801 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.874 â”‚ 0.826 â”‚ 0.873 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.85  â”‚ 0.883 â”‚ 0.898 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1354, ET: 0.1729, TC: 0.1349, WT: 0.0984
[0m
[1;31m2025-05-18 03:39:56,549  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch21_loss0.1414_dice0.8605_20250518033705.pth[0m
[0;32m2025-05-18 03:39:56,604  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.1354_dice0.8664_20250518033956.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:39:56,604  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-18 03:42:15,500  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-18 03:42:15,501  - INFO - - Train mean loss: 0.2164
- ET loss: 0.2669
- TC loss: 0.2250
- WT loss: 0.1574
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:42:15,501  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-18 03:42:47,736  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:32.2337s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.828 â”‚ 0.866 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.747 â”‚ 0.804 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.843 â”‚ 0.902 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.858 â”‚ 0.832 â”‚ 0.852 â”‚ 0.889 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1371, ET: 0.1735, TC: 0.1350, WT: 0.1029
[0m
[0;33m2025-05-18 03:42:47,736  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 03:42:47,736  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-18 03:45:06,608  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-18 03:45:06,609  - INFO - - Train mean loss: 0.2165
- ET loss: 0.2670
- TC loss: 0.2241
- WT loss: 0.1582
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:45:06,610  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-18 03:45:38,921  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:32.3108s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.83  â”‚ 0.872 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.749 â”‚ 0.811 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.876 â”‚ 0.833 â”‚ 0.891 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.847 â”‚ 0.874 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1330, ET: 0.1715, TC: 0.1287, WT: 0.0990
[0m
[1;31m2025-05-18 03:45:38,923  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.1354_dice0.8664_20250518033956.pth[0m
[0;32m2025-05-18 03:45:38,979  - INFO - âœ¨ Saved checkpoint (epoch 24) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch24_loss0.1330_dice0.8685_20250518034538.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:45:38,979  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-18 03:47:57,788  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-18 03:47:57,789  - INFO - - Train mean loss: 0.2305
- ET loss: 0.2843
- TC loss: 0.2394
- WT loss: 0.1676
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:47:57,790  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-18 03:48:30,385  - INFO - === [Epoch 25/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:32.5945s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.831 â”‚ 0.873 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.751 â”‚ 0.815 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.837 â”‚ 0.881 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.845 â”‚ 0.886 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1325, ET: 0.1707, TC: 0.1275, WT: 0.0994
[0m
[1;31m2025-05-18 03:48:30,387  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch24_loss0.1330_dice0.8685_20250518034538.pth[0m
[0;32m2025-05-18 03:48:30,444  - INFO - âœ¨ Saved checkpoint (epoch 25) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch25_loss0.1325_dice0.8689_20250518034830.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:48:30,444  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-18 03:50:49,490  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-18 03:50:49,492  - INFO - - Train mean loss: 0.2228
- ET loss: 0.2724
- TC loss: 0.2346
- WT loss: 0.1613
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:50:49,492  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-18 03:51:21,653  - INFO - === [Epoch 26/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:32.1606s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.832 â”‚ 0.867 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.752 â”‚ 0.802 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.848 â”‚ 0.816 â”‚ 0.851 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.906 â”‚ 0.87  â”‚ 0.91  â”‚ 0.938 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1358, ET: 0.1699, TC: 0.1344, WT: 0.1032
[0m
[0;33m2025-05-18 03:51:21,654  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 03:51:21,654  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-18 03:53:40,581  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-18 03:53:40,583  - INFO - - Train mean loss: 0.2221
- ET loss: 0.2729
- TC loss: 0.2312
- WT loss: 0.1623
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:53:40,583  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-18 03:54:12,707  - INFO - === [Epoch 27/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:32.1225s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.826 â”‚ 0.866 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.745 â”‚ 0.804 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.848 â”‚ 0.806 â”‚ 0.851 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.869 â”‚ 0.906 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1369, ET: 0.1753, TC: 0.1348, WT: 0.1007
[0m
[0;33m2025-05-18 03:54:12,707  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 03:54:12,707  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-18 03:56:31,435  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-18 03:56:31,436  - INFO - - Train mean loss: 0.2250
- ET loss: 0.2797
- TC loss: 0.2342
- WT loss: 0.1612
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 03:56:31,436  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-18 03:57:03,610  - INFO - === [Epoch 28/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:32.1734s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.833 â”‚ 0.871 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.799 â”‚ 0.755 â”‚ 0.808 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.833 â”‚ 0.869 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.853 â”‚ 0.896 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1337, ET: 0.1686, TC: 0.1310, WT: 0.1016
[0m
[0;33m2025-05-18 03:57:03,611  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 03:57:03,611  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-18 03:59:22,890  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-18 03:59:22,891  - INFO - - Train mean loss: 0.2208
- ET loss: 0.2701
- TC loss: 0.2320
- WT loss: 0.1604
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 03:59:22,891  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-18 03:59:55,771  - INFO - === [Epoch 29/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:32.8783s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.834 â”‚ 0.874 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.755 â”‚ 0.813 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.849 â”‚ 0.894 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.841 â”‚ 0.877 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1296, ET: 0.1673, TC: 0.1272, WT: 0.0942
[0m
[1;31m2025-05-18 03:59:55,773  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch25_loss0.1325_dice0.8689_20250518034830.pth[0m
[0;32m2025-05-18 03:59:55,830  - INFO - âœ¨ Saved checkpoint (epoch 29) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch29_loss0.1296_dice0.8720_20250518035955.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 03:59:55,831  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-18 04:02:15,367  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-18 04:02:15,369  - INFO - - Train mean loss: 0.2062
- ET loss: 0.2561
- TC loss: 0.2142
- WT loss: 0.1484
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 04:02:15,369  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-18 04:02:47,528  - INFO - === [Epoch 30/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:32.1579s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.832 â”‚ 0.87  â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.754 â”‚ 0.81  â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.859 â”‚ 0.913 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.827 â”‚ 0.853 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1313, ET: 0.1692, TC: 0.1308, WT: 0.0940
[0m
[0;33m2025-05-18 04:02:47,529  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 04:02:47,529  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-18 04:05:06,462  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-18 04:05:06,463  - INFO - - Train mean loss: 0.2212
- ET loss: 0.2723
- TC loss: 0.2312
- WT loss: 0.1601
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:05:06,463  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-18 04:05:38,391  - INFO - === [Epoch 31/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:31.9272s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.833 â”‚ 0.869 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.753 â”‚ 0.806 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.818 â”‚ 0.866 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.868 â”‚ 0.9   â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1312, ET: 0.1686, TC: 0.1317, WT: 0.0934
[0m
[0;33m2025-05-18 04:05:38,391  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 04:05:38,391  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-18 04:07:57,385  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-18 04:07:57,387  - INFO - - Train mean loss: 0.2128
- ET loss: 0.2651
- TC loss: 0.2220
- WT loss: 0.1512
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:07:57,388  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-18 04:08:29,855  - INFO - === [Epoch 32/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:32.4662s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.878 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.816 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.84  â”‚ 0.887 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.855 â”‚ 0.893 â”‚ 0.915 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1270, ET: 0.1641, TC: 0.1228, WT: 0.0941
[0m
[1;31m2025-05-18 04:08:29,857  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch29_loss0.1296_dice0.8720_20250518035955.pth[0m
[0;32m2025-05-18 04:08:29,911  - INFO - âœ¨ Saved checkpoint (epoch 32) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch32_loss0.1270_dice0.8744_20250518040829.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:08:29,911  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-18 04:10:48,577  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-18 04:10:48,578  - INFO - - Train mean loss: 0.2282
- ET loss: 0.2788
- TC loss: 0.2387
- WT loss: 0.1673
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:10:48,578  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-18 04:11:20,848  - INFO - === [Epoch 33/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:32.2686s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.82  â”‚ 0.871 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.791 â”‚ 0.734 â”‚ 0.806 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.842 â”‚ 0.778 â”‚ 0.86  â”‚ 0.889 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.908 â”‚ 0.891 â”‚ 0.905 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1373, ET: 0.1810, TC: 0.1303, WT: 0.1007
[0m
[0;33m2025-05-18 04:11:20,848  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 04:11:20,848  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-18 04:13:39,697  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-18 04:13:39,699  - INFO - - Train mean loss: 0.2208
- ET loss: 0.2766
- TC loss: 0.2320
- WT loss: 0.1537
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:13:39,699  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-18 04:14:12,198  - INFO - === [Epoch 34/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:32.4976s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.834 â”‚ 0.876 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.755 â”‚ 0.815 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.864 â”‚ 0.911 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.823 â”‚ 0.861 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1279, ET: 0.1670, TC: 0.1244, WT: 0.0924
[0m
[0;33m2025-05-18 04:14:12,198  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 04:14:12,198  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-18 04:16:31,066  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-18 04:16:31,068  - INFO - - Train mean loss: 0.2163
- ET loss: 0.2672
- TC loss: 0.2262
- WT loss: 0.1556
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:16:31,068  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-18 04:17:03,326  - INFO - === [Epoch 35/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:32.2572s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.828 â”‚ 0.87  â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.749 â”‚ 0.808 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.908 â”‚ 0.871 â”‚ 0.914 â”‚ 0.94  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.851 â”‚ 0.809 â”‚ 0.848 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1316, ET: 0.1730, TC: 0.1312, WT: 0.0907
[0m
[0;33m2025-05-18 04:17:03,326  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 04:17:03,326  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-18 04:19:22,562  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-18 04:19:22,564  - INFO - - Train mean loss: 0.2255
- ET loss: 0.2770
- TC loss: 0.2374
- WT loss: 0.1622
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:19:22,564  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-18 04:19:54,780  - INFO - === [Epoch 36/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:32.2145s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.838 â”‚ 0.88  â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.762 â”‚ 0.822 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.845 â”‚ 0.901 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.85  â”‚ 0.885 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1258, ET: 0.1632, TC: 0.1205, WT: 0.0937
[0m
[1;31m2025-05-18 04:19:54,782  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch32_loss0.1270_dice0.8744_20250518040829.pth[0m
[0;32m2025-05-18 04:19:54,835  - INFO - âœ¨ Saved checkpoint (epoch 36) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch36_loss0.1258_dice0.8753_20250518041954.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:19:54,836  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-18 04:22:14,882  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-18 04:22:14,884  - INFO - - Train mean loss: 0.2170
- ET loss: 0.2692
- TC loss: 0.2275
- WT loss: 0.1542
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 04:22:14,884  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-18 04:22:47,608  - INFO - === [Epoch 37/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:32.7236s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.837 â”‚ 0.877 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.758 â”‚ 0.817 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.862 â”‚ 0.836 â”‚ 0.889 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.855 â”‚ 0.886 â”‚ 0.951 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1309, ET: 0.1642, TC: 0.1235, WT: 0.1050
[0m
[0;33m2025-05-18 04:22:47,608  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 04:22:47,608  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-18 04:25:06,479  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-18 04:25:06,481  - INFO - - Train mean loss: 0.2031
- ET loss: 0.2553
- TC loss: 0.2126
- WT loss: 0.1414
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:25:06,481  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-18 04:25:38,538  - INFO - === [Epoch 38/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:32.0561s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.839 â”‚ 0.88  â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.762 â”‚ 0.823 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.843 â”‚ 0.899 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.888 â”‚ 0.853 â”‚ 0.883 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1241, ET: 0.1624, TC: 0.1202, WT: 0.0898
[0m
[1;31m2025-05-18 04:25:38,540  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch36_loss0.1258_dice0.8753_20250518041954.pth[0m
[0;32m2025-05-18 04:25:38,595  - INFO - âœ¨ Saved checkpoint (epoch 38) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch38_loss0.1241_dice0.8771_20250518042538.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:25:38,595  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-18 04:27:57,498  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-18 04:27:57,499  - INFO - - Train mean loss: 0.2254
- ET loss: 0.2757
- TC loss: 0.2381
- WT loss: 0.1624
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:27:57,499  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-18 04:28:29,396  - INFO - === [Epoch 39/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:31.8959s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.832 â”‚ 0.869 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.753 â”‚ 0.805 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.858 â”‚ 0.825 â”‚ 0.852 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.86  â”‚ 0.915 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1323, ET: 0.1694, TC: 0.1323, WT: 0.0954
[0m
[0;33m2025-05-18 04:28:29,396  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 04:28:29,396  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-18 04:30:47,994  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-18 04:30:47,995  - INFO - - Train mean loss: 0.2063
- ET loss: 0.2566
- TC loss: 0.2153
- WT loss: 0.1470
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:30:47,995  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-18 04:31:19,961  - INFO - === [Epoch 40/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:31.9653s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.881 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.763 â”‚ 0.823 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.872 â”‚ 0.837 â”‚ 0.892 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.859 â”‚ 0.886 â”‚ 0.939 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1256, ET: 0.1612, TC: 0.1199, WT: 0.0959
[0m
[0;33m2025-05-18 04:31:19,962  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 04:31:19,962  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-18 04:33:38,974  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-18 04:33:38,976  - INFO - - Train mean loss: 0.2170
- ET loss: 0.2686
- TC loss: 0.2246
- WT loss: 0.1579
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:33:38,976  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-18 04:34:11,015  - INFO - === [Epoch 41/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:32.0376s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.84  â”‚ 0.872 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.764 â”‚ 0.815 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚ 0.838 â”‚ 0.901 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.86  â”‚ 0.867 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1612, TC: 0.1282, WT: 0.0903
[0m
[0;33m2025-05-18 04:34:11,015  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 04:34:11,015  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-18 04:36:30,112  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-18 04:36:30,113  - INFO - - Train mean loss: 0.2073
- ET loss: 0.2581
- TC loss: 0.2144
- WT loss: 0.1493
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:36:30,113  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-18 04:37:02,395  - INFO - === [Epoch 42/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:32.2810s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.839 â”‚ 0.88  â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.763 â”‚ 0.821 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.852 â”‚ 0.886 â”‚ 0.897 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.844 â”‚ 0.894 â”‚ 0.934 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1249, ET: 0.1616, TC: 0.1206, WT: 0.0923
[0m
[0;33m2025-05-18 04:37:02,395  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 04:37:02,395  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-18 04:39:21,173  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-18 04:39:21,174  - INFO - - Train mean loss: 0.2048
- ET loss: 0.2522
- TC loss: 0.2093
- WT loss: 0.1529
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:39:21,174  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-18 04:39:53,410  - INFO - === [Epoch 43/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:32.2347s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.838 â”‚ 0.879 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.761 â”‚ 0.82  â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.902 â”‚ 0.875 â”‚ 0.912 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.869 â”‚ 0.822 â”‚ 0.867 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1240, ET: 0.1627, TC: 0.1215, WT: 0.0879
[0m
[1;31m2025-05-18 04:39:53,412  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch38_loss0.1241_dice0.8771_20250518042538.pth[0m
[0;32m2025-05-18 04:39:53,467  - INFO - âœ¨ Saved checkpoint (epoch 43) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch43_loss0.1240_dice0.8771_20250518043953.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:39:53,467  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-18 04:42:12,143  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-18 04:42:12,144  - INFO - - Train mean loss: 0.2011
- ET loss: 0.2513
- TC loss: 0.2080
- WT loss: 0.1441
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:42:12,144  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-18 04:42:44,240  - INFO - === [Epoch 44/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:32.0947s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.833 â”‚ 0.876 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.758 â”‚ 0.818 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.865 â”‚ 0.91  â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.83  â”‚ 0.87  â”‚ 0.936 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1291, ET: 0.1682, TC: 0.1246, WT: 0.0945
[0m
[0;33m2025-05-18 04:42:44,240  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 04:42:44,240  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-18 04:45:02,712  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-18 04:45:02,715  - INFO - - Train mean loss: 0.1930
- ET loss: 0.2443
- TC loss: 0.2025
- WT loss: 0.1323
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:45:02,715  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-18 04:45:34,735  - INFO - === [Epoch 45/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:32.0189s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.844 â”‚ 0.886 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.816 â”‚ 0.768 â”‚ 0.829 â”‚ 0.852 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.846 â”‚ 0.901 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.859 â”‚ 0.891 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1200, ET: 0.1574, TC: 0.1143, WT: 0.0882
[0m
[1;31m2025-05-18 04:45:34,737  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch43_loss0.1240_dice0.8771_20250518043953.pth[0m
[0;32m2025-05-18 04:45:34,791  - INFO - âœ¨ Saved checkpoint (epoch 45) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch45_loss0.1200_dice0.8813_20250518044534.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:45:34,792  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-18 04:47:53,447  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-18 04:47:53,449  - INFO - - Train mean loss: 0.1991
- ET loss: 0.2538
- TC loss: 0.2064
- WT loss: 0.1371
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:47:53,449  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-18 04:48:25,835  - INFO - === [Epoch 46/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:32.3851s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.881 â”‚ 0.845 â”‚ 0.885 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.769 â”‚ 0.827 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.9   â”‚ 0.86  â”‚ 0.91  â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.847 â”‚ 0.878 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1197, ET: 0.1565, TC: 0.1159, WT: 0.0866
[0m
[1;31m2025-05-18 04:48:25,837  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch45_loss0.1200_dice0.8813_20250518044534.pth[0m
[0;32m2025-05-18 04:48:25,891  - INFO - âœ¨ Saved checkpoint (epoch 46) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch46_loss0.1197_dice0.8814_20250518044825.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:48:25,892  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-18 04:50:44,492  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-18 04:50:44,495  - INFO - - Train mean loss: 0.2103
- ET loss: 0.2619
- TC loss: 0.2208
- WT loss: 0.1480
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 04:50:44,495  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-18 04:51:16,219  - INFO - === [Epoch 47/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:31.7227s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.886 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.828 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.841 â”‚ 0.892 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.865 â”‚ 0.896 â”‚ 0.919 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1190, ET: 0.1565, TC: 0.1152, WT: 0.0855
[0m
[1;31m2025-05-18 04:51:16,221  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch46_loss0.1197_dice0.8814_20250518044825.pth[0m
[0;32m2025-05-18 04:51:16,276  - INFO - âœ¨ Saved checkpoint (epoch 47) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch47_loss0.1190_dice0.8822_20250518045116.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 04:51:16,276  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-18 04:53:35,802  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-18 04:53:35,804  - INFO - - Train mean loss: 0.2128
- ET loss: 0.2676
- TC loss: 0.2260
- WT loss: 0.1448
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 04:53:35,804  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-18 04:54:07,576  - INFO - === [Epoch 48/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:31.7707s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.841 â”‚ 0.873 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.764 â”‚ 0.811 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.864 â”‚ 0.835 â”‚ 0.855 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.864 â”‚ 0.917 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1262, ET: 0.1599, TC: 0.1280, WT: 0.0906
[0m
[0;33m2025-05-18 04:54:07,576  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 04:54:07,576  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-18 04:56:26,622  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-18 04:56:26,623  - INFO - - Train mean loss: 0.2056
- ET loss: 0.2582
- TC loss: 0.2116
- WT loss: 0.1470
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 04:56:26,623  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-18 04:56:58,658  - INFO - === [Epoch 49/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:32.0337s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.842 â”‚ 0.882 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.827 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.852 â”‚ 0.902 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.85  â”‚ 0.885 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1207, ET: 0.1587, TC: 0.1181, WT: 0.0852
[0m
[0;33m2025-05-18 04:56:58,658  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 04:56:58,658  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-18 04:59:20,139  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-18 04:59:20,140  - INFO - - Train mean loss: 0.1983
- ET loss: 0.2540
- TC loss: 0.2088
- WT loss: 0.1322
- Cost time: 2.36mins â±ï¸
[0m
[0;32m2025-05-18 04:59:20,140  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-18 04:59:52,276  - INFO - === [Epoch 50/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:32.1354s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.834 â”‚ 0.879 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.757 â”‚ 0.821 â”‚ 0.85  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.861 â”‚ 0.81  â”‚ 0.864 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.909 â”‚ 0.881 â”‚ 0.919 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1263, ET: 0.1675, TC: 0.1217, WT: 0.0896
[0m
[0;33m2025-05-18 04:59:52,276  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 04:59:52,276  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-18 05:02:11,221  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-18 05:02:11,223  - INFO - - Train mean loss: 0.2039
- ET loss: 0.2573
- TC loss: 0.2101
- WT loss: 0.1444
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:02:11,223  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-18 05:02:43,061  - INFO - === [Epoch 51/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:31.8373s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.88  â”‚ 0.842 â”‚ 0.883 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.815 â”‚ 0.767 â”‚ 0.826 â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.838 â”‚ 0.886 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.863 â”‚ 0.899 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1214, ET: 0.1590, TC: 0.1177, WT: 0.0874
[0m
[0;33m2025-05-18 05:02:43,061  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 05:02:43,061  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-18 05:05:01,946  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-18 05:05:01,948  - INFO - - Train mean loss: 0.2026
- ET loss: 0.2559
- TC loss: 0.2126
- WT loss: 0.1392
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:05:01,948  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-18 05:05:33,926  - INFO - === [Epoch 52/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:31.9763s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.843 â”‚ 0.887 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.817 â”‚ 0.768 â”‚ 0.83  â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.842 â”‚ 0.895 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.862 â”‚ 0.897 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1194, ET: 0.1578, TC: 0.1133, WT: 0.0871
[0m
[0;33m2025-05-18 05:05:33,926  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 05:05:33,926  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-18 05:07:52,812  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-18 05:07:52,815  - INFO - - Train mean loss: 0.1976
- ET loss: 0.2469
- TC loss: 0.2042
- WT loss: 0.1417
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:07:52,815  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-18 05:08:24,632  - INFO - === [Epoch 53/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:31.8165s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.841 â”‚ 0.88  â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.814 â”‚ 0.765 â”‚ 0.822 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.913 â”‚ 0.866 â”‚ 0.923 â”‚ 0.95  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.863 â”‚ 0.835 â”‚ 0.86  â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1225, ET: 0.1605, TC: 0.1203, WT: 0.0866
[0m
[0;33m2025-05-18 05:08:24,632  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 05:08:24,632  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-18 05:10:43,362  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-18 05:10:43,363  - INFO - - Train mean loss: 0.1890
- ET loss: 0.2393
- TC loss: 0.1942
- WT loss: 0.1336
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:10:43,363  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-18 05:11:15,372  - INFO - === [Epoch 54/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:32.0082s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.884 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚ 0.763 â”‚ 0.827 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.824 â”‚ 0.88  â”‚ 0.893 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.907 â”‚ 0.875 â”‚ 0.909 â”‚ 0.937 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1240, ET: 0.1617, TC: 0.1163, WT: 0.0940
[0m
[0;33m2025-05-18 05:11:15,373  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 05:11:15,373  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-18 05:13:34,407  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-18 05:13:34,409  - INFO - - Train mean loss: 0.2051
- ET loss: 0.2575
- TC loss: 0.2168
- WT loss: 0.1409
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:13:34,409  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-18 05:14:06,010  - INFO - === [Epoch 55/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:31.6007s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.886 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.772 â”‚ 0.83  â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.893 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.859 â”‚ 0.898 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1177, ET: 0.1547, TC: 0.1144, WT: 0.0840
[0m
[1;31m2025-05-18 05:14:06,012  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch47_loss0.1190_dice0.8822_20250518045116.pth[0m
[0;32m2025-05-18 05:14:06,067  - INFO - âœ¨ Saved checkpoint (epoch 55) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch55_loss0.1177_dice0.8835_20250518051406.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 05:14:06,068  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-18 05:16:25,054  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-18 05:16:25,055  - INFO - - Train mean loss: 0.1981
- ET loss: 0.2487
- TC loss: 0.2073
- WT loss: 0.1384
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:16:25,055  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-18 05:16:57,135  - INFO - === [Epoch 56/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:32.0785s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.844 â”‚ 0.887 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.77  â”‚ 0.83  â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.844 â”‚ 0.89  â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.863 â”‚ 0.904 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1185, ET: 0.1567, TC: 0.1136, WT: 0.0852
[0m
[0;33m2025-05-18 05:16:57,135  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 05:16:57,135  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-18 05:19:16,751  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-18 05:19:16,753  - INFO - - Train mean loss: 0.1929
- ET loss: 0.2462
- TC loss: 0.2001
- WT loss: 0.1325
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 05:19:16,753  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-18 05:19:48,699  - INFO - === [Epoch 57/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:31.9455s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.845 â”‚ 0.889 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.771 â”‚ 0.832 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.852 â”‚ 0.897 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.856 â”‚ 0.896 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1171, ET: 0.1557, TC: 0.1117, WT: 0.0839
[0m
[1;31m2025-05-18 05:19:48,702  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch55_loss0.1177_dice0.8835_20250518051406.pth[0m
[0;32m2025-05-18 05:19:48,756  - INFO - âœ¨ Saved checkpoint (epoch 57) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch57_loss0.1171_dice0.8840_20250518051948.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 05:19:48,757  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-18 05:22:07,328  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-18 05:22:07,330  - INFO - - Train mean loss: 0.2035
- ET loss: 0.2577
- TC loss: 0.2144
- WT loss: 0.1384
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:22:07,330  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-18 05:22:39,188  - INFO - === [Epoch 58/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:31.8565s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.889 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.834 â”‚ 0.856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.839 â”‚ 0.898 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.872 â”‚ 0.897 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1175, ET: 0.1546, TC: 0.1121, WT: 0.0857
[0m
[0;33m2025-05-18 05:22:39,188  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 05:22:39,188  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-18 05:24:58,092  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-18 05:24:58,093  - INFO - - Train mean loss: 0.1963
- ET loss: 0.2466
- TC loss: 0.2029
- WT loss: 0.1393
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:24:58,093  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-18 05:25:30,290  - INFO - === [Epoch 59/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:32.1955s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.886 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.83  â”‚ 0.853 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.843 â”‚ 0.899 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.865 â”‚ 0.892 â”‚ 0.939 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1196, ET: 0.1562, TC: 0.1146, WT: 0.0879
[0m
[0;33m2025-05-18 05:25:30,290  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 05:25:30,290  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-18 05:27:49,363  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-18 05:27:49,364  - INFO - - Train mean loss: 0.2043
- ET loss: 0.2551
- TC loss: 0.2122
- WT loss: 0.1456
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:27:49,365  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-18 05:28:21,142  - INFO - === [Epoch 60/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:31.7765s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.844 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.768 â”‚ 0.832 â”‚ 0.857 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.877 â”‚ 0.825 â”‚ 0.889 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.904 â”‚ 0.881 â”‚ 0.906 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1183, ET: 0.1574, TC: 0.1127, WT: 0.0849
[0m
[0;33m2025-05-18 05:28:21,142  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 05:28:21,142  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-18 05:30:40,260  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-18 05:30:40,262  - INFO - - Train mean loss: 0.1959
- ET loss: 0.2473
- TC loss: 0.2028
- WT loss: 0.1375
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:30:40,262  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-18 05:31:12,171  - INFO - === [Epoch 61/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:31.9081s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.848 â”‚ 0.888 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.775 â”‚ 0.833 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.851 â”‚ 0.906 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.859 â”‚ 0.889 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1168, ET: 0.1531, TC: 0.1125, WT: 0.0848
[0m
[1;31m2025-05-18 05:31:12,173  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch57_loss0.1171_dice0.8840_20250518051948.pth[0m
[0;32m2025-05-18 05:31:12,227  - INFO - âœ¨ Saved checkpoint (epoch 61) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch61_loss0.1168_dice0.8843_20250518053112.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 05:31:12,228  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-18 05:33:30,862  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-18 05:33:30,863  - INFO - - Train mean loss: 0.1931
- ET loss: 0.2437
- TC loss: 0.1995
- WT loss: 0.1362
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:33:30,863  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-18 05:34:02,713  - INFO - === [Epoch 62/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:31.8492s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.845 â”‚ 0.885 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.77  â”‚ 0.828 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.843 â”‚ 0.908 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.861 â”‚ 0.877 â”‚ 0.937 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1191, ET: 0.1562, TC: 0.1160, WT: 0.0850
[0m
[0;33m2025-05-18 05:34:02,713  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 05:34:02,713  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-18 05:36:21,372  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-18 05:36:21,374  - INFO - - Train mean loss: 0.1898
- ET loss: 0.2431
- TC loss: 0.1961
- WT loss: 0.1302
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:36:21,374  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-18 05:36:53,278  - INFO - === [Epoch 63/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:31.9033s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.845 â”‚ 0.889 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.818 â”‚ 0.772 â”‚ 0.833 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.842 â”‚ 0.902 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.9   â”‚ 0.867 â”‚ 0.895 â”‚ 0.937 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1185, ET: 0.1557, TC: 0.1117, WT: 0.0881
[0m
[0;33m2025-05-18 05:36:53,279  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 05:36:53,279  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-18 05:39:12,065  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-18 05:39:12,067  - INFO - - Train mean loss: 0.1906
- ET loss: 0.2410
- TC loss: 0.1971
- WT loss: 0.1337
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:39:12,067  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-18 05:39:44,160  - INFO - === [Epoch 64/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:32.0923s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.885 â”‚ 0.848 â”‚ 0.887 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.823 â”‚ 0.774 â”‚ 0.833 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.849 â”‚ 0.901 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.859 â”‚ 0.891 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1159, ET: 0.1532, TC: 0.1134, WT: 0.0812
[0m
[1;31m2025-05-18 05:39:44,162  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch61_loss0.1168_dice0.8843_20250518053112.pth[0m
[0;32m2025-05-18 05:39:44,217  - INFO - âœ¨ Saved checkpoint (epoch 64) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch64_loss0.1159_dice0.8851_20250518053944.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 05:39:44,218  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-18 05:42:02,954  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-18 05:42:02,955  - INFO - - Train mean loss: 0.1958
- ET loss: 0.2517
- TC loss: 0.2044
- WT loss: 0.1315
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:42:02,955  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-18 05:42:34,973  - INFO - === [Epoch 65/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:32.0168s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.882 â”‚ 0.844 â”‚ 0.883 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.82  â”‚ 0.771 â”‚ 0.828 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.903 â”‚ 0.857 â”‚ 0.909 â”‚ 0.942 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.85  â”‚ 0.879 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1189, ET: 0.1568, TC: 0.1177, WT: 0.0822
[0m
[0;33m2025-05-18 05:42:34,973  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 05:42:34,973  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-18 05:44:53,902  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-18 05:44:53,905  - INFO - - Train mean loss: 0.2077
- ET loss: 0.2643
- TC loss: 0.2149
- WT loss: 0.1437
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:44:53,905  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-18 05:45:26,142  - INFO - === [Epoch 66/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:32.2367s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.848 â”‚ 0.887 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.832 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.851 â”‚ 0.906 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.858 â”‚ 0.889 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1166, ET: 0.1535, TC: 0.1134, WT: 0.0831
[0m
[0;33m2025-05-18 05:45:26,143  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 05:45:26,143  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-18 05:47:44,995  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-18 05:47:44,997  - INFO - - Train mean loss: 0.1888
- ET loss: 0.2407
- TC loss: 0.1948
- WT loss: 0.1309
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:47:44,997  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-18 05:48:16,687  - INFO - === [Epoch 67/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:31.6893s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.846 â”‚ 0.888 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.773 â”‚ 0.833 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.834 â”‚ 0.892 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.905 â”‚ 0.875 â”‚ 0.903 â”‚ 0.935 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1169, ET: 0.1546, TC: 0.1131, WT: 0.0830
[0m
[0;33m2025-05-18 05:48:16,687  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 05:48:16,687  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-18 05:50:35,494  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-18 05:50:35,495  - INFO - - Train mean loss: 0.1981
- ET loss: 0.2521
- TC loss: 0.2063
- WT loss: 0.1360
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:50:35,495  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-18 05:51:07,485  - INFO - === [Epoch 68/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:31.9893s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.887 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.821 â”‚ 0.772 â”‚ 0.833 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.836 â”‚ 0.894 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.901 â”‚ 0.872 â”‚ 0.897 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1172, ET: 0.1545, TC: 0.1133, WT: 0.0837
[0m
[0;33m2025-05-18 05:51:07,485  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 05:51:07,485  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-18 05:53:26,350  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-18 05:53:26,352  - INFO - - Train mean loss: 0.2008
- ET loss: 0.2547
- TC loss: 0.2104
- WT loss: 0.1372
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:53:26,352  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-18 05:53:58,395  - INFO - === [Epoch 69/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:32.0422s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.885 â”‚ 0.848 â”‚ 0.887 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.823 â”‚ 0.775 â”‚ 0.832 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.863 â”‚ 0.907 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.849 â”‚ 0.886 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1160, ET: 0.1531, TC: 0.1134, WT: 0.0814
[0m
[0;33m2025-05-18 05:53:58,395  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 05:53:58,395  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-18 05:56:17,203  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-18 05:56:17,204  - INFO - - Train mean loss: 0.1905
- ET loss: 0.2426
- TC loss: 0.1974
- WT loss: 0.1316
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 05:56:17,205  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-18 05:56:49,249  - INFO - === [Epoch 70/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:32.0434s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.891 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.823 â”‚ 0.776 â”‚ 0.835 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.851 â”‚ 0.898 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.861 â”‚ 0.901 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1152, ET: 0.1525, TC: 0.1100, WT: 0.0830
[0m
[1;31m2025-05-18 05:56:49,251  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch64_loss0.1159_dice0.8851_20250518053944.pth[0m
[0;32m2025-05-18 05:56:49,308  - INFO - âœ¨ Saved checkpoint (epoch 70) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch70_loss0.1152_dice0.8859_20250518055649.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 05:56:49,309  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-18 05:59:08,358  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-18 05:59:08,360  - INFO - - Train mean loss: 0.1988
- ET loss: 0.2547
- TC loss: 0.2059
- WT loss: 0.1357
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 05:59:08,360  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-18 05:59:40,298  - INFO - === [Epoch 71/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:31.9365s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.884 â”‚ 0.847 â”‚ 0.887 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.822 â”‚ 0.774 â”‚ 0.832 â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.898 â”‚ 0.858 â”‚ 0.913 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.851 â”‚ 0.881 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1168, ET: 0.1538, TC: 0.1131, WT: 0.0835
[0m
[0;33m2025-05-18 05:59:40,298  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 05:59:40,298  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-18 06:01:58,983  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-18 06:01:58,984  - INFO - - Train mean loss: 0.1888
- ET loss: 0.2404
- TC loss: 0.1934
- WT loss: 0.1325
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:01:58,984  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-18 06:02:30,820  - INFO - === [Epoch 72/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:31.8347s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.883 â”‚ 0.847 â”‚ 0.891 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.819 â”‚ 0.773 â”‚ 0.835 â”‚ 0.849 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.878 â”‚ 0.84  â”‚ 0.895 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.903 â”‚ 0.869 â”‚ 0.902 â”‚ 0.939 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1179, ET: 0.1538, TC: 0.1100, WT: 0.0899
[0m
[0;33m2025-05-18 06:02:30,820  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 06:02:30,820  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-18 06:04:49,885  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-18 06:04:49,887  - INFO - - Train mean loss: 0.1949
- ET loss: 0.2474
- TC loss: 0.2036
- WT loss: 0.1337
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:04:49,887  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-18 06:05:21,811  - INFO - === [Epoch 73/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:31.9231s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.893 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.838 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.852 â”‚ 0.902 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.862 â”‚ 0.899 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1139, ET: 0.1514, TC: 0.1081, WT: 0.0823
[0m
[1;31m2025-05-18 06:05:21,813  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch70_loss0.1152_dice0.8859_20250518055649.pth[0m
[0;32m2025-05-18 06:05:21,869  - INFO - âœ¨ Saved checkpoint (epoch 73) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch73_loss0.1139_dice0.8872_20250518060521.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 06:05:21,869  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-18 06:07:40,782  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-18 06:07:40,784  - INFO - - Train mean loss: 0.1930
- ET loss: 0.2490
- TC loss: 0.2021
- WT loss: 0.1280
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:07:40,784  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-18 06:08:12,675  - INFO - === [Epoch 74/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:31.8899s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.891 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.823 â”‚ 0.777 â”‚ 0.836 â”‚ 0.858 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.858 â”‚ 0.914 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.855 â”‚ 0.884 â”‚ 0.934 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1150, ET: 0.1520, TC: 0.1097, WT: 0.0834
[0m
[0;33m2025-05-18 06:08:12,676  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 06:08:12,676  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-18 06:10:31,529  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-18 06:10:31,530  - INFO - - Train mean loss: 0.1894
- ET loss: 0.2388
- TC loss: 0.1934
- WT loss: 0.1359
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:10:31,530  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-18 06:11:03,367  - INFO - === [Epoch 75/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:31.8357s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.776 â”‚ 0.836 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.853 â”‚ 0.91  â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.86  â”‚ 0.887 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1144, ET: 0.1525, TC: 0.1101, WT: 0.0806
[0m
[0;33m2025-05-18 06:11:03,367  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 06:11:03,367  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-18 06:13:22,166  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-18 06:13:22,169  - INFO - - Train mean loss: 0.2010
- ET loss: 0.2572
- TC loss: 0.2118
- WT loss: 0.1340
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:13:22,169  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-18 06:13:53,884  - INFO - === [Epoch 76/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:31.7142s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.848 â”‚ 0.892 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.776 â”‚ 0.837 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.855 â”‚ 0.91  â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.858 â”‚ 0.889 â”‚ 0.926 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1143, ET: 0.1526, TC: 0.1088, WT: 0.0813
[0m
[0;33m2025-05-18 06:13:53,885  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 06:13:53,885  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-18 06:16:12,879  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-18 06:16:12,880  - INFO - - Train mean loss: 0.1885
- ET loss: 0.2393
- TC loss: 0.1953
- WT loss: 0.1309
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:16:12,880  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-18 06:16:44,879  - INFO - === [Epoch 77/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:31.9983s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.893 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.776 â”‚ 0.839 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.845 â”‚ 0.904 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.867 â”‚ 0.898 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1136, ET: 0.1525, TC: 0.1074, WT: 0.0810
[0m
[1;31m2025-05-18 06:16:44,881  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch73_loss0.1139_dice0.8872_20250518060521.pth[0m
[0;32m2025-05-18 06:16:44,935  - INFO - âœ¨ Saved checkpoint (epoch 77) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch77_loss0.1136_dice0.8874_20250518061644.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 06:16:44,935  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-18 06:19:03,543  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-18 06:19:03,546  - INFO - - Train mean loss: 0.1864
- ET loss: 0.2418
- TC loss: 0.1936
- WT loss: 0.1239
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:19:03,546  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-18 06:19:35,579  - INFO - === [Epoch 78/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:32.0318s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.89  â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.824 â”‚ 0.775 â”‚ 0.835 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.844 â”‚ 0.904 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.895 â”‚ 0.867 â”‚ 0.893 â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1147, ET: 0.1526, TC: 0.1106, WT: 0.0810
[0m
[0;33m2025-05-18 06:19:35,579  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 06:19:35,579  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-18 06:21:54,478  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-18 06:21:54,479  - INFO - - Train mean loss: 0.1902
- ET loss: 0.2435
- TC loss: 0.1929
- WT loss: 0.1342
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:21:54,479  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-18 06:22:26,324  - INFO - === [Epoch 79/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:31.8443s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.889 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.824 â”‚ 0.776 â”‚ 0.835 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.844 â”‚ 0.906 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.868 â”‚ 0.892 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1150, ET: 0.1524, TC: 0.1112, WT: 0.0815
[0m
[0;33m2025-05-18 06:22:26,324  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 06:22:26,324  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-18 06:24:45,554  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-18 06:24:45,555  - INFO - - Train mean loss: 0.2010
- ET loss: 0.2541
- TC loss: 0.2081
- WT loss: 0.1409
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:24:45,555  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-18 06:25:17,586  - INFO - === [Epoch 80/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:32.0296s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.888 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.824 â”‚ 0.776 â”‚ 0.834 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.853 â”‚ 0.907 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.86  â”‚ 0.889 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1153, ET: 0.1524, TC: 0.1123, WT: 0.0813
[0m
[0;33m2025-05-18 06:25:17,586  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 06:25:17,586  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-18 06:27:36,788  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-18 06:27:36,789  - INFO - - Train mean loss: 0.1892
- ET loss: 0.2413
- TC loss: 0.1961
- WT loss: 0.1301
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:27:36,789  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-18 06:28:09,117  - INFO - === [Epoch 81/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:32.3266s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.891 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.776 â”‚ 0.836 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.843 â”‚ 0.897 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.868 â”‚ 0.901 â”‚ 0.928 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1143, ET: 0.1525, TC: 0.1095, WT: 0.0810
[0m
[0;33m2025-05-18 06:28:09,117  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 06:28:09,117  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-18 06:30:27,656  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-18 06:30:27,658  - INFO - - Train mean loss: 0.1837
- ET loss: 0.2329
- TC loss: 0.1860
- WT loss: 0.1321
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:30:27,659  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-18 06:31:00,428  - INFO - === [Epoch 82/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:32.7686s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.776 â”‚ 0.837 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.84  â”‚ 0.899 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.872 â”‚ 0.9   â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1139, ET: 0.1524, TC: 0.1092, WT: 0.0802
[0m
[0;33m2025-05-18 06:31:00,428  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 06:31:00,428  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-18 06:33:19,402  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-18 06:33:19,403  - INFO - - Train mean loss: 0.2112
- ET loss: 0.2638
- TC loss: 0.2196
- WT loss: 0.1503
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:33:19,403  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-18 06:33:51,658  - INFO - === [Epoch 83/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:32.2545s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.889 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.835 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.853 â”‚ 0.908 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.861 â”‚ 0.889 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1146, ET: 0.1519, TC: 0.1117, WT: 0.0804
[0m
[0;33m2025-05-18 06:33:51,658  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 06:33:51,658  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-18 06:36:10,863  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-18 06:36:10,865  - INFO - - Train mean loss: 0.1891
- ET loss: 0.2409
- TC loss: 0.1927
- WT loss: 0.1337
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:36:10,865  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-18 06:36:42,739  - INFO - === [Epoch 84/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:31.8730s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.777 â”‚ 0.836 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.85  â”‚ 0.902 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.864 â”‚ 0.896 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1138, ET: 0.1513, TC: 0.1098, WT: 0.0802
[0m
[0;33m2025-05-18 06:36:42,739  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 06:36:42,739  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-18 06:39:01,539  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-18 06:39:01,540  - INFO - - Train mean loss: 0.1859
- ET loss: 0.2391
- TC loss: 0.1877
- WT loss: 0.1309
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:39:01,540  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-18 06:39:33,521  - INFO - === [Epoch 85/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:31.9801s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.89  â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.778 â”‚ 0.836 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.854 â”‚ 0.906 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.859 â”‚ 0.891 â”‚ 0.922 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1138, ET: 0.1513, TC: 0.1103, WT: 0.0799
[0m
[0;33m2025-05-18 06:39:33,522  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-18 06:39:33,522  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-18 06:41:52,397  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-18 06:41:52,399  - INFO - - Train mean loss: 0.1898
- ET loss: 0.2452
- TC loss: 0.1961
- WT loss: 0.1281
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:41:52,399  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-18 06:42:24,783  - INFO - === [Epoch 86/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:32.3829s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.89  â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.824 â”‚ 0.776 â”‚ 0.835 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.849 â”‚ 0.909 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.863 â”‚ 0.889 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1150, ET: 0.1522, TC: 0.1108, WT: 0.0820
[0m
[0;33m2025-05-18 06:42:24,783  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-18 06:42:24,783  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-18 06:44:43,686  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-18 06:44:43,687  - INFO - - Train mean loss: 0.1953
- ET loss: 0.2463
- TC loss: 0.2021
- WT loss: 0.1376
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:44:43,687  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-18 06:45:15,843  - INFO - === [Epoch 87/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:32.1552s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.886 â”‚ 0.849 â”‚ 0.89  â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.824 â”‚ 0.777 â”‚ 0.837 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.85  â”‚ 0.907 â”‚ 0.916 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.863 â”‚ 0.893 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1146, ET: 0.1517, TC: 0.1101, WT: 0.0821
[0m
[0;33m2025-05-18 06:45:15,844  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-18 06:45:15,844  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-18 06:47:34,536  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-18 06:47:34,537  - INFO - - Train mean loss: 0.1939
- ET loss: 0.2471
- TC loss: 0.2008
- WT loss: 0.1339
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:47:34,537  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-18 06:48:06,499  - INFO - === [Epoch 88/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:31.9606s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.848 â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.776 â”‚ 0.837 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.844 â”‚ 0.902 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.869 â”‚ 0.898 â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1144, ET: 0.1526, TC: 0.1099, WT: 0.0806
[0m
[0;33m2025-05-18 06:48:06,499  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-18 06:48:06,499  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-18 06:50:25,373  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-18 06:50:25,374  - INFO - - Train mean loss: 0.1947
- ET loss: 0.2465
- TC loss: 0.1997
- WT loss: 0.1379
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:50:25,374  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-18 06:50:57,445  - INFO - === [Epoch 89/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:32.0704s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.891 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.836 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.852 â”‚ 0.906 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.862 â”‚ 0.893 â”‚ 0.933 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1143, ET: 0.1518, TC: 0.1096, WT: 0.0817
[0m
[0;33m2025-05-18 06:50:57,446  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[0;32m2025-05-18 06:50:57,446  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-18 06:53:15,972  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-18 06:53:15,973  - INFO - - Train mean loss: 0.1900
- ET loss: 0.2449
- TC loss: 0.1972
- WT loss: 0.1278
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 06:53:15,973  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-18 06:53:47,990  - INFO - === [Epoch 90/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:32.0157s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.778 â”‚ 0.836 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.854 â”‚ 0.905 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.861 â”‚ 0.893 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1139, ET: 0.1512, TC: 0.1099, WT: 0.0805
[0m
[0;33m2025-05-18 06:53:47,990  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 13/100[0m
[0;32m2025-05-18 06:53:47,990  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-18 06:56:07,699  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-18 06:56:07,701  - INFO - - Train mean loss: 0.1958
- ET loss: 0.2476
- TC loss: 0.2012
- WT loss: 0.1385
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 06:56:07,701  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-18 06:56:39,508  - INFO - === [Epoch 91/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:31.8063s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.888 â”‚ 0.85  â”‚ 0.893 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.778 â”‚ 0.838 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.848 â”‚ 0.905 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.898 â”‚ 0.867 â”‚ 0.897 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1134, ET: 0.1511, TC: 0.1077, WT: 0.0814
[0m
[1;31m2025-05-18 06:56:39,510  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch77_loss0.1136_dice0.8874_20250518061644.pth[0m
[0;32m2025-05-18 06:56:39,567  - INFO - âœ¨ Saved checkpoint (epoch 91) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch91_loss0.1134_dice0.8876_20250518065639.pth;             Size 14.23 MB[0m
[0;32m2025-05-18 06:56:39,568  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-18 06:58:58,525  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-18 06:58:58,526  - INFO - - Train mean loss: 0.2052
- ET loss: 0.2602
- TC loss: 0.2122
- WT loss: 0.1434
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 06:58:58,526  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-18 06:59:30,608  - INFO - === [Epoch 92/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:32.0809s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.889 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.835 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.854 â”‚ 0.906 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.86  â”‚ 0.89  â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1145, ET: 0.1523, TC: 0.1113, WT: 0.0798
[0m
[0;33m2025-05-18 06:59:30,608  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 06:59:30,608  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-18 07:01:50,332  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-18 07:01:50,333  - INFO - - Train mean loss: 0.1974
- ET loss: 0.2520
- TC loss: 0.2051
- WT loss: 0.1350
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 07:01:50,333  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-18 07:02:22,274  - INFO - === [Epoch 93/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:31.9403s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.892 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.838 â”‚ 0.861 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.846 â”‚ 0.903 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.867 â”‚ 0.897 â”‚ 0.932 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1139, ET: 0.1517, TC: 0.1085, WT: 0.0814
[0m
[0;33m2025-05-18 07:02:22,275  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 07:02:22,275  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-18 07:04:41,180  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-18 07:04:41,182  - INFO - - Train mean loss: 0.1927
- ET loss: 0.2446
- TC loss: 0.1973
- WT loss: 0.1361
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 07:04:41,182  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-18 07:05:13,250  - INFO - === [Epoch 94/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:32.0662s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.888 â”‚ 0.85  â”‚ 0.893 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.777 â”‚ 0.838 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.851 â”‚ 0.906 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.863 â”‚ 0.895 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1135, ET: 0.1514, TC: 0.1079, WT: 0.0811
[0m
[0;33m2025-05-18 07:05:13,250  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 07:05:13,250  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-18 07:07:32,295  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-18 07:07:32,296  - INFO - - Train mean loss: 0.1925
- ET loss: 0.2466
- TC loss: 0.1976
- WT loss: 0.1332
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 07:07:32,296  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-18 07:08:04,262  - INFO - === [Epoch 95/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:31.9645s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.892 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.777 â”‚ 0.838 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.847 â”‚ 0.902 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.899 â”‚ 0.867 â”‚ 0.899 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1136, ET: 0.1516, TC: 0.1081, WT: 0.0811
[0m
[0;33m2025-05-18 07:08:04,262  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 07:08:04,262  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-18 07:10:22,922  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-18 07:10:22,923  - INFO - - Train mean loss: 0.2001
- ET loss: 0.2564
- TC loss: 0.2084
- WT loss: 0.1355
- Cost time: 2.31mins â±ï¸
[0m
[0;32m2025-05-18 07:10:22,923  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-18 07:10:54,872  - INFO - === [Epoch 96/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:31.9473s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.89  â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.777 â”‚ 0.836 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.898 â”‚ 0.856 â”‚ 0.908 â”‚ 0.93  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.891 â”‚ 0.859 â”‚ 0.89  â”‚ 0.925 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1141, ET: 0.1516, TC: 0.1110, WT: 0.0796
[0m
[0;33m2025-05-18 07:10:54,872  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 07:10:54,872  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-18 07:13:14,434  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-18 07:13:14,436  - INFO - - Train mean loss: 0.1832
- ET loss: 0.2337
- TC loss: 0.1842
- WT loss: 0.1318
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 07:13:14,436  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-18 07:13:46,680  - INFO - === [Epoch 97/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:32.2429s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.777 â”‚ 0.837 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.849 â”‚ 0.903 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.897 â”‚ 0.865 â”‚ 0.896 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1137, ET: 0.1515, TC: 0.1095, WT: 0.0801
[0m
[0;33m2025-05-18 07:13:46,680  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 07:13:46,680  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-18 07:16:06,254  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-18 07:16:06,255  - INFO - - Train mean loss: 0.1996
- ET loss: 0.2553
- TC loss: 0.2053
- WT loss: 0.1382
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 07:16:06,255  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-18 07:16:38,448  - INFO - === [Epoch 98/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:32.1915s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.891 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.837 â”‚ 0.862 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.852 â”‚ 0.904 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.896 â”‚ 0.862 â”‚ 0.895 â”‚ 0.931 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1139, ET: 0.1514, TC: 0.1095, WT: 0.0807
[0m
[0;33m2025-05-18 07:16:38,448  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 07:16:38,448  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-18 07:18:58,064  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-18 07:18:58,065  - INFO - - Train mean loss: 0.1841
- ET loss: 0.2341
- TC loss: 0.1882
- WT loss: 0.1298
- Cost time: 2.33mins â±ï¸
[0m
[0;32m2025-05-18 07:18:58,065  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-18 07:19:30,007  - INFO - === [Epoch 99/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:31.9411s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.849 â”‚ 0.889 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.825 â”‚ 0.777 â”‚ 0.835 â”‚ 0.864 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.853 â”‚ 0.908 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.861 â”‚ 0.889 â”‚ 0.927 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1145, ET: 0.1519, TC: 0.1119, WT: 0.0796
[0m
[0;33m2025-05-18 07:19:30,008  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-18 07:19:30,008  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-18 07:21:49,074  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-18 07:21:49,075  - INFO - - Train mean loss: 0.1924
- ET loss: 0.2447
- TC loss: 0.1966
- WT loss: 0.1358
- Cost time: 2.32mins â±ï¸
[0m
[0;32m2025-05-18 07:21:49,075  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-18 07:22:20,897  - INFO - === [Epoch 100/100] ===
- Model:    ResUNetBaseline_S_DCLAv1_SLKv2_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:31.8204s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.887 â”‚ 0.85  â”‚ 0.892 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.826 â”‚ 0.778 â”‚ 0.837 â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.853 â”‚ 0.906 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.861 â”‚ 0.893 â”‚ 0.929 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1137, ET: 0.1513, TC: 0.1090, WT: 0.0807
[0m
[0;33m2025-05-18 07:22:20,897  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[1;31m2025-05-18 07:22:22,106  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1134 at epoch 91[0m
[0;32m2025-05-18 07:22:22,106  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-18 07:22:22,114  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/ResUNetBaseline_S_DCLAv1_SLKv2_v2_final_model.pth[0m
[1;31m2025-05-18 07:22:22,114  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-18 07:22:22,114  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-18 07:25:48,984  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚  0.824 â”‚ 0.883 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.811 â”‚  0.746 â”‚ 0.821 â”‚ 0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚  0.823 â”‚ 0.917 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚  0.844 â”‚ 0.88  â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  6.828 â”‚ 11.134 â”‚ 5.732 â”‚ 3.618 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1231;ET: 0.1767;ET: 0.1767;TC: 0.1172;WT: 0.0755
[0m
[0;32m2025-05-18 07:25:48,985  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-18 07:25:48,985  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_DCLAv1_SLKv2_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-18.log[0m
[0;32m2025-05-18 07:25:55,319  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-18 07:25:58,586  - INFO - Total number of parameters: 0.82 M[0m
[0;32m2025-05-18 07:25:58,589  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-18 07:25:58,589  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-18 07:25:58,589  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-18 07:25:58,589  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-18 07:25:58,589  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-18 07:25:58,596  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-18 07:25:58,596  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-18 07:25:58,596  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-18 07:25:58,600  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ DCLA_UNet_v2_3                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.82 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-18 07:26:01,441  - INFO - 
model: DCLA_UNet_v2_3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-18 07:26:01,442  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-18 07:30:50,276  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-18 07:30:50,278  - INFO - - Train mean loss: 0.5470
- ET loss: 0.5690
- TC loss: 0.6068
- WT loss: 0.4652
- Cost time: 4.81mins â±ï¸
[0m
[0;32m2025-05-18 07:30:50,278  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-18 07:31:28,465  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:38.1854s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.628 â”‚ 0.626 â”‚ 0.47  â”‚ 0.788 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.496 â”‚ 0.486 â”‚ 0.334 â”‚ 0.67  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.572 â”‚ 0.543 â”‚ 0.348 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.843 â”‚ 0.828 â”‚ 0.917 â”‚ 0.784 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3819, ET: 0.3866, TC: 0.5361, WT: 0.2229
[0m
[0;32m2025-05-18 07:31:28,541  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.3819_dice0.6279_20250518073128.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 07:31:28,541  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-18 07:36:15,873  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-18 07:36:15,874  - INFO - - Train mean loss: 0.4414
- ET loss: 0.4451
- TC loss: 0.5507
- WT loss: 0.3286
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 07:36:15,874  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-18 07:36:53,453  - INFO - === [Epoch 2/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:37.5768s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.64  â”‚ 0.653 â”‚ 0.47  â”‚ 0.798 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.513 â”‚ 0.519 â”‚ 0.334 â”‚ 0.685 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.575 â”‚ 0.559 â”‚ 0.346 â”‚ 0.82  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.863 â”‚ 0.933 â”‚ 0.804 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3681, ET: 0.3599, TC: 0.5346, WT: 0.2097
[0m
[0;32m2025-05-18 07:36:53,529  - INFO - âœ¨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.3681_dice0.6401_20250518073653.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 07:36:53,529  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-18 07:41:40,677  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-18 07:41:40,679  - INFO - - Train mean loss: 0.4116
- ET loss: 0.4016
- TC loss: 0.5311
- WT loss: 0.3021
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 07:41:40,679  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-18 07:42:18,154  - INFO - === [Epoch 3/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:37.4745s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.718 â”‚ 0.707 â”‚ 0.629 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.598 â”‚ 0.583 â”‚ 0.499 â”‚ 0.711 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.687 â”‚ 0.639 â”‚ 0.553 â”‚ 0.868 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.835 â”‚ 0.843 â”‚ 0.866 â”‚ 0.797 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2919, ET: 0.3001, TC: 0.3803, WT: 0.1954
[0m
[1;31m2025-05-18 07:42:18,156  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch2_loss0.3681_dice0.6401_20250518073653.pth[0m
[0;32m2025-05-18 07:42:18,615  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.2919_dice0.7178_20250518074218.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 07:42:18,615  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-18 07:47:05,458  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-18 07:47:05,459  - INFO - - Train mean loss: 0.3591
- ET loss: 0.3943
- TC loss: 0.4050
- WT loss: 0.2780
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 07:47:05,459  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-18 07:47:42,941  - INFO - === [Epoch 4/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:37.4813s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.776 â”‚ 0.744 â”‚ 0.751 â”‚ 0.831 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.666 â”‚ 0.632 â”‚ 0.639 â”‚ 0.729 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.766 â”‚ 0.699 â”‚ 0.73  â”‚ 0.87  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.832 â”‚ 0.842 â”‚ 0.834 â”‚ 0.819 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2315, ET: 0.2605, TC: 0.2584, WT: 0.1755
[0m
[1;31m2025-05-18 07:47:42,943  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.2919_dice0.7178_20250518074218.pth[0m
[0;32m2025-05-18 07:47:43,017  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.2315_dice0.7756_20250518074742.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 07:47:43,018  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-18 07:52:29,962  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-18 07:52:29,963  - INFO - - Train mean loss: 0.3141
- ET loss: 0.3489
- TC loss: 0.3463
- WT loss: 0.2471
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 07:52:29,963  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-18 07:53:07,281  - INFO - === [Epoch 5/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:37.3165s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.786 â”‚ 0.762 â”‚ 0.758 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.681 â”‚ 0.657 â”‚ 0.649 â”‚ 0.736 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.765 â”‚ 0.732 â”‚ 0.732 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.846 â”‚ 0.83  â”‚ 0.845 â”‚ 0.865 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2211, ET: 0.2428, TC: 0.2498, WT: 0.1708
[0m
[1;31m2025-05-18 07:53:07,282  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.2315_dice0.7756_20250518074742.pth[0m
[0;32m2025-05-18 07:53:07,358  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.2211_dice0.7856_20250518075307.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 07:53:07,359  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-18 07:57:54,924  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-18 07:57:54,926  - INFO - - Train mean loss: 0.3094
- ET loss: 0.3474
- TC loss: 0.3407
- WT loss: 0.2401
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 07:57:54,926  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-18 07:58:32,562  - INFO - === [Epoch 6/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:37.6353s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.792 â”‚ 0.774 â”‚ 0.764 â”‚ 0.838 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.691 â”‚ 0.673 â”‚ 0.659 â”‚ 0.739 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.779 â”‚ 0.77  â”‚ 0.749 â”‚ 0.819 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.84  â”‚ 0.808 â”‚ 0.831 â”‚ 0.881 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2151, ET: 0.2303, TC: 0.2423, WT: 0.1729
[0m
[1;31m2025-05-18 07:58:32,564  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.2211_dice0.7856_20250518075307.pth[0m
[0;32m2025-05-18 07:58:32,636  - INFO - âœ¨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.2151_dice0.7919_20250518075832.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 07:58:32,637  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-18 08:03:19,789  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-18 08:03:19,790  - INFO - - Train mean loss: 0.2912
- ET loss: 0.3255
- TC loss: 0.3196
- WT loss: 0.2286
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:03:19,790  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-18 08:03:57,441  - INFO - === [Epoch 7/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:37.6492s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.81  â”‚ 0.785 â”‚ 0.791 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.714 â”‚ 0.687 â”‚ 0.693 â”‚ 0.761 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.837 â”‚ 0.79  â”‚ 0.841 â”‚ 0.881 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.815 â”‚ 0.81  â”‚ 0.787 â”‚ 0.85  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1952, ET: 0.2192, TC: 0.2136, WT: 0.1527
[0m
[1;31m2025-05-18 08:03:57,442  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch6_loss0.2151_dice0.7919_20250518075832.pth[0m
[0;32m2025-05-18 08:03:57,517  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.1952_dice0.8099_20250518080357.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 08:03:57,517  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-18 08:08:44,524  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-18 08:08:44,525  - INFO - - Train mean loss: 0.3024
- ET loss: 0.3461
- TC loss: 0.3380
- WT loss: 0.2230
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 08:08:44,526  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-18 08:09:21,921  - INFO - === [Epoch 8/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:37.3940s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.813 â”‚ 0.788 â”‚ 0.798 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.718 â”‚ 0.691 â”‚ 0.702 â”‚ 0.763 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.83  â”‚ 0.795 â”‚ 0.799 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.827 â”‚ 0.807 â”‚ 0.839 â”‚ 0.835 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1909, ET: 0.2161, TC: 0.2068, WT: 0.1499
[0m
[1;31m2025-05-18 08:09:21,922  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.1952_dice0.8099_20250518080357.pth[0m
[0;32m2025-05-18 08:09:21,996  - INFO - âœ¨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch8_loss0.1909_dice0.8134_20250518080921.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 08:09:21,997  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-18 08:14:09,212  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-18 08:14:09,213  - INFO - - Train mean loss: 0.2774
- ET loss: 0.3195
- TC loss: 0.3054
- WT loss: 0.2074
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:14:09,213  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-18 08:14:46,713  - INFO - === [Epoch 9/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:37.4991s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.821 â”‚ 0.789 â”‚ 0.809 â”‚ 0.865 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.728 â”‚ 0.692 â”‚ 0.716 â”‚ 0.776 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.806 â”‚ 0.772 â”‚ 0.791 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.865 â”‚ 0.835 â”‚ 0.865 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1841, ET: 0.2154, TC: 0.1960, WT: 0.1411
[0m
[1;31m2025-05-18 08:14:46,715  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch8_loss0.1909_dice0.8134_20250518080921.pth[0m
[0;32m2025-05-18 08:14:46,786  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.1841_dice0.8211_20250518081446.pth;             Size 10.45 MB[0m
[0;32m2025-05-18 08:14:46,787  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-18 08:19:34,110  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-18 08:19:34,111  - INFO - - Train mean loss: 0.2750
- ET loss: 0.3132
- TC loss: 0.2980
- WT loss: 0.2139
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:19:34,111  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-18 08:20:11,621  - INFO - === [Epoch 10/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:37.5085s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.797 â”‚ 0.811 â”‚ 0.87  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.735 â”‚ 0.703 â”‚ 0.721 â”‚ 0.782 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.822 â”‚ 0.804 â”‚ 0.806 â”‚ 0.855 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.857 â”‚ 0.814 â”‚ 0.855 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1794, ET: 0.2067, TC: 0.1939, WT: 0.1375
[0m
[1;31m2025-05-18 08:20:11,622  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.1841_dice0.8211_20250518081446.pth[0m
[0;32m2025-05-18 08:20:11,695  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.1794_dice0.8259_20250518082011.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 08:20:11,695  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-18 08:24:59,003  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-18 08:24:59,004  - INFO - - Train mean loss: 0.2711
- ET loss: 0.3104
- TC loss: 0.2950
- WT loss: 0.2080
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:24:59,005  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-18 08:25:36,431  - INFO - === [Epoch 11/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:37.4250s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.826 â”‚ 0.79  â”‚ 0.816 â”‚ 0.87  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.738 â”‚ 0.697 â”‚ 0.731 â”‚ 0.788 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.868 â”‚ 0.843 â”‚ 0.863 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.814 â”‚ 0.771 â”‚ 0.808 â”‚ 0.864 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1785, ET: 0.2130, TC: 0.1875, WT: 0.1348
[0m
[1;31m2025-05-18 08:25:36,432  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.1794_dice0.8259_20250518082011.pth[0m
[0;32m2025-05-18 08:25:36,505  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.1785_dice0.8256_20250518082536.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 08:25:36,505  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-18 08:30:23,594  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-18 08:30:23,595  - INFO - - Train mean loss: 0.2905
- ET loss: 0.3354
- TC loss: 0.3171
- WT loss: 0.2191
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 08:30:23,595  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-18 08:31:01,119  - INFO - === [Epoch 12/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:37.5229s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.832 â”‚ 0.803 â”‚ 0.817 â”‚ 0.875 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.745 â”‚ 0.711 â”‚ 0.73  â”‚ 0.793 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.827 â”‚ 0.794 â”‚ 0.798 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.865 â”‚ 0.839 â”‚ 0.876 â”‚ 0.882 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1726, ET: 0.2007, TC: 0.1874, WT: 0.1298
[0m
[1;31m2025-05-18 08:31:01,121  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.1785_dice0.8256_20250518082536.pth[0m
[0;32m2025-05-18 08:31:01,192  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.1726_dice0.8317_20250518083101.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 08:31:01,193  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-18 08:35:48,622  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-18 08:35:48,623  - INFO - - Train mean loss: 0.2677
- ET loss: 0.3141
- TC loss: 0.2922
- WT loss: 0.1968
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:35:48,623  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-18 08:36:26,185  - INFO - === [Epoch 13/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:37.5612s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.831 â”‚ 0.802 â”‚ 0.813 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.744 â”‚ 0.711 â”‚ 0.725 â”‚ 0.796 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.825 â”‚ 0.794 â”‚ 0.79  â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.837 â”‚ 0.881 â”‚ 0.88  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1728, ET: 0.2008, TC: 0.1905, WT: 0.1270
[0m
[0;33m2025-05-18 08:36:26,186  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 08:36:26,186  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-18 08:41:13,024  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-18 08:41:13,026  - INFO - - Train mean loss: 0.2629
- ET loss: 0.3046
- TC loss: 0.2815
- WT loss: 0.2028
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 08:41:13,026  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-18 08:41:50,244  - INFO - === [Epoch 14/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:37.2172s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.838 â”‚ 0.807 â”‚ 0.831 â”‚ 0.875 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.754 â”‚ 0.718 â”‚ 0.749 â”‚ 0.795 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.863 â”‚ 0.825 â”‚ 0.84  â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.839 â”‚ 0.815 â”‚ 0.855 â”‚ 0.848 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1653, ET: 0.1955, TC: 0.1718, WT: 0.1287
[0m
[1;31m2025-05-18 08:41:50,246  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.1726_dice0.8317_20250518083101.pth[0m
[0;32m2025-05-18 08:41:50,317  - INFO - âœ¨ Saved checkpoint (epoch 14) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch14_loss0.1653_dice0.8379_20250518084150.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 08:41:50,318  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-18 08:46:37,303  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-18 08:46:37,304  - INFO - - Train mean loss: 0.2579
- ET loss: 0.3029
- TC loss: 0.2783
- WT loss: 0.1924
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 08:46:37,305  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-18 08:47:14,647  - INFO - === [Epoch 15/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:37.3413s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.841 â”‚ 0.809 â”‚ 0.832 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.757 â”‚ 0.718 â”‚ 0.749 â”‚ 0.804 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.845 â”‚ 0.803 â”‚ 0.828 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.861 â”‚ 0.837 â”‚ 0.868 â”‚ 0.879 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1621, ET: 0.1939, TC: 0.1712, WT: 0.1214
[0m
[1;31m2025-05-18 08:47:14,648  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch14_loss0.1653_dice0.8379_20250518084150.pth[0m
[0;32m2025-05-18 08:47:14,721  - INFO - âœ¨ Saved checkpoint (epoch 15) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch15_loss0.1621_dice0.8409_20250518084714.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 08:47:14,721  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-18 08:52:02,343  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-18 08:52:02,345  - INFO - - Train mean loss: 0.2605
- ET loss: 0.3054
- TC loss: 0.2806
- WT loss: 0.1954
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:52:02,345  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-18 08:52:39,889  - INFO - === [Epoch 16/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:37.5410s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.843 â”‚ 0.811 â”‚ 0.839 â”‚ 0.879 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.761 â”‚ 0.723 â”‚ 0.759 â”‚ 0.801 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.859 â”‚ 0.82  â”‚ 0.843 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.851 â”‚ 0.824 â”‚ 0.864 â”‚ 0.867 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1599, ET: 0.1917, TC: 0.1640, WT: 0.1241
[0m
[1;31m2025-05-18 08:52:39,891  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch15_loss0.1621_dice0.8409_20250518084714.pth[0m
[0;32m2025-05-18 08:52:39,967  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.1599_dice0.8430_20250518085239.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 08:52:39,968  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-18 08:57:27,425  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-18 08:57:27,426  - INFO - - Train mean loss: 0.2500
- ET loss: 0.2927
- TC loss: 0.2671
- WT loss: 0.1901
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 08:57:27,426  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-18 08:58:04,959  - INFO - === [Epoch 17/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:37.5301s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.843 â”‚ 0.809 â”‚ 0.835 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.759 â”‚ 0.72  â”‚ 0.753 â”‚ 0.804 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.828 â”‚ 0.795 â”‚ 0.811 â”‚ 0.878 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.849 â”‚ 0.89  â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1607, ET: 0.1937, TC: 0.1679, WT: 0.1206
[0m
[0;33m2025-05-18 08:58:04,959  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 08:58:04,959  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-18 09:02:52,179  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-18 09:02:52,180  - INFO - - Train mean loss: 0.2568
- ET loss: 0.3051
- TC loss: 0.2755
- WT loss: 0.1900
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:02:52,180  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-18 09:03:29,719  - INFO - === [Epoch 18/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:37.5377s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.845 â”‚ 0.809 â”‚ 0.842 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.765 â”‚ 0.721 â”‚ 0.765 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.852 â”‚ 0.809 â”‚ 0.847 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.861 â”‚ 0.834 â”‚ 0.864 â”‚ 0.887 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1574, ET: 0.1935, TC: 0.1600, WT: 0.1187
[0m
[1;31m2025-05-18 09:03:29,720  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.1599_dice0.8430_20250518085239.pth[0m
[0;32m2025-05-18 09:03:29,794  - INFO - âœ¨ Saved checkpoint (epoch 18) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch18_loss0.1574_dice0.8451_20250518090329.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:03:29,794  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-18 09:08:17,233  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-18 09:08:17,235  - INFO - - Train mean loss: 0.2544
- ET loss: 0.3010
- TC loss: 0.2708
- WT loss: 0.1914
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:08:17,235  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-18 09:08:54,623  - INFO - === [Epoch 19/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:37.3871s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.847 â”‚ 0.813 â”‚ 0.843 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.768 â”‚ 0.725 â”‚ 0.766 â”‚ 0.811 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.827 â”‚ 0.851 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.852 â”‚ 0.825 â”‚ 0.866 â”‚ 0.864 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1552, ET: 0.1897, TC: 0.1595, WT: 0.1166
[0m
[1;31m2025-05-18 09:08:54,625  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch18_loss0.1574_dice0.8451_20250518090329.pth[0m
[0;32m2025-05-18 09:08:54,697  - INFO - âœ¨ Saved checkpoint (epoch 19) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch19_loss0.1552_dice0.8472_20250518090854.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:08:54,698  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-18 09:13:42,339  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-18 09:13:42,341  - INFO - - Train mean loss: 0.2439
- ET loss: 0.2917
- TC loss: 0.2600
- WT loss: 0.1801
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:13:42,341  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-18 09:14:19,690  - INFO - === [Epoch 20/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:37.3480s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.844 â”‚ 0.804 â”‚ 0.844 â”‚ 0.883 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.763 â”‚ 0.712 â”‚ 0.768 â”‚ 0.809 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.843 â”‚ 0.773 â”‚ 0.833 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.863 â”‚ 0.884 â”‚ 0.863 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1583, ET: 0.1979, TC: 0.1575, WT: 0.1195
[0m
[0;33m2025-05-18 09:14:19,690  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 09:14:19,690  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-18 09:19:07,035  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-18 09:19:07,036  - INFO - - Train mean loss: 0.2507
- ET loss: 0.3027
- TC loss: 0.2684
- WT loss: 0.1810
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:19:07,036  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-18 09:19:44,596  - INFO - === [Epoch 21/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:37.5599s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.852 â”‚ 0.814 â”‚ 0.851 â”‚ 0.89  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.773 â”‚ 0.725 â”‚ 0.777 â”‚ 0.816 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.859 â”‚ 0.805 â”‚ 0.867 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.868 â”‚ 0.848 â”‚ 0.863 â”‚ 0.893 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1509, ET: 0.1886, TC: 0.1510, WT: 0.1130
[0m
[1;31m2025-05-18 09:19:44,598  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch19_loss0.1552_dice0.8472_20250518090854.pth[0m
[0;32m2025-05-18 09:19:44,671  - INFO - âœ¨ Saved checkpoint (epoch 21) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.1509_dice0.8516_20250518091944.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:19:44,671  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-18 09:24:31,879  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-18 09:24:31,880  - INFO - - Train mean loss: 0.2519
- ET loss: 0.3001
- TC loss: 0.2680
- WT loss: 0.1878
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:24:31,880  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-18 09:25:09,328  - INFO - === [Epoch 22/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:37.4470s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.818 â”‚ 0.856 â”‚ 0.891 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.778 â”‚ 0.732 â”‚ 0.783 â”‚ 0.819 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.87  â”‚ 0.816 â”‚ 0.867 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.847 â”‚ 0.87  â”‚ 0.875 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1473, ET: 0.1839, TC: 0.1464, WT: 0.1114
[0m
[1;31m2025-05-18 09:25:09,330  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch21_loss0.1509_dice0.8516_20250518091944.pth[0m
[0;32m2025-05-18 09:25:09,401  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.1473_dice0.8551_20250518092509.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:25:09,401  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-18 09:29:56,652  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-18 09:29:56,654  - INFO - - Train mean loss: 0.2311
- ET loss: 0.2789
- TC loss: 0.2414
- WT loss: 0.1729
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:29:56,654  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-18 09:30:34,151  - INFO - === [Epoch 23/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:37.4962s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.85  â”‚ 0.815 â”‚ 0.847 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.773 â”‚ 0.729 â”‚ 0.773 â”‚ 0.815 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.886 â”‚ 0.838 â”‚ 0.886 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.841 â”‚ 0.818 â”‚ 0.837 â”‚ 0.867 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1519, ET: 0.1866, TC: 0.1545, WT: 0.1146
[0m
[0;33m2025-05-18 09:30:34,151  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 09:30:34,151  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-18 09:35:21,881  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-18 09:35:21,882  - INFO - - Train mean loss: 0.2299
- ET loss: 0.2767
- TC loss: 0.2397
- WT loss: 0.1733
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 09:35:21,882  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-18 09:35:59,419  - INFO - === [Epoch 24/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:37.5352s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.818 â”‚ 0.852 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.777 â”‚ 0.732 â”‚ 0.779 â”‚ 0.82  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.856 â”‚ 0.817 â”‚ 0.858 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.844 â”‚ 0.872 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1475, ET: 0.1843, TC: 0.1491, WT: 0.1090
[0m
[0;33m2025-05-18 09:35:59,419  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 09:35:59,419  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-18 09:40:46,055  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-18 09:40:46,056  - INFO - - Train mean loss: 0.2456
- ET loss: 0.2982
- TC loss: 0.2599
- WT loss: 0.1786
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 09:40:46,056  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-18 09:41:23,546  - INFO - === [Epoch 25/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:37.4889s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.858 â”‚ 0.822 â”‚ 0.856 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.782 â”‚ 0.737 â”‚ 0.784 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.821 â”‚ 0.857 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.871 â”‚ 0.845 â”‚ 0.883 â”‚ 0.885 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1445, ET: 0.1806, TC: 0.1461, WT: 0.1069
[0m
[1;31m2025-05-18 09:41:23,548  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.1473_dice0.8551_20250518092509.pth[0m
[0;32m2025-05-18 09:41:23,635  - INFO - âœ¨ Saved checkpoint (epoch 25) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch25_loss0.1445_dice0.8581_20250518094123.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:41:23,636  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-18 09:46:10,746  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-18 09:46:10,747  - INFO - - Train mean loss: 0.2358
- ET loss: 0.2846
- TC loss: 0.2495
- WT loss: 0.1732
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:46:10,747  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-18 09:46:48,365  - INFO - === [Epoch 26/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:37.6167s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.849 â”‚ 0.817 â”‚ 0.835 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.77  â”‚ 0.732 â”‚ 0.754 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.851 â”‚ 0.822 â”‚ 0.817 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.874 â”‚ 0.84  â”‚ 0.891 â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1536, ET: 0.1850, TC: 0.1673, WT: 0.1085
[0m
[0;33m2025-05-18 09:46:48,365  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 09:46:48,365  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-18 09:51:35,659  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-18 09:51:35,661  - INFO - - Train mean loss: 0.2342
- ET loss: 0.2826
- TC loss: 0.2475
- WT loss: 0.1725
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 09:51:35,661  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-18 09:52:13,139  - INFO - === [Epoch 27/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:37.4773s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.821 â”‚ 0.859 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.782 â”‚ 0.735 â”‚ 0.787 â”‚ 0.823 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.846 â”‚ 0.802 â”‚ 0.848 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.893 â”‚ 0.866 â”‚ 0.893 â”‚ 0.92  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1439, ET: 0.1814, TC: 0.1434, WT: 0.1069
[0m
[1;31m2025-05-18 09:52:13,141  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch25_loss0.1445_dice0.8581_20250518094123.pth[0m
[0;32m2025-05-18 09:52:13,218  - INFO - âœ¨ Saved checkpoint (epoch 27) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch27_loss0.1439_dice0.8586_20250518095213.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:52:13,218  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-18 09:57:00,217  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-18 09:57:00,219  - INFO - - Train mean loss: 0.2391
- ET loss: 0.2895
- TC loss: 0.2510
- WT loss: 0.1767
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 09:57:00,219  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-18 09:57:37,687  - INFO - === [Epoch 28/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:37.4672s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.862 â”‚ 0.826 â”‚ 0.863 â”‚ 0.896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.788 â”‚ 0.743 â”‚ 0.795 â”‚ 0.825 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.866 â”‚ 0.827 â”‚ 0.868 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.848 â”‚ 0.881 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1407, ET: 0.1765, TC: 0.1390, WT: 0.1066
[0m
[1;31m2025-05-18 09:57:37,689  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch27_loss0.1439_dice0.8586_20250518095213.pth[0m
[0;32m2025-05-18 09:57:37,763  - INFO - âœ¨ Saved checkpoint (epoch 28) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch28_loss0.1407_dice0.8616_20250518095737.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 09:57:37,763  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-18 10:02:25,149  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-18 10:02:25,151  - INFO - - Train mean loss: 0.2319
- ET loss: 0.2806
- TC loss: 0.2441
- WT loss: 0.1710
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 10:02:25,151  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-18 10:03:02,642  - INFO - === [Epoch 29/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:37.4901s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.821 â”‚ 0.858 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.785 â”‚ 0.738 â”‚ 0.789 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.844 â”‚ 0.89  â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.854 â”‚ 0.825 â”‚ 0.851 â”‚ 0.885 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1431, ET: 0.1807, TC: 0.1438, WT: 0.1048
[0m
[0;33m2025-05-18 10:03:02,642  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 10:03:02,642  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-18 10:07:49,680  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-18 10:07:49,681  - INFO - - Train mean loss: 0.2187
- ET loss: 0.2680
- TC loss: 0.2282
- WT loss: 0.1601
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 10:07:49,681  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-18 10:08:27,188  - INFO - === [Epoch 30/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:37.5062s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.855 â”‚ 0.82  â”‚ 0.857 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.781 â”‚ 0.738 â”‚ 0.789 â”‚ 0.817 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.854 â”‚ 0.894 â”‚ 0.948 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.837 â”‚ 0.81  â”‚ 0.844 â”‚ 0.857 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1465, ET: 0.1815, TC: 0.1444, WT: 0.1137
[0m
[0;33m2025-05-18 10:08:27,188  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 10:08:27,188  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-18 10:13:14,242  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-18 10:13:14,243  - INFO - - Train mean loss: 0.2341
- ET loss: 0.2837
- TC loss: 0.2454
- WT loss: 0.1732
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 10:13:14,243  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-18 10:13:51,647  - INFO - === [Epoch 31/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:37.4022s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.863 â”‚ 0.823 â”‚ 0.864 â”‚ 0.901 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.79  â”‚ 0.739 â”‚ 0.797 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.814 â”‚ 0.875 â”‚ 0.918 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.859 â”‚ 0.876 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1394, ET: 0.1788, TC: 0.1376, WT: 0.1016
[0m
[1;31m2025-05-18 10:13:51,649  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch28_loss0.1407_dice0.8616_20250518095737.pth[0m
[0;32m2025-05-18 10:13:51,721  - INFO - âœ¨ Saved checkpoint (epoch 31) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch31_loss0.1394_dice0.8626_20250518101351.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 10:13:51,721  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-18 10:18:39,062  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-18 10:18:39,063  - INFO - - Train mean loss: 0.2254
- ET loss: 0.2755
- TC loss: 0.2361
- WT loss: 0.1645
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 10:18:39,063  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-18 10:19:16,533  - INFO - === [Epoch 32/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:37.4692s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.859 â”‚ 0.821 â”‚ 0.857 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.784 â”‚ 0.736 â”‚ 0.786 â”‚ 0.828 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.879 â”‚ 0.862 â”‚ 0.877 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.86  â”‚ 0.803 â”‚ 0.86  â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1431, ET: 0.1816, TC: 0.1447, WT: 0.1030
[0m
[0;33m2025-05-18 10:19:16,534  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 10:19:16,534  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-18 10:24:03,179  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-18 10:24:03,180  - INFO - - Train mean loss: 0.2401
- ET loss: 0.2897
- TC loss: 0.2525
- WT loss: 0.1780
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 10:24:03,180  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-18 10:24:40,851  - INFO - === [Epoch 33/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:37.6693s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.862 â”‚ 0.823 â”‚ 0.863 â”‚ 0.899 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.788 â”‚ 0.739 â”‚ 0.796 â”‚ 0.829 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.865 â”‚ 0.817 â”‚ 0.874 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.856 â”‚ 0.875 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1400, ET: 0.1789, TC: 0.1377, WT: 0.1034
[0m
[0;33m2025-05-18 10:24:40,851  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 10:24:40,851  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-18 10:29:27,792  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-18 10:29:27,793  - INFO - - Train mean loss: 0.2328
- ET loss: 0.2860
- TC loss: 0.2447
- WT loss: 0.1678
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 10:29:27,794  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-18 10:30:05,484  - INFO - === [Epoch 34/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:37.6893s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.827 â”‚ 0.865 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.792 â”‚ 0.745 â”‚ 0.799 â”‚ 0.832 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.854 â”‚ 0.899 â”‚ 0.917 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.858 â”‚ 0.821 â”‚ 0.852 â”‚ 0.901 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1374, ET: 0.1746, TC: 0.1366, WT: 0.1009
[0m
[1;31m2025-05-18 10:30:05,486  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch31_loss0.1394_dice0.8626_20250518101351.pth[0m
[0;32m2025-05-18 10:30:05,559  - INFO - âœ¨ Saved checkpoint (epoch 34) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch34_loss0.1374_dice0.8646_20250518103005.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 10:30:05,560  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-18 10:34:53,154  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-18 10:34:53,155  - INFO - - Train mean loss: 0.2252
- ET loss: 0.2751
- TC loss: 0.2338
- WT loss: 0.1667
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 10:34:53,155  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-18 10:35:30,660  - INFO - === [Epoch 35/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:37.5044s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.858 â”‚ 0.818 â”‚ 0.857 â”‚ 0.898 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.783 â”‚ 0.734 â”‚ 0.789 â”‚ 0.826 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.908 â”‚ 0.87  â”‚ 0.907 â”‚ 0.947 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.831 â”‚ 0.792 â”‚ 0.833 â”‚ 0.867 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1441, ET: 0.1837, TC: 0.1443, WT: 0.1042
[0m
[0;33m2025-05-18 10:35:30,661  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 10:35:30,661  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-18 10:40:18,027  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-18 10:40:18,029  - INFO - - Train mean loss: 0.2355
- ET loss: 0.2863
- TC loss: 0.2469
- WT loss: 0.1734
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 10:40:18,029  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-18 10:40:55,586  - INFO - === [Epoch 36/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:37.5554s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.866 â”‚ 0.828 â”‚ 0.868 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.794 â”‚ 0.747 â”‚ 0.802 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.845 â”‚ 0.883 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.868 â”‚ 0.832 â”‚ 0.872 â”‚ 0.898 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1352, ET: 0.1734, TC: 0.1331, WT: 0.0990
[0m
[1;31m2025-05-18 10:40:55,588  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch34_loss0.1374_dice0.8646_20250518103005.pth[0m
[0;32m2025-05-18 10:40:55,662  - INFO - âœ¨ Saved checkpoint (epoch 36) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch36_loss0.1352_dice0.8665_20250518104055.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 10:40:55,663  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-18 10:45:43,367  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-18 10:45:43,368  - INFO - - Train mean loss: 0.2270
- ET loss: 0.2790
- TC loss: 0.2365
- WT loss: 0.1654
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 10:45:43,368  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-18 10:46:20,869  - INFO - === [Epoch 37/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:37.4992s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.827 â”‚ 0.864 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.791 â”‚ 0.745 â”‚ 0.794 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.861 â”‚ 0.826 â”‚ 0.857 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.85  â”‚ 0.894 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1372, ET: 0.1746, TC: 0.1379, WT: 0.0990
[0m
[0;33m2025-05-18 10:46:20,870  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 10:46:20,870  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-18 10:51:08,063  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-18 10:51:08,064  - INFO - - Train mean loss: 0.2162
- ET loss: 0.2650
- TC loss: 0.2261
- WT loss: 0.1574
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 10:51:08,064  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-18 10:51:45,566  - INFO - === [Epoch 38/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:37.5008s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.861 â”‚ 0.826 â”‚ 0.864 â”‚ 0.894 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.789 â”‚ 0.744 â”‚ 0.799 â”‚ 0.824 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.83  â”‚ 0.88  â”‚ 0.946 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.861 â”‚ 0.846 â”‚ 0.873 â”‚ 0.865 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1400, ET: 0.1756, TC: 0.1366, WT: 0.1078
[0m
[0;33m2025-05-18 10:51:45,566  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 10:51:45,566  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-18 10:56:32,831  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-18 10:56:32,832  - INFO - - Train mean loss: 0.2348
- ET loss: 0.2837
- TC loss: 0.2439
- WT loss: 0.1767
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 10:56:32,832  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-18 10:57:10,528  - INFO - === [Epoch 39/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:37.6949s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.865 â”‚ 0.829 â”‚ 0.862 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.791 â”‚ 0.746 â”‚ 0.791 â”‚ 0.836 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.86  â”‚ 0.82  â”‚ 0.845 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.89  â”‚ 0.857 â”‚ 0.905 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1369, ET: 0.1733, TC: 0.1398, WT: 0.0978
[0m
[0;33m2025-05-18 10:57:10,528  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 10:57:10,528  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-18 11:01:57,420  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-18 11:01:57,421  - INFO - - Train mean loss: 0.2172
- ET loss: 0.2682
- TC loss: 0.2255
- WT loss: 0.1580
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 11:01:57,421  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-18 11:02:35,050  - INFO - === [Epoch 40/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:37.6271s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.83  â”‚ 0.871 â”‚ 0.904 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.749 â”‚ 0.807 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.876 â”‚ 0.83  â”‚ 0.884 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.851 â”‚ 0.879 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1335, ET: 0.1716, TC: 0.1303, WT: 0.0986
[0m
[1;31m2025-05-18 11:02:35,052  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch36_loss0.1352_dice0.8665_20250518104055.pth[0m
[0;32m2025-05-18 11:02:35,127  - INFO - âœ¨ Saved checkpoint (epoch 40) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch40_loss0.1335_dice0.8680_20250518110235.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 11:02:35,128  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-18 11:07:22,493  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-18 11:07:22,495  - INFO - - Train mean loss: 0.2260
- ET loss: 0.2760
- TC loss: 0.2344
- WT loss: 0.1675
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 11:07:22,495  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-18 11:08:00,215  - INFO - === [Epoch 41/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:37.7194s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.832 â”‚ 0.872 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.798 â”‚ 0.752 â”‚ 0.808 â”‚ 0.834 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.842 â”‚ 0.898 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.865 â”‚ 0.844 â”‚ 0.863 â”‚ 0.888 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1326, ET: 0.1693, TC: 0.1289, WT: 0.0995
[0m
[1;31m2025-05-18 11:08:00,217  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch40_loss0.1335_dice0.8680_20250518110235.pth[0m
[0;32m2025-05-18 11:08:00,288  - INFO - âœ¨ Saved checkpoint (epoch 41) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch41_loss0.1326_dice0.8690_20250518110800.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 11:08:00,288  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-18 11:12:47,129  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-18 11:12:47,130  - INFO - - Train mean loss: 0.2193
- ET loss: 0.2693
- TC loss: 0.2271
- WT loss: 0.1615
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 11:12:47,130  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-18 11:13:24,650  - INFO - === [Epoch 42/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:37.5186s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.831 â”‚ 0.872 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.751 â”‚ 0.805 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.871 â”‚ 0.832 â”‚ 0.873 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.851 â”‚ 0.891 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1332, ET: 0.1703, TC: 0.1296, WT: 0.0998
[0m
[0;33m2025-05-18 11:13:24,650  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 11:13:24,650  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-18 11:18:11,629  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-18 11:18:11,630  - INFO - - Train mean loss: 0.2146
- ET loss: 0.2596
- TC loss: 0.2191
- WT loss: 0.1650
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 11:18:11,630  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-18 11:18:49,269  - INFO - === [Epoch 43/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:37.6375s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.832 â”‚ 0.87  â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.797 â”‚ 0.751 â”‚ 0.805 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.85  â”‚ 0.895 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.868 â”‚ 0.833 â”‚ 0.863 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1328, ET: 0.1701, TC: 0.1311, WT: 0.0973
[0m
[0;33m2025-05-18 11:18:49,269  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 11:18:49,269  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-18 11:23:36,703  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-18 11:23:36,704  - INFO - - Train mean loss: 0.2128
- ET loss: 0.2629
- TC loss: 0.2209
- WT loss: 0.1546
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 11:23:36,704  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-18 11:24:14,334  - INFO - === [Epoch 44/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:37.6293s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.864 â”‚ 0.824 â”‚ 0.862 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.792 â”‚ 0.744 â”‚ 0.796 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.866 â”‚ 0.908 â”‚ 0.922 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.851 â”‚ 0.81  â”‚ 0.842 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1381, ET: 0.1773, TC: 0.1392, WT: 0.0977
[0m
[0;33m2025-05-18 11:24:14,335  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 11:24:14,335  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-18 11:29:01,106  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-18 11:29:01,107  - INFO - - Train mean loss: 0.2029
- ET loss: 0.2520
- TC loss: 0.2118
- WT loss: 0.1451
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 11:29:01,107  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-18 11:29:38,933  - INFO - === [Epoch 45/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:37.8251s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.836 â”‚ 0.875 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.756 â”‚ 0.81  â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.837 â”‚ 0.885 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.852 â”‚ 0.885 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1292, ET: 0.1658, TC: 0.1263, WT: 0.0954
[0m
[1;31m2025-05-18 11:29:38,935  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch41_loss0.1326_dice0.8690_20250518110800.pth[0m
[0;32m2025-05-18 11:29:39,007  - INFO - âœ¨ Saved checkpoint (epoch 45) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch45_loss0.1292_dice0.8726_20250518112938.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 11:29:39,007  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-18 11:34:26,223  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-18 11:34:26,225  - INFO - - Train mean loss: 0.2103
- ET loss: 0.2634
- TC loss: 0.2188
- WT loss: 0.1487
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 11:34:26,225  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-18 11:35:04,044  - INFO - === [Epoch 46/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:37.8175s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.835 â”‚ 0.876 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚ 0.755 â”‚ 0.811 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.887 â”‚ 0.847 â”‚ 0.896 â”‚ 0.919 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.844 â”‚ 0.876 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1297, ET: 0.1668, TC: 0.1248, WT: 0.0976
[0m
[0;33m2025-05-18 11:35:04,044  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 11:35:04,044  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-18 11:39:51,093  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-18 11:39:51,094  - INFO - - Train mean loss: 0.2196
- ET loss: 0.2701
- TC loss: 0.2317
- WT loss: 0.1569
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 11:39:51,094  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-18 11:40:28,900  - INFO - === [Epoch 47/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:37.8045s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.836 â”‚ 0.875 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.757 â”‚ 0.81  â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.835 â”‚ 0.882 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.856 â”‚ 0.888 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1289, ET: 0.1655, TC: 0.1265, WT: 0.0947
[0m
[1;31m2025-05-18 11:40:28,902  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch45_loss0.1292_dice0.8726_20250518112938.pth[0m
[0;32m2025-05-18 11:40:28,978  - INFO - âœ¨ Saved checkpoint (epoch 47) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch47_loss0.1289_dice0.8729_20250518114028.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 11:40:28,978  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-18 11:45:15,866  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-18 11:45:15,868  - INFO - - Train mean loss: 0.2220
- ET loss: 0.2765
- TC loss: 0.2345
- WT loss: 0.1551
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 11:45:15,868  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-18 11:45:53,539  - INFO - === [Epoch 48/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:37.6699s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.833 â”‚ 0.869 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.796 â”‚ 0.753 â”‚ 0.801 â”‚ 0.833 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.867 â”‚ 0.844 â”‚ 0.861 â”‚ 0.895 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.887 â”‚ 0.841 â”‚ 0.897 â”‚ 0.923 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1336, ET: 0.1685, TC: 0.1323, WT: 0.0999
[0m
[0;33m2025-05-18 11:45:53,539  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 11:45:53,539  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-18 11:50:40,877  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-18 11:50:40,879  - INFO - - Train mean loss: 0.2152
- ET loss: 0.2681
- TC loss: 0.2210
- WT loss: 0.1565
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 11:50:40,879  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-18 11:51:18,714  - INFO - === [Epoch 49/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:37.8333s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.868 â”‚ 0.832 â”‚ 0.868 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.798 â”‚ 0.752 â”‚ 0.804 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.849 â”‚ 0.898 â”‚ 0.937 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.861 â”‚ 0.836 â”‚ 0.86  â”‚ 0.886 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1338, ET: 0.1700, TC: 0.1331, WT: 0.0983
[0m
[0;33m2025-05-18 11:51:18,714  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 11:51:18,714  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-18 11:56:05,920  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-18 11:56:05,921  - INFO - - Train mean loss: 0.2096
- ET loss: 0.2628
- TC loss: 0.2203
- WT loss: 0.1455
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 11:56:05,921  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-18 11:56:43,609  - INFO - === [Epoch 50/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:37.6867s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.838 â”‚ 0.881 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.816 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.88  â”‚ 0.838 â”‚ 0.881 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.857 â”‚ 0.9   â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1261, ET: 0.1637, TC: 0.1208, WT: 0.0937
[0m
[1;31m2025-05-18 11:56:43,611  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch47_loss0.1289_dice0.8729_20250518114028.pth[0m
[0;32m2025-05-18 11:56:43,873  - INFO - âœ¨ Saved checkpoint (epoch 50) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch50_loss0.1261_dice0.8757_20250518115643.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 11:56:43,873  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-18 12:01:30,424  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-18 12:01:30,425  - INFO - - Train mean loss: 0.2126
- ET loss: 0.2652
- TC loss: 0.2192
- WT loss: 0.1533
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:01:30,425  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-18 12:02:08,124  - INFO - === [Epoch 51/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:37.6985s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.872 â”‚ 0.835 â”‚ 0.876 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.755 â”‚ 0.812 â”‚ 0.839 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.883 â”‚ 0.842 â”‚ 0.895 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.846 â”‚ 0.876 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1292, ET: 0.1665, TC: 0.1253, WT: 0.0958
[0m
[0;33m2025-05-18 12:02:08,125  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 12:02:08,125  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-18 12:06:54,967  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-18 12:06:54,968  - INFO - - Train mean loss: 0.2154
- ET loss: 0.2699
- TC loss: 0.2253
- WT loss: 0.1510
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:06:54,968  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-18 12:07:32,786  - INFO - === [Epoch 52/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:37.8168s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.833 â”‚ 0.87  â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.753 â”‚ 0.806 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.847 â”‚ 0.885 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.839 â”‚ 0.877 â”‚ 0.913 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1315, ET: 0.1684, TC: 0.1307, WT: 0.0955
[0m
[0;33m2025-05-18 12:07:32,786  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 12:07:32,786  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-18 12:12:19,661  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-18 12:12:19,663  - INFO - - Train mean loss: 0.2066
- ET loss: 0.2557
- TC loss: 0.2124
- WT loss: 0.1515
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:12:19,663  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-18 12:12:57,377  - INFO - === [Epoch 53/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:37.7130s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.835 â”‚ 0.874 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.756 â”‚ 0.811 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.841 â”‚ 0.891 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.852 â”‚ 0.883 â”‚ 0.898 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1290, ET: 0.1668, TC: 0.1265, WT: 0.0937
[0m
[0;33m2025-05-18 12:12:57,377  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 12:12:57,377  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-18 12:17:44,304  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-18 12:17:44,305  - INFO - - Train mean loss: 0.2007
- ET loss: 0.2488
- TC loss: 0.2061
- WT loss: 0.1473
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:17:44,305  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-18 12:18:22,087  - INFO - === [Epoch 54/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:37.7808s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.838 â”‚ 0.876 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.804 â”‚ 0.758 â”‚ 0.811 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.882 â”‚ 0.845 â”‚ 0.886 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.849 â”‚ 0.886 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1272, ET: 0.1637, TC: 0.1249, WT: 0.0932
[0m
[0;33m2025-05-18 12:18:22,087  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 12:18:22,087  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-18 12:23:08,898  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-18 12:23:08,899  - INFO - - Train mean loss: 0.2164
- ET loss: 0.2682
- TC loss: 0.2279
- WT loss: 0.1532
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:23:08,900  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-18 12:23:46,474  - INFO - === [Epoch 55/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:37.5732s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.837 â”‚ 0.875 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.758 â”‚ 0.812 â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.897 â”‚ 0.853 â”‚ 0.902 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.84  â”‚ 0.869 â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1285, ET: 0.1642, TC: 0.1261, WT: 0.0951
[0m
[0;33m2025-05-18 12:23:46,474  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 12:23:46,474  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-18 12:28:33,464  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-18 12:28:33,465  - INFO - - Train mean loss: 0.2087
- ET loss: 0.2591
- TC loss: 0.2172
- WT loss: 0.1499
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:28:33,466  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-18 12:29:11,167  - INFO - === [Epoch 56/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:37.7002s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.837 â”‚ 0.874 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.757 â”‚ 0.809 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.869 â”‚ 0.832 â”‚ 0.867 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.894 â”‚ 0.859 â”‚ 0.901 â”‚ 0.921 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1287, ET: 0.1652, TC: 0.1270, WT: 0.0939
[0m
[0;33m2025-05-18 12:29:11,167  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 12:29:11,167  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-18 12:33:58,382  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-18 12:33:58,383  - INFO - - Train mean loss: 0.2053
- ET loss: 0.2576
- TC loss: 0.2123
- WT loss: 0.1459
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 12:33:58,383  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-18 12:34:36,206  - INFO - === [Epoch 57/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:37.8224s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.87  â”‚ 0.833 â”‚ 0.872 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.8   â”‚ 0.754 â”‚ 0.807 â”‚ 0.84  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.861 â”‚ 0.904 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.861 â”‚ 0.827 â”‚ 0.861 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1313, ET: 0.1687, TC: 0.1293, WT: 0.0959
[0m
[0;33m2025-05-18 12:34:36,207  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 12:34:36,207  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-18 12:39:23,230  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-18 12:39:23,231  - INFO - - Train mean loss: 0.2149
- ET loss: 0.2703
- TC loss: 0.2254
- WT loss: 0.1490
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:39:23,231  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-18 12:40:01,027  - INFO - === [Epoch 58/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:37.7949s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.878 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.762 â”‚ 0.816 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.851 â”‚ 0.896 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.848 â”‚ 0.882 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1259, ET: 0.1616, TC: 0.1227, WT: 0.0935
[0m
[1;31m2025-05-18 12:40:01,029  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch50_loss0.1261_dice0.8757_20250518115643.pth[0m
[0;32m2025-05-18 12:40:01,104  - INFO - âœ¨ Saved checkpoint (epoch 58) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch58_loss0.1259_dice0.8756_20250518124001.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 12:40:01,104  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-18 12:44:47,938  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-18 12:44:47,939  - INFO - - Train mean loss: 0.2066
- ET loss: 0.2545
- TC loss: 0.2114
- WT loss: 0.1538
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 12:44:47,940  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-18 12:45:25,754  - INFO - === [Epoch 59/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:37.8132s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.838 â”‚ 0.874 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.76  â”‚ 0.811 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.849 â”‚ 0.905 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.845 â”‚ 0.864 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1274, ET: 0.1634, TC: 0.1271, WT: 0.0917
[0m
[0;33m2025-05-18 12:45:25,754  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 12:45:25,754  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-18 12:50:13,014  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-18 12:50:13,016  - INFO - - Train mean loss: 0.2172
- ET loss: 0.2660
- TC loss: 0.2255
- WT loss: 0.1601
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 12:50:13,016  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-18 12:50:50,666  - INFO - === [Epoch 60/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:37.6494s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.836 â”‚ 0.879 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.755 â”‚ 0.815 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.819 â”‚ 0.88  â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.892 â”‚ 0.872 â”‚ 0.897 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1269, ET: 0.1655, TC: 0.1224, WT: 0.0927
[0m
[0;33m2025-05-18 12:50:50,667  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 12:50:50,667  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-18 12:55:37,789  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-18 12:55:37,790  - INFO - - Train mean loss: 0.2055
- ET loss: 0.2569
- TC loss: 0.2128
- WT loss: 0.1468
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 12:55:37,790  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-18 12:56:15,566  - INFO - === [Epoch 61/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:37.7749s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.836 â”‚ 0.873 â”‚ 0.903 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.758 â”‚ 0.812 â”‚ 0.837 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.851 â”‚ 0.9   â”‚ 0.947 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.863 â”‚ 0.842 â”‚ 0.869 â”‚ 0.876 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1306, ET: 0.1656, TC: 0.1273, WT: 0.0988
[0m
[0;33m2025-05-18 12:56:15,567  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 12:56:15,567  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-18 13:01:03,021  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-18 13:01:03,022  - INFO - - Train mean loss: 0.2039
- ET loss: 0.2534
- TC loss: 0.2103
- WT loss: 0.1479
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:01:03,023  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-18 13:01:40,856  - INFO - === [Epoch 62/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:37.8326s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.838 â”‚ 0.877 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.758 â”‚ 0.812 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.881 â”‚ 0.839 â”‚ 0.888 â”‚ 0.915 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.853 â”‚ 0.883 â”‚ 0.917 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1267, ET: 0.1640, TC: 0.1243, WT: 0.0917
[0m
[0;33m2025-05-18 13:01:40,856  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 13:01:40,856  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-18 13:06:27,756  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-18 13:06:27,757  - INFO - - Train mean loss: 0.2015
- ET loss: 0.2532
- TC loss: 0.2089
- WT loss: 0.1424
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 13:06:27,757  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-18 13:07:05,381  - INFO - === [Epoch 63/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:37.6229s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.871 â”‚ 0.835 â”‚ 0.874 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.755 â”‚ 0.81  â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.835 â”‚ 0.887 â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.853 â”‚ 0.881 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1300, ET: 0.1668, TC: 0.1272, WT: 0.0960
[0m
[0;33m2025-05-18 13:07:05,381  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 13:07:05,382  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-18 13:11:52,600  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-18 13:11:52,602  - INFO - - Train mean loss: 0.2024
- ET loss: 0.2519
- TC loss: 0.2080
- WT loss: 0.1474
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:11:52,602  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-18 13:12:30,418  - INFO - === [Epoch 64/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:37.8148s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.838 â”‚ 0.879 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.76  â”‚ 0.816 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.842 â”‚ 0.889 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.882 â”‚ 0.853 â”‚ 0.89  â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1253, ET: 0.1632, TC: 0.1215, WT: 0.0910
[0m
[1;31m2025-05-18 13:12:30,420  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch58_loss0.1259_dice0.8756_20250518124001.pth[0m
[0;32m2025-05-18 13:12:30,498  - INFO - âœ¨ Saved checkpoint (epoch 64) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch64_loss0.1253_dice0.8761_20250518131230.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 13:12:30,499  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-18 13:17:18,156  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-18 13:17:18,160  - INFO - - Train mean loss: 0.2077
- ET loss: 0.2635
- TC loss: 0.2175
- WT loss: 0.1422
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:17:18,160  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-18 13:17:55,925  - INFO - === [Epoch 65/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:37.7628s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.837 â”‚ 0.875 â”‚ 0.906 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.759 â”‚ 0.813 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.898 â”‚ 0.85  â”‚ 0.902 â”‚ 0.942 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.868 â”‚ 0.843 â”‚ 0.871 â”‚ 0.889 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1285, ET: 0.1645, TC: 0.1259, WT: 0.0951
[0m
[0;33m2025-05-18 13:17:55,925  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 13:17:55,925  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-18 13:22:42,848  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-18 13:22:42,849  - INFO - - Train mean loss: 0.2192
- ET loss: 0.2745
- TC loss: 0.2275
- WT loss: 0.1556
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 13:22:42,849  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-18 13:23:20,604  - INFO - === [Epoch 66/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:37.7525s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.835 â”‚ 0.873 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.758 â”‚ 0.811 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.854 â”‚ 0.902 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.836 â”‚ 0.868 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1284, ET: 0.1660, TC: 0.1274, WT: 0.0918
[0m
[0;33m2025-05-18 13:23:20,604  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 13:23:20,604  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-18 13:28:07,465  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-18 13:28:07,466  - INFO - - Train mean loss: 0.2018
- ET loss: 0.2531
- TC loss: 0.2093
- WT loss: 0.1429
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 13:28:07,466  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-18 13:28:45,177  - INFO - === [Epoch 67/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:37.7100s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.876 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.814 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.848 â”‚ 0.895 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.844 â”‚ 0.879 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1272, ET: 0.1649, TC: 0.1249, WT: 0.0917
[0m
[0;33m2025-05-18 13:28:45,177  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 13:28:45,177  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-18 13:33:32,360  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-18 13:33:32,361  - INFO - - Train mean loss: 0.2093
- ET loss: 0.2621
- TC loss: 0.2162
- WT loss: 0.1495
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:33:32,361  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-18 13:34:09,912  - INFO - === [Epoch 68/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:37.5493s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.836 â”‚ 0.876 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.803 â”‚ 0.757 â”‚ 0.811 â”‚ 0.842 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.875 â”‚ 0.832 â”‚ 0.873 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.859 â”‚ 0.899 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1288, ET: 0.1660, TC: 0.1255, WT: 0.0951
[0m
[0;33m2025-05-18 13:34:09,912  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 13:34:09,912  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-18 13:38:56,799  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-18 13:38:56,801  - INFO - - Train mean loss: 0.2113
- ET loss: 0.2640
- TC loss: 0.2201
- WT loss: 0.1498
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 13:38:56,801  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-18 13:39:34,546  - INFO - === [Epoch 69/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:37.7436s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.838 â”‚ 0.875 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.76  â”‚ 0.813 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.851 â”‚ 0.894 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.843 â”‚ 0.878 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1268, ET: 0.1637, TC: 0.1256, WT: 0.0913
[0m
[0;33m2025-05-18 13:39:34,546  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 13:39:34,546  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-18 13:44:21,678  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-18 13:44:21,679  - INFO - - Train mean loss: 0.2040
- ET loss: 0.2547
- TC loss: 0.2100
- WT loss: 0.1472
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:44:21,679  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-18 13:44:59,295  - INFO - === [Epoch 70/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:37.6146s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.875 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.814 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.853 â”‚ 0.899 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.873 â”‚ 0.839 â”‚ 0.875 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1272, ET: 0.1649, TC: 0.1252, WT: 0.0917
[0m
[0;33m2025-05-18 13:44:59,296  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 13:44:59,296  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-18 13:49:46,399  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-18 13:49:46,401  - INFO - - Train mean loss: 0.2120
- ET loss: 0.2658
- TC loss: 0.2208
- WT loss: 0.1494
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:49:46,401  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-18 13:50:24,162  - INFO - === [Epoch 71/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:37.7604s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.869 â”‚ 0.833 â”‚ 0.871 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.802 â”‚ 0.756 â”‚ 0.81  â”‚ 0.841 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.9   â”‚ 0.862 â”‚ 0.906 â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.862 â”‚ 0.828 â”‚ 0.863 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1318, ET: 0.1684, TC: 0.1299, WT: 0.0971
[0m
[0;33m2025-05-18 13:50:24,162  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 13:50:24,162  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-18 13:55:11,375  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-18 13:55:11,376  - INFO - - Train mean loss: 0.2018
- ET loss: 0.2530
- TC loss: 0.2071
- WT loss: 0.1453
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 13:55:11,376  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-18 13:55:49,035  - INFO - === [Epoch 72/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:37.6579s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.876 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.814 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.846 â”‚ 0.896 â”‚ 0.914 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.846 â”‚ 0.878 â”‚ 0.918 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1276, ET: 0.1647, TC: 0.1250, WT: 0.0932
[0m
[0;33m2025-05-18 13:55:49,035  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-18 13:55:49,035  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-18 14:00:36,274  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-18 14:00:36,275  - INFO - - Train mean loss: 0.2078
- ET loss: 0.2600
- TC loss: 0.2161
- WT loss: 0.1473
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 14:00:36,275  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-18 14:01:13,849  - INFO - === [Epoch 73/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:37.5730s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.837 â”‚ 0.876 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.76  â”‚ 0.815 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.89  â”‚ 0.849 â”‚ 0.897 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.845 â”‚ 0.879 â”‚ 0.91  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1267, ET: 0.1643, TC: 0.1245, WT: 0.0914
[0m
[0;33m2025-05-18 14:01:13,850  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-18 14:01:13,850  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-18 14:06:01,319  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-18 14:06:01,321  - INFO - - Train mean loss: 0.2050
- ET loss: 0.2600
- TC loss: 0.2127
- WT loss: 0.1422
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 14:06:01,321  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-18 14:06:38,864  - INFO - === [Epoch 74/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:37.5426s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.875 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.76  â”‚ 0.813 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.896 â”‚ 0.854 â”‚ 0.905 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.871 â”‚ 0.841 â”‚ 0.868 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1276, ET: 0.1641, TC: 0.1258, WT: 0.0929
[0m
[0;33m2025-05-18 14:06:38,864  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-18 14:06:38,864  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-18 14:11:25,915  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-18 14:11:25,916  - INFO - - Train mean loss: 0.2007
- ET loss: 0.2495
- TC loss: 0.2041
- WT loss: 0.1486
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 14:11:25,916  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-18 14:12:03,470  - INFO - === [Epoch 75/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:37.5537s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.838 â”‚ 0.874 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.805 â”‚ 0.76  â”‚ 0.812 â”‚ 0.843 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.902 â”‚ 0.858 â”‚ 0.909 â”‚ 0.94  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.864 â”‚ 0.837 â”‚ 0.864 â”‚ 0.892 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1282, ET: 0.1641, TC: 0.1269, WT: 0.0938
[0m
[0;33m2025-05-18 14:12:03,471  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-18 14:12:03,471  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-18 14:16:50,765  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-18 14:16:50,766  - INFO - - Train mean loss: 0.2152
- ET loss: 0.2697
- TC loss: 0.2247
- WT loss: 0.1512
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 14:16:50,766  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-18 14:17:28,426  - INFO - === [Epoch 76/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:37.6581s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.876 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.814 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.853 â”‚ 0.902 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.842 â”‚ 0.872 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1631, TC: 0.1244, WT: 0.0923
[0m
[0;33m2025-05-18 14:17:28,426  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[0;32m2025-05-18 14:17:28,427  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-18 14:22:15,849  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-18 14:22:15,851  - INFO - - Train mean loss: 0.2015
- ET loss: 0.2536
- TC loss: 0.2082
- WT loss: 0.1426
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 14:22:15,851  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-18 14:22:53,631  - INFO - === [Epoch 77/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:37.7789s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.874 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.812 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.9   â”‚ 0.857 â”‚ 0.907 â”‚ 0.936 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.866 â”‚ 0.836 â”‚ 0.864 â”‚ 0.899 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1276, ET: 0.1644, TC: 0.1264, WT: 0.0918
[0m
[0;33m2025-05-18 14:22:53,632  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 13/100[0m
[0;32m2025-05-18 14:22:53,632  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-18 14:27:40,636  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-18 14:27:40,638  - INFO - - Train mean loss: 0.1967
- ET loss: 0.2501
- TC loss: 0.2033
- WT loss: 0.1366
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 14:27:40,638  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-18 14:28:18,265  - INFO - === [Epoch 78/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:37.6255s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.877 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.762 â”‚ 0.816 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.894 â”‚ 0.849 â”‚ 0.9   â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.876 â”‚ 0.847 â”‚ 0.876 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1251, ET: 0.1619, TC: 0.1235, WT: 0.0899
[0m
[1;31m2025-05-18 14:28:18,267  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch64_loss0.1253_dice0.8761_20250518131230.pth[0m
[0;32m2025-05-18 14:28:18,347  - INFO - âœ¨ Saved checkpoint (epoch 78) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch78_loss0.1251_dice0.8763_20250518142818.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 14:28:18,347  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-18 14:33:06,431  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-18 14:33:06,433  - INFO - - Train mean loss: 0.2013
- ET loss: 0.2523
- TC loss: 0.2051
- WT loss: 0.1463
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 14:33:06,433  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-18 14:33:44,089  - INFO - === [Epoch 79/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:37.6554s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.839 â”‚ 0.877 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.762 â”‚ 0.814 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.899 â”‚ 0.858 â”‚ 0.905 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.838 â”‚ 0.87  â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1258, ET: 0.1624, TC: 0.1239, WT: 0.0910
[0m
[0;33m2025-05-18 14:33:44,090  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 14:33:44,090  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-18 14:38:31,214  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-18 14:38:31,215  - INFO - - Train mean loss: 0.2120
- ET loss: 0.2635
- TC loss: 0.2185
- WT loss: 0.1540
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 14:38:31,216  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-18 14:39:08,764  - INFO - === [Epoch 80/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:37.5476s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.878 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.816 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.885 â”‚ 0.837 â”‚ 0.888 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.884 â”‚ 0.859 â”‚ 0.89  â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1264, ET: 0.1626, TC: 0.1226, WT: 0.0939
[0m
[0;33m2025-05-18 14:39:08,764  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 14:39:08,764  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-18 14:43:56,299  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-18 14:43:56,301  - INFO - - Train mean loss: 0.2005
- ET loss: 0.2522
- TC loss: 0.2081
- WT loss: 0.1411
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 14:43:56,301  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-18 14:44:34,091  - INFO - === [Epoch 81/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:37.7894s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.838 â”‚ 0.877 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.761 â”‚ 0.814 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.849 â”‚ 0.891 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.846 â”‚ 0.884 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1632, TC: 0.1237, WT: 0.0929
[0m
[0;33m2025-05-18 14:44:34,092  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 14:44:34,092  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-18 14:49:21,054  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-18 14:49:21,055  - INFO - - Train mean loss: 0.1945
- ET loss: 0.2437
- TC loss: 0.1957
- WT loss: 0.1442
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 14:49:21,055  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-18 14:49:58,577  - INFO - === [Epoch 82/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:37.5202s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.878 â”‚ 0.841 â”‚ 0.88  â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.763 â”‚ 0.818 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.843 â”‚ 0.895 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.885 â”‚ 0.857 â”‚ 0.886 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1237, ET: 0.1608, TC: 0.1205, WT: 0.0897
[0m
[1;31m2025-05-18 14:49:58,578  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch78_loss0.1251_dice0.8763_20250518142818.pth[0m
[0;32m2025-05-18 14:49:58,653  - INFO - âœ¨ Saved checkpoint (epoch 82) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch82_loss0.1237_dice0.8778_20250518144958.pth;             Size 10.46 MB[0m
[0;32m2025-05-18 14:49:58,653  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-18 14:54:46,353  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-18 14:54:46,354  - INFO - - Train mean loss: 0.2243
- ET loss: 0.2761
- TC loss: 0.2327
- WT loss: 0.1640
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 14:54:46,355  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-18 14:55:24,000  - INFO - === [Epoch 83/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:37.6443s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚ 0.837 â”‚ 0.873 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.76  â”‚ 0.812 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.9   â”‚ 0.86  â”‚ 0.908 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.867 â”‚ 0.834 â”‚ 0.864 â”‚ 0.904 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1282, ET: 0.1648, TC: 0.1276, WT: 0.0922
[0m
[0;33m2025-05-18 14:55:24,000  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 14:55:24,000  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-18 15:00:11,306  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-18 15:00:11,307  - INFO - - Train mean loss: 0.2038
- ET loss: 0.2552
- TC loss: 0.2075
- WT loss: 0.1486
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:00:11,307  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-18 15:00:48,988  - INFO - === [Epoch 84/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:37.6796s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.839 â”‚ 0.876 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.814 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.849 â”‚ 0.898 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.875 â”‚ 0.846 â”‚ 0.877 â”‚ 0.901 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1270, ET: 0.1630, TC: 0.1245, WT: 0.0936
[0m
[0;33m2025-05-18 15:00:48,988  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 2/100[0m
[0;32m2025-05-18 15:00:48,988  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-18 15:05:36,152  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-18 15:05:36,153  - INFO - - Train mean loss: 0.1973
- ET loss: 0.2492
- TC loss: 0.1987
- WT loss: 0.1441
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:05:36,153  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-18 15:06:13,915  - INFO - === [Epoch 85/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:37.7606s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.838 â”‚ 0.877 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.815 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.898 â”‚ 0.853 â”‚ 0.904 â”‚ 0.938 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.87  â”‚ 0.842 â”‚ 0.872 â”‚ 0.895 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1272, ET: 0.1631, TC: 0.1241, WT: 0.0942
[0m
[0;33m2025-05-18 15:06:13,915  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 3/100[0m
[0;32m2025-05-18 15:06:13,915  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-18 15:11:01,910  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-18 15:11:01,911  - INFO - - Train mean loss: 0.2032
- ET loss: 0.2592
- TC loss: 0.2089
- WT loss: 0.1415
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 15:11:01,911  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-18 15:11:39,634  - INFO - === [Epoch 86/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:37.7214s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.874 â”‚ 0.837 â”‚ 0.874 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.806 â”‚ 0.759 â”‚ 0.812 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.856 â”‚ 0.907 â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.872 â”‚ 0.837 â”‚ 0.864 â”‚ 0.914 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1271, ET: 0.1645, TC: 0.1267, WT: 0.0902
[0m
[0;33m2025-05-18 15:11:39,634  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 4/100[0m
[0;32m2025-05-18 15:11:39,634  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-18 15:16:26,789  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-18 15:16:26,791  - INFO - - Train mean loss: 0.2086
- ET loss: 0.2598
- TC loss: 0.2152
- WT loss: 0.1509
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:16:26,791  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-18 15:17:04,473  - INFO - === [Epoch 87/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:37.6814s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.878 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.85  â”‚ 0.9   â”‚ 0.923 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.847 â”‚ 0.879 â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1251, ET: 0.1618, TC: 0.1222, WT: 0.0912
[0m
[0;33m2025-05-18 15:17:04,473  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 5/100[0m
[0;32m2025-05-18 15:17:04,473  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-18 15:21:51,448  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-18 15:21:51,449  - INFO - - Train mean loss: 0.2068
- ET loss: 0.2598
- TC loss: 0.2147
- WT loss: 0.1459
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 15:21:51,449  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-18 15:22:29,332  - INFO - === [Epoch 88/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:37.8816s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.878 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.847 â”‚ 0.9   â”‚ 0.933 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.85  â”‚ 0.878 â”‚ 0.902 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1258, ET: 0.1624, TC: 0.1229, WT: 0.0922
[0m
[0;33m2025-05-18 15:22:29,332  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 6/100[0m
[0;32m2025-05-18 15:22:29,332  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-18 15:27:16,574  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-18 15:27:16,575  - INFO - - Train mean loss: 0.2091
- ET loss: 0.2607
- TC loss: 0.2157
- WT loss: 0.1510
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:27:16,575  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-18 15:27:54,345  - INFO - === [Epoch 89/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:37.7684s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.878 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.85  â”‚ 0.899 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.846 â”‚ 0.877 â”‚ 0.906 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1258, ET: 0.1623, TC: 0.1227, WT: 0.0924
[0m
[0;33m2025-05-18 15:27:54,345  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 7/100[0m
[0;32m2025-05-18 15:27:54,345  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-18 15:32:42,392  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-18 15:32:42,394  - INFO - - Train mean loss: 0.2028
- ET loss: 0.2577
- TC loss: 0.2123
- WT loss: 0.1384
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 15:32:42,394  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-18 15:33:20,038  - INFO - === [Epoch 90/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:37.6427s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.841 â”‚ 0.88  â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.763 â”‚ 0.818 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.895 â”‚ 0.848 â”‚ 0.903 â”‚ 0.935 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.852 â”‚ 0.88  â”‚ 0.901 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1245, ET: 0.1609, TC: 0.1208, WT: 0.0918
[0m
[0;33m2025-05-18 15:33:20,038  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 8/100[0m
[0;32m2025-05-18 15:33:20,038  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-18 15:38:07,138  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-18 15:38:07,139  - INFO - - Train mean loss: 0.2087
- ET loss: 0.2595
- TC loss: 0.2142
- WT loss: 0.1523
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:38:07,139  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-18 15:38:44,651  - INFO - === [Epoch 91/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:37.5103s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.841 â”‚ 0.879 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.763 â”‚ 0.817 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.849 â”‚ 0.899 â”‚ 0.92  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.881 â”‚ 0.849 â”‚ 0.879 â”‚ 0.916 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1246, ET: 0.1610, TC: 0.1218, WT: 0.0911
[0m
[0;33m2025-05-18 15:38:44,651  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 9/100[0m
[0;32m2025-05-18 15:38:44,651  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-18 15:43:31,741  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-18 15:43:31,742  - INFO - - Train mean loss: 0.2182
- ET loss: 0.2740
- TC loss: 0.2252
- WT loss: 0.1555
- Cost time: 4.78mins â±ï¸
[0m
[0;32m2025-05-18 15:43:31,742  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-18 15:44:09,432  - INFO - === [Epoch 92/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:37.6885s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.88  â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.763 â”‚ 0.818 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.851 â”‚ 0.896 â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.847 â”‚ 0.884 â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1242, ET: 0.1614, TC: 0.1208, WT: 0.0903
[0m
[0;33m2025-05-18 15:44:09,432  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 10/100[0m
[0;32m2025-05-18 15:44:09,432  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-18 15:48:56,546  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-18 15:48:56,547  - INFO - - Train mean loss: 0.2124
- ET loss: 0.2666
- TC loss: 0.2210
- WT loss: 0.1496
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:48:56,547  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-18 15:49:34,257  - INFO - === [Epoch 93/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:37.7090s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.879 â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.852 â”‚ 0.899 â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.846 â”‚ 0.88  â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1250, ET: 0.1620, TC: 0.1221, WT: 0.0909
[0m
[0;33m2025-05-18 15:49:34,258  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 11/100[0m
[0;32m2025-05-18 15:49:34,258  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-18 15:54:21,732  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-18 15:54:21,733  - INFO - - Train mean loss: 0.2074
- ET loss: 0.2582
- TC loss: 0.2119
- WT loss: 0.1521
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 15:54:21,733  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-18 15:54:59,854  - INFO - === [Epoch 94/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:38.1200s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.877 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.815 â”‚ 0.845 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.889 â”‚ 0.848 â”‚ 0.896 â”‚ 0.924 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.847 â”‚ 0.88  â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1265, ET: 0.1629, TC: 0.1236, WT: 0.0929
[0m
[0;33m2025-05-18 15:54:59,854  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 12/100[0m
[0;32m2025-05-18 15:54:59,854  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-18 15:59:47,626  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-18 15:59:47,627  - INFO - - Train mean loss: 0.2056
- ET loss: 0.2566
- TC loss: 0.2128
- WT loss: 0.1475
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 15:59:47,627  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-18 16:00:25,304  - INFO - === [Epoch 95/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:37.6759s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.88  â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.762 â”‚ 0.817 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.888 â”‚ 0.844 â”‚ 0.894 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.853 â”‚ 0.886 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1248, ET: 0.1617, TC: 0.1212, WT: 0.0914
[0m
[0;33m2025-05-18 16:00:25,304  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 13/100[0m
[0;32m2025-05-18 16:00:25,304  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-18 16:05:12,741  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-18 16:05:12,743  - INFO - - Train mean loss: 0.2123
- ET loss: 0.2676
- TC loss: 0.2205
- WT loss: 0.1489
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 16:05:12,743  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-18 16:05:50,555  - INFO - === [Epoch 96/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:37.8110s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.841 â”‚ 0.88  â”‚ 0.911 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.81  â”‚ 0.763 â”‚ 0.818 â”‚ 0.847 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.893 â”‚ 0.851 â”‚ 0.9   â”‚ 0.929 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.848 â”‚ 0.881 â”‚ 0.907 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1241, ET: 0.1610, TC: 0.1207, WT: 0.0907
[0m
[0;33m2025-05-18 16:05:50,556  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 14/100[0m
[0;32m2025-05-18 16:05:50,556  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-18 16:10:37,872  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-18 16:10:37,873  - INFO - - Train mean loss: 0.1952
- ET loss: 0.2445
- TC loss: 0.1978
- WT loss: 0.1433
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 16:10:37,873  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-18 16:11:15,642  - INFO - === [Epoch 97/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:37.7667s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.84  â”‚ 0.878 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.851 â”‚ 0.898 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.846 â”‚ 0.88  â”‚ 0.908 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1252, ET: 0.1619, TC: 0.1223, WT: 0.0915
[0m
[0;33m2025-05-18 16:11:15,642  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 15/100[0m
[0;32m2025-05-18 16:11:15,642  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-18 16:16:03,562  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-18 16:16:03,563  - INFO - - Train mean loss: 0.2122
- ET loss: 0.2678
- TC loss: 0.2188
- WT loss: 0.1500
- Cost time: 4.80mins â±ï¸
[0m
[0;32m2025-05-18 16:16:03,564  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-18 16:16:41,331  - INFO - === [Epoch 98/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:37.7655s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.876 â”‚ 0.839 â”‚ 0.878 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.808 â”‚ 0.762 â”‚ 0.816 â”‚ 0.846 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.85  â”‚ 0.898 â”‚ 0.926 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚ 0.846 â”‚ 0.879 â”‚ 0.909 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1255, ET: 0.1623, TC: 0.1227, WT: 0.0914
[0m
[0;33m2025-05-18 16:16:41,331  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 16/100[0m
[0;32m2025-05-18 16:16:41,331  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-18 16:21:28,675  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-18 16:21:28,677  - INFO - - Train mean loss: 0.1963
- ET loss: 0.2457
- TC loss: 0.2011
- WT loss: 0.1420
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 16:21:28,677  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-18 16:22:06,436  - INFO - === [Epoch 99/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:37.7579s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.877 â”‚ 0.84  â”‚ 0.879 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.809 â”‚ 0.763 â”‚ 0.818 â”‚ 0.848 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.892 â”‚ 0.85  â”‚ 0.9   â”‚ 0.925 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.88  â”‚ 0.85  â”‚ 0.88  â”‚ 0.912 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1243, ET: 0.1611, TC: 0.1217, WT: 0.0902
[0m
[0;33m2025-05-18 16:22:06,436  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 17/100[0m
[0;32m2025-05-18 16:22:06,436  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-18 16:26:53,778  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-18 16:26:53,779  - INFO - - Train mean loss: 0.2053
- ET loss: 0.2576
- TC loss: 0.2100
- WT loss: 0.1483
- Cost time: 4.79mins â±ï¸
[0m
[0;32m2025-05-18 16:26:53,779  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-18 16:27:31,565  - INFO - === [Epoch 100/100] ===
- Model:    DCLA_UNet_v2_3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:37.7849s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.875 â”‚ 0.839 â”‚ 0.877 â”‚ 0.908 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.807 â”‚ 0.761 â”‚ 0.815 â”‚ 0.844 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.891 â”‚ 0.85  â”‚ 0.896 â”‚ 0.928 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.877 â”‚ 0.846 â”‚ 0.879 â”‚ 0.905 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1266, ET: 0.1629, TC: 0.1236, WT: 0.0934
[0m
[0;33m2025-05-18 16:27:31,565  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 18/100[0m
[1;31m2025-05-18 16:27:33,172  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠTrain finished. Best val loss: ğŸ‘‰0.1237 at epoch 82[0m
[0;32m2025-05-18 16:27:33,172  - INFO - ğŸ› ï¸ å‡†å¤‡ä¿å­˜æœ€ç»ˆæ¨¡å‹.......[0m
[0;32m2025-05-18 16:27:33,179  - INFO - âœ… æœ€åä¸€ä¸ªæƒé‡æ–‡ä»¶å·²å¤åˆ¶ä¸º /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/DCLA_UNet_v2_3_final_model.pth[0m
[1;31m2025-05-18 16:27:33,179  - CRITICAL - ğŸ¥³ğŸ‰ğŸŠ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜[0m
[0;32m2025-05-18 16:27:33,179  - INFO - ğŸ› ï¸ å‡†å¤‡æµ‹è¯•æ¨¡å‹.......[0m
[1;31m2025-05-18 16:31:06,790  - CRITICAL - === [FINAL TEST METRIC] ===
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚     ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.873 â”‚  0.818 â”‚ 0.879 â”‚ 0.921 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.801 â”‚  0.735 â”‚ 0.81  â”‚ 0.859 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.884 â”‚  0.814 â”‚ 0.904 â”‚ 0.934 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.878 â”‚  0.842 â”‚ 0.878 â”‚ 0.913 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ H95           â”‚  6.891 â”‚ 10.462 â”‚ 5.376 â”‚ 4.837 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1288;ET: 0.1836;ET: 0.1836;TC: 0.1215;WT: 0.0812
[0m
[0;32m2025-05-18 16:31:06,791  - INFO - ğŸ¥³ğŸ‰ğŸŠ æ¨¡å‹æµ‹è¯•å·²å®Œæˆ.......[0m
[0;32m2025-05-18 16:31:06,791  - INFO - æµ‹è¯•é›†çš„æŒ‡æ ‡å·²ä¿å­˜è‡³/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v2_3_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-18.log[0m
[0;32m2025-05-18 16:31:13,312  - INFO - åŠ è½½é…ç½®æ–‡ä»¶è€—æ—¶: 0.00 s[0m
[0;32m2025-05-18 16:31:16,882  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-18 16:31:16,884  - INFO - æ•°æ®é›†å·®å¼‚åˆ†æç»“æœ:
è®­ç»ƒé›†æ ·æœ¬æ•°: 875
éªŒè¯é›†æ ·æœ¬æ•°: 250
æµ‹è¯•é›†æ ·æœ¬æ•°: 126
----------------------------------------[0m
[0;32m2025-05-18 16:31:16,884  - INFO - train_val_overlap: æ— é‡å [0m
[0;32m2025-05-18 16:31:16,885  - INFO - train_test_overlap: æ— é‡å [0m
[0;32m2025-05-18 16:31:16,885  - INFO - val_test_overlap: æ— é‡å [0m
[0;32m2025-05-18 16:31:16,885  - INFO - all_overlap: æ— é‡å [0m
[0;33m2025-05-18 16:31:16,891  - WARNING - è®­ç»ƒé›†å¤§å°å˜æˆï¼š875[0m
[0;33m2025-05-18 16:31:16,892  - WARNING - éªŒè¯é›†å¤§å°å˜æˆï¼š250[0m
[0;33m2025-05-18 16:31:16,892  - WARNING - æµ‹è¯•å¤§å°å˜æˆï¼š126[0m
[0;32m2025-05-18 16:31:16,895  - INFO - ğŸ§  é¡¹ç›®åï¼š0510_DCLA_UNet_v2 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Parameter           â”‚ Value                                                           â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ data_root           â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ outputs_dir         â”‚ /root/autodl-tmp/DCLA-UNet/outputs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ results_dir         â”‚ /root/autodl-tmp/DCLA-UNet/results                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ in_channel          â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ out_channel         â”‚ 4                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ config              â”‚ None                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model_name          â”‚ ResUNetBaseline_S_SLKv2_MSF_v2                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb_project         â”‚ 0510_DCLA_UNet_v2                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ resume              â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss_type           â”‚ diceloss                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ optimizer_type      â”‚ adamw                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ epochs              â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_size          â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ num_workers         â”‚ 8                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lr                  â”‚ 0.0001                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ wd                  â”‚ 1e-05                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_eta_min      â”‚ 1e-06                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ cosine_T_max        â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ early_stop_patience â”‚ 100                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scheduler_type      â”‚ cosine                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ save_max            â”‚ 2                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ interval            â”‚ 1                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ commit              â”‚ Training                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ data_split          â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ local               â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_length        â”‚ 875                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_length          â”‚ 250                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_length         â”‚ 126                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ slb                 â”‚ True                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ tb                  â”‚ False                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_csv_path      â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ val_csv_path        â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test_csv_path       â”‚ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ total_parms         â”‚ 0.68 M                                                          â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›[0m
[0;32m2025-05-18 16:31:19,747  - INFO - 
model: ResUNetBaseline_S_SLKv2_MSF_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-18 16:31:19,748  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-18 16:35:50,726  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-18 16:35:50,729  - INFO - - Train mean loss: 0.5431
- ET loss: 0.6411
- TC loss: 0.5410
- WT loss: 0.4471
- Cost time: 4.52mins â±ï¸
[0m
[0;32m2025-05-18 16:35:50,729  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-18 16:36:26,298  - INFO - === [Epoch 1/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:35.5679s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.582 â”‚ 0.534 â”‚ 0.639 â”‚ 0.574 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.446 â”‚ 0.393 â”‚ 0.51  â”‚ 0.434 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.65  â”‚ 0.435 â”‚ 0.602 â”‚ 0.912 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.7   â”‚ 0.837 â”‚ 0.813 â”‚ 0.449 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4210, ET: 0.4719, TC: 0.3662, WT: 0.4250
[0m
[0;32m2025-05-18 16:36:26,367  - INFO - âœ¨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.4210_dice0.5825_20250518163626.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 16:36:26,368  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-18 16:40:55,406  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-18 16:40:55,407  - INFO - - Train mean loss: 0.4941
- ET loss: 0.5740
- TC loss: 0.4624
- WT loss: 0.4460
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 16:40:55,407  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-18 16:41:30,945  - INFO - === [Epoch 2/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:35.5365s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.559 â”‚ 0.427 â”‚ 0.561 â”‚ 0.687 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.422 â”‚ 0.292 â”‚ 0.425 â”‚ 0.549 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.516 â”‚ 0.297 â”‚ 0.438 â”‚ 0.813 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.833 â”‚ 0.934 â”‚ 0.938 â”‚ 0.628 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.4455, ET: 0.5769, TC: 0.4439, WT: 0.3158
[0m
[0;33m2025-05-18 16:41:30,945  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 16:41:30,945  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-18 16:46:00,683  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-18 16:46:00,685  - INFO - - Train mean loss: 0.4739
- ET loss: 0.5243
- TC loss: 0.4048
- WT loss: 0.4926
- Cost time: 4.50mins â±ï¸
[0m
[0;32m2025-05-18 16:46:00,685  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-18 16:46:36,105  - INFO - === [Epoch 3/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:35.4200s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.622 â”‚ 0.612 â”‚ 0.733 â”‚ 0.521 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.491 â”‚ 0.475 â”‚ 0.619 â”‚ 0.379 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.719 â”‚ 0.515 â”‚ 0.71  â”‚ 0.932 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.691 â”‚ 0.852 â”‚ 0.834 â”‚ 0.387 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3803, ET: 0.3911, TC: 0.2711, WT: 0.4788
[0m
[0;32m2025-05-18 16:46:36,164  - INFO - âœ¨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.3803_dice0.6218_20250518164636.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 16:46:36,165  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-18 16:51:05,623  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-18 16:51:05,624  - INFO - - Train mean loss: 0.4664
- ET loss: 0.5118
- TC loss: 0.3938
- WT loss: 0.4935
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 16:51:05,624  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-18 16:51:41,296  - INFO - === [Epoch 4/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:35.6712s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.627 â”‚ 0.611 â”‚ 0.741 â”‚ 0.529 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.496 â”‚ 0.472 â”‚ 0.63  â”‚ 0.386 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.7   â”‚ 0.497 â”‚ 0.692 â”‚ 0.909 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.719 â”‚ 0.885 â”‚ 0.871 â”‚ 0.401 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3748, ET: 0.3913, TC: 0.2618, WT: 0.4713
[0m
[1;31m2025-05-18 16:51:41,298  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch3_loss0.3803_dice0.6218_20250518164636.pth[0m
[0;32m2025-05-18 16:51:41,357  - INFO - âœ¨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.3748_dice0.6270_20250518165141.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 16:51:41,358  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-18 16:56:10,829  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-18 16:56:10,830  - INFO - - Train mean loss: 0.4435
- ET loss: 0.4765
- TC loss: 0.3563
- WT loss: 0.4977
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 16:56:10,830  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-18 16:56:46,365  - INFO - === [Epoch 5/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:35.5335s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.635 â”‚ 0.62  â”‚ 0.754 â”‚ 0.53  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.506 â”‚ 0.483 â”‚ 0.647 â”‚ 0.387 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.708 â”‚ 0.509 â”‚ 0.706 â”‚ 0.907 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.724 â”‚ 0.89  â”‚ 0.878 â”‚ 0.402 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3677, ET: 0.3832, TC: 0.2497, WT: 0.4702
[0m
[1;31m2025-05-18 16:56:46,367  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch4_loss0.3748_dice0.6270_20250518165141.pth[0m
[0;32m2025-05-18 16:56:46,427  - INFO - âœ¨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.3677_dice0.6347_20250518165646.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 16:56:46,428  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-18 17:01:15,567  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-18 17:01:15,571  - INFO - - Train mean loss: 0.4419
- ET loss: 0.4847
- TC loss: 0.3633
- WT loss: 0.4778
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 17:01:15,571  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-18 17:01:51,033  - INFO - === [Epoch 6/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:35.4606s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.625 â”‚ 0.563 â”‚ 0.708 â”‚ 0.603 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.491 â”‚ 0.423 â”‚ 0.591 â”‚ 0.458 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.652 â”‚ 0.437 â”‚ 0.619 â”‚ 0.902 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.78  â”‚ 0.928 â”‚ 0.926 â”‚ 0.487 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3773, ET: 0.4398, TC: 0.2948, WT: 0.3973
[0m
[0;33m2025-05-18 17:01:51,033  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 17:01:51,033  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-18 17:06:20,326  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-18 17:06:20,328  - INFO - - Train mean loss: 0.4267
- ET loss: 0.4563
- TC loss: 0.3296
- WT loss: 0.4942
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 17:06:20,328  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-18 17:06:56,042  - INFO - === [Epoch 7/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:35.7136s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.649 â”‚ 0.664 â”‚ 0.786 â”‚ 0.496 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.526 â”‚ 0.534 â”‚ 0.688 â”‚ 0.356 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.76  â”‚ 0.569 â”‚ 0.776 â”‚ 0.937 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.698 â”‚ 0.878 â”‚ 0.853 â”‚ 0.363 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3532, ET: 0.3380, TC: 0.2171, WT: 0.5046
[0m
[1;31m2025-05-18 17:06:56,044  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch5_loss0.3677_dice0.6347_20250518165646.pth[0m
[0;32m2025-05-18 17:06:56,107  - INFO - âœ¨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.3532_dice0.6487_20250518170656.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:06:56,107  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-18 17:11:24,747  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-18 17:11:24,748  - INFO - - Train mean loss: 0.4448
- ET loss: 0.4844
- TC loss: 0.3620
- WT loss: 0.4882
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 17:11:24,749  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-18 17:12:00,626  - INFO - === [Epoch 8/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:35.8770s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.646 â”‚ 0.634 â”‚ 0.777 â”‚ 0.528 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.52  â”‚ 0.499 â”‚ 0.675 â”‚ 0.385 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.741 â”‚ 0.531 â”‚ 0.745 â”‚ 0.947 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.717 â”‚ 0.882 â”‚ 0.876 â”‚ 0.393 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3549, ET: 0.3676, TC: 0.2250, WT: 0.4721
[0m
[0;33m2025-05-18 17:12:00,627  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 17:12:00,627  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-18 17:16:29,124  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-18 17:16:29,126  - INFO - - Train mean loss: 0.4229
- ET loss: 0.4548
- TC loss: 0.3308
- WT loss: 0.4831
- Cost time: 4.47mins â±ï¸
[0m
[0;32m2025-05-18 17:16:29,126  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-18 17:17:05,274  - INFO - === [Epoch 9/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:36.1476s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.655 â”‚ 0.688 â”‚ 0.798 â”‚ 0.477 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.534 â”‚ 0.564 â”‚ 0.701 â”‚ 0.338 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.78  â”‚ 0.604 â”‚ 0.806 â”‚ 0.931 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.689 â”‚ 0.876 â”‚ 0.842 â”‚ 0.348 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3481, ET: 0.3147, TC: 0.2066, WT: 0.5232
[0m
[1;31m2025-05-18 17:17:05,276  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch7_loss0.3532_dice0.6487_20250518170656.pth[0m
[0;32m2025-05-18 17:17:05,335  - INFO - âœ¨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.3481_dice0.6545_20250518171705.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:17:05,336  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-18 17:21:33,914  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-18 17:21:33,915  - INFO - - Train mean loss: 0.4276
- ET loss: 0.4495
- TC loss: 0.3225
- WT loss: 0.5108
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 17:21:33,915  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-18 17:22:09,623  - INFO - === [Epoch 10/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:35.7072s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.654 â”‚ 0.654 â”‚ 0.792 â”‚ 0.518 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.53  â”‚ 0.52  â”‚ 0.693 â”‚ 0.376 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.732 â”‚ 0.54  â”‚ 0.745 â”‚ 0.91  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.731 â”‚ 0.908 â”‚ 0.894 â”‚ 0.39  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3480, ET: 0.3491, TC: 0.2124, WT: 0.4826
[0m
[1;31m2025-05-18 17:22:09,626  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch9_loss0.3481_dice0.6545_20250518171705.pth[0m
[0;32m2025-05-18 17:22:09,689  - INFO - âœ¨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.3480_dice0.6544_20250518172209.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:22:09,689  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-18 17:26:38,936  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-18 17:26:38,937  - INFO - - Train mean loss: 0.4191
- ET loss: 0.4445
- TC loss: 0.3162
- WT loss: 0.4967
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 17:26:38,937  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-18 17:27:14,184  - INFO - === [Epoch 11/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:35.2455s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.666 â”‚ 0.673 â”‚ 0.813 â”‚ 0.513 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.545 â”‚ 0.543 â”‚ 0.72  â”‚ 0.372 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.776 â”‚ 0.578 â”‚ 0.795 â”‚ 0.954 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.718 â”‚ 0.891 â”‚ 0.881 â”‚ 0.381 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3357, ET: 0.3293, TC: 0.1906, WT: 0.4871
[0m
[1;31m2025-05-18 17:27:14,185  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch10_loss0.3480_dice0.6544_20250518172209.pth[0m
[0;32m2025-05-18 17:27:14,244  - INFO - âœ¨ Saved checkpoint (epoch 11) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.3357_dice0.6662_20250518172714.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:27:14,244  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-18 17:31:43,028  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-18 17:31:43,029  - INFO - - Train mean loss: 0.4341
- ET loss: 0.4629
- TC loss: 0.3400
- WT loss: 0.4993
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 17:31:43,029  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-18 17:32:18,567  - INFO - === [Epoch 12/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:35.5377s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.667 â”‚ 0.663 â”‚ 0.808 â”‚ 0.531 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.547 â”‚ 0.534 â”‚ 0.717 â”‚ 0.389 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.762 â”‚ 0.562 â”‚ 0.776 â”‚ 0.948 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.735 â”‚ 0.903 â”‚ 0.899 â”‚ 0.402 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.3345, ET: 0.3400, TC: 0.1962, WT: 0.4672
[0m
[1;31m2025-05-18 17:32:18,569  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch11_loss0.3357_dice0.6662_20250518172714.pth[0m
[0;32m2025-05-18 17:32:18,627  - INFO - âœ¨ Saved checkpoint (epoch 12) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.3345_dice0.6671_20250518173218.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:32:18,627  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-18 17:36:47,783  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-18 17:36:47,784  - INFO - - Train mean loss: 0.3560
- ET loss: 0.4218
- TC loss: 0.3313
- WT loss: 0.3150
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 17:36:47,784  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-18 17:37:23,241  - INFO - === [Epoch 13/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:35.4559s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.773 â”‚ 0.672 â”‚ 0.795 â”‚ 0.851 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.663 â”‚ 0.539 â”‚ 0.693 â”‚ 0.756 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.725 â”‚ 0.561 â”‚ 0.761 â”‚ 0.854 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.879 â”‚ 0.9   â”‚ 0.868 â”‚ 0.869 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2336, ET: 0.3301, TC: 0.2092, WT: 0.1615
[0m
[1;31m2025-05-18 17:37:23,242  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch12_loss0.3345_dice0.6671_20250518173218.pth[0m
[0;32m2025-05-18 17:37:23,300  - INFO - âœ¨ Saved checkpoint (epoch 13) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.2336_dice0.7726_20250518173723.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:37:23,300  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-18 17:41:52,207  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-18 17:41:52,208  - INFO - - Train mean loss: 0.3174
- ET loss: 0.3912
- TC loss: 0.3251
- WT loss: 0.2360
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 17:41:52,209  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-18 17:42:27,769  - INFO - === [Epoch 14/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:35.5601s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.792 â”‚ 0.717 â”‚ 0.8   â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.691 â”‚ 0.598 â”‚ 0.701 â”‚ 0.773 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.803 â”‚ 0.656 â”‚ 0.852 â”‚ 0.9   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.828 â”‚ 0.85  â”‚ 0.789 â”‚ 0.846 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2108, ET: 0.2855, TC: 0.2021, WT: 0.1447
[0m
[1;31m2025-05-18 17:42:27,771  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch13_loss0.2336_dice0.7726_20250518173723.pth[0m
[0;32m2025-05-18 17:42:27,831  - INFO - âœ¨ Saved checkpoint (epoch 14) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch14_loss0.2108_dice0.7924_20250518174227.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:42:27,832  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-18 17:46:56,813  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-18 17:46:56,814  - INFO - - Train mean loss: 0.3092
- ET loss: 0.3865
- TC loss: 0.3225
- WT loss: 0.2187
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 17:46:56,814  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-18 17:47:32,257  - INFO - === [Epoch 15/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:35.4417s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.795 â”‚ 0.702 â”‚ 0.813 â”‚ 0.869 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.695 â”‚ 0.578 â”‚ 0.722 â”‚ 0.785 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.776 â”‚ 0.618 â”‚ 0.823 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.862 â”‚ 0.876 â”‚ 0.838 â”‚ 0.873 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2094, ET: 0.3007, TC: 0.1901, WT: 0.1374
[0m
[1;31m2025-05-18 17:47:32,258  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch14_loss0.2108_dice0.7924_20250518174227.pth[0m
[0;32m2025-05-18 17:47:32,317  - INFO - âœ¨ Saved checkpoint (epoch 15) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch15_loss0.2094_dice0.7947_20250518174732.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:47:32,318  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-18 17:52:01,470  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-18 17:52:01,471  - INFO - - Train mean loss: 0.3100
- ET loss: 0.3893
- TC loss: 0.3220
- WT loss: 0.2187
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 17:52:01,471  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-18 17:52:36,911  - INFO - === [Epoch 16/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:35.4395s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.801 â”‚ 0.717 â”‚ 0.812 â”‚ 0.873 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.703 â”‚ 0.598 â”‚ 0.72  â”‚ 0.79  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.801 â”‚ 0.653 â”‚ 0.856 â”‚ 0.892 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.845 â”‚ 0.855 â”‚ 0.804 â”‚ 0.875 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2035, ET: 0.2858, TC: 0.1917, WT: 0.1330
[0m
[1;31m2025-05-18 17:52:36,913  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch15_loss0.2094_dice0.7947_20250518174732.pth[0m
[0;32m2025-05-18 17:52:36,971  - INFO - âœ¨ Saved checkpoint (epoch 16) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch16_loss0.2035_dice0.8006_20250518175236.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:52:36,971  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-18 17:57:05,975  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-18 17:57:05,976  - INFO - - Train mean loss: 0.2972
- ET loss: 0.3690
- TC loss: 0.3127
- WT loss: 0.2099
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 17:57:05,976  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-18 17:57:41,624  - INFO - === [Epoch 17/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:35.6469s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.804 â”‚ 0.732 â”‚ 0.803 â”‚ 0.876 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.704 â”‚ 0.615 â”‚ 0.705 â”‚ 0.792 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.786 â”‚ 0.654 â”‚ 0.836 â”‚ 0.867 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.862 â”‚ 0.88  â”‚ 0.803 â”‚ 0.903 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2004, ET: 0.2713, TC: 0.1998, WT: 0.1302
[0m
[1;31m2025-05-18 17:57:41,625  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch16_loss0.2035_dice0.8006_20250518175236.pth[0m
[0;32m2025-05-18 17:57:41,684  - INFO - âœ¨ Saved checkpoint (epoch 17) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch17_loss0.2004_dice0.8036_20250518175741.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 17:57:41,684  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-18 18:02:10,701  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-18 18:02:10,702  - INFO - - Train mean loss: 0.3037
- ET loss: 0.3791
- TC loss: 0.3241
- WT loss: 0.2080
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 18:02:10,702  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-18 18:02:46,236  - INFO - === [Epoch 18/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:35.5328s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.802 â”‚ 0.712 â”‚ 0.818 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.702 â”‚ 0.59  â”‚ 0.724 â”‚ 0.793 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.764 â”‚ 0.617 â”‚ 0.815 â”‚ 0.86  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.889 â”‚ 0.903 â”‚ 0.853 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.2027, ET: 0.2910, TC: 0.1864, WT: 0.1306
[0m
[0;33m2025-05-18 18:02:46,236  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 18:02:46,236  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-18 18:07:15,582  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-18 18:07:15,583  - INFO - - Train mean loss: 0.2964
- ET loss: 0.3726
- TC loss: 0.3129
- WT loss: 0.2038
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 18:07:15,584  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-18 18:07:51,251  - INFO - === [Epoch 19/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:35.6654s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.811 â”‚ 0.735 â”‚ 0.821 â”‚ 0.877 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.713 â”‚ 0.618 â”‚ 0.725 â”‚ 0.795 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.79  â”‚ 0.658 â”‚ 0.85  â”‚ 0.863 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.873 â”‚ 0.887 â”‚ 0.821 â”‚ 0.911 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1933, ET: 0.2677, TC: 0.1834, WT: 0.1290
[0m
[1;31m2025-05-18 18:07:51,254  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch17_loss0.2004_dice0.8036_20250518175741.pth[0m
[0;32m2025-05-18 18:07:51,315  - INFO - âœ¨ Saved checkpoint (epoch 19) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch19_loss0.1933_dice0.8110_20250518180751.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 18:07:51,316  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-18 18:12:20,448  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-18 18:12:20,449  - INFO - - Train mean loss: 0.2874
- ET loss: 0.3593
- TC loss: 0.3067
- WT loss: 0.1962
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 18:12:20,449  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-18 18:12:55,957  - INFO - === [Epoch 20/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:35.5075s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.806 â”‚ 0.711 â”‚ 0.825 â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.708 â”‚ 0.587 â”‚ 0.734 â”‚ 0.803 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.774 â”‚ 0.616 â”‚ 0.823 â”‚ 0.885 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.883 â”‚ 0.897 â”‚ 0.856 â”‚ 0.896 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1965, ET: 0.2903, TC: 0.1778, WT: 0.1212
[0m
[0;33m2025-05-18 18:12:55,957  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 18:12:55,958  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-18 18:17:25,121  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-18 18:17:25,122  - INFO - - Train mean loss: 0.2954
- ET loss: 0.3735
- TC loss: 0.3193
- WT loss: 0.1933
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 18:17:25,122  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-18 18:18:00,508  - INFO - === [Epoch 21/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:35.3853s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.81  â”‚ 0.75  â”‚ 0.794 â”‚ 0.886 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.713 â”‚ 0.64  â”‚ 0.692 â”‚ 0.807 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.826 â”‚ 0.709 â”‚ 0.881 â”‚ 0.888 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.83  â”‚ 0.841 â”‚ 0.748 â”‚ 0.9   â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1930, ET: 0.2521, TC: 0.2084, WT: 0.1185
[0m
[1;31m2025-05-18 18:18:00,510  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch19_loss0.1933_dice0.8110_20250518180751.pth[0m
[0;32m2025-05-18 18:18:00,572  - INFO - âœ¨ Saved checkpoint (epoch 21) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.1930_dice0.8099_20250518181800.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 18:18:00,572  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-18 18:22:29,416  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-18 18:22:29,417  - INFO - - Train mean loss: 0.2962
- ET loss: 0.3656
- TC loss: 0.3223
- WT loss: 0.2006
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 18:22:29,417  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-18 18:23:05,078  - INFO - === [Epoch 22/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:35.6605s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.813 â”‚ 0.737 â”‚ 0.82  â”‚ 0.882 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.718 â”‚ 0.621 â”‚ 0.727 â”‚ 0.806 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.826 â”‚ 0.677 â”‚ 0.874 â”‚ 0.927 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.843 â”‚ 0.867 â”‚ 0.802 â”‚ 0.86  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1896, ET: 0.2654, TC: 0.1828, WT: 0.1205
[0m
[1;31m2025-05-18 18:23:05,080  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch21_loss0.1930_dice0.8099_20250518181800.pth[0m
[0;32m2025-05-18 18:23:05,139  - INFO - âœ¨ Saved checkpoint (epoch 22) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch22_loss0.1896_dice0.8130_20250518182305.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 18:23:05,139  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-18 18:27:34,204  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-18 18:27:34,205  - INFO - - Train mean loss: 0.2703
- ET loss: 0.3473
- TC loss: 0.2833
- WT loss: 0.1804
- Cost time: 4.48mins â±ï¸
[0m
[0;32m2025-05-18 18:27:34,205  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-18 18:28:09,699  - INFO - === [Epoch 23/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:35.4928s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.811 â”‚ 0.73  â”‚ 0.814 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.717 â”‚ 0.615 â”‚ 0.724 â”‚ 0.812 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.811 â”‚ 0.666 â”‚ 0.863 â”‚ 0.905 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.85  â”‚ 0.863 â”‚ 0.801 â”‚ 0.887 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1920, ET: 0.2720, TC: 0.1883, WT: 0.1156
[0m
[0;33m2025-05-18 18:28:09,699  - WARNING - ğŸ˜¢ğŸ˜¢ğŸ˜¢Early stopping counter: 1/100[0m
[0;32m2025-05-18 18:28:09,699  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-18 18:32:39,168  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-18 18:32:39,169  - INFO - - Train mean loss: 0.2725
- ET loss: 0.3517
- TC loss: 0.2834
- WT loss: 0.1824
- Cost time: 4.49mins â±ï¸
[0m
[0;32m2025-05-18 18:32:39,169  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-18 18:33:14,554  - INFO - === [Epoch 24/100] ===
- Model:    ResUNetBaseline_S_SLKv2_MSF_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:35.3843s â±ï¸
- early_stopping: 100
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••
â”‚ Metric_Name   â”‚   MEAN â”‚    ET â”‚    TC â”‚    WT â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ Dice          â”‚  0.817 â”‚ 0.732 â”‚ 0.831 â”‚ 0.887 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Jaccard       â”‚  0.721 â”‚ 0.614 â”‚ 0.741 â”‚ 0.807 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Precision     â”‚  0.788 â”‚ 0.65  â”‚ 0.85  â”‚ 0.865 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recall        â”‚  0.886 â”‚ 0.894 â”‚ 0.84  â”‚ 0.924 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›
Mean Loss: 0.1867, ET: 0.2701, TC: 0.1723, WT: 0.1178
[0m
[1;31m2025-05-18 18:33:14,555  - CRITICAL - ğŸ—‘ï¸ Due to reach the max save amount, Removed best_epoch22_loss0.1896_dice0.8130_20250518182305.pth[0m
[0;32m2025-05-18 18:33:14,614  - INFO - âœ¨ Saved checkpoint (epoch 24) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLKv2_MSF_v2_2025-05-18_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch24_loss0.1867_dice0.8165_20250518183314.pth;             Size 8.62 MB[0m
[0;32m2025-05-18 18:33:14,615  - INFO - === Training on [Epoch 25/100] ===:[0m
