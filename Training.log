[0;32m2025-05-15 17:44:50,888  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 17:44:52,389  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 17:44:52,395  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 17:44:52,395  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 17:44:52,395  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 17:44:52,395  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 17:44:52,395  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 17:44:52,403  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 17:44:52,403  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 17:44:52,403  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 17:44:52,405  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA_UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA_UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA_UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v2                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA_UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA_UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA_UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.65 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 17:44:52,872  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 17:44:52,872  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 17:47:33,057  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 17:47:33,058  - INFO - - Train mean loss: 0.8566
- ET loss: 0.6492
- TC loss: 0.9768
- WT loss: 0.9439
- Cost time: 2.67mins ⏱️
[0m
[0;32m2025-05-15 17:47:33,058  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 17:47:53,047  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v2
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:19.9877s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.258 │ 0.662 │ 0.031 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.192 │ 0.519 │ 0.016 │ 0.042 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.232 │ 0.638 │ 0.016 │ 0.042 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.908 │ 0.742 │ 0.983 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7472, ET: 0.3528, TC: 0.9686, WT: 0.9202
[0m
[0;32m2025-05-15 17:47:53,390  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA_UNet/results/DCLA_UNet_v2_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7472_dice0.2578_20250515174753.pth;             Size 8.29 MB[0m
[0;32m2025-05-15 17:47:53,390  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 18:23:47,997  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 18:23:49,780  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 18:23:49,787  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 18:23:49,787  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 18:23:49,787  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 18:23:49,787  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 18:23:49,787  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 18:23:49,794  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 18:23:49,794  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 18:23:49,794  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 18:23:49,797  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA_UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA_UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA_UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v2                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA_UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA_UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA_UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.65 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 18:23:50,266  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 18:23:50,266  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 18:25:06,844  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 18:25:08,555  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 18:25:08,556  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 18:25:08,556  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 18:25:08,556  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 18:25:08,557  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 18:25:08,557  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 18:25:08,561  - WARNING - 训练集大小变成：875[0m
[0;33m2025-05-15 18:25:08,561  - WARNING - 验证集大小变成：250[0m
[0;33m2025-05-15 18:25:08,561  - WARNING - 测试大小变成：126[0m
[0;32m2025-05-15 18:25:08,563  - INFO - 🧠 项目名：0515_DCLA_UNet_v2 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA_UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA_UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA_UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v2                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ 0515_DCLA_UNet_v2                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-06                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 875                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 250                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 126                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA_UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA_UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA_UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.65 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 18:25:11,097  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 18:25:11,097  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 18:27:40,546  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 18:27:42,399  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-15 18:27:42,401  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 18:27:42,402  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 18:27:42,402  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 18:27:42,402  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 18:27:42,402  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 18:27:42,407  - WARNING - 训练集大小变成：875[0m
[0;33m2025-05-15 18:27:42,407  - WARNING - 验证集大小变成：250[0m
[0;33m2025-05-15 18:27:42,407  - WARNING - 测试大小变成：126[0m
[0;32m2025-05-15 18:27:42,409  - INFO - 🧠 项目名：0515_DCLA_UNet_v2 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v2                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ 0515_DCLA_UNet_v2                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-06                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 875                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 250                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 126                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.65 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 18:27:44,652  - INFO - 
model: DCLA_UNet_v2
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 18:27:44,652  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 19:12:19,496  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 19:12:21,431  - INFO - Total number of parameters: 0.70 M[0m
[0;32m2025-05-15 19:12:21,437  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 19:12:21,437  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 19:12:21,437  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:12:21,437  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:12:21,437  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 19:12:21,451  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 19:12:21,451  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 19:12:21,451  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 19:12:21,454  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.70 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 19:12:21,802  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:12:21,802  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:15:33,643  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:15:33,644  - INFO - - Train mean loss: 0.6509
- ET loss: 0.6540
- TC loss: 0.7319
- WT loss: 0.5668
- Cost time: 3.20mins ⏱️
[0m
[0;32m2025-05-15 19:15:33,644  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:15:59,196  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:25.5510s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.627 │ 0.625 │ 0.496 │ 0.759 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.493 │ 0.482 │ 0.357 │ 0.639 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.611 │ 0.585 │ 0.397 │ 0.85  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.775 │ 0.737 │ 0.868 │ 0.72  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3791, ET: 0.3852, TC: 0.5084, WT: 0.2438
[0m
[0;32m2025-05-15 19:15:59,293  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3791_dice0.6267_20250515191559.pth;             Size 8.86 MB[0m
[0;32m2025-05-15 19:15:59,294  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:16:36,932  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 19:16:38,848  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 19:16:38,850  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 19:16:38,850  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 19:16:38,850  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:16:38,850  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:16:38,850  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 19:16:38,855  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 19:16:38,855  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 19:16:38,855  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 19:16:38,858  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.68 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 19:16:39,219  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:16:39,219  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:19:40,664  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:19:40,664  - INFO - - Train mean loss: 0.7285
- ET loss: 0.8120
- TC loss: 0.7506
- WT loss: 0.6230
- Cost time: 3.02mins ⏱️
[0m
[0;32m2025-05-15 19:19:40,664  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:20:05,058  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.3930s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.592 │ 0.499 │ 0.555 │ 0.722 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.456 │ 0.353 │ 0.416 │ 0.598 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.595 │ 0.406 │ 0.487 │ 0.891 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.744 │ 0.773 │ 0.816 │ 0.645 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4120, ET: 0.5086, TC: 0.4505, WT: 0.2768
[0m
[0;32m2025-05-15 19:20:05,164  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4120_dice0.5922_20250515192005.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 19:20:05,164  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 19:23:04,684  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 19:23:04,684  - INFO - - Train mean loss: 0.4839
- ET loss: 0.5692
- TC loss: 0.5375
- WT loss: 0.3450
- Cost time: 2.99mins ⏱️
[0m
[0;32m2025-05-15 19:23:04,684  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:23:29,481  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.7965s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.68  │ 0.62  │ 0.647 │ 0.773 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.546 │ 0.473 │ 0.512 │ 0.654 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.72  │ 0.574 │ 0.711 │ 0.877 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.711 │ 0.743 │ 0.664 │ 0.726 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3285, ET: 0.3906, TC: 0.3643, WT: 0.2305
[0m
[1;31m2025-05-15 19:23:29,482  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.4120_dice0.5922_20250515192005.pth[0m
[0;32m2025-05-15 19:23:29,580  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3285_dice0.6798_20250515192329.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 19:23:29,581  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 19:27:13,584  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 19:27:15,497  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-15 19:27:15,498  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 19:27:15,498  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 19:27:15,498  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:27:15,498  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:27:15,498  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 19:27:15,503  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 19:27:15,503  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 19:27:15,503  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 19:27:15,506  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.64 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 19:27:15,877  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:27:15,877  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:30:15,022  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:30:15,023  - INFO - - Train mean loss: 0.6804
- ET loss: 0.7841
- TC loss: 0.7089
- WT loss: 0.5482
- Cost time: 2.99mins ⏱️
[0m
[0;32m2025-05-15 19:30:15,023  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:30:39,299  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.2754s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.57  │ 0.417 │ 0.555 │ 0.737 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.439 │ 0.284 │ 0.419 │ 0.615 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.574 │ 0.316 │ 0.48  │ 0.926 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.767 │ 0.825 │ 0.839 │ 0.638 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4343, ET: 0.5868, TC: 0.4502, WT: 0.2660
[0m
[1;31m2025-05-15 19:30:39,301  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.3285_dice0.6798_20250515192329.pth[0m
[0;32m2025-05-15 19:30:39,396  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4343_dice0.5696_20250515193039.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:30:39,396  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 19:33:36,435  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 19:33:36,436  - INFO - - Train mean loss: 0.5199
- ET loss: 0.6505
- TC loss: 0.5474
- WT loss: 0.3617
- Cost time: 2.95mins ⏱️
[0m
[0;32m2025-05-15 19:33:36,436  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:34:00,537  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.1006s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.584 │ 0.424 │ 0.576 │ 0.753 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.454 │ 0.291 │ 0.44  │ 0.631 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.575 │ 0.314 │ 0.486 │ 0.925 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.795 │ 0.854 │ 0.874 │ 0.657 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4183, ET: 0.5777, TC: 0.4285, WT: 0.2488
[0m
[1;31m2025-05-15 19:34:00,539  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.4343_dice0.5696_20250515193039.pth[0m
[0;32m2025-05-15 19:34:00,628  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4183_dice0.5844_20250515193400.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:34:00,628  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-15 19:36:58,217  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-15 19:36:58,218  - INFO - - Train mean loss: 0.4852
- ET loss: 0.6111
- TC loss: 0.5023
- WT loss: 0.3421
- Cost time: 2.96mins ⏱️
[0m
[0;32m2025-05-15 19:36:58,218  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 19:37:22,471  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:24.2527s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.589 │ 0.422 │ 0.572 │ 0.772 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.46  │ 0.289 │ 0.438 │ 0.654 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.565 │ 0.307 │ 0.471 │ 0.918 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.822 │ 0.879 │ 0.898 │ 0.689 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4135, ET: 0.5802, TC: 0.4309, WT: 0.2295
[0m
[1;31m2025-05-15 19:37:22,472  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.4183_dice0.5844_20250515193400.pth[0m
[0;32m2025-05-15 19:37:22,560  - INFO - ✨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.4135_dice0.5886_20250515193722.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:37:22,560  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;32m2025-05-15 19:39:33,167  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 19:39:35,066  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-15 19:39:35,068  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 19:39:35,068  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 19:39:35,068  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:39:35,068  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:39:35,068  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 19:39:35,073  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 19:39:35,073  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 19:39:35,073  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 19:39:35,076  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.64 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 19:39:35,426  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:39:35,426  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:42:35,196  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:42:35,196  - INFO - - Train mean loss: 0.8548
- ET loss: 0.6814
- TC loss: 0.9645
- WT loss: 0.9184
- Cost time: 3.00mins ⏱️
[0m
[0;32m2025-05-15 19:42:35,196  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:42:59,671  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.4739s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.254 │ 0.619 │ 0.041 │ 0.102 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.183 │ 0.472 │ 0.021 │ 0.055 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.205 │ 0.538 │ 0.021 │ 0.055 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.925 │ 0.791 │ 0.983 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7541, ET: 0.4053, TC: 0.9591, WT: 0.8980
[0m
[1;31m2025-05-15 19:42:59,672  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.4135_dice0.5886_20250515193722.pth[0m
[0;32m2025-05-15 19:42:59,776  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7541_dice0.2540_20250515194259.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:42:59,776  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 19:45:57,975  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 19:45:57,975  - INFO - - Train mean loss: 0.7838
- ET loss: 0.5014
- TC loss: 0.9559
- WT loss: 0.8942
- Cost time: 2.97mins ⏱️
[0m
[0;32m2025-05-15 19:45:57,976  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:46:22,309  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.3333s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.291 │ 0.69  │ 0.053 │ 0.13  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.218 │ 0.554 │ 0.028 │ 0.072 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.256 │ 0.669 │ 0.028 │ 0.072 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.91  │ 0.758 │ 0.981 │ 0.991 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7143, ET: 0.3262, TC: 0.9467, WT: 0.8701
[0m
[1;31m2025-05-15 19:46:22,311  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.7541_dice0.2540_20250515194259.pth[0m
[0;32m2025-05-15 19:46:22,398  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.7143_dice0.2909_20250515194622.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:46:22,399  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 19:46:33,363  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 19:46:35,493  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 19:46:35,494  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 19:46:35,494  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 19:46:35,494  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:46:35,494  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:46:35,494  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 19:46:35,502  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 19:46:35,502  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 19:46:35,502  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 19:46:35,505  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.68 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 19:46:35,867  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:46:35,867  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:49:36,282  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:49:36,283  - INFO - - Train mean loss: 0.8387
- ET loss: 0.5975
- TC loss: 0.9768
- WT loss: 0.9418
- Cost time: 3.01mins ⏱️
[0m
[0;32m2025-05-15 19:49:36,283  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:50:01,138  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.8539s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.272 │ 0.704 │ 0.031 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.21  │ 0.573 │ 0.016 │ 0.042 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.262 │ 0.729 │ 0.016 │ 0.042 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.906 │ 0.735 │ 0.983 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7286, ET: 0.2972, TC: 0.9685, WT: 0.9200
[0m
[1;31m2025-05-15 19:50:01,139  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.7143_dice0.2909_20250515194622.pth[0m
[0;32m2025-05-15 19:50:01,243  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7286_dice0.2719_20250515195001.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 19:50:01,243  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 19:56:01,982  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 19:56:03,959  - INFO - Total number of parameters: 0.64 M[0m
[0;32m2025-05-15 19:56:03,960  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 19:56:03,960  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 19:56:03,960  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:56:03,961  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 19:56:03,961  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 19:56:03,965  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 19:56:03,965  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 19:56:03,965  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 19:56:03,968  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.64 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 19:56:04,335  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 19:56:04,336  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 19:59:07,367  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 19:59:07,368  - INFO - - Train mean loss: 0.8565
- ET loss: 0.6874
- TC loss: 0.9640
- WT loss: 0.9180
- Cost time: 3.05mins ⏱️
[0m
[0;32m2025-05-15 19:59:07,368  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 19:59:32,018  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.6496s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.258 │ 0.629 │ 0.042 │ 0.104 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.187 │ 0.483 │ 0.022 │ 0.056 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.211 │ 0.556 │ 0.022 │ 0.056 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.922 │ 0.782 │ 0.983 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7493, ET: 0.3929, TC: 0.9584, WT: 0.8966
[0m
[1;31m2025-05-15 19:59:32,020  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.7286_dice0.2719_20250515195001.pth[0m
[0;32m2025-05-15 19:59:32,119  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.7493_dice0.2579_20250515195932.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 19:59:32,119  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 20:02:31,396  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 20:02:31,396  - INFO - - Train mean loss: 0.7694
- ET loss: 0.5031
- TC loss: 0.9377
- WT loss: 0.8674
- Cost time: 2.99mins ⏱️
[0m
[0;32m2025-05-15 20:02:31,396  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 20:02:55,726  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:24.3292s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.546 │ 0.598 │ 0.465 │ 0.576 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.413 │ 0.465 │ 0.333 │ 0.442 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.612 │ 0.663 │ 0.426 │ 0.747 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.634 │ 0.652 │ 0.731 │ 0.518 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4588, ET: 0.4103, TC: 0.5399, WT: 0.4261
[0m
[1;31m2025-05-15 20:02:55,727  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.7493_dice0.2579_20250515195932.pth[0m
[0;32m2025-05-15 20:02:55,819  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4588_dice0.5463_20250515200255.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 20:02:55,819  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-15 20:05:53,401  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-15 20:05:53,401  - INFO - - Train mean loss: 0.4644
- ET loss: 0.4611
- TC loss: 0.5625
- WT loss: 0.3696
- Cost time: 2.96mins ⏱️
[0m
[0;32m2025-05-15 20:05:53,401  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 20:06:17,672  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:24.2704s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.652 │ 0.677 │ 0.483 │ 0.796 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.522 │ 0.539 │ 0.348 │ 0.679 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.591 │ 0.601 │ 0.365 │ 0.805 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.856 │ 0.821 │ 0.934 │ 0.813 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3554, ET: 0.3344, TC: 0.5213, WT: 0.2104
[0m
[1;31m2025-05-15 20:06:17,673  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.4588_dice0.5463_20250515200255.pth[0m
[0;32m2025-05-15 20:06:17,768  - INFO - ✨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3554_dice0.6521_20250515200617.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 20:06:17,768  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-15 20:09:15,642  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-15 20:09:15,643  - INFO - - Train mean loss: 0.4435
- ET loss: 0.4466
- TC loss: 0.5513
- WT loss: 0.3326
- Cost time: 2.96mins ⏱️
[0m
[0;32m2025-05-15 20:09:15,643  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-15 20:09:39,954  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:24.3105s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.669 │ 0.708 │ 0.487 │ 0.811 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.544 │ 0.581 │ 0.352 │ 0.7   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.648 │ 0.745 │ 0.37  │ 0.828 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.822 │ 0.712 │ 0.933 │ 0.821 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3362, ET: 0.2991, TC: 0.5157, WT: 0.1939
[0m
[1;31m2025-05-15 20:09:39,955  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.3554_dice0.6521_20250515200617.pth[0m
[0;32m2025-05-15 20:09:40,050  - INFO - ✨ Saved checkpoint (epoch 4) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.3362_dice0.6688_20250515200939.pth;             Size 8.22 MB[0m
[0;32m2025-05-15 20:09:40,050  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;32m2025-05-15 20:14:54,180  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 20:14:56,094  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 20:14:56,096  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 20:14:56,096  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 20:14:56,096  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 20:14:56,096  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 20:14:56,096  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 20:14:56,100  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-15 20:14:56,100  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-15 20:14:56,101  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-15 20:14:56,103  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                             │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.68 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 20:14:56,428  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-15 20:14:56,428  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-15 20:17:54,629  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-15 20:17:54,630  - INFO - - Train mean loss: 0.6699
- ET loss: 1.0000
- TC loss: 0.5798
- WT loss: 0.4299
- Cost time: 2.97mins ⏱️
[0m
[0;32m2025-05-15 20:17:54,630  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-15 20:18:19,043  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:24.4118s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │   ET │    TC │    WT │
╞═══════════════╪════════╪══════╪═══════╪═══════╡
│ Dice          │  0.501 │    0 │ 0.702 │ 0.8   │
├───────────────┼────────┼──────┼───────┼───────┤
│ Jaccard       │  0.418 │    0 │ 0.569 │ 0.686 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Precision     │  0.496 │    0 │ 0.653 │ 0.836 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Recall        │  0.54  │    0 │ 0.831 │ 0.789 │
╘═══════════════╧════════╧══════╧═══════╧═══════╛
Mean Loss: 0.5036, ET: 1.0000, TC: 0.3071, WT: 0.2038
[0m
[1;31m2025-05-15 20:18:19,045  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch4_loss0.3362_dice0.6688_20250515200939.pth[0m
[0;32m2025-05-15 20:18:19,143  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5036_dice0.5007_20250515201819.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 20:18:19,143  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-15 20:21:15,622  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-15 20:21:15,623  - INFO - - Train mean loss: 0.5875
- ET loss: 1.0000
- TC loss: 0.4553
- WT loss: 0.3073
- Cost time: 2.94mins ⏱️
[0m
[0;32m2025-05-15 20:21:15,623  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-15 20:21:39,621  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:23.9979s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │   ET │    TC │    WT │
╞═══════════════╪════════╪══════╪═══════╪═══════╡
│ Dice          │  0.505 │    0 │ 0.718 │ 0.796 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Jaccard       │  0.423 │    0 │ 0.59  │ 0.68  │
├───────────────┼────────┼──────┼───────┼───────┤
│ Precision     │  0.464 │    0 │ 0.649 │ 0.743 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Recall        │  0.581 │    0 │ 0.86  │ 0.882 │
╘═══════════════╧════════╧══════╧═══════╧═══════╛
Mean Loss: 0.5002, ET: 1.0000, TC: 0.2914, WT: 0.2093
[0m
[1;31m2025-05-15 20:21:39,622  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.5036_dice0.5007_20250515201819.pth[0m
[0;32m2025-05-15 20:21:39,720  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5002_dice0.5049_20250515202139.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 20:21:39,721  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-15 20:24:36,983  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-15 20:24:36,983  - INFO - - Train mean loss: 0.5656
- ET loss: 1.0000
- TC loss: 0.4110
- WT loss: 0.2857
- Cost time: 2.95mins ⏱️
[0m
[0;32m2025-05-15 20:24:36,983  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-15 20:25:01,606  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:24.6217s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │   ET │    TC │    WT │
╞═══════════════╪════════╪══════╪═══════╪═══════╡
│ Dice          │  0.495 │    0 │ 0.673 │ 0.812 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Jaccard       │  0.413 │    0 │ 0.539 │ 0.699 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Precision     │  0.445 │    0 │ 0.564 │ 0.771 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Recall        │  0.595 │    0 │ 0.906 │ 0.878 │
╘═══════════════╧════════╧══════╧═══════╧═══════╛
Mean Loss: 0.5095, ET: 1.0000, TC: 0.3349, WT: 0.1936
[0m
[0;33m2025-05-15 20:25:01,606  - WARNING - 😢😢😢Early stopping counter: 1/5[0m
[0;32m2025-05-15 20:25:01,606  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;32m2025-05-15 20:25:30,024  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 20:25:31,967  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-15 20:25:31,969  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 20:25:31,969  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 20:25:31,969  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 20:25:31,969  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 20:25:31,969  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 20:25:31,975  - WARNING - 训练集大小变成：875[0m
[0;33m2025-05-15 20:25:31,975  - WARNING - 验证集大小变成：250[0m
[0;33m2025-05-15 20:25:31,975  - WARNING - 测试大小变成：126[0m
[0;32m2025-05-15 20:25:31,978  - INFO - 🧠 项目名：0515_DCLA_UNet_v2 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ 0515_DCLA_UNet_v2                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-06                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 875                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 250                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 126                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.68 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 20:25:34,770  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 1
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 20:25:34,770  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-15 20:37:57,702  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-15 20:37:57,704  - INFO - - Train mean loss: 0.5939
- ET loss: 1.0000
- TC loss: 0.4670
- WT loss: 0.3145
- Cost time: 12.38mins ⏱️
[0m
[0;32m2025-05-15 20:37:57,704  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 20:39:36,650  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:98.9445s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │   ET │    TC │    WT │
╞═══════════════╪════════╪══════╪═══════╪═══════╡
│ Dice          │  0.511 │    0 │ 0.708 │ 0.827 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Jaccard       │  0.441 │    0 │ 0.595 │ 0.729 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Precision     │  0.553 │    0 │ 0.797 │ 0.862 │
├───────────────┼────────┼──────┼───────┼───────┤
│ Recall        │  0.512 │    0 │ 0.714 │ 0.822 │
╘═══════════════╧════════╧══════╧═══════╧═══════╛
Mean Loss: 0.4919, ET: 1.0000, TC: 0.2976, WT: 0.1782
[0m
[0;32m2025-05-15 20:39:36,760  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.4919_dice0.5115_20250515203936.pth;             Size 8.73 MB[0m
[0;32m2025-05-15 20:39:36,760  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;32m2025-05-15 21:47:46,040  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 21:47:48,084  - INFO - Total number of parameters: 3.03 M[0m
[0;32m2025-05-15 21:47:48,091  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 21:47:48,091  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 21:47:48,091  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 21:47:48,091  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 21:47:48,091  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 21:47:48,101  - WARNING - 训练集大小变成：875[0m
[0;33m2025-05-15 21:47:48,101  - WARNING - 验证集大小变成：250[0m
[0;33m2025-05-15 21:47:48,101  - WARNING - 测试大小变成：126[0m
[0;32m2025-05-15 21:47:48,103  - INFO - 🧠 项目名：0515_DCLA_UNet_v2 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ Mamba3d                                                        │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ 0515_DCLA_UNet_v2                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-06                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 875                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 250                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 126                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 3.03 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 21:47:51,171  - INFO - 
model: Mamba3d
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 21:47:51,172  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-15 21:51:35,037  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-15 21:51:35,038  - INFO - - Train mean loss: 0.8887
- ET loss: 0.8723
- TC loss: 0.8631
- WT loss: 0.9306
- Cost time: 3.73mins ⏱️
[0m
[0;32m2025-05-15 21:51:35,038  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 21:52:22,606  - INFO - === [Epoch 1/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:47.5668s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.401 │ 0.477 │ 0.636 │ 0.089 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.296 │ 0.338 │ 0.502 │ 0.047 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.334 │ 0.371 │ 0.584 │ 0.047 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.873 │ 0.807 │ 0.825 │ 0.987 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.6357, ET: 0.5547, TC: 0.4416, WT: 0.9108
[0m
[0;32m2025-05-15 21:52:22,756  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.6357_dice0.4006_20250515215222.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 21:52:22,756  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;32m2025-05-15 21:52:40,998  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-15 21:52:43,169  - INFO - Total number of parameters: 3.03 M[0m
[0;32m2025-05-15 21:52:43,170  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-15 21:52:43,170  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-15 21:52:43,170  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-15 21:52:43,170  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-15 21:52:43,171  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-15 21:52:43,175  - WARNING - 训练集大小变成：875[0m
[0;33m2025-05-15 21:52:43,175  - WARNING - 验证集大小变成：250[0m
[0;33m2025-05-15 21:52:43,175  - WARNING - 测试大小变成：126[0m
[0;32m2025-05-15 21:52:43,178  - INFO - 🧠 项目名：0515_DCLA_UNet_v2 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ Mamba3d                                                        │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ 0515_DCLA_UNet_v2                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-06                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 875                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 250                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 126                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 3.03 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-15 21:52:45,440  - INFO - 
model: Mamba3d
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-15 21:52:45,441  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-15 21:56:29,381  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-15 21:56:29,382  - INFO - - Train mean loss: 0.8894
- ET loss: 0.8738
- TC loss: 0.8638
- WT loss: 0.9305
- Cost time: 3.73mins ⏱️
[0m
[0;32m2025-05-15 21:56:29,382  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-15 21:56:55,664  - INFO - === [Epoch 1/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:26.2805s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.413 │ 0.495 │ 0.657 │ 0.087 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.307 │ 0.354 │ 0.522 │ 0.046 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.361 │ 0.402 │ 0.635 │ 0.046 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.848 │ 0.768 │ 0.792 │ 0.985 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.6299, ET: 0.5451, TC: 0.4331, WT: 0.9116
[0m
[0;32m2025-05-15 21:56:55,732  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.6299_dice0.4128_20250515215655.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 21:56:55,732  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-15 22:00:39,953  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-15 22:00:39,954  - INFO - - Train mean loss: 0.6518
- ET loss: 0.5535
- TC loss: 0.4614
- WT loss: 0.9406
- Cost time: 3.74mins ⏱️
[0m
[0;32m2025-05-15 22:00:39,954  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-15 22:01:07,600  - INFO - === [Epoch 2/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:27.6457s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.451 │ 0.559 │ 0.704 │ 0.089 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.349 │ 0.417 │ 0.581 │ 0.047 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.443 │ 0.506 │ 0.777 │ 0.047 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.801 │ 0.697 │ 0.708 │ 0.999 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5526, ET: 0.4443, TC: 0.3021, WT: 0.9114
[0m
[1;31m2025-05-15 22:01:07,604  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.6299_dice0.4128_20250515215655.pth[0m
[0;32m2025-05-15 22:01:07,677  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.5526_dice0.4508_20250515220107.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:01:07,677  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;33m2025-05-15 22:01:09,201  - WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /api/house/metrics[0m
[0;33m2025-05-15 22:05:00,765  - WARNING - lr reduce to 9.978031724785248e-05[0m
[0;32m2025-05-15 22:05:00,766  - INFO - - Train mean loss: 0.6187
- ET loss: 0.5139
- TC loss: 0.4058
- WT loss: 0.9364
- Cost time: 3.88mins ⏱️
[0m
[0;32m2025-05-15 22:05:00,766  - INFO - === Validating on [Epoch 3/100] ===:[0m
[0;32m2025-05-15 22:05:29,717  - INFO - === [Epoch 3/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.978031724785248e-05
- val_cost_time:28.9499s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.471 │ 0.571 │ 0.748 │ 0.095 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.37  │ 0.429 │ 0.632 │ 0.051 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.417 │ 0.471 │ 0.729 │ 0.051 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.87  │ 0.811 │ 0.83  │ 0.968 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5302, ET: 0.4307, TC: 0.2548, WT: 0.9051
[0m
[1;31m2025-05-15 22:05:29,721  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.5526_dice0.4508_20250515220107.pth[0m
[0;32m2025-05-15 22:05:29,811  - INFO - ✨ Saved checkpoint (epoch 3) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch3_loss0.5302_dice0.4713_20250515220529.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:05:29,811  - INFO - === Training on [Epoch 4/100] ===:[0m
[0;33m2025-05-15 22:09:33,015  - WARNING - lr reduce to 9.960967771506668e-05[0m
[0;32m2025-05-15 22:09:33,016  - INFO - - Train mean loss: 0.5713
- ET loss: 0.4993
- TC loss: 0.3887
- WT loss: 0.8260
- Cost time: 4.05mins ⏱️
[0m
[0;32m2025-05-15 22:09:33,016  - INFO - === Validating on [Epoch 4/100] ===:[0m
[0;32m2025-05-15 22:10:01,696  - INFO - === [Epoch 4/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.960967771506668e-05
- val_cost_time:28.6792s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.642 │ 0.536 │ 0.711 │ 0.678 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.505 │ 0.395 │ 0.589 │ 0.531 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.573 │ 0.412 │ 0.639 │ 0.668 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.84  │ 0.878 │ 0.889 │ 0.751 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3882, ET: 0.4680, TC: 0.2957, WT: 0.4009
[0m
[1;31m2025-05-15 22:10:01,699  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.5302_dice0.4713_20250515220529.pth[0m
[0;32m2025-05-15 22:10:01,779  - INFO - ✨ Saved checkpoint (epoch 4) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch4_loss0.3882_dice0.6415_20250515221001.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:10:01,779  - INFO - === Training on [Epoch 5/100] ===:[0m
[0;33m2025-05-15 22:14:02,227  - WARNING - lr reduce to 9.939057285945934e-05[0m
[0;32m2025-05-15 22:14:02,227  - INFO - - Train mean loss: 0.4383
- ET loss: 0.5097
- TC loss: 0.4058
- WT loss: 0.3993
- Cost time: 4.01mins ⏱️
[0m
[0;32m2025-05-15 22:14:02,227  - INFO - === Validating on [Epoch 5/100] ===:[0m
[0;32m2025-05-15 22:14:30,191  - INFO - === [Epoch 5/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.939057285945934e-05
- val_cost_time:27.9633s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.707 │ 0.595 │ 0.76  │ 0.765 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.58  │ 0.455 │ 0.649 │ 0.635 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.672 │ 0.499 │ 0.753 │ 0.764 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.807 │ 0.813 │ 0.816 │ 0.793 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3004, ET: 0.4082, TC: 0.2451, WT: 0.2478
[0m
[1;31m2025-05-15 22:14:30,194  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch4_loss0.3882_dice0.6415_20250515221001.pth[0m
[0;32m2025-05-15 22:14:30,265  - INFO - ✨ Saved checkpoint (epoch 5) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch5_loss0.3004_dice0.7069_20250515221430.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:14:30,265  - INFO - === Training on [Epoch 6/100] ===:[0m
[0;33m2025-05-15 22:18:33,685  - WARNING - lr reduce to 9.912321891107012e-05[0m
[0;32m2025-05-15 22:18:33,685  - INFO - - Train mean loss: 0.4027
- ET loss: 0.4959
- TC loss: 0.3888
- WT loss: 0.3233
- Cost time: 4.06mins ⏱️
[0m
[0;32m2025-05-15 22:18:33,685  - INFO - === Validating on [Epoch 6/100] ===:[0m
[0;32m2025-05-15 22:19:01,774  - INFO - === [Epoch 6/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.912321891107012e-05
- val_cost_time:28.0882s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.718 │ 0.61  │ 0.76  │ 0.783 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.593 │ 0.47  │ 0.652 │ 0.657 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.714 │ 0.533 │ 0.794 │ 0.815 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.773 │ 0.774 │ 0.773 │ 0.773 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2865, ET: 0.3919, TC: 0.2429, WT: 0.2247
[0m
[1;31m2025-05-15 22:19:01,778  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch5_loss0.3004_dice0.7069_20250515221430.pth[0m
[0;32m2025-05-15 22:19:01,847  - INFO - ✨ Saved checkpoint (epoch 6) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch6_loss0.2865_dice0.7177_20250515221901.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:19:01,848  - INFO - === Training on [Epoch 7/100] ===:[0m
[0;33m2025-05-15 22:22:45,032  - WARNING - lr reduce to 9.880787971596802e-05[0m
[0;32m2025-05-15 22:22:45,033  - INFO - - Train mean loss: 0.3837
- ET loss: 0.4813
- TC loss: 0.3678
- WT loss: 0.3018
- Cost time: 3.72mins ⏱️
[0m
[0;32m2025-05-15 22:22:45,033  - INFO - === Validating on [Epoch 7/100] ===:[0m
[0;32m2025-05-15 22:23:10,309  - INFO - === [Epoch 7/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.880787971596802e-05
- val_cost_time:25.2755s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.72  │ 0.601 │ 0.761 │ 0.796 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.597 │ 0.461 │ 0.65  │ 0.678 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.68  │ 0.496 │ 0.747 │ 0.798 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.824 │ 0.828 │ 0.825 │ 0.817 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2846, ET: 0.4018, TC: 0.2428, WT: 0.2092
[0m
[1;31m2025-05-15 22:23:10,312  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch6_loss0.2865_dice0.7177_20250515221901.pth[0m
[0;32m2025-05-15 22:23:10,374  - INFO - ✨ Saved checkpoint (epoch 7) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch7_loss0.2846_dice0.7196_20250515222310.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:23:10,374  - INFO - === Training on [Epoch 8/100] ===:[0m
[0;33m2025-05-15 22:26:44,774  - WARNING - lr reduce to 9.844486647586726e-05[0m
[0;32m2025-05-15 22:26:44,774  - INFO - - Train mean loss: 0.3710
- ET loss: 0.4717
- TC loss: 0.3578
- WT loss: 0.2834
- Cost time: 3.57mins ⏱️
[0m
[0;32m2025-05-15 22:26:44,775  - INFO - === Validating on [Epoch 8/100] ===:[0m
[0;32m2025-05-15 22:27:09,958  - INFO - === [Epoch 8/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.844486647586726e-05
- val_cost_time:25.1824s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.696 │ 0.574 │ 0.751 │ 0.764 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.57  │ 0.432 │ 0.638 │ 0.64  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.604 │ 0.45  │ 0.685 │ 0.678 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.901 │ 0.888 │ 0.895 │ 0.921 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3067, ET: 0.4280, TC: 0.2522, WT: 0.2397
[0m
[0;33m2025-05-15 22:27:09,958  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-15 22:27:09,958  - INFO - === Training on [Epoch 9/100] ===:[0m
[0;33m2025-05-15 22:30:44,231  - WARNING - lr reduce to 9.80345374410087e-05[0m
[0;32m2025-05-15 22:30:44,232  - INFO - - Train mean loss: 0.3640
- ET loss: 0.4673
- TC loss: 0.3495
- WT loss: 0.2752
- Cost time: 3.57mins ⏱️
[0m
[0;32m2025-05-15 22:30:44,232  - INFO - === Validating on [Epoch 9/100] ===:[0m
[0;32m2025-05-15 22:31:09,658  - INFO - === [Epoch 9/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.80345374410087e-05
- val_cost_time:25.4251s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.737 │ 0.631 │ 0.764 │ 0.818 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.62  │ 0.491 │ 0.662 │ 0.707 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.737 │ 0.568 │ 0.834 │ 0.808 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.789 │ 0.765 │ 0.753 │ 0.85  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2658, ET: 0.3712, TC: 0.2391, WT: 0.1871
[0m
[1;31m2025-05-15 22:31:09,661  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch7_loss0.2846_dice0.7196_20250515222310.pth[0m
[0;32m2025-05-15 22:31:09,726  - INFO - ✨ Saved checkpoint (epoch 9) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch9_loss0.2658_dice0.7375_20250515223109.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:31:09,726  - INFO - === Training on [Epoch 10/100] ===:[0m
[0;33m2025-05-15 22:34:43,995  - WARNING - lr reduce to 9.757729755661012e-05[0m
[0;32m2025-05-15 22:34:43,995  - INFO - - Train mean loss: 0.3468
- ET loss: 0.4473
- TC loss: 0.3328
- WT loss: 0.2605
- Cost time: 3.57mins ⏱️
[0m
[0;32m2025-05-15 22:34:43,995  - INFO - === Validating on [Epoch 10/100] ===:[0m
[0;32m2025-05-15 22:35:09,206  - INFO - === [Epoch 10/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.757729755661012e-05
- val_cost_time:25.2100s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.742 │ 0.626 │ 0.766 │ 0.833 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.627 │ 0.488 │ 0.666 │ 0.728 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.74  │ 0.562 │ 0.826 │ 0.831 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.791 │ 0.764 │ 0.756 │ 0.854 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2619, ET: 0.3760, TC: 0.2366, WT: 0.1731
[0m
[1;31m2025-05-15 22:35:09,209  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch9_loss0.2658_dice0.7375_20250515223109.pth[0m
[0;32m2025-05-15 22:35:09,279  - INFO - ✨ Saved checkpoint (epoch 10) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch10_loss0.2619_dice0.7417_20250515223509.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:35:09,279  - INFO - === Training on [Epoch 11/100] ===:[0m
[0;33m2025-05-15 22:38:57,482  - WARNING - lr reduce to 9.707359806323419e-05[0m
[0;32m2025-05-15 22:38:57,482  - INFO - - Train mean loss: 0.3387
- ET loss: 0.4452
- TC loss: 0.3281
- WT loss: 0.2428
- Cost time: 3.80mins ⏱️
[0m
[0;32m2025-05-15 22:38:57,483  - INFO - === Validating on [Epoch 11/100] ===:[0m
[0;32m2025-05-15 22:39:24,710  - INFO - === [Epoch 11/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.707359806323419e-05
- val_cost_time:27.2270s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.752 │ 0.631 │ 0.795 │ 0.83  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.64  │ 0.496 │ 0.701 │ 0.724 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.722 │ 0.546 │ 0.824 │ 0.794 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.836 │ 0.808 │ 0.81  │ 0.89  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2513, ET: 0.3712, TC: 0.2080, WT: 0.1748
[0m
[1;31m2025-05-15 22:39:24,714  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch10_loss0.2619_dice0.7417_20250515223509.pth[0m
[0;32m2025-05-15 22:39:24,782  - INFO - ✨ Saved checkpoint (epoch 11) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch11_loss0.2513_dice0.7519_20250515223924.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:39:24,782  - INFO - === Training on [Epoch 12/100] ===:[0m
[0;33m2025-05-15 22:43:15,779  - WARNING - lr reduce to 9.652393605146847e-05[0m
[0;32m2025-05-15 22:43:15,779  - INFO - - Train mean loss: 0.3319
- ET loss: 0.4381
- TC loss: 0.3230
- WT loss: 0.2344
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 22:43:15,779  - INFO - === Validating on [Epoch 12/100] ===:[0m
[0;32m2025-05-15 22:43:43,176  - INFO - === [Epoch 12/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.652393605146847e-05
- val_cost_time:27.3962s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.763 │ 0.647 │ 0.793 │ 0.849 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.655 │ 0.511 │ 0.703 │ 0.751 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.753 │ 0.566 │ 0.835 │ 0.858 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.822 │ 0.811 │ 0.799 │ 0.856 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2409, ET: 0.3557, TC: 0.2099, WT: 0.1569
[0m
[1;31m2025-05-15 22:43:43,180  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch11_loss0.2513_dice0.7519_20250515223924.pth[0m
[0;32m2025-05-15 22:43:43,312  - INFO - ✨ Saved checkpoint (epoch 12) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch12_loss0.2409_dice0.7628_20250515224343.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:43:43,313  - INFO - === Training on [Epoch 13/100] ===:[0m
[0;33m2025-05-15 22:47:34,131  - WARNING - lr reduce to 9.592885397135708e-05[0m
[0;32m2025-05-15 22:47:34,131  - INFO - - Train mean loss: 0.3289
- ET loss: 0.4349
- TC loss: 0.3218
- WT loss: 0.2299
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 22:47:34,131  - INFO - === Validating on [Epoch 13/100] ===:[0m
[0;32m2025-05-15 22:48:01,398  - INFO - === [Epoch 13/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.592885397135708e-05
- val_cost_time:27.2658s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.764 │ 0.648 │ 0.792 │ 0.852 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.658 │ 0.513 │ 0.702 │ 0.757 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.744 │ 0.565 │ 0.826 │ 0.842 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.836 │ 0.823 │ 0.805 │ 0.88  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2394, ET: 0.3545, TC: 0.2108, WT: 0.1529
[0m
[1;31m2025-05-15 22:48:01,401  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch12_loss0.2409_dice0.7628_20250515224343.pth[0m
[0;32m2025-05-15 22:48:01,468  - INFO - ✨ Saved checkpoint (epoch 13) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch13_loss0.2394_dice0.7640_20250515224801.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:48:01,468  - INFO - === Training on [Epoch 14/100] ===:[0m
[0;33m2025-05-15 22:51:51,460  - WARNING - lr reduce to 9.5288939097068e-05[0m
[0;32m2025-05-15 22:51:51,461  - INFO - - Train mean loss: 0.3141
- ET loss: 0.4223
- TC loss: 0.3078
- WT loss: 0.2123
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-15 22:51:51,461  - INFO - === Validating on [Epoch 14/100] ===:[0m
[0;32m2025-05-15 22:52:18,571  - INFO - === [Epoch 14/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5288939097068e-05
- val_cost_time:27.1092s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.767 │ 0.647 │ 0.797 │ 0.858 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.66  │ 0.512 │ 0.705 │ 0.765 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.769 │ 0.586 │ 0.87  │ 0.853 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.813 │ 0.783 │ 0.775 │ 0.881 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2362, ET: 0.3551, TC: 0.2059, WT: 0.1478
[0m
[1;31m2025-05-15 22:52:18,574  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch13_loss0.2394_dice0.7640_20250515224801.pth[0m
[0;32m2025-05-15 22:52:18,647  - INFO - ✨ Saved checkpoint (epoch 14) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch14_loss0.2362_dice0.7674_20250515225218.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 22:52:18,647  - INFO - === Training on [Epoch 15/100] ===:[0m
[0;33m2025-05-15 22:56:08,475  - WARNING - lr reduce to 9.460482294732424e-05[0m
[0;32m2025-05-15 22:56:08,476  - INFO - - Train mean loss: 0.3305
- ET loss: 0.4366
- TC loss: 0.3267
- WT loss: 0.2282
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-15 22:56:08,476  - INFO - === Validating on [Epoch 15/100] ===:[0m
[0;32m2025-05-15 22:56:35,631  - INFO - === [Epoch 15/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.460482294732424e-05
- val_cost_time:27.1548s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.764 │ 0.635 │ 0.803 │ 0.853 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.658 │ 0.501 │ 0.714 │ 0.758 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.734 │ 0.544 │ 0.809 │ 0.85  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.847 │ 0.836 │ 0.833 │ 0.872 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2399, ET: 0.3665, TC: 0.2002, WT: 0.1530
[0m
[0;33m2025-05-15 22:56:35,631  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-15 22:56:35,631  - INFO - === Training on [Epoch 16/100] ===:[0m
[0;33m2025-05-15 23:00:24,997  - WARNING - lr reduce to 9.387718066217127e-05[0m
[0;32m2025-05-15 23:00:24,997  - INFO - - Train mean loss: 0.3045
- ET loss: 0.4119
- TC loss: 0.2981
- WT loss: 0.2035
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-15 23:00:24,997  - INFO - === Validating on [Epoch 16/100] ===:[0m
[0;32m2025-05-15 23:00:52,067  - INFO - === [Epoch 16/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.387718066217127e-05
- val_cost_time:27.0694s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.757 │ 0.632 │ 0.801 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.649 │ 0.499 │ 0.712 │ 0.737 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.715 │ 0.547 │ 0.814 │ 0.784 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.864 │ 0.835 │ 0.83  │ 0.926 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2461, ET: 0.3699, TC: 0.2017, WT: 0.1668
[0m
[0;33m2025-05-15 23:00:52,068  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-15 23:00:52,068  - INFO - === Training on [Epoch 17/100] ===:[0m
[0;33m2025-05-15 23:04:41,617  - WARNING - lr reduce to 9.310673033669524e-05[0m
[0;32m2025-05-15 23:04:41,618  - INFO - - Train mean loss: 0.3124
- ET loss: 0.4230
- TC loss: 0.3108
- WT loss: 0.2035
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-15 23:04:41,618  - INFO - === Validating on [Epoch 17/100] ===:[0m
[0;32m2025-05-15 23:05:08,794  - INFO - === [Epoch 17/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.310673033669524e-05
- val_cost_time:27.1757s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.779 │ 0.661 │ 0.802 │ 0.873 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.674 │ 0.527 │ 0.708 │ 0.786 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.781 │ 0.603 │ 0.88  │ 0.861 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.819 │ 0.788 │ 0.77  │ 0.9   │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2247, ET: 0.3410, TC: 0.2012, WT: 0.1317
[0m
[1;31m2025-05-15 23:05:08,797  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch14_loss0.2362_dice0.7674_20250515225218.pth[0m
[0;32m2025-05-15 23:05:08,860  - INFO - ✨ Saved checkpoint (epoch 17) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch17_loss0.2247_dice0.7787_20250515230508.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:05:08,860  - INFO - === Training on [Epoch 18/100] ===:[0m
[0;33m2025-05-15 23:08:59,175  - WARNING - lr reduce to 9.229423231234978e-05[0m
[0;32m2025-05-15 23:08:59,175  - INFO - - Train mean loss: 0.3068
- ET loss: 0.4088
- TC loss: 0.3059
- WT loss: 0.2056
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-15 23:08:59,176  - INFO - === Validating on [Epoch 18/100] ===:[0m
[0;32m2025-05-15 23:09:26,723  - INFO - === [Epoch 18/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.229423231234978e-05
- val_cost_time:27.5465s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.782 │ 0.661 │ 0.814 │ 0.872 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.683 │ 0.529 │ 0.73  │ 0.788 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.775 │ 0.574 │ 0.846 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.836 │ 0.834 │ 0.82  │ 0.856 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2209, ET: 0.3418, TC: 0.1891, WT: 0.1317
[0m
[1;31m2025-05-15 23:09:26,726  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch17_loss0.2247_dice0.7787_20250515230508.pth[0m
[0;32m2025-05-15 23:09:26,798  - INFO - ✨ Saved checkpoint (epoch 18) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch18_loss0.2209_dice0.7821_20250515230926.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:09:26,798  - INFO - === Training on [Epoch 19/100] ===:[0m
[0;33m2025-05-15 23:13:16,823  - WARNING - lr reduce to 9.144048842659084e-05[0m
[0;32m2025-05-15 23:13:16,823  - INFO - - Train mean loss: 0.3010
- ET loss: 0.4098
- TC loss: 0.2944
- WT loss: 0.1988
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-15 23:13:16,824  - INFO - === Validating on [Epoch 19/100] ===:[0m
[0;32m2025-05-15 23:13:44,092  - INFO - === [Epoch 19/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.144048842659084e-05
- val_cost_time:27.2678s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.788 │ 0.662 │ 0.826 │ 0.877 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.69  │ 0.532 │ 0.745 │ 0.794 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.762 │ 0.574 │ 0.839 │ 0.872 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.871 │ 0.863 │ 0.851 │ 0.899 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2147, ET: 0.3401, TC: 0.1770, WT: 0.1269
[0m
[1;31m2025-05-15 23:13:44,095  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch18_loss0.2209_dice0.7821_20250515230926.pth[0m
[0;32m2025-05-15 23:13:44,156  - INFO - ✨ Saved checkpoint (epoch 19) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch19_loss0.2147_dice0.7882_20250515231344.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:13:44,157  - INFO - === Training on [Epoch 20/100] ===:[0m
[0;33m2025-05-15 23:17:35,038  - WARNING - lr reduce to 9.054634122155993e-05[0m
[0;32m2025-05-15 23:17:35,039  - INFO - - Train mean loss: 0.2914
- ET loss: 0.4025
- TC loss: 0.2829
- WT loss: 0.1889
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 23:17:35,039  - INFO - === Validating on [Epoch 20/100] ===:[0m
[0;32m2025-05-15 23:18:02,399  - INFO - === [Epoch 20/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.054634122155993e-05
- val_cost_time:27.3588s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.791 │ 0.658 │ 0.838 │ 0.878 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.694 │ 0.528 │ 0.758 │ 0.796 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.763 │ 0.573 │ 0.849 │ 0.868 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.877 │ 0.861 │ 0.863 │ 0.905 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2114, ET: 0.3435, TC: 0.1649, WT: 0.1258
[0m
[1;31m2025-05-15 23:18:02,403  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch19_loss0.2147_dice0.7882_20250515231344.pth[0m
[0;32m2025-05-15 23:18:02,469  - INFO - ✨ Saved checkpoint (epoch 20) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch20_loss0.2114_dice0.7914_20250515231802.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:18:02,470  - INFO - === Training on [Epoch 21/100] ===:[0m
[0;33m2025-05-15 23:21:53,443  - WARNING - lr reduce to 8.961267311259669e-05[0m
[0;32m2025-05-15 23:21:53,444  - INFO - - Train mean loss: 0.2913
- ET loss: 0.4003
- TC loss: 0.2794
- WT loss: 0.1941
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 23:21:53,444  - INFO - === Validating on [Epoch 21/100] ===:[0m
[0;32m2025-05-15 23:22:20,550  - INFO - === [Epoch 21/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.961267311259669e-05
- val_cost_time:27.1057s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.792 │ 0.661 │ 0.841 │ 0.875 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.695 │ 0.53  │ 0.761 │ 0.793 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.765 │ 0.577 │ 0.859 │ 0.86  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.876 │ 0.858 │ 0.861 │ 0.908 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2104, ET: 0.3409, TC: 0.1619, WT: 0.1283
[0m
[1;31m2025-05-15 23:22:20,553  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch20_loss0.2114_dice0.7914_20250515231802.pth[0m
[0;32m2025-05-15 23:22:20,616  - INFO - ✨ Saved checkpoint (epoch 21) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch21_loss0.2104_dice0.7924_20250515232220.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:22:20,616  - INFO - === Training on [Epoch 22/100] ===:[0m
[0;33m2025-05-15 23:26:11,627  - WARNING - lr reduce to 8.864040551740159e-05[0m
[0;32m2025-05-15 23:26:11,628  - INFO - - Train mean loss: 0.2910
- ET loss: 0.4040
- TC loss: 0.2844
- WT loss: 0.1846
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 23:26:11,628  - INFO - === Validating on [Epoch 22/100] ===:[0m
[0;32m2025-05-15 23:26:38,801  - INFO - === [Epoch 22/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.864040551740159e-05
- val_cost_time:27.1723s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.79  │ 0.657 │ 0.836 │ 0.878 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.693 │ 0.527 │ 0.757 │ 0.796 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.748 │ 0.557 │ 0.829 │ 0.859 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.895 │ 0.886 │ 0.884 │ 0.915 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2123, ET: 0.3448, TC: 0.1664, WT: 0.1256
[0m
[0;33m2025-05-15 23:26:38,801  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-15 23:26:38,801  - INFO - === Training on [Epoch 23/100] ===:[0m
[0;33m2025-05-15 23:30:29,117  - WARNING - lr reduce to 8.763049794670778e-05[0m
[0;32m2025-05-15 23:30:29,118  - INFO - - Train mean loss: 0.2912
- ET loss: 0.4017
- TC loss: 0.2805
- WT loss: 0.1913
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-15 23:30:29,118  - INFO - === Validating on [Epoch 23/100] ===:[0m
[0;32m2025-05-15 23:30:56,391  - INFO - === [Epoch 23/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.763049794670778e-05
- val_cost_time:27.2726s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.796 │ 0.669 │ 0.837 │ 0.883 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.702 │ 0.542 │ 0.759 │ 0.805 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.787 │ 0.588 │ 0.864 │ 0.909 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.85  │ 0.841 │ 0.836 │ 0.872 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2058, ET: 0.3325, TC: 0.1654, WT: 0.1194
[0m
[1;31m2025-05-15 23:30:56,394  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch21_loss0.2104_dice0.7924_20250515232220.pth[0m
[0;32m2025-05-15 23:30:56,470  - INFO - ✨ Saved checkpoint (epoch 23) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch23_loss0.2058_dice0.7964_20250515233056.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:30:56,470  - INFO - === Training on [Epoch 24/100] ===:[0m
[0;33m2025-05-15 23:34:47,218  - WARNING - lr reduce to 8.65839470573599e-05[0m
[0;32m2025-05-15 23:34:47,218  - INFO - - Train mean loss: 0.2848
- ET loss: 0.3938
- TC loss: 0.2761
- WT loss: 0.1844
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 23:34:47,218  - INFO - === Validating on [Epoch 24/100] ===:[0m
[0;32m2025-05-15 23:35:14,367  - INFO - === [Epoch 24/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.65839470573599e-05
- val_cost_time:27.1482s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.8   │ 0.676 │ 0.837 │ 0.887 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.705 │ 0.548 │ 0.759 │ 0.809 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.786 │ 0.595 │ 0.873 │ 0.89  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.866 │ 0.857 │ 0.842 │ 0.9   │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2022, ET: 0.3250, TC: 0.1653, WT: 0.1161
[0m
[1;31m2025-05-15 23:35:14,370  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch23_loss0.2058_dice0.7964_20250515233056.pth[0m
[0;32m2025-05-15 23:35:14,431  - INFO - ✨ Saved checkpoint (epoch 24) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch24_loss0.2022_dice0.8001_20250515233514.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:35:14,431  - INFO - === Training on [Epoch 25/100] ===:[0m
[0;33m2025-05-15 23:39:05,018  - WARNING - lr reduce to 8.550178566873413e-05[0m
[0;32m2025-05-15 23:39:05,019  - INFO - - Train mean loss: 0.2843
- ET loss: 0.3924
- TC loss: 0.2750
- WT loss: 0.1854
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-15 23:39:05,019  - INFO - === Validating on [Epoch 25/100] ===:[0m
[0;32m2025-05-15 23:39:32,316  - INFO - === [Epoch 25/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.550178566873413e-05
- val_cost_time:27.2970s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.796 │ 0.662 │ 0.844 │ 0.882 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.701 │ 0.533 │ 0.768 │ 0.802 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.758 │ 0.565 │ 0.839 │ 0.87  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.894 │ 0.885 │ 0.887 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2061, ET: 0.3393, TC: 0.1578, WT: 0.1211
[0m
[0;33m2025-05-15 23:39:32,317  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-15 23:39:32,317  - INFO - === Training on [Epoch 26/100] ===:[0m
[0;33m2025-05-15 23:43:23,380  - WARNING - lr reduce to 8.438508174347012e-05[0m
[0;32m2025-05-15 23:43:23,381  - INFO - - Train mean loss: 0.2829
- ET loss: 0.3905
- TC loss: 0.2773
- WT loss: 0.1808
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 23:43:23,381  - INFO - === Validating on [Epoch 26/100] ===:[0m
[0;32m2025-05-15 23:43:50,688  - INFO - === [Epoch 26/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.438508174347012e-05
- val_cost_time:27.3066s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.801 │ 0.664 │ 0.85  │ 0.888 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.707 │ 0.536 │ 0.774 │ 0.81  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.767 │ 0.57  │ 0.847 │ 0.884 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.89  │ 0.879 │ 0.884 │ 0.908 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2012, ET: 0.3370, TC: 0.1516, WT: 0.1151
[0m
[1;31m2025-05-15 23:43:50,692  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch24_loss0.2022_dice0.8001_20250515233514.pth[0m
[0;32m2025-05-15 23:43:50,764  - INFO - ✨ Saved checkpoint (epoch 26) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch26_loss0.2012_dice0.8008_20250515234350.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:43:50,765  - INFO - === Training on [Epoch 27/100] ===:[0m
[0;33m2025-05-15 23:47:41,183  - WARNING - lr reduce to 8.32349373335208e-05[0m
[0;32m2025-05-15 23:47:41,183  - INFO - - Train mean loss: 0.2872
- ET loss: 0.3960
- TC loss: 0.2780
- WT loss: 0.1876
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-15 23:47:41,183  - INFO - === Validating on [Epoch 27/100] ===:[0m
[0;32m2025-05-15 23:48:08,259  - INFO - === [Epoch 27/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.32349373335208e-05
- val_cost_time:27.0752s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.804 │ 0.673 │ 0.849 │ 0.89  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.71  │ 0.545 │ 0.773 │ 0.813 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.783 │ 0.579 │ 0.853 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.877 │ 0.879 │ 0.874 │ 0.877 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1979, ET: 0.3282, TC: 0.1531, WT: 0.1123
[0m
[1;31m2025-05-15 23:48:08,263  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch26_loss0.2012_dice0.8008_20250515234350.pth[0m
[0;32m2025-05-15 23:48:08,331  - INFO - ✨ Saved checkpoint (epoch 27) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch27_loss0.1979_dice0.8041_20250515234808.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:48:08,331  - INFO - === Training on [Epoch 28/100] ===:[0m
[0;33m2025-05-15 23:51:59,094  - WARNING - lr reduce to 8.205248749256017e-05[0m
[0;32m2025-05-15 23:51:59,095  - INFO - - Train mean loss: 0.2804
- ET loss: 0.3966
- TC loss: 0.2681
- WT loss: 0.1763
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-15 23:51:59,095  - INFO - === Validating on [Epoch 28/100] ===:[0m
[0;32m2025-05-15 23:52:26,168  - INFO - === [Epoch 28/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.205248749256017e-05
- val_cost_time:27.0723s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.802 │ 0.667 │ 0.851 │ 0.89  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.709 │ 0.539 │ 0.776 │ 0.812 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.769 │ 0.572 │ 0.845 │ 0.889 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.894 │ 0.886 │ 0.891 │ 0.906 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1993, ET: 0.3343, TC: 0.1510, WT: 0.1128
[0m
[0;33m2025-05-15 23:52:26,168  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-15 23:52:26,168  - INFO - === Training on [Epoch 29/100] ===:[0m
[0;33m2025-05-15 23:56:16,846  - WARNING - lr reduce to 8.083889915582238e-05[0m
[0;32m2025-05-15 23:56:16,847  - INFO - - Train mean loss: 0.2769
- ET loss: 0.3846
- TC loss: 0.2699
- WT loss: 0.1762
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-15 23:56:16,847  - INFO - === Validating on [Epoch 29/100] ===:[0m
[0;32m2025-05-15 23:56:43,993  - INFO - === [Epoch 29/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.083889915582238e-05
- val_cost_time:27.1456s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.805 │ 0.679 │ 0.845 │ 0.892 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.713 │ 0.553 │ 0.77  │ 0.817 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.796 │ 0.6   │ 0.881 │ 0.908 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.866 │ 0.86  │ 0.847 │ 0.891 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1962, ET: 0.3216, TC: 0.1569, WT: 0.1102
[0m
[1;31m2025-05-15 23:56:43,996  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch27_loss0.1979_dice0.8041_20250515234808.pth[0m
[0;32m2025-05-15 23:56:44,080  - INFO - ✨ Saved checkpoint (epoch 29) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch29_loss0.1962_dice0.8054_20250515235643.pth;             Size 36.60 MB[0m
[0;32m2025-05-15 23:56:44,080  - INFO - === Training on [Epoch 30/100] ===:[0m
[0;33m2025-05-16 00:00:34,598  - WARNING - lr reduce to 7.959536998847746e-05[0m
[0;32m2025-05-16 00:00:34,599  - INFO - - Train mean loss: 0.2782
- ET loss: 0.3851
- TC loss: 0.2698
- WT loss: 0.1797
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 00:00:34,599  - INFO - === Validating on [Epoch 30/100] ===:[0m
[0;32m2025-05-16 00:01:01,709  - INFO - === [Epoch 30/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.959536998847746e-05
- val_cost_time:27.1093s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.803 │ 0.672 │ 0.845 │ 0.892 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.71  │ 0.546 │ 0.767 │ 0.817 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.785 │ 0.59  │ 0.864 │ 0.9   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.875 │ 0.868 │ 0.861 │ 0.897 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1987, ET: 0.3290, TC: 0.1565, WT: 0.1107
[0m
[0;33m2025-05-16 00:01:01,709  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:01:01,709  - INFO - === Training on [Epoch 31/100] ===:[0m
[0;33m2025-05-16 00:04:52,100  - WARNING - lr reduce to 7.83231272036805e-05[0m
[0;32m2025-05-16 00:04:52,101  - INFO - - Train mean loss: 0.2863
- ET loss: 0.3970
- TC loss: 0.2811
- WT loss: 0.1808
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 00:04:52,101  - INFO - === Validating on [Epoch 31/100] ===:[0m
[0;32m2025-05-16 00:05:19,229  - INFO - === [Epoch 31/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.83231272036805e-05
- val_cost_time:27.1275s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.808 │ 0.675 │ 0.854 │ 0.895 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.716 │ 0.547 │ 0.781 │ 0.82  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.801 │ 0.594 │ 0.876 │ 0.932 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.863 │ 0.858 │ 0.86  │ 0.872 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1934, ET: 0.3256, TC: 0.1472, WT: 0.1074
[0m
[1;31m2025-05-16 00:05:19,232  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch29_loss0.1962_dice0.8054_20250515235643.pth[0m
[0;32m2025-05-16 00:05:19,306  - INFO - ✨ Saved checkpoint (epoch 31) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch31_loss0.1934_dice0.8081_20250516000519.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:05:19,306  - INFO - === Training on [Epoch 32/100] ===:[0m
[0;33m2025-05-16 00:09:09,112  - WARNING - lr reduce to 7.702342635146036e-05[0m
[0;32m2025-05-16 00:09:09,113  - INFO - - Train mean loss: 0.2773
- ET loss: 0.3870
- TC loss: 0.2679
- WT loss: 0.1770
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 00:09:09,113  - INFO - === Validating on [Epoch 32/100] ===:[0m
[0;32m2025-05-16 00:09:36,341  - INFO - === [Epoch 32/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.702342635146036e-05
- val_cost_time:27.2268s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.803 │ 0.689 │ 0.835 │ 0.885 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.707 │ 0.56  │ 0.754 │ 0.807 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.775 │ 0.597 │ 0.855 │ 0.873 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.878 │ 0.875 │ 0.844 │ 0.915 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1985, ET: 0.3112, TC: 0.1670, WT: 0.1173
[0m
[0;33m2025-05-16 00:09:36,341  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:09:36,341  - INFO - === Training on [Epoch 33/100] ===:[0m
[0;33m2025-05-16 00:13:25,769  - WARNING - lr reduce to 7.56975500796434e-05[0m
[0;32m2025-05-16 00:13:25,770  - INFO - - Train mean loss: 0.2647
- ET loss: 0.3744
- TC loss: 0.2576
- WT loss: 0.1621
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-16 00:13:25,770  - INFO - === Validating on [Epoch 33/100] ===:[0m
[0;32m2025-05-16 00:13:53,111  - INFO - === [Epoch 33/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.56975500796434e-05
- val_cost_time:27.3402s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.808 │ 0.675 │ 0.852 │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.716 │ 0.546 │ 0.779 │ 0.822 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.777 │ 0.572 │ 0.843 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.89  │ 0.893 │ 0.888 │ 0.888 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1937, ET: 0.3259, TC: 0.1498, WT: 0.1056
[0m
[0;33m2025-05-16 00:13:53,111  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 00:13:53,111  - INFO - === Training on [Epoch 34/100] ===:[0m
[0;33m2025-05-16 00:17:43,831  - WARNING - lr reduce to 7.434680686803493e-05[0m
[0;32m2025-05-16 00:17:43,831  - INFO - - Train mean loss: 0.2668
- ET loss: 0.3816
- TC loss: 0.2493
- WT loss: 0.1695
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 00:17:43,831  - INFO - === Validating on [Epoch 34/100] ===:[0m
[0;32m2025-05-16 00:18:11,134  - INFO - === [Epoch 34/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.434680686803493e-05
- val_cost_time:27.3024s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.812 │ 0.694 │ 0.845 │ 0.896 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.719 │ 0.565 │ 0.77  │ 0.821 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.612 │ 0.879 │ 0.9   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.869 │ 0.86  │ 0.841 │ 0.905 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1897, ET: 0.3068, TC: 0.1561, WT: 0.1064
[0m
[1;31m2025-05-16 00:18:11,137  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch31_loss0.1934_dice0.8081_20250516000519.pth[0m
[0;32m2025-05-16 00:18:11,202  - INFO - ✨ Saved checkpoint (epoch 34) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch34_loss0.1897_dice0.8117_20250516001811.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:18:11,203  - INFO - === Training on [Epoch 35/100] ===:[0m
[0;33m2025-05-16 00:22:02,040  - WARNING - lr reduce to 7.297252973710759e-05[0m
[0;32m2025-05-16 00:22:02,041  - INFO - - Train mean loss: 0.2771
- ET loss: 0.3831
- TC loss: 0.2674
- WT loss: 0.1809
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 00:22:02,041  - INFO - === Validating on [Epoch 35/100] ===:[0m
[0;32m2025-05-16 00:22:29,348  - INFO - === [Epoch 35/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.297252973710759e-05
- val_cost_time:27.3062s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.806 │ 0.684 │ 0.851 │ 0.884 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.713 │ 0.556 │ 0.779 │ 0.803 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.773 │ 0.595 │ 0.868 │ 0.856 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.893 │ 0.879 │ 0.868 │ 0.932 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1952, ET: 0.3170, TC: 0.1503, WT: 0.1181
[0m
[0;33m2025-05-16 00:22:29,348  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:22:29,348  - INFO - === Training on [Epoch 36/100] ===:[0m
[0;33m2025-05-16 00:26:19,699  - WARNING - lr reduce to 7.157607493247112e-05[0m
[0;32m2025-05-16 00:26:19,699  - INFO - - Train mean loss: 0.2726
- ET loss: 0.3844
- TC loss: 0.2640
- WT loss: 0.1694
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 00:26:19,699  - INFO - === Validating on [Epoch 36/100] ===:[0m
[0;32m2025-05-16 00:26:46,863  - INFO - === [Epoch 36/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.157607493247112e-05
- val_cost_time:27.1626s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.812 │ 0.688 │ 0.851 │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.72  │ 0.561 │ 0.777 │ 0.823 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.61  │ 0.888 │ 0.899 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.87  │ 0.858 │ 0.845 │ 0.908 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1896, ET: 0.3126, TC: 0.1511, WT: 0.1053
[0m
[1;31m2025-05-16 00:26:46,871  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch34_loss0.1897_dice0.8117_20250516001811.pth[0m
[0;32m2025-05-16 00:26:46,934  - INFO - ✨ Saved checkpoint (epoch 36) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch36_loss0.1896_dice0.8119_20250516002646.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:26:46,934  - INFO - === Training on [Epoch 37/100] ===:[0m
[0;33m2025-05-16 00:30:37,644  - WARNING - lr reduce to 7.015882058642166e-05[0m
[0;32m2025-05-16 00:30:37,645  - INFO - - Train mean loss: 0.2715
- ET loss: 0.3817
- TC loss: 0.2580
- WT loss: 0.1748
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 00:30:37,645  - INFO - === Validating on [Epoch 37/100] ===:[0m
[0;32m2025-05-16 00:31:04,927  - INFO - === [Epoch 37/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.015882058642166e-05
- val_cost_time:27.2815s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.81  │ 0.681 │ 0.858 │ 0.891 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.719 │ 0.556 │ 0.786 │ 0.817 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.604 │ 0.89  │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.875 │ 0.866 │ 0.861 │ 0.899 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1912, ET: 0.3197, TC: 0.1432, WT: 0.1108
[0m
[0;33m2025-05-16 00:31:04,927  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:31:04,927  - INFO - === Training on [Epoch 38/100] ===:[0m
[0;33m2025-05-16 00:34:55,569  - WARNING - lr reduce to 6.87221653578916e-05[0m
[0;32m2025-05-16 00:34:55,570  - INFO - - Train mean loss: 0.2624
- ET loss: 0.3725
- TC loss: 0.2472
- WT loss: 0.1675
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 00:34:55,570  - INFO - === Validating on [Epoch 38/100] ===:[0m
[0;32m2025-05-16 00:35:22,857  - INFO - === [Epoch 38/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.87221653578916e-05
- val_cost_time:27.2866s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.807 │ 0.67  │ 0.855 │ 0.896 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.715 │ 0.543 │ 0.781 │ 0.822 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.772 │ 0.573 │ 0.845 │ 0.9   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.9   │ 0.901 │ 0.906 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1943, ET: 0.3302, TC: 0.1464, WT: 0.1062
[0m
[0;33m2025-05-16 00:35:22,857  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 00:35:22,857  - INFO - === Training on [Epoch 39/100] ===:[0m
[0;33m2025-05-16 00:39:12,836  - WARNING - lr reduce to 6.726752705214197e-05[0m
[0;32m2025-05-16 00:39:12,836  - INFO - - Train mean loss: 0.2734
- ET loss: 0.3908
- TC loss: 0.2595
- WT loss: 0.1699
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 00:39:12,836  - INFO - === Validating on [Epoch 39/100] ===:[0m
[0;32m2025-05-16 00:39:39,901  - INFO - === [Epoch 39/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.726752705214197e-05
- val_cost_time:27.0637s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.814 │ 0.679 │ 0.866 │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.724 │ 0.553 │ 0.794 │ 0.824 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.782 │ 0.588 │ 0.864 │ 0.893 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.899 │ 0.887 │ 0.894 │ 0.915 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1871, ET: 0.3215, TC: 0.1351, WT: 0.1048
[0m
[1;31m2025-05-16 00:39:39,904  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch36_loss0.1896_dice0.8119_20250516002646.pth[0m
[0;32m2025-05-16 00:39:39,965  - INFO - ✨ Saved checkpoint (epoch 39) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch39_loss0.1871_dice0.8143_20250516003939.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 00:39:39,965  - INFO - === Training on [Epoch 40/100] ===:[0m
[0;33m2025-05-16 00:43:29,749  - WARNING - lr reduce to 6.579634122155994e-05[0m
[0;32m2025-05-16 00:43:29,749  - INFO - - Train mean loss: 0.2639
- ET loss: 0.3699
- TC loss: 0.2513
- WT loss: 0.1704
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 00:43:29,749  - INFO - === Validating on [Epoch 40/100] ===:[0m
[0;32m2025-05-16 00:43:57,023  - INFO - === [Epoch 40/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.579634122155994e-05
- val_cost_time:27.2732s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.814 │ 0.684 │ 0.858 │ 0.899 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.723 │ 0.557 │ 0.787 │ 0.825 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.785 │ 0.59  │ 0.869 │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.891 │ 0.885 │ 0.877 │ 0.913 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1876, ET: 0.3163, TC: 0.1432, WT: 0.1034
[0m
[0;33m2025-05-16 00:43:57,023  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 00:43:57,023  - INFO - === Training on [Epoch 41/100] ===:[0m
[0;33m2025-05-16 00:47:47,856  - WARNING - lr reduce to 6.431005974894189e-05[0m
[0;32m2025-05-16 00:47:47,856  - INFO - - Train mean loss: 0.2639
- ET loss: 0.3799
- TC loss: 0.2463
- WT loss: 0.1656
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 00:47:47,856  - INFO - === Validating on [Epoch 41/100] ===:[0m
[0;32m2025-05-16 00:48:15,082  - INFO - === [Epoch 41/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.431005974894189e-05
- val_cost_time:27.2253s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.812 │ 0.675 │ 0.861 │ 0.898 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.722 │ 0.549 │ 0.792 │ 0.826 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.783 │ 0.584 │ 0.858 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.892 │ 0.883 │ 0.892 │ 0.903 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1896, ET: 0.3255, TC: 0.1398, WT: 0.1033
[0m
[0;33m2025-05-16 00:48:15,082  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 00:48:15,082  - INFO - === Training on [Epoch 42/100] ===:[0m
[0;33m2025-05-16 00:52:05,739  - WARNING - lr reduce to 6.281014941466034e-05[0m
[0;32m2025-05-16 00:52:05,739  - INFO - - Train mean loss: 0.2593
- ET loss: 0.3749
- TC loss: 0.2408
- WT loss: 0.1623
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 00:52:05,739  - INFO - === Validating on [Epoch 42/100] ===:[0m
[0;32m2025-05-16 00:52:33,111  - INFO - === [Epoch 42/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.281014941466034e-05
- val_cost_time:27.3712s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.811 │ 0.68  │ 0.857 │ 0.896 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.721 │ 0.553 │ 0.786 │ 0.823 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.782 │ 0.59  │ 0.865 │ 0.891 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.892 │ 0.881 │ 0.879 │ 0.915 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1903, ET: 0.3210, TC: 0.1442, WT: 0.1058
[0m
[0;33m2025-05-16 00:52:33,111  - WARNING - 😢😢😢Early stopping counter: 3/100[0m
[0;32m2025-05-16 00:52:33,111  - INFO - === Training on [Epoch 43/100] ===:[0m
[0;33m2025-05-16 00:56:23,908  - WARNING - lr reduce to 6.12980904491289e-05[0m
[0;32m2025-05-16 00:56:23,908  - INFO - - Train mean loss: 0.2688
- ET loss: 0.3815
- TC loss: 0.2583
- WT loss: 0.1666
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 00:56:23,908  - INFO - === Validating on [Epoch 43/100] ===:[0m
[0;32m2025-05-16 00:56:51,338  - INFO - === [Epoch 43/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.12980904491289e-05
- val_cost_time:27.4292s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.814 │ 0.691 │ 0.855 │ 0.895 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.723 │ 0.564 │ 0.783 │ 0.821 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.787 │ 0.602 │ 0.875 │ 0.885 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.888 │ 0.881 │ 0.865 │ 0.919 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1879, ET: 0.3100, TC: 0.1466, WT: 0.1071
[0m
[0;33m2025-05-16 00:56:51,338  - WARNING - 😢😢😢Early stopping counter: 4/100[0m
[0;32m2025-05-16 00:56:51,338  - INFO - === Training on [Epoch 44/100] ===:[0m
[0;33m2025-05-16 01:00:41,485  - WARNING - lr reduce to 5.977537507199341e-05[0m
[0;32m2025-05-16 01:00:41,486  - INFO - - Train mean loss: 0.2647
- ET loss: 0.3770
- TC loss: 0.2469
- WT loss: 0.1702
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:00:41,486  - INFO - === Validating on [Epoch 44/100] ===:[0m
[0;32m2025-05-16 01:01:08,581  - INFO - === [Epoch 44/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.977537507199341e-05
- val_cost_time:27.0951s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.813 │ 0.685 │ 0.856 │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.723 │ 0.56  │ 0.783 │ 0.825 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.784 │ 0.59  │ 0.863 │ 0.9   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.89  │ 0.887 │ 0.877 │ 0.906 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1885, ET: 0.3161, TC: 0.1450, WT: 0.1045
[0m
[0;33m2025-05-16 01:01:08,582  - WARNING - 😢😢😢Early stopping counter: 5/100[0m
[0;32m2025-05-16 01:01:08,582  - INFO - === Training on [Epoch 45/100] ===:[0m
[0;33m2025-05-16 01:04:58,839  - WARNING - lr reduce to 5.8243506019491463e-05[0m
[0;32m2025-05-16 01:04:58,840  - INFO - - Train mean loss: 0.2723
- ET loss: 0.3878
- TC loss: 0.2584
- WT loss: 0.1707
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:04:58,840  - INFO - === Validating on [Epoch 45/100] ===:[0m
[0;32m2025-05-16 01:05:26,144  - INFO - === [Epoch 45/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.8243506019491463e-05
- val_cost_time:27.3035s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.811 │ 0.682 │ 0.859 │ 0.891 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.721 │ 0.557 │ 0.786 │ 0.819 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.793 │ 0.59  │ 0.865 │ 0.924 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.88  │ 0.885 │ 0.883 │ 0.873 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1902, ET: 0.3186, TC: 0.1420, WT: 0.1100
[0m
[0;33m2025-05-16 01:05:26,144  - WARNING - 😢😢😢Early stopping counter: 6/100[0m
[0;32m2025-05-16 01:05:26,144  - INFO - === Training on [Epoch 46/100] ===:[0m
[0;33m2025-05-16 01:09:16,428  - WARNING - lr reduce to 5.67039950614331e-05[0m
[0;32m2025-05-16 01:09:16,429  - INFO - - Train mean loss: 0.2729
- ET loss: 0.3907
- TC loss: 0.2632
- WT loss: 0.1647
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:09:16,429  - INFO - === Validating on [Epoch 46/100] ===:[0m
[0;32m2025-05-16 01:09:43,885  - INFO - === [Epoch 46/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.67039950614331e-05
- val_cost_time:27.4555s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.805 │ 0.665 │ 0.854 │ 0.896 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.714 │ 0.538 │ 0.779 │ 0.824 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.758 │ 0.559 │ 0.822 │ 0.891 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.918 │ 0.917 │ 0.924 │ 0.914 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1960, ET: 0.3355, TC: 0.1468, WT: 0.1058
[0m
[0;33m2025-05-16 01:09:43,885  - WARNING - 😢😢😢Early stopping counter: 7/100[0m
[0;32m2025-05-16 01:09:43,885  - INFO - === Training on [Epoch 47/100] ===:[0m
[0;33m2025-05-16 01:13:34,857  - WARNING - lr reduce to 5.515836150926649e-05[0m
[0;32m2025-05-16 01:13:34,858  - INFO - - Train mean loss: 0.2577
- ET loss: 0.3766
- TC loss: 0.2375
- WT loss: 0.1591
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 01:13:34,858  - INFO - === Validating on [Epoch 47/100] ===:[0m
[0;32m2025-05-16 01:14:02,082  - INFO - === [Epoch 47/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.515836150926649e-05
- val_cost_time:27.2237s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.813 │ 0.681 │ 0.858 │ 0.899 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.725 │ 0.558 │ 0.787 │ 0.828 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.81  │ 0.615 │ 0.896 │ 0.921 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.864 │ 0.849 │ 0.855 │ 0.889 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1884, ET: 0.3195, TC: 0.1432, WT: 0.1025
[0m
[0;33m2025-05-16 01:14:02,083  - WARNING - 😢😢😢Early stopping counter: 8/100[0m
[0;32m2025-05-16 01:14:02,083  - INFO - === Training on [Epoch 48/100] ===:[0m
[0;33m2025-05-16 01:17:52,603  - WARNING - lr reduce to 5.3608130716701046e-05[0m
[0;32m2025-05-16 01:17:52,604  - INFO - - Train mean loss: 0.2673
- ET loss: 0.3822
- TC loss: 0.2545
- WT loss: 0.1651
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:17:52,604  - INFO - === Validating on [Epoch 48/100] ===:[0m
[0;32m2025-05-16 01:18:19,675  - INFO - === [Epoch 48/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.3608130716701046e-05
- val_cost_time:27.0702s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.818 │ 0.686 │ 0.867 │ 0.902 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.73  │ 0.56  │ 0.798 │ 0.831 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.602 │ 0.882 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.887 │ 0.874 │ 0.879 │ 0.909 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1829, ET: 0.3147, TC: 0.1342, WT: 0.0997
[0m
[1;31m2025-05-16 01:18:19,678  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch39_loss0.1871_dice0.8143_20250516003939.pth[0m
[0;32m2025-05-16 01:18:19,749  - INFO - ✨ Saved checkpoint (epoch 48) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch48_loss0.1829_dice0.8183_20250516011819.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:18:19,749  - INFO - === Training on [Epoch 49/100] ===:[0m
[0;33m2025-05-16 01:22:09,724  - WARNING - lr reduce to 5.205483257436738e-05[0m
[0;32m2025-05-16 01:22:09,724  - INFO - - Train mean loss: 0.2634
- ET loss: 0.3809
- TC loss: 0.2457
- WT loss: 0.1637
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 01:22:09,724  - INFO - === Validating on [Epoch 49/100] ===:[0m
[0;32m2025-05-16 01:22:37,028  - INFO - === [Epoch 49/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.205483257436738e-05
- val_cost_time:27.3031s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.816 │ 0.68  │ 0.869 │ 0.9   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.727 │ 0.555 │ 0.799 │ 0.828 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.787 │ 0.59  │ 0.866 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.899 │ 0.89  │ 0.9   │ 0.907 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1849, ET: 0.3210, TC: 0.1320, WT: 0.1018
[0m
[0;33m2025-05-16 01:22:37,028  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 01:22:37,028  - INFO - === Training on [Epoch 50/100] ===:[0m
[0;33m2025-05-16 01:26:27,729  - WARNING - lr reduce to 5.050000000000003e-05[0m
[0;32m2025-05-16 01:26:27,730  - INFO - - Train mean loss: 0.2610
- ET loss: 0.3730
- TC loss: 0.2435
- WT loss: 0.1665
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 01:26:27,730  - INFO - === Validating on [Epoch 50/100] ===:[0m
[0;32m2025-05-16 01:26:54,923  - INFO - === [Epoch 50/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.050000000000003e-05
- val_cost_time:27.1926s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.818 │ 0.687 │ 0.868 │ 0.899 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.728 │ 0.561 │ 0.797 │ 0.827 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.801 │ 0.602 │ 0.886 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.882 │ 0.876 │ 0.877 │ 0.895 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1831, ET: 0.3139, TC: 0.1331, WT: 0.1022
[0m
[0;33m2025-05-16 01:26:54,923  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 01:26:54,923  - INFO - === Training on [Epoch 51/100] ===:[0m
[0;33m2025-05-16 01:30:45,788  - WARNING - lr reduce to 4.894516742563268e-05[0m
[0;32m2025-05-16 01:30:45,788  - INFO - - Train mean loss: 0.2652
- ET loss: 0.3773
- TC loss: 0.2517
- WT loss: 0.1666
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 01:30:45,788  - INFO - === Validating on [Epoch 51/100] ===:[0m
[0;32m2025-05-16 01:31:13,002  - INFO - === [Epoch 51/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.894516742563268e-05
- val_cost_time:27.2126s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.815 │ 0.688 │ 0.856 │ 0.899 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.726 │ 0.563 │ 0.786 │ 0.829 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.608 │ 0.888 │ 0.91  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.875 │ 0.865 │ 0.857 │ 0.902 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1864, ET: 0.3121, TC: 0.1449, WT: 0.1023
[0m
[0;33m2025-05-16 01:31:13,002  - WARNING - 😢😢😢Early stopping counter: 3/100[0m
[0;32m2025-05-16 01:31:13,002  - INFO - === Training on [Epoch 52/100] ===:[0m
[0;33m2025-05-16 01:35:03,806  - WARNING - lr reduce to 4.739186928329902e-05[0m
[0;32m2025-05-16 01:35:03,807  - INFO - - Train mean loss: 0.2649
- ET loss: 0.3786
- TC loss: 0.2475
- WT loss: 0.1686
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 01:35:03,807  - INFO - === Validating on [Epoch 52/100] ===:[0m
[0;32m2025-05-16 01:35:31,033  - INFO - === [Epoch 52/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.739186928329902e-05
- val_cost_time:27.2255s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.817 │ 0.685 │ 0.869 │ 0.899 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.728 │ 0.559 │ 0.8   │ 0.826 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.786 │ 0.594 │ 0.874 │ 0.89  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.9   │ 0.888 │ 0.892 │ 0.92  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1838, ET: 0.3159, TC: 0.1323, WT: 0.1031
[0m
[0;33m2025-05-16 01:35:31,033  - WARNING - 😢😢😢Early stopping counter: 4/100[0m
[0;32m2025-05-16 01:35:31,034  - INFO - === Training on [Epoch 53/100] ===:[0m
[0;33m2025-05-16 01:39:22,055  - WARNING - lr reduce to 4.584163849073357e-05[0m
[0;32m2025-05-16 01:39:22,055  - INFO - - Train mean loss: 0.2638
- ET loss: 0.3786
- TC loss: 0.2546
- WT loss: 0.1582
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 01:39:22,055  - INFO - === Validating on [Epoch 53/100] ===:[0m
[0;32m2025-05-16 01:39:49,147  - INFO - === [Epoch 53/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.584163849073357e-05
- val_cost_time:27.0917s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.821 │ 0.687 │ 0.872 │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.732 │ 0.561 │ 0.8   │ 0.834 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.793 │ 0.592 │ 0.872 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.898 │ 0.894 │ 0.896 │ 0.905 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1801, ET: 0.3137, TC: 0.1293, WT: 0.0975
[0m
[1;31m2025-05-16 01:39:49,151  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch48_loss0.1829_dice0.8183_20250516011819.pth[0m
[0;32m2025-05-16 01:39:49,220  - INFO - ✨ Saved checkpoint (epoch 53) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch53_loss0.1801_dice0.8209_20250516013949.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:39:49,220  - INFO - === Training on [Epoch 54/100] ===:[0m
[0;33m2025-05-16 01:43:39,758  - WARNING - lr reduce to 4.429600493856697e-05[0m
[0;32m2025-05-16 01:43:39,758  - INFO - - Train mean loss: 0.2651
- ET loss: 0.3834
- TC loss: 0.2497
- WT loss: 0.1623
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:43:39,758  - INFO - === Validating on [Epoch 54/100] ===:[0m
[0;32m2025-05-16 01:44:07,002  - INFO - === [Epoch 54/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.429600493856697e-05
- val_cost_time:27.2432s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.822 │ 0.69  │ 0.871 │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.733 │ 0.565 │ 0.8   │ 0.834 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.601 │ 0.883 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.892 │ 0.886 │ 0.885 │ 0.904 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1792, ET: 0.3102, TC: 0.1299, WT: 0.0975
[0m
[1;31m2025-05-16 01:44:07,005  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch53_loss0.1801_dice0.8209_20250516013949.pth[0m
[0;32m2025-05-16 01:44:07,062  - INFO - ✨ Saved checkpoint (epoch 54) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch54_loss0.1792_dice0.8218_20250516014407.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:44:07,062  - INFO - === Training on [Epoch 55/100] ===:[0m
[0;33m2025-05-16 01:47:57,692  - WARNING - lr reduce to 4.275649398050859e-05[0m
[0;32m2025-05-16 01:47:57,693  - INFO - - Train mean loss: 0.2514
- ET loss: 0.3672
- TC loss: 0.2321
- WT loss: 0.1550
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:47:57,693  - INFO - === Validating on [Epoch 55/100] ===:[0m
[0;32m2025-05-16 01:48:25,174  - INFO - === [Epoch 55/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.275649398050859e-05
- val_cost_time:27.4804s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.815 │ 0.68  │ 0.871 │ 0.894 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.723 │ 0.554 │ 0.799 │ 0.817 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.764 │ 0.578 │ 0.849 │ 0.864 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.922 │ 0.909 │ 0.918 │ 0.938 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1859, ET: 0.3200, TC: 0.1296, WT: 0.1082
[0m
[0;33m2025-05-16 01:48:25,174  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 01:48:25,174  - INFO - === Training on [Epoch 56/100] ===:[0m
[0;33m2025-05-16 01:52:15,741  - WARNING - lr reduce to 4.122462492800665e-05[0m
[0;32m2025-05-16 01:52:15,742  - INFO - - Train mean loss: 0.2462
- ET loss: 0.3583
- TC loss: 0.2269
- WT loss: 0.1534
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 01:52:15,742  - INFO - === Validating on [Epoch 56/100] ===:[0m
[0;32m2025-05-16 01:52:43,046  - INFO - === [Epoch 56/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.122462492800665e-05
- val_cost_time:27.3039s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.822 │ 0.689 │ 0.875 │ 0.902 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.733 │ 0.563 │ 0.804 │ 0.831 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.793 │ 0.596 │ 0.879 │ 0.902 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.899 │ 0.892 │ 0.892 │ 0.913 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1792, ET: 0.3117, TC: 0.1260, WT: 0.0997
[0m
[1;31m2025-05-16 01:52:43,049  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch54_loss0.1792_dice0.8218_20250516014407.pth[0m
[0;32m2025-05-16 01:52:43,125  - INFO - ✨ Saved checkpoint (epoch 56) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch56_loss0.1792_dice0.8218_20250516015243.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:52:43,126  - INFO - === Training on [Epoch 57/100] ===:[0m
[0;33m2025-05-16 01:56:33,949  - WARNING - lr reduce to 3.9701909550871175e-05[0m
[0;32m2025-05-16 01:56:33,950  - INFO - - Train mean loss: 0.2606
- ET loss: 0.3762
- TC loss: 0.2449
- WT loss: 0.1606
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 01:56:33,950  - INFO - === Validating on [Epoch 57/100] ===:[0m
[0;32m2025-05-16 01:57:01,237  - INFO - === [Epoch 57/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.9701909550871175e-05
- val_cost_time:27.2864s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.822 │ 0.688 │ 0.875 │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.734 │ 0.563 │ 0.805 │ 0.834 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.796 │ 0.597 │ 0.877 │ 0.915 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.897 │ 0.891 │ 0.896 │ 0.903 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1789, ET: 0.3126, TC: 0.1262, WT: 0.0978
[0m
[1;31m2025-05-16 01:57:01,240  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch56_loss0.1792_dice0.8218_20250516015243.pth[0m
[0;32m2025-05-16 01:57:01,304  - INFO - ✨ Saved checkpoint (epoch 57) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch57_loss0.1789_dice0.8220_20250516015701.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 01:57:01,304  - INFO - === Training on [Epoch 58/100] ===:[0m
[0;33m2025-05-16 02:00:51,654  - WARNING - lr reduce to 3.81898505853397e-05[0m
[0;32m2025-05-16 02:00:51,654  - INFO - - Train mean loss: 0.2513
- ET loss: 0.3657
- TC loss: 0.2326
- WT loss: 0.1555
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 02:00:51,654  - INFO - === Validating on [Epoch 58/100] ===:[0m
[0;32m2025-05-16 02:01:18,804  - INFO - === [Epoch 58/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.81898505853397e-05
- val_cost_time:27.1488s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.819 │ 0.681 │ 0.873 │ 0.902 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.731 │ 0.556 │ 0.804 │ 0.832 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.782 │ 0.587 │ 0.862 │ 0.897 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.908 │ 0.897 │ 0.909 │ 0.919 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1823, ET: 0.3196, TC: 0.1281, WT: 0.0992
[0m
[0;33m2025-05-16 02:01:18,804  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:01:18,804  - INFO - === Training on [Epoch 59/100] ===:[0m
[0;33m2025-05-16 02:05:08,696  - WARNING - lr reduce to 3.668994025105817e-05[0m
[0;32m2025-05-16 02:05:08,697  - INFO - - Train mean loss: 0.2679
- ET loss: 0.3867
- TC loss: 0.2507
- WT loss: 0.1664
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:05:08,697  - INFO - === Validating on [Epoch 59/100] ===:[0m
[0;32m2025-05-16 02:05:35,904  - INFO - === [Epoch 59/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.668994025105817e-05
- val_cost_time:27.2065s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.82  │ 0.685 │ 0.873 │ 0.901 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.732 │ 0.561 │ 0.803 │ 0.831 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.602 │ 0.883 │ 0.921 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.885 │ 0.876 │ 0.884 │ 0.894 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1810, ET: 0.3151, TC: 0.1281, WT: 0.0999
[0m
[0;33m2025-05-16 02:05:35,904  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:05:35,904  - INFO - === Training on [Epoch 60/100] ===:[0m
[0;33m2025-05-16 02:09:25,675  - WARNING - lr reduce to 3.520365877844013e-05[0m
[0;32m2025-05-16 02:09:25,676  - INFO - - Train mean loss: 0.2574
- ET loss: 0.3773
- TC loss: 0.2354
- WT loss: 0.1594
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:09:25,676  - INFO - === Validating on [Epoch 60/100] ===:[0m
[0;32m2025-05-16 02:09:52,875  - INFO - === [Epoch 60/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.520365877844013e-05
- val_cost_time:27.1987s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.818 │ 0.682 │ 0.873 │ 0.898 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.729 │ 0.557 │ 0.803 │ 0.826 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.782 │ 0.586 │ 0.865 │ 0.896 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.906 │ 0.898 │ 0.905 │ 0.914 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1833, ET: 0.3181, TC: 0.1283, WT: 0.1037
[0m
[0;33m2025-05-16 02:09:52,875  - WARNING - 😢😢😢Early stopping counter: 3/100[0m
[0;32m2025-05-16 02:09:52,875  - INFO - === Training on [Epoch 61/100] ===:[0m
[0;33m2025-05-16 02:13:42,226  - WARNING - lr reduce to 3.373247294785809e-05[0m
[0;32m2025-05-16 02:13:42,226  - INFO - - Train mean loss: 0.2468
- ET loss: 0.3589
- TC loss: 0.2245
- WT loss: 0.1571
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-16 02:13:42,226  - INFO - === Validating on [Epoch 61/100] ===:[0m
[0;32m2025-05-16 02:14:09,522  - INFO - === [Epoch 61/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.373247294785809e-05
- val_cost_time:27.2955s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.823 │ 0.69  │ 0.877 │ 0.903 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.737 │ 0.566 │ 0.809 │ 0.835 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.805 │ 0.605 │ 0.885 │ 0.924 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.891 │ 0.885 │ 0.893 │ 0.895 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1774, ET: 0.3109, TC: 0.1237, WT: 0.0978
[0m
[1;31m2025-05-16 02:14:09,526  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch57_loss0.1789_dice0.8220_20250516015701.pth[0m
[0;32m2025-05-16 02:14:09,590  - INFO - ✨ Saved checkpoint (epoch 61) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch61_loss0.1774_dice0.8235_20250516021409.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 02:14:09,590  - INFO - === Training on [Epoch 62/100] ===:[0m
[0;33m2025-05-16 02:17:59,032  - WARNING - lr reduce to 3.227783464210847e-05[0m
[0;32m2025-05-16 02:17:59,033  - INFO - - Train mean loss: 0.2431
- ET loss: 0.3570
- TC loss: 0.2215
- WT loss: 0.1508
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-16 02:17:59,033  - INFO - === Validating on [Epoch 62/100] ===:[0m
[0;32m2025-05-16 02:18:26,359  - INFO - === [Epoch 62/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.227783464210847e-05
- val_cost_time:27.3253s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.821 │ 0.696 │ 0.863 │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.734 │ 0.571 │ 0.794 │ 0.836 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.81  │ 0.614 │ 0.895 │ 0.922 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.879 │ 0.874 │ 0.865 │ 0.898 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1795, ET: 0.3041, TC: 0.1375, WT: 0.0969
[0m
[0;33m2025-05-16 02:18:26,359  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:18:26,359  - INFO - === Training on [Epoch 63/100] ===:[0m
[0;33m2025-05-16 02:22:16,117  - WARNING - lr reduce to 3.0841179413578366e-05[0m
[0;32m2025-05-16 02:22:16,117  - INFO - - Train mean loss: 0.2457
- ET loss: 0.3586
- TC loss: 0.2262
- WT loss: 0.1522
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:22:16,117  - INFO - === Validating on [Epoch 63/100] ===:[0m
[0;32m2025-05-16 02:22:43,408  - INFO - === [Epoch 63/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.0841179413578366e-05
- val_cost_time:27.2905s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.823 │ 0.687 │ 0.877 │ 0.905 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.735 │ 0.562 │ 0.808 │ 0.836 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.79  │ 0.592 │ 0.87  │ 0.909 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.906 │ 0.899 │ 0.906 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1779, ET: 0.3131, TC: 0.1241, WT: 0.0963
[0m
[0;33m2025-05-16 02:22:43,409  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:22:43,409  - INFO - === Training on [Epoch 64/100] ===:[0m
[0;33m2025-05-16 02:26:32,839  - WARNING - lr reduce to 2.9423925067528915e-05[0m
[0;32m2025-05-16 02:26:32,840  - INFO - - Train mean loss: 0.2457
- ET loss: 0.3597
- TC loss: 0.2224
- WT loss: 0.1551
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-16 02:26:32,840  - INFO - === Validating on [Epoch 64/100] ===:[0m
[0;32m2025-05-16 02:26:59,817  - INFO - === [Epoch 64/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9423925067528915e-05
- val_cost_time:26.9763s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.826 │ 0.694 │ 0.877 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.738 │ 0.57  │ 0.808 │ 0.837 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.809 │ 0.612 │ 0.898 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.886 │ 0.876 │ 0.877 │ 0.905 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1752, ET: 0.3065, TC: 0.1237, WT: 0.0955
[0m
[1;31m2025-05-16 02:26:59,820  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch61_loss0.1774_dice0.8235_20250516021409.pth[0m
[0;32m2025-05-16 02:26:59,882  - INFO - ✨ Saved checkpoint (epoch 64) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch64_loss0.1752_dice0.8257_20250516022659.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 02:26:59,882  - INFO - === Training on [Epoch 65/100] ===:[0m
[0;33m2025-05-16 02:30:49,981  - WARNING - lr reduce to 2.8027470262892447e-05[0m
[0;32m2025-05-16 02:30:49,982  - INFO - - Train mean loss: 0.2399
- ET loss: 0.3549
- TC loss: 0.2191
- WT loss: 0.1458
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:30:49,982  - INFO - === Validating on [Epoch 65/100] ===:[0m
[0;32m2025-05-16 02:31:17,196  - INFO - === [Epoch 65/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.8027470262892447e-05
- val_cost_time:27.2132s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.823 │ 0.697 │ 0.866 │ 0.905 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.734 │ 0.57  │ 0.798 │ 0.836 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.796 │ 0.601 │ 0.877 │ 0.91  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.897 │ 0.896 │ 0.883 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1782, ET: 0.3035, TC: 0.1349, WT: 0.0961
[0m
[0;33m2025-05-16 02:31:17,196  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:31:17,196  - INFO - === Training on [Epoch 66/100] ===:[0m
[0;33m2025-05-16 02:35:07,236  - WARNING - lr reduce to 2.6653193131965096e-05[0m
[0;32m2025-05-16 02:35:07,237  - INFO - - Train mean loss: 0.2480
- ET loss: 0.3626
- TC loss: 0.2285
- WT loss: 0.1530
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:35:07,237  - INFO - === Validating on [Epoch 66/100] ===:[0m
[0;32m2025-05-16 02:35:34,491  - INFO - === [Epoch 66/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.6653193131965096e-05
- val_cost_time:27.2531s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.823 │ 0.69  │ 0.877 │ 0.903 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.736 │ 0.566 │ 0.808 │ 0.835 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.602 │ 0.884 │ 0.912 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.895 │ 0.888 │ 0.892 │ 0.906 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1777, ET: 0.3103, TC: 0.1244, WT: 0.0984
[0m
[0;33m2025-05-16 02:35:34,491  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:35:34,491  - INFO - === Training on [Epoch 67/100] ===:[0m
[0;33m2025-05-16 02:39:24,280  - WARNING - lr reduce to 2.530244992035663e-05[0m
[0;32m2025-05-16 02:39:24,281  - INFO - - Train mean loss: 0.2673
- ET loss: 0.3828
- TC loss: 0.2534
- WT loss: 0.1658
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:39:24,281  - INFO - === Validating on [Epoch 67/100] ===:[0m
[0;32m2025-05-16 02:39:51,430  - INFO - === [Epoch 67/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.530244992035663e-05
- val_cost_time:27.1493s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.825 │ 0.693 │ 0.876 │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.737 │ 0.569 │ 0.807 │ 0.835 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.604 │ 0.885 │ 0.916 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.895 │ 0.89  │ 0.891 │ 0.904 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1763, ET: 0.3074, TC: 0.1248, WT: 0.0968
[0m
[0;33m2025-05-16 02:39:51,431  - WARNING - 😢😢😢Early stopping counter: 3/100[0m
[0;32m2025-05-16 02:39:51,431  - INFO - === Training on [Epoch 68/100] ===:[0m
[0;33m2025-05-16 02:43:41,288  - WARNING - lr reduce to 2.3976573648539666e-05[0m
[0;32m2025-05-16 02:43:41,289  - INFO - - Train mean loss: 0.2528
- ET loss: 0.3679
- TC loss: 0.2337
- WT loss: 0.1567
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:43:41,289  - INFO - === Validating on [Epoch 68/100] ===:[0m
[0;32m2025-05-16 02:44:08,626  - INFO - === [Epoch 68/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.3976573648539666e-05
- val_cost_time:27.3371s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.825 │ 0.693 │ 0.876 │ 0.905 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.737 │ 0.568 │ 0.807 │ 0.836 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.603 │ 0.888 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.894 │ 0.888 │ 0.888 │ 0.907 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1759, ET: 0.3072, TC: 0.1245, WT: 0.0960
[0m
[0;33m2025-05-16 02:44:08,627  - WARNING - 😢😢😢Early stopping counter: 4/100[0m
[0;32m2025-05-16 02:44:08,627  - INFO - === Training on [Epoch 69/100] ===:[0m
[0;33m2025-05-16 02:47:58,418  - WARNING - lr reduce to 2.2676872796319543e-05[0m
[0;32m2025-05-16 02:47:58,418  - INFO - - Train mean loss: 0.2619
- ET loss: 0.3778
- TC loss: 0.2414
- WT loss: 0.1665
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:47:58,419  - INFO - === Validating on [Epoch 69/100] ===:[0m
[0;32m2025-05-16 02:48:25,799  - INFO - === [Epoch 69/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.2676872796319543e-05
- val_cost_time:27.3804s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.826 │ 0.692 │ 0.88  │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.739 │ 0.567 │ 0.812 │ 0.837 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.601 │ 0.883 │ 0.924 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.896 │ 0.891 │ 0.898 │ 0.899 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1749, ET: 0.3087, TC: 0.1207, WT: 0.0954
[0m
[1;31m2025-05-16 02:48:25,802  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch64_loss0.1752_dice0.8257_20250516022659.pth[0m
[0;32m2025-05-16 02:48:25,863  - INFO - ✨ Saved checkpoint (epoch 69) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch69_loss0.1749_dice0.8259_20250516024825.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 02:48:25,863  - INFO - === Training on [Epoch 70/100] ===:[0m
[0;33m2025-05-16 02:52:15,777  - WARNING - lr reduce to 2.1404630011522596e-05[0m
[0;32m2025-05-16 02:52:15,778  - INFO - - Train mean loss: 0.2403
- ET loss: 0.3547
- TC loss: 0.2183
- WT loss: 0.1479
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 02:52:15,778  - INFO - === Validating on [Epoch 70/100] ===:[0m
[0;32m2025-05-16 02:52:42,906  - INFO - === [Epoch 70/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1404630011522596e-05
- val_cost_time:27.1279s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.82  │ 0.683 │ 0.875 │ 0.902 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.732 │ 0.557 │ 0.806 │ 0.831 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.777 │ 0.582 │ 0.858 │ 0.892 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.918 │ 0.91  │ 0.918 │ 0.925 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1809, ET: 0.3179, TC: 0.1255, WT: 0.0995
[0m
[0;33m2025-05-16 02:52:42,906  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 02:52:42,906  - INFO - === Training on [Epoch 71/100] ===:[0m
[0;33m2025-05-16 02:56:32,371  - WARNING - lr reduce to 2.016110084417767e-05[0m
[0;32m2025-05-16 02:56:32,372  - INFO - - Train mean loss: 0.2412
- ET loss: 0.3550
- TC loss: 0.2203
- WT loss: 0.1482
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-16 02:56:32,372  - INFO - === Validating on [Epoch 71/100] ===:[0m
[0;32m2025-05-16 02:56:59,473  - INFO - === [Epoch 71/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.016110084417767e-05
- val_cost_time:27.1001s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.823 │ 0.688 │ 0.878 │ 0.903 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.735 │ 0.563 │ 0.81  │ 0.833 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.788 │ 0.592 │ 0.871 │ 0.902 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.908 │ 0.9   │ 0.908 │ 0.916 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1777, ET: 0.3124, TC: 0.1224, WT: 0.0983
[0m
[0;33m2025-05-16 02:56:59,473  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 02:56:59,473  - INFO - === Training on [Epoch 72/100] ===:[0m
[0;33m2025-05-16 03:00:49,191  - WARNING - lr reduce to 1.894751250743987e-05[0m
[0;32m2025-05-16 03:00:49,191  - INFO - - Train mean loss: 0.2496
- ET loss: 0.3652
- TC loss: 0.2340
- WT loss: 0.1497
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:00:49,192  - INFO - === Validating on [Epoch 72/100] ===:[0m
[0;32m2025-05-16 03:01:16,439  - INFO - === [Epoch 72/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.894751250743987e-05
- val_cost_time:27.2466s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.824 │ 0.689 │ 0.88  │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.738 │ 0.565 │ 0.813 │ 0.835 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.601 │ 0.884 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.901 │ 0.889 │ 0.899 │ 0.913 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1766, ET: 0.3117, TC: 0.1208, WT: 0.0972
[0m
[0;33m2025-05-16 03:01:16,439  - WARNING - 😢😢😢Early stopping counter: 3/100[0m
[0;32m2025-05-16 03:01:16,439  - INFO - === Training on [Epoch 73/100] ===:[0m
[0;33m2025-05-16 03:05:06,358  - WARNING - lr reduce to 1.776506266647925e-05[0m
[0;32m2025-05-16 03:05:06,359  - INFO - - Train mean loss: 0.2443
- ET loss: 0.3607
- TC loss: 0.2246
- WT loss: 0.1475
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:05:06,359  - INFO - === Validating on [Epoch 73/100] ===:[0m
[0;32m2025-05-16 03:05:33,816  - INFO - === [Epoch 73/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.776506266647925e-05
- val_cost_time:27.4562s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.825 │ 0.692 │ 0.878 │ 0.905 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.738 │ 0.568 │ 0.81  │ 0.837 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.801 │ 0.603 │ 0.888 │ 0.912 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.896 │ 0.889 │ 0.89  │ 0.91  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1757, ET: 0.3081, TC: 0.1232, WT: 0.0957
[0m
[0;33m2025-05-16 03:05:33,816  - WARNING - 😢😢😢Early stopping counter: 4/100[0m
[0;32m2025-05-16 03:05:33,816  - INFO - === Training on [Epoch 74/100] ===:[0m
[0;33m2025-05-16 03:09:24,448  - WARNING - lr reduce to 1.661491825652992e-05[0m
[0;32m2025-05-16 03:09:24,448  - INFO - - Train mean loss: 0.2546
- ET loss: 0.3723
- TC loss: 0.2374
- WT loss: 0.1540
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 03:09:24,449  - INFO - === Validating on [Epoch 74/100] ===:[0m
[0;32m2025-05-16 03:09:51,762  - INFO - === [Epoch 74/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.661491825652992e-05
- val_cost_time:27.3125s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.824 │ 0.693 │ 0.873 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.738 │ 0.569 │ 0.807 │ 0.837 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.804 │ 0.605 │ 0.891 │ 0.915 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.893 │ 0.888 │ 0.884 │ 0.907 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1770, ET: 0.3071, TC: 0.1282, WT: 0.0956
[0m
[0;33m2025-05-16 03:09:51,762  - WARNING - 😢😢😢Early stopping counter: 5/100[0m
[0;32m2025-05-16 03:09:51,762  - INFO - === Training on [Epoch 75/100] ===:[0m
[0;33m2025-05-16 03:13:42,604  - WARNING - lr reduce to 1.549821433126591e-05[0m
[0;32m2025-05-16 03:13:42,605  - INFO - - Train mean loss: 0.2410
- ET loss: 0.3584
- TC loss: 0.2215
- WT loss: 0.1432
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 03:13:42,605  - INFO - === Validating on [Epoch 75/100] ===:[0m
[0;32m2025-05-16 03:14:09,927  - INFO - === [Epoch 75/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.549821433126591e-05
- val_cost_time:27.3218s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.822 │ 0.685 │ 0.877 │ 0.904 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.735 │ 0.56  │ 0.809 │ 0.835 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.788 │ 0.586 │ 0.864 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.909 │ 0.905 │ 0.914 │ 0.907 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1788, ET: 0.3157, TC: 0.1239, WT: 0.0968
[0m
[0;33m2025-05-16 03:14:09,927  - WARNING - 😢😢😢Early stopping counter: 6/100[0m
[0;32m2025-05-16 03:14:09,927  - INFO - === Training on [Epoch 76/100] ===:[0m
[0;33m2025-05-16 03:18:00,312  - WARNING - lr reduce to 1.4416052942640147e-05[0m
[0;32m2025-05-16 03:18:00,312  - INFO - - Train mean loss: 0.2395
- ET loss: 0.3540
- TC loss: 0.2154
- WT loss: 0.1491
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 03:18:00,312  - INFO - === Validating on [Epoch 76/100] ===:[0m
[0;32m2025-05-16 03:18:27,498  - INFO - === [Epoch 76/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.4416052942640147e-05
- val_cost_time:27.1847s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.826 │ 0.691 │ 0.88  │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.739 │ 0.566 │ 0.813 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.6   │ 0.883 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.901 │ 0.894 │ 0.899 │ 0.91  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1750, ET: 0.3099, TC: 0.1206, WT: 0.0945
[0m
[0;33m2025-05-16 03:18:27,498  - WARNING - 😢😢😢Early stopping counter: 7/100[0m
[0;32m2025-05-16 03:18:27,498  - INFO - === Training on [Epoch 77/100] ===:[0m
[0;33m2025-05-16 03:22:17,004  - WARNING - lr reduce to 1.3369502053292257e-05[0m
[0;32m2025-05-16 03:22:17,005  - INFO - - Train mean loss: 0.2476
- ET loss: 0.3619
- TC loss: 0.2292
- WT loss: 0.1518
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:22:17,005  - INFO - === Validating on [Epoch 77/100] ===:[0m
[0;32m2025-05-16 03:22:44,385  - INFO - === [Epoch 77/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3369502053292257e-05
- val_cost_time:27.3798s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.823 │ 0.692 │ 0.873 │ 0.905 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.737 │ 0.567 │ 0.807 │ 0.836 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.599 │ 0.882 │ 0.91  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.9   │ 0.895 │ 0.893 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1774, ET: 0.3083, TC: 0.1281, WT: 0.0957
[0m
[0;33m2025-05-16 03:22:44,386  - WARNING - 😢😢😢Early stopping counter: 8/100[0m
[0;32m2025-05-16 03:22:44,386  - INFO - === Training on [Epoch 78/100] ===:[0m
[0;33m2025-05-16 03:26:34,446  - WARNING - lr reduce to 1.2359594482598444e-05[0m
[0;32m2025-05-16 03:26:34,446  - INFO - - Train mean loss: 0.2304
- ET loss: 0.3480
- TC loss: 0.2068
- WT loss: 0.1364
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:26:34,446  - INFO - === Validating on [Epoch 78/100] ===:[0m
[0;32m2025-05-16 03:27:01,822  - INFO - === [Epoch 78/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2359594482598444e-05
- val_cost_time:27.3758s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.824 │ 0.691 │ 0.877 │ 0.905 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.738 │ 0.567 │ 0.811 │ 0.836 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.796 │ 0.599 │ 0.884 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.903 │ 0.895 │ 0.897 │ 0.915 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1764, ET: 0.3093, TC: 0.1236, WT: 0.0964
[0m
[0;33m2025-05-16 03:27:01,822  - WARNING - 😢😢😢Early stopping counter: 9/100[0m
[0;32m2025-05-16 03:27:01,823  - INFO - === Training on [Epoch 79/100] ===:[0m
[0;33m2025-05-16 03:30:52,256  - WARNING - lr reduce to 1.1387326887403332e-05[0m
[0;32m2025-05-16 03:30:52,256  - INFO - - Train mean loss: 0.2640
- ET loss: 0.3873
- TC loss: 0.2502
- WT loss: 0.1546
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 03:30:52,256  - INFO - === Validating on [Epoch 79/100] ===:[0m
[0;32m2025-05-16 03:31:19,424  - INFO - === [Epoch 79/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.1387326887403332e-05
- val_cost_time:27.1668s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.826 │ 0.692 │ 0.88  │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.568 │ 0.814 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.804 │ 0.603 │ 0.889 │ 0.919 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.897 │ 0.89  │ 0.895 │ 0.905 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1745, ET: 0.3088, TC: 0.1207, WT: 0.0939
[0m
[1;31m2025-05-16 03:31:19,427  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch69_loss0.1749_dice0.8259_20250516024825.pth[0m
[0;32m2025-05-16 03:31:19,491  - INFO - ✨ Saved checkpoint (epoch 79) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch79_loss0.1745_dice0.8264_20250516033119.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:31:19,491  - INFO - === Training on [Epoch 80/100] ===:[0m
[0;33m2025-05-16 03:35:09,216  - WARNING - lr reduce to 1.0453658778440112e-05[0m
[0;32m2025-05-16 03:35:09,216  - INFO - - Train mean loss: 0.2409
- ET loss: 0.3584
- TC loss: 0.2178
- WT loss: 0.1464
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:35:09,217  - INFO - === Validating on [Epoch 80/100] ===:[0m
[0;32m2025-05-16 03:35:36,392  - INFO - === [Epoch 80/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0453658778440112e-05
- val_cost_time:27.1751s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.881 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.567 │ 0.813 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.601 │ 0.884 │ 0.915 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.9   │ 0.891 │ 0.898 │ 0.909 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1743, ET: 0.3088, TC: 0.1200, WT: 0.0940
[0m
[1;31m2025-05-16 03:35:36,395  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch79_loss0.1745_dice0.8264_20250516033119.pth[0m
[0;32m2025-05-16 03:35:36,456  - INFO - ✨ Saved checkpoint (epoch 80) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch80_loss0.1743_dice0.8266_20250516033536.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:35:36,457  - INFO - === Training on [Epoch 81/100] ===:[0m
[0;33m2025-05-16 03:39:26,491  - WARNING - lr reduce to 9.5595115734092e-06[0m
[0;32m2025-05-16 03:39:26,492  - INFO - - Train mean loss: 0.2400
- ET loss: 0.3593
- TC loss: 0.2212
- WT loss: 0.1396
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:39:26,492  - INFO - === Validating on [Epoch 81/100] ===:[0m
[0;32m2025-05-16 03:39:53,889  - INFO - === [Epoch 81/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.5595115734092e-06
- val_cost_time:27.3967s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.695 │ 0.879 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.57  │ 0.812 │ 0.84  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.809 │ 0.61  │ 0.899 │ 0.918 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.892 │ 0.884 │ 0.884 │ 0.907 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1740, ET: 0.3060, TC: 0.1221, WT: 0.0939
[0m
[1;31m2025-05-16 03:39:53,892  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch80_loss0.1743_dice0.8266_20250516033536.pth[0m
[0;32m2025-05-16 03:39:53,955  - INFO - ✨ Saved checkpoint (epoch 81) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch81_loss0.1740_dice0.8269_20250516033953.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:39:53,956  - INFO - === Training on [Epoch 82/100] ===:[0m
[0;33m2025-05-16 03:43:44,724  - WARNING - lr reduce to 8.70576768765027e-06[0m
[0;32m2025-05-16 03:43:44,724  - INFO - - Train mean loss: 0.2444
- ET loss: 0.3641
- TC loss: 0.2263
- WT loss: 0.1428
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 03:43:44,724  - INFO - === Validating on [Epoch 82/100] ===:[0m
[0;32m2025-05-16 03:44:12,080  - INFO - === [Epoch 82/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       8.70576768765027e-06
- val_cost_time:27.3548s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.826 │ 0.69  │ 0.881 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.566 │ 0.815 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.798 │ 0.599 │ 0.881 │ 0.915 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.903 │ 0.895 │ 0.904 │ 0.91  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1747, ET: 0.3105, TC: 0.1194, WT: 0.0942
[0m
[0;33m2025-05-16 03:44:12,080  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 03:44:12,080  - INFO - === Training on [Epoch 83/100] ===:[0m
[0;33m2025-05-16 03:48:02,723  - WARNING - lr reduce to 7.893269663304789e-06[0m
[0;32m2025-05-16 03:48:02,724  - INFO - - Train mean loss: 0.2564
- ET loss: 0.3742
- TC loss: 0.2346
- WT loss: 0.1603
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 03:48:02,724  - INFO - === Validating on [Epoch 83/100] ===:[0m
[0;32m2025-05-16 03:48:30,062  - INFO - === [Epoch 83/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.893269663304789e-06
- val_cost_time:27.3381s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.694 │ 0.88  │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.569 │ 0.812 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.603 │ 0.888 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.898 │ 0.891 │ 0.893 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1739, ET: 0.3066, TC: 0.1210, WT: 0.0940
[0m
[1;31m2025-05-16 03:48:30,066  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch81_loss0.1740_dice0.8269_20250516033953.pth[0m
[0;32m2025-05-16 03:48:30,128  - INFO - ✨ Saved checkpoint (epoch 83) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch83_loss0.1739_dice0.8270_20250516034830.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:48:30,129  - INFO - === Training on [Epoch 84/100] ===:[0m
[0;33m2025-05-16 03:52:20,720  - WARNING - lr reduce to 7.1228193378287565e-06[0m
[0;32m2025-05-16 03:52:20,721  - INFO - - Train mean loss: 0.2529
- ET loss: 0.3728
- TC loss: 0.2335
- WT loss: 0.1523
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 03:52:20,721  - INFO - === Validating on [Epoch 84/100] ===:[0m
[0;32m2025-05-16 03:52:48,055  - INFO - === [Epoch 84/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       7.1228193378287565e-06
- val_cost_time:27.3340s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.567 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.802 │ 0.602 │ 0.887 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.899 │ 0.891 │ 0.899 │ 0.908 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3088, TC: 0.1181, WT: 0.0938
[0m
[1;31m2025-05-16 03:52:48,059  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch83_loss0.1739_dice0.8270_20250516034830.pth[0m
[0;32m2025-05-16 03:52:48,122  - INFO - ✨ Saved checkpoint (epoch 84) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch84_loss0.1736_dice0.8272_20250516035248.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 03:52:48,122  - INFO - === Training on [Epoch 85/100] ===:[0m
[0;33m2025-05-16 03:56:38,098  - WARNING - lr reduce to 6.395177052675798e-06[0m
[0;32m2025-05-16 03:56:38,098  - INFO - - Train mean loss: 0.2416
- ET loss: 0.3554
- TC loss: 0.2150
- WT loss: 0.1543
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 03:56:38,098  - INFO - === Validating on [Epoch 85/100] ===:[0m
[0;32m2025-05-16 03:57:05,511  - INFO - === [Epoch 85/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       6.395177052675798e-06
- val_cost_time:27.4119s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.69  │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.566 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.598 │ 0.88  │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.905 │ 0.896 │ 0.906 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1742, ET: 0.3101, TC: 0.1181, WT: 0.0945
[0m
[0;33m2025-05-16 03:57:05,511  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 03:57:05,511  - INFO - === Training on [Epoch 86/100] ===:[0m
[0;33m2025-05-16 04:00:56,171  - WARNING - lr reduce to 5.711060902932045e-06[0m
[0;32m2025-05-16 04:00:56,172  - INFO - - Train mean loss: 0.2587
- ET loss: 0.3763
- TC loss: 0.2385
- WT loss: 0.1614
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 04:00:56,172  - INFO - === Validating on [Epoch 86/100] ===:[0m
[0;32m2025-05-16 04:01:23,417  - INFO - === [Epoch 86/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.711060902932045e-06
- val_cost_time:27.2451s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.803 │ 0.605 │ 0.889 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.899 │ 0.89  │ 0.897 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3084, TC: 0.1182, WT: 0.0942
[0m
[0;33m2025-05-16 04:01:23,417  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 04:01:23,417  - INFO - === Training on [Epoch 87/100] ===:[0m
[0;33m2025-05-16 04:05:13,284  - WARNING - lr reduce to 5.071146028642947e-06[0m
[0;32m2025-05-16 04:05:13,284  - INFO - - Train mean loss: 0.2475
- ET loss: 0.3676
- TC loss: 0.2260
- WT loss: 0.1488
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 04:05:13,284  - INFO - === Validating on [Epoch 87/100] ===:[0m
[0;32m2025-05-16 04:05:40,453  - INFO - === [Epoch 87/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       5.071146028642947e-06
- val_cost_time:27.1684s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.693 │ 0.882 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.569 │ 0.814 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.602 │ 0.887 │ 0.911 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.901 │ 0.892 │ 0.897 │ 0.914 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1734, ET: 0.3074, TC: 0.1190, WT: 0.0938
[0m
[1;31m2025-05-16 04:05:40,456  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch84_loss0.1736_dice0.8272_20250516035248.pth[0m
[0;32m2025-05-16 04:05:40,520  - INFO - ✨ Saved checkpoint (epoch 87) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch87_loss0.1734_dice0.8274_20250516040540.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 04:05:40,520  - INFO - === Training on [Epoch 88/100] ===:[0m
[0;33m2025-05-16 04:09:30,732  - WARNING - lr reduce to 4.476063948531561e-06[0m
[0;32m2025-05-16 04:09:30,733  - INFO - - Train mean loss: 0.2527
- ET loss: 0.3707
- TC loss: 0.2315
- WT loss: 0.1558
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 04:09:30,733  - INFO - === Validating on [Epoch 88/100] ===:[0m
[0;32m2025-05-16 04:09:58,115  - INFO - === [Epoch 88/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       4.476063948531561e-06
- val_cost_time:27.3814s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.828 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.84  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.602 │ 0.885 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.894 │ 0.901 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1732, ET: 0.3081, TC: 0.1178, WT: 0.0937
[0m
[1;31m2025-05-16 04:09:58,118  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch87_loss0.1734_dice0.8274_20250516040540.pth[0m
[0;32m2025-05-16 04:09:58,179  - INFO - ✨ Saved checkpoint (epoch 88) to /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch88_loss0.1732_dice0.8276_20250516040958.pth;             Size 36.60 MB[0m
[0;32m2025-05-16 04:09:58,179  - INFO - === Training on [Epoch 89/100] ===:[0m
[0;33m2025-05-16 04:13:49,041  - WARNING - lr reduce to 3.926401936765843e-06[0m
[0;32m2025-05-16 04:13:49,042  - INFO - - Train mean loss: 0.2505
- ET loss: 0.3666
- TC loss: 0.2294
- WT loss: 0.1554
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 04:13:49,042  - INFO - === Validating on [Epoch 89/100] ===:[0m
[0;32m2025-05-16 04:14:16,345  - INFO - === [Epoch 89/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.926401936765843e-06
- val_cost_time:27.3030s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.828 │ 0.693 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.569 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.803 │ 0.606 │ 0.89  │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.899 │ 0.889 │ 0.896 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1732, ET: 0.3077, TC: 0.1180, WT: 0.0940
[0m
[0;33m2025-05-16 04:14:16,345  - WARNING - 😢😢😢Early stopping counter: 1/100[0m
[0;32m2025-05-16 04:14:16,346  - INFO - === Training on [Epoch 90/100] ===:[0m
[0;33m2025-05-16 04:18:07,135  - WARNING - lr reduce to 3.4227024433899027e-06[0m
[0;32m2025-05-16 04:18:07,136  - INFO - - Train mean loss: 0.2514
- ET loss: 0.3701
- TC loss: 0.2299
- WT loss: 0.1543
- Cost time: 3.85mins ⏱️
[0m
[0;32m2025-05-16 04:18:07,136  - INFO - === Validating on [Epoch 90/100] ===:[0m
[0;32m2025-05-16 04:18:34,317  - INFO - === [Epoch 90/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       3.4227024433899027e-06
- val_cost_time:27.1810s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.691 │ 0.882 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.567 │ 0.815 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.797 │ 0.6   │ 0.882 │ 0.91  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.904 │ 0.895 │ 0.904 │ 0.914 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1741, ET: 0.3091, TC: 0.1185, WT: 0.0945
[0m
[0;33m2025-05-16 04:18:34,317  - WARNING - 😢😢😢Early stopping counter: 2/100[0m
[0;32m2025-05-16 04:18:34,317  - INFO - === Training on [Epoch 91/100] ===:[0m
[0;33m2025-05-16 04:22:24,635  - WARNING - lr reduce to 2.9654625589913256e-06[0m
[0;32m2025-05-16 04:22:24,636  - INFO - - Train mean loss: 0.2513
- ET loss: 0.3703
- TC loss: 0.2301
- WT loss: 0.1535
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 04:22:24,636  - INFO - === Validating on [Epoch 91/100] ===:[0m
[0;32m2025-05-16 04:22:52,008  - INFO - === [Epoch 91/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.9654625589913256e-06
- val_cost_time:27.3718s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.602 │ 0.885 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.893 │ 0.901 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1735, ET: 0.3083, TC: 0.1181, WT: 0.0940
[0m
[0;33m2025-05-16 04:22:52,008  - WARNING - 😢😢😢Early stopping counter: 3/100[0m
[0;32m2025-05-16 04:22:52,008  - INFO - === Training on [Epoch 92/100] ===:[0m
[0;33m2025-05-16 04:26:41,718  - WARNING - lr reduce to 2.5551335241327686e-06[0m
[0;32m2025-05-16 04:26:41,719  - INFO - - Train mean loss: 0.2527
- ET loss: 0.3691
- TC loss: 0.2334
- WT loss: 0.1556
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 04:26:41,719  - INFO - === Validating on [Epoch 92/100] ===:[0m
[0;32m2025-05-16 04:27:08,946  - INFO - === [Epoch 92/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.5551335241327686e-06
- val_cost_time:27.2267s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.882 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.74  │ 0.567 │ 0.815 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.6   │ 0.882 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.903 │ 0.894 │ 0.904 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1738, ET: 0.3089, TC: 0.1186, WT: 0.0940
[0m
[0;33m2025-05-16 04:27:08,946  - WARNING - 😢😢😢Early stopping counter: 4/100[0m
[0;32m2025-05-16 04:27:08,946  - INFO - === Training on [Epoch 93/100] ===:[0m
[0;33m2025-05-16 04:30:58,781  - WARNING - lr reduce to 2.1921202840320086e-06[0m
[0;32m2025-05-16 04:30:58,782  - INFO - - Train mean loss: 0.2458
- ET loss: 0.3649
- TC loss: 0.2258
- WT loss: 0.1466
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 04:30:58,782  - INFO - === Validating on [Epoch 93/100] ===:[0m
[0;32m2025-05-16 04:31:26,383  - INFO - === [Epoch 93/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       2.1921202840320086e-06
- val_cost_time:27.6005s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.603 │ 0.885 │ 0.91  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.903 │ 0.893 │ 0.902 │ 0.914 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3082, TC: 0.1181, WT: 0.0946
[0m
[0;33m2025-05-16 04:31:26,383  - WARNING - 😢😢😢Early stopping counter: 5/100[0m
[0;32m2025-05-16 04:31:26,383  - INFO - === Training on [Epoch 94/100] ===:[0m
[0;33m2025-05-16 04:35:15,874  - WARNING - lr reduce to 1.8767810889299092e-06[0m
[0;32m2025-05-16 04:35:15,874  - INFO - - Train mean loss: 0.2488
- ET loss: 0.3656
- TC loss: 0.2319
- WT loss: 0.1490
- Cost time: 3.82mins ⏱️
[0m
[0;32m2025-05-16 04:35:15,874  - INFO - === Validating on [Epoch 94/100] ===:[0m
[0;32m2025-05-16 04:35:43,104  - INFO - === [Epoch 94/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.8767810889299092e-06
- val_cost_time:27.2294s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.601 │ 0.883 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.903 │ 0.894 │ 0.903 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3085, TC: 0.1182, WT: 0.0941
[0m
[0;33m2025-05-16 04:35:43,104  - WARNING - 😢😢😢Early stopping counter: 6/100[0m
[0;32m2025-05-16 04:35:43,104  - INFO - === Training on [Epoch 95/100] ===:[0m
[0;33m2025-05-16 04:39:32,783  - WARNING - lr reduce to 1.6094271405406865e-06[0m
[0;32m2025-05-16 04:39:32,784  - INFO - - Train mean loss: 0.2570
- ET loss: 0.3744
- TC loss: 0.2367
- WT loss: 0.1599
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 04:39:32,784  - INFO - === Validating on [Epoch 95/100] ===:[0m
[0;32m2025-05-16 04:39:59,915  - INFO - === [Epoch 95/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.6094271405406865e-06
- val_cost_time:27.1305s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.693 │ 0.882 │ 0.906 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.569 │ 0.815 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.801 │ 0.605 │ 0.889 │ 0.909 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.9   │ 0.89  │ 0.897 │ 0.914 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3073, TC: 0.1184, WT: 0.0950
[0m
[0;33m2025-05-16 04:39:59,915  - WARNING - 😢😢😢Early stopping counter: 7/100[0m
[0;32m2025-05-16 04:39:59,915  - INFO - === Training on [Epoch 96/100] ===:[0m
[0;33m2025-05-16 04:43:49,583  - WARNING - lr reduce to 1.3903222849333511e-06[0m
[0;32m2025-05-16 04:43:49,584  - INFO - - Train mean loss: 0.2346
- ET loss: 0.3502
- TC loss: 0.2126
- WT loss: 0.1411
- Cost time: 3.83mins ⏱️
[0m
[0;32m2025-05-16 04:43:49,584  - INFO - === Validating on [Epoch 96/100] ===:[0m
[0;32m2025-05-16 04:44:16,800  - INFO - === [Epoch 96/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.3903222849333511e-06
- val_cost_time:27.2159s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.602 │ 0.885 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.901 │ 0.893 │ 0.9   │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3082, TC: 0.1183, WT: 0.0944
[0m
[0;33m2025-05-16 04:44:16,800  - WARNING - 😢😢😢Early stopping counter: 8/100[0m
[0;32m2025-05-16 04:44:16,800  - INFO - === Training on [Epoch 97/100] ===:[0m
[0;33m2025-05-16 04:48:07,111  - WARNING - lr reduce to 1.2196827521475405e-06[0m
[0;32m2025-05-16 04:48:07,111  - INFO - - Train mean loss: 0.2407
- ET loss: 0.3566
- TC loss: 0.2176
- WT loss: 0.1478
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 04:48:07,111  - INFO - === Validating on [Epoch 97/100] ===:[0m
[0;32m2025-05-16 04:48:34,630  - INFO - === [Epoch 97/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.2196827521475405e-06
- val_cost_time:27.5182s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.799 │ 0.601 │ 0.883 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.894 │ 0.903 │ 0.91  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1738, ET: 0.3089, TC: 0.1181, WT: 0.0944
[0m
[0;33m2025-05-16 04:48:34,630  - WARNING - 😢😢😢Early stopping counter: 9/100[0m
[0;32m2025-05-16 04:48:34,630  - INFO - === Training on [Epoch 98/100] ===:[0m
[0;33m2025-05-16 04:52:24,900  - WARNING - lr reduce to 1.097676942800558e-06[0m
[0;32m2025-05-16 04:52:24,901  - INFO - - Train mean loss: 0.2463
- ET loss: 0.3633
- TC loss: 0.2206
- WT loss: 0.1552
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 04:52:24,901  - INFO - === Validating on [Epoch 98/100] ===:[0m
[0;32m2025-05-16 04:52:52,230  - INFO - === [Epoch 98/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.097676942800558e-06
- val_cost_time:27.3288s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.601 │ 0.884 │ 0.914 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.894 │ 0.903 │ 0.91  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1738, ET: 0.3088, TC: 0.1181, WT: 0.0943
[0m
[0;33m2025-05-16 04:52:52,230  - WARNING - 😢😢😢Early stopping counter: 10/100[0m
[0;32m2025-05-16 04:52:52,231  - INFO - === Training on [Epoch 99/100] ===:[0m
[0;33m2025-05-16 04:56:42,928  - WARNING - lr reduce to 1.0244252618962857e-06[0m
[0;32m2025-05-16 04:56:42,929  - INFO - - Train mean loss: 0.2532
- ET loss: 0.3702
- TC loss: 0.2351
- WT loss: 0.1543
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 04:56:42,929  - INFO - === Validating on [Epoch 99/100] ===:[0m
[0;32m2025-05-16 04:57:10,335  - INFO - === [Epoch 99/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1.0244252618962857e-06
- val_cost_time:27.4049s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.602 │ 0.885 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.893 │ 0.901 │ 0.912 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1737, ET: 0.3083, TC: 0.1184, WT: 0.0943
[0m
[0;33m2025-05-16 04:57:10,335  - WARNING - 😢😢😢Early stopping counter: 11/100[0m
[0;32m2025-05-16 04:57:10,335  - INFO - === Training on [Epoch 100/100] ===:[0m
[0;33m2025-05-16 05:01:00,875  - WARNING - lr reduce to 1e-06[0m
[0;32m2025-05-16 05:01:00,875  - INFO - - Train mean loss: 0.2498
- ET loss: 0.3636
- TC loss: 0.2275
- WT loss: 0.1583
- Cost time: 3.84mins ⏱️
[0m
[0;32m2025-05-16 05:01:00,875  - INFO - === Validating on [Epoch 100/100] ===:[0m
[0;32m2025-05-16 05:01:28,170  - INFO - === [Epoch 100/100] ===
- Model:    Mamba3d
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       1e-06
- val_cost_time:27.2947s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.827 │ 0.692 │ 0.883 │ 0.907 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.741 │ 0.568 │ 0.816 │ 0.839 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.8   │ 0.601 │ 0.884 │ 0.913 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.902 │ 0.894 │ 0.902 │ 0.911 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.1736, ET: 0.3085, TC: 0.1182, WT: 0.0942
[0m
[0;33m2025-05-16 05:01:28,170  - WARNING - 😢😢😢Early stopping counter: 12/100[0m
[1;31m2025-05-16 05:01:29,783  - CRITICAL - 🥳🎉🎊Train finished. Best val loss: 👉0.1732 at epoch 88[0m
[0;32m2025-05-16 05:01:29,783  - INFO - 🛠️ 准备保存最终模型.......[0m
[0;32m2025-05-16 05:01:29,800  - INFO - ✅ 最后一个权重文件已复制为 /root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/Mamba3d_final_model.pth[0m
[1;31m2025-05-16 05:01:29,800  - CRITICAL - 🥳🎉🎊 最终模型已保存[0m
[0;32m2025-05-16 05:01:29,800  - INFO - 🛠️ 准备测试模型.......[0m
[1;31m2025-05-16 05:04:06,052  - CRITICAL - === [FINAL TEST METRIC] ===
╒═══════════════╤════════╤════════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │     ET │    TC │    WT │
╞═══════════════╪════════╪════════╪═══════╪═══════╡
│ Dice          │  0.811 │  0.674 │ 0.865 │ 0.894 │
├───────────────┼────────┼────────┼───────┼───────┤
│ Jaccard       │  0.723 │  0.553 │ 0.796 │ 0.821 │
├───────────────┼────────┼────────┼───────┼───────┤
│ Precision     │  0.789 │  0.592 │ 0.878 │ 0.898 │
├───────────────┼────────┼────────┼───────┼───────┤
│ Recall        │  0.888 │  0.89  │ 0.873 │ 0.901 │
├───────────────┼────────┼────────┼───────┼───────┤
│ H95           │  7.731 │ 11.096 │ 6.902 │ 5.196 │
╘═══════════════╧════════╧════════╧═══════╧═══════╛
Mean Loss: 0.1896;ET: 0.3262;ET: 0.3262;TC: 0.1355;WT: 0.1071
[0m
[0;32m2025-05-16 05:04:06,052  - INFO - 🥳🎉🎊 模型测试已完成.......[0m
[0;32m2025-05-16 05:04:06,052  - INFO - 测试集的指标已保存至/root/workspace/DCLA-UNet/results/Mamba3d_2025-05-15_lr0.0001_mlr1e-06_Tmax100_100_100/logs/2025-05-15.log[0m
[0;32m2025-05-16 05:04:14,323  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 05:04:16,619  - INFO - Total number of parameters: 0.68 M[0m
[0;32m2025-05-16 05:04:16,623  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 05:04:16,623  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 05:04:16,623  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 05:04:16,623  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 05:04:16,623  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 05:04:16,629  - WARNING - 训练集大小变成：875[0m
[0;33m2025-05-16 05:04:16,629  - WARNING - 验证集大小变成：250[0m
[0;33m2025-05-16 05:04:16,629  - WARNING - 测试大小变成：126[0m
[0;32m2025-05-16 05:04:16,632  - INFO - 🧠 项目名：0515_DCLA_UNet_v2 
╒═════════════════════╤════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                          │
╞═════════════════════╪════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/workspace/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/workspace/DCLA-UNet/outputs                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/workspace/DCLA-UNet/results                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ config              │ None                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                   │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb_project         │ 0515_DCLA_UNet_v2                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ epochs              │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-06                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 100                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                         │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                              │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                       │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ local               │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_length        │ 875                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_length          │ 250                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_length         │ 126                                                            │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ slb                 │ True                                                           │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                          │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/workspace/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/workspace/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/workspace/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.68 M                                                         │
╘═════════════════════╧════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 05:04:19,904  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 100
early_stopping: 100
[0m
[0;32m2025-05-16 05:04:19,905  - INFO - === Training on [Epoch 1/100] ===:[0m
[0;33m2025-05-16 06:41:21,655  - WARNING - lr reduce to 9.997557473810373e-05[0m
[0;32m2025-05-16 06:41:21,656  - INFO - - Train mean loss: 0.8200
- ET loss: 0.5384
- TC loss: 0.9783
- WT loss: 0.9432
- Cost time: 97.03mins ⏱️
[0m
[0;32m2025-05-16 06:41:21,656  - INFO - === Validating on [Epoch 1/100] ===:[0m
[0;32m2025-05-16 06:44:59,875  - INFO - === [Epoch 1/100] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997557473810373e-05
- val_cost_time:218.2176s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.261 │ 0.665 │ 0.033 │ 0.086 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.201 │ 0.54  │ 0.017 │ 0.046 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.243 │ 0.666 │ 0.017 │ 0.046 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.905 │ 0.718 │ 0.996 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7422, ET: 0.3450, TC: 0.9672, WT: 0.9142
[0m
[0;32m2025-05-16 06:44:59,961  - INFO - ✨ Saved checkpoint (epoch 1) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch1_loss0.7422_dice0.2612_20250516064459.pth;             Size 8.73 MB[0m
[0;32m2025-05-16 06:44:59,961  - INFO - === Training on [Epoch 2/100] ===:[0m
[0;33m2025-05-16 08:23:33,786  - WARNING - lr reduce to 9.990232305719946e-05[0m
[0;32m2025-05-16 08:23:33,787  - INFO - - Train mean loss: 0.7776
- ET loss: 0.4122
- TC loss: 0.9785
- WT loss: 0.9423
- Cost time: 98.56mins ⏱️
[0m
[0;32m2025-05-16 08:23:33,787  - INFO - === Validating on [Epoch 2/100] ===:[0m
[0;32m2025-05-16 08:27:17,608  - INFO - === [Epoch 2/100] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.990232305719946e-05
- val_cost_time:223.8199s ⏱️
- early_stopping: 100
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.273 │ 0.699 │ 0.033 │ 0.086 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.215 │ 0.582 │ 0.017 │ 0.046 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.273 │ 0.757 │ 0.017 │ 0.046 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.896 │ 0.693 │ 0.996 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.7295, ET: 0.3071, TC: 0.9672, WT: 0.9142
[0m
[0;32m2025-05-16 08:27:17,684  - INFO - ✨ Saved checkpoint (epoch 2) to /root/workspace/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-06_Tmax100_100_100/checkpoints/best_epoch2_loss0.7295_dice0.2726_20250516082717.pth;             Size 8.73 MB[0m
[0;32m2025-05-16 08:27:17,684  - INFO - === Training on [Epoch 3/100] ===:[0m
[0;32m2025-05-16 10:55:21,090  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 10:55:24,507  - INFO - Total number of parameters: 0.69 M[0m
[0;32m2025-05-16 10:55:24,513  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 10:55:24,513  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 10:55:24,513  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 10:55:24,514  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 10:55:24,514  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 10:55:24,525  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 10:55:24,525  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 10:55:24,525  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 10:55:24,530  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.69 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 10:55:25,059  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 10:55:25,059  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 10:56:33,117  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 10:56:33,118  - INFO - - Train mean loss: 0.7998
- ET loss: 0.7595
- TC loss: 0.7026
- WT loss: 0.9372
- Cost time: 1.13mins ⏱️
[0m
[0;32m2025-05-16 10:56:33,118  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 10:56:43,554  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.4352s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.362 │ 0.485 │ 0.521 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.255 │ 0.342 │ 0.38  │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.309 │ 0.417 │ 0.467 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.83  │ 0.721 │ 0.768 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.6605, ET: 0.5545, TC: 0.5071, WT: 0.9200
[0m
[0;32m2025-05-16 10:56:43,652  - INFO - ✨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.6605_dice0.3622_20250516105643.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 10:56:43,652  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 10:57:50,588  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 10:57:50,589  - INFO - - Train mean loss: 0.6818
- ET loss: 0.5769
- TC loss: 0.5284
- WT loss: 0.9401
- Cost time: 1.12mins ⏱️
[0m
[0;32m2025-05-16 10:57:50,589  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 10:58:00,720  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.1296s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.402 │ 0.561 │ 0.566 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.295 │ 0.416 │ 0.425 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.327 │ 0.459 │ 0.48  │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.884 │ 0.816 │ 0.836 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.6150, ET: 0.4709, TC: 0.4542, WT: 0.9198
[0m
[0;32m2025-05-16 10:58:00,802  - INFO - ✨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.6150_dice0.4025_20250516105800.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 10:58:00,802  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 10:59:07,532  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 10:59:07,532  - INFO - - Train mean loss: 0.6422
- ET loss: 0.5063
- TC loss: 0.4822
- WT loss: 0.9382
- Cost time: 1.11mins ⏱️
[0m
[0;32m2025-05-16 10:59:07,532  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 10:59:17,551  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:10.0182s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.477 │ 0.677 │ 0.674 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.38  │ 0.55  │ 0.548 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.476 │ 0.677 │ 0.708 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.821 │ 0.729 │ 0.734 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5341, ET: 0.3442, TC: 0.3386, WT: 0.9195
[0m
[1;31m2025-05-16 10:59:17,553  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.6150_dice0.4025_20250516105800.pth[0m
[0;32m2025-05-16 10:59:17,634  - INFO - ✨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.5341_dice0.4774_20250516105917.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 10:59:17,634  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 11:00:24,377  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 11:00:24,378  - INFO - - Train mean loss: 0.6080
- ET loss: 0.4617
- TC loss: 0.4253
- WT loss: 0.9372
- Cost time: 1.11mins ⏱️
[0m
[0;32m2025-05-16 11:00:24,378  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:00:34,725  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:10.3461s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.49  │ 0.695 │ 0.695 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.396 │ 0.572 │ 0.573 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.491 │ 0.701 │ 0.729 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.826 │ 0.735 │ 0.744 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5198, ET: 0.3229, TC: 0.3169, WT: 0.9195
[0m
[1;31m2025-05-16 11:00:34,726  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.5341_dice0.4774_20250516105917.pth[0m
[0;32m2025-05-16 11:00:34,822  - INFO - ✨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.5198_dice0.4901_20250516110034.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:00:34,823  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 11:01:41,618  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 11:01:41,618  - INFO - - Train mean loss: 0.6051
- ET loss: 0.4492
- TC loss: 0.4245
- WT loss: 0.9415
- Cost time: 1.11mins ⏱️
[0m
[0;32m2025-05-16 11:01:41,618  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 11:01:51,867  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:10.2478s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.491 │ 0.688 │ 0.703 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.395 │ 0.563 │ 0.58  │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.449 │ 0.631 │ 0.674 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.872 │ 0.805 │ 0.811 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5186, ET: 0.3275, TC: 0.3088, WT: 0.9195
[0m
[1;31m2025-05-16 11:01:51,868  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch4_loss0.5198_dice0.4901_20250516110034.pth[0m
[0;32m2025-05-16 11:01:51,963  - INFO - ✨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.5186_dice0.4906_20250516110151.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:01:51,963  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 11:02:58,992  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 11:02:58,992  - INFO - - Train mean loss: 0.5952
- ET loss: 0.4312
- TC loss: 0.4143
- WT loss: 0.9401
- Cost time: 1.12mins ⏱️
[0m
[0;32m2025-05-16 11:02:58,992  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 11:03:09,213  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:10.2196s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.485 │ 0.671 │ 0.704 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.389 │ 0.543 │ 0.581 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.427 │ 0.584 │ 0.656 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.892 │ 0.844 │ 0.833 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5229, ET: 0.3405, TC: 0.3085, WT: 0.9195
[0m
[0;33m2025-05-16 11:03:09,213  - WARNING - 😢😢😢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:03:09,213  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 11:04:16,082  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 11:04:16,083  - INFO - - Train mean loss: 0.5793
- ET loss: 0.4169
- TC loss: 0.3848
- WT loss: 0.9360
- Cost time: 1.11mins ⏱️
[0m
[0;32m2025-05-16 11:04:16,083  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 11:04:26,213  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:10.1292s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.507 │ 0.716 │ 0.724 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.418 │ 0.603 │ 0.608 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.463 │ 0.667 │ 0.681 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.885 │ 0.817 │ 0.838 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5039, ET: 0.3014, TC: 0.2906, WT: 0.9195
[0m
[1;31m2025-05-16 11:04:26,215  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch5_loss0.5186_dice0.4906_20250516110151.pth[0m
[0;32m2025-05-16 11:04:26,292  - INFO - ✨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch7_loss0.5039_dice0.5066_20250516110426.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:04:26,293  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 11:05:33,345  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 11:05:33,345  - INFO - - Train mean loss: 0.5643
- ET loss: 0.3839
- TC loss: 0.3690
- WT loss: 0.9401
- Cost time: 1.12mins ⏱️
[0m
[0;32m2025-05-16 11:05:33,345  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 11:05:43,739  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:10.3926s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.532 │ 0.751 │ 0.764 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.45  │ 0.646 │ 0.661 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.529 │ 0.757 │ 0.786 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.852 │ 0.771 │ 0.784 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4763, ET: 0.2623, TC: 0.2472, WT: 0.9195
[0m
[1;31m2025-05-16 11:05:43,740  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch7_loss0.5039_dice0.5066_20250516110426.pth[0m
[0;32m2025-05-16 11:05:43,819  - INFO - ✨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch8_loss0.4763_dice0.5316_20250516110543.pth;             Size 8.87 MB[0m
[0;32m2025-05-16 11:05:43,820  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 11:06:50,324  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 11:06:50,324  - INFO - - Train mean loss: 0.5555
- ET loss: 0.3794
- TC loss: 0.3496
- WT loss: 0.9376
- Cost time: 1.11mins ⏱️
[0m
[0;32m2025-05-16 11:06:50,324  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 11:07:00,783  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:10.4578s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.526 │ 0.741 │ 0.758 │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.442 │ 0.633 │ 0.651 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.49  │ 0.697 │ 0.731 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.885 │ 0.823 │ 0.833 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4826, ET: 0.2730, TC: 0.2552, WT: 0.9195
[0m
[0;33m2025-05-16 11:07:00,783  - WARNING - 😢😢😢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:07:00,784  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-16 11:08:07,948  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-16 11:08:07,948  - INFO - - Train mean loss: 0.5380
- ET loss: 0.3507
- TC loss: 0.3247
- WT loss: 0.9385
- Cost time: 1.12mins ⏱️
[0m
[0;32m2025-05-16 11:08:07,948  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 11:08:18,718  - INFO - === [Epoch 10/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:10.7687s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.537 │ 0.76  │ 0.77  │ 0.08  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.458 │ 0.66  │ 0.672 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.539 │ 0.772 │ 0.804 │ 0.043 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.851 │ 0.772 │ 0.779 │ 1     │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4701, ET: 0.2521, TC: 0.2387, WT: 0.9195
[0m
[1;31m2025-05-16 11:08:18,719  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch8_loss0.4763_dice0.5316_20250516110543.pth[0m
[0;32m2025-05-16 11:08:18,809  - INFO - ✨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch10_loss0.4701_dice0.5370_20250516110818.pth;             Size 8.88 MB[0m
[1;31m2025-05-16 11:08:18,809  - CRITICAL - 🥳🎉🎊Train finished. Best val loss: 👉0.4701 at epoch 10[0m
[0;32m2025-05-16 11:08:18,809  - INFO - 🛠️ 准备保存最终模型.......[0m
[0;32m2025-05-16 11:08:18,816  - INFO - ✅ 最后一个权重文件已复制为 /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/DCLA_UNet_v3_final_model.pth[0m
[1;31m2025-05-16 11:08:18,816  - CRITICAL - 🥳🎉🎊 最终模型已保存[0m
[0;32m2025-05-16 11:08:18,816  - INFO - 🛠️ 准备测试模型.......[0m
[0;32m2025-05-16 11:15:28,427  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:15:31,899  - INFO - Total number of parameters: 0.60 M[0m
[0;32m2025-05-16 11:15:31,903  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:15:31,903  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:15:31,903  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:15:31,903  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:15:31,903  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:15:31,913  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:15:31,913  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:15:31,913  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:15:31,920  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.60 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:15:32,397  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:15:32,398  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:16:38,909  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:16:38,910  - INFO - - Train mean loss: 0.8784
- ET loss: 0.9109
- TC loss: 0.8866
- WT loss: 0.8377
- Cost time: 1.11mins ⏱️
[0m
[0;32m2025-05-16 11:16:38,910  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:16:49,358  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:10.4463s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.529 │ 0.463 │ 0.487 │ 0.636 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.395 │ 0.323 │ 0.349 │ 0.511 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.533 │ 0.398 │ 0.421 │ 0.779 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.678 │ 0.694 │ 0.748 │ 0.591 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4926, ET: 0.5621, TC: 0.5385, WT: 0.3771
[0m
[1;31m2025-05-16 11:16:49,359  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch10_loss0.4701_dice0.5370_20250516110818.pth[0m
[0;32m2025-05-16 11:16:49,443  - INFO - ✨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4926_dice0.5286_20250516111649.pth;             Size 7.83 MB[0m
[0;32m2025-05-16 11:16:49,444  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:17:54,961  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:17:54,962  - INFO - - Train mean loss: 0.5311
- ET loss: 0.5963
- TC loss: 0.5903
- WT loss: 0.4068
- Cost time: 1.09mins ⏱️
[0m
[0;32m2025-05-16 11:17:54,962  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:18:05,296  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.3336s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.593 │ 0.593 │ 0.472 │ 0.715 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.462 │ 0.454 │ 0.334 │ 0.599 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.556 │ 0.516 │ 0.375 │ 0.778 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.774 │ 0.752 │ 0.839 │ 0.731 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4210, ET: 0.4362, TC: 0.5345, WT: 0.2925
[0m
[1;31m2025-05-16 11:18:05,298  - CRITICAL - 🗑️ Due to reach the max save amount, Removed DCLA_UNet_v3_final_model.pth[0m
[0;32m2025-05-16 11:18:05,394  - INFO - ✨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4210_dice0.5932_20250516111805.pth;             Size 7.83 MB[0m
[0;32m2025-05-16 11:18:05,394  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 11:19:10,778  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 11:19:10,778  - INFO - - Train mean loss: 0.5007
- ET loss: 0.5346
- TC loss: 0.5981
- WT loss: 0.3694
- Cost time: 1.09mins ⏱️
[0m
[0;32m2025-05-16 11:19:10,778  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:19:20,973  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:10.1936s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.625 │ 0.636 │ 0.494 │ 0.746 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.491 │ 0.498 │ 0.351 │ 0.624 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.567 │ 0.558 │ 0.385 │ 0.759 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.81  │ 0.794 │ 0.853 │ 0.782 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3922, ET: 0.3928, TC: 0.5157, WT: 0.2680
[0m
[1;31m2025-05-16 11:19:20,974  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.4926_dice0.5286_20250516111649.pth[0m
[0;32m2025-05-16 11:19:21,060  - INFO - ✨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3922_dice0.6252_20250516111920.pth;             Size 7.83 MB[0m
[0;32m2025-05-16 11:19:21,060  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:19:45,055  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:19:48,482  - INFO - Total number of parameters: 0.60 M[0m
[0;32m2025-05-16 11:19:48,484  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:19:48,484  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:19:48,484  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:19:48,484  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:19:48,484  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:19:48,491  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:19:48,491  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:19:48,491  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:19:48,494  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v3                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.60 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:19:48,836  - INFO - 
model: DCLA_UNet_v3
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:19:48,837  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:20:48,578  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:20:48,579  - INFO - - Train mean loss: 0.7098
- ET loss: 0.8247
- TC loss: 0.7460
- WT loss: 0.5589
- Cost time: 1.00mins ⏱️
[0m
[0;32m2025-05-16 11:20:48,579  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:20:58,524  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.9434s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.521 │ 0.363 │ 0.475 │ 0.726 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.395 │ 0.235 │ 0.336 │ 0.613 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.516 │ 0.266 │ 0.4   │ 0.882 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.719 │ 0.738 │ 0.763 │ 0.657 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4851, ET: 0.6443, TC: 0.5329, WT: 0.2783
[0m
[1;31m2025-05-16 11:20:58,526  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.4210_dice0.5932_20250516111805.pth[0m
[0;32m2025-05-16 11:20:58,620  - INFO - ✨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4851_dice0.5214_20250516112058.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:20:58,620  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:21:57,204  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:21:57,205  - INFO - - Train mean loss: 0.5222
- ET loss: 0.6878
- TC loss: 0.5531
- WT loss: 0.3257
- Cost time: 0.98mins ⏱️
[0m
[0;32m2025-05-16 11:21:57,205  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:22:06,898  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:9.6917s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.563 │ 0.414 │ 0.532 │ 0.744 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.434 │ 0.279 │ 0.39  │ 0.633 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.567 │ 0.318 │ 0.458 │ 0.927 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.759 │ 0.795 │ 0.817 │ 0.664 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4403, ET: 0.5901, TC: 0.4724, WT: 0.2584
[0m
[1;31m2025-05-16 11:22:06,899  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.3922_dice0.6252_20250516111920.pth[0m
[0;32m2025-05-16 11:22:06,994  - INFO - ✨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.4403_dice0.5631_20250516112206.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:22:06,994  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 11:23:05,619  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 11:23:05,619  - INFO - - Train mean loss: 0.5309
- ET loss: 0.6889
- TC loss: 0.5649
- WT loss: 0.3389
- Cost time: 0.98mins ⏱️
[0m
[0;32m2025-05-16 11:23:05,619  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:23:15,318  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:9.6971s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.573 │ 0.406 │ 0.527 │ 0.788 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.445 │ 0.271 │ 0.384 │ 0.68  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.53  │ 0.287 │ 0.413 │ 0.889 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.826 │ 0.863 │ 0.88  │ 0.735 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4314, ET: 0.5982, TC: 0.4786, WT: 0.2173
[0m
[1;31m2025-05-16 11:23:15,320  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch1_loss0.4851_dice0.5214_20250516112058.pth[0m
[0;32m2025-05-16 11:23:15,413  - INFO - ✨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.4314_dice0.5735_20250516112315.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:23:15,414  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 11:24:14,015  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 11:24:14,015  - INFO - - Train mean loss: 0.4980
- ET loss: 0.6585
- TC loss: 0.5207
- WT loss: 0.3148
- Cost time: 0.98mins ⏱️
[0m
[0;32m2025-05-16 11:24:14,015  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:24:23,456  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:9.4403s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.587 │ 0.437 │ 0.561 │ 0.763 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.455 │ 0.299 │ 0.419 │ 0.648 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.565 │ 0.319 │ 0.458 │ 0.918 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.801 │ 0.853 │ 0.871 │ 0.681 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4165, ET: 0.5663, TC: 0.4434, WT: 0.2398
[0m
[1;31m2025-05-16 11:24:23,457  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.4403_dice0.5631_20250516112206.pth[0m
[0;32m2025-05-16 11:24:23,532  - INFO - ✨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.4165_dice0.5870_20250516112423.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:24:23,533  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 11:25:22,888  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 11:25:22,888  - INFO - - Train mean loss: 0.4860
- ET loss: 0.6419
- TC loss: 0.5041
- WT loss: 0.3121
- Cost time: 0.99mins ⏱️
[0m
[0;32m2025-05-16 11:25:22,888  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 11:25:32,347  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:9.4566s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.59  │ 0.441 │ 0.564 │ 0.765 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.458 │ 0.303 │ 0.422 │ 0.649 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.564 │ 0.319 │ 0.455 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.807 │ 0.86  │ 0.878 │ 0.681 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4132, ET: 0.5619, TC: 0.4400, WT: 0.2376
[0m
[1;31m2025-05-16 11:25:32,348  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.4314_dice0.5735_20250516112315.pth[0m
[0;32m2025-05-16 11:25:32,438  - INFO - ✨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.4132_dice0.5901_20250516112532.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:25:32,438  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 11:26:31,256  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 11:26:31,256  - INFO - - Train mean loss: 0.4879
- ET loss: 0.6230
- TC loss: 0.4891
- WT loss: 0.3514
- Cost time: 0.98mins ⏱️
[0m
[0;32m2025-05-16 11:26:31,256  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 11:26:40,822  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:9.5645s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.597 │ 0.496 │ 0.615 │ 0.679 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.458 │ 0.355 │ 0.478 │ 0.543 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.627 │ 0.388 │ 0.547 │ 0.948 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.736 │ 0.82  │ 0.833 │ 0.555 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4053, ET: 0.5069, TC: 0.3882, WT: 0.3209
[0m
[1;31m2025-05-16 11:26:40,824  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch4_loss0.4165_dice0.5870_20250516112423.pth[0m
[0;32m2025-05-16 11:26:40,918  - INFO - ✨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch6_loss0.4053_dice0.5967_20250516112640.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:26:40,918  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 11:27:39,279  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 11:27:39,279  - INFO - - Train mean loss: 0.4801
- ET loss: 0.6061
- TC loss: 0.4689
- WT loss: 0.3654
- Cost time: 0.97mins ⏱️
[0m
[0;32m2025-05-16 11:27:39,279  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 11:27:48,157  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:8.8769s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.6   │ 0.503 │ 0.623 │ 0.675 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.463 │ 0.361 │ 0.488 │ 0.54  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.621 │ 0.387 │ 0.547 │ 0.929 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.753 │ 0.844 │ 0.856 │ 0.56  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4014, ET: 0.5003, TC: 0.3799, WT: 0.3241
[0m
[1;31m2025-05-16 11:27:48,159  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch5_loss0.4132_dice0.5901_20250516112532.pth[0m
[0;32m2025-05-16 11:27:48,236  - INFO - ✨ Saved checkpoint (epoch 7) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch7_loss0.4014_dice0.6003_20250516112748.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:27:48,236  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 11:28:46,652  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 11:28:46,652  - INFO - - Train mean loss: 0.4748
- ET loss: 0.5885
- TC loss: 0.4519
- WT loss: 0.3841
- Cost time: 0.97mins ⏱️
[0m
[0;32m2025-05-16 11:28:46,652  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 11:28:55,488  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:8.8347s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.599 │ 0.472 │ 0.596 │ 0.728 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.463 │ 0.331 │ 0.457 │ 0.6   │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.585 │ 0.346 │ 0.492 │ 0.918 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.794 │ 0.871 │ 0.884 │ 0.628 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4034, ET: 0.5306, TC: 0.4071, WT: 0.2725
[0m
[0;33m2025-05-16 11:28:55,488  - WARNING - 😢😢😢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:28:55,488  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 11:29:53,951  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 11:29:53,951  - INFO - - Train mean loss: 0.4590
- ET loss: 0.5684
- TC loss: 0.4356
- WT loss: 0.3729
- Cost time: 0.97mins ⏱️
[0m
[0;32m2025-05-16 11:29:53,951  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 11:30:02,706  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v3
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:8.7540s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.612 │ 0.527 │ 0.651 │ 0.658 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.474 │ 0.385 │ 0.52  │ 0.518 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.628 │ 0.402 │ 0.566 │ 0.917 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.76  │ 0.865 │ 0.877 │ 0.539 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3898, ET: 0.4762, TC: 0.3523, WT: 0.3408
[0m
[1;31m2025-05-16 11:30:02,707  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch6_loss0.4053_dice0.5967_20250516112640.pth[0m
[0;32m2025-05-16 11:30:02,783  - INFO - ✨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v3_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch9_loss0.3898_dice0.6119_20250516113002.pth;             Size 7.82 MB[0m
[0;32m2025-05-16 11:30:02,783  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 11:31:01,333  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:31:09,287  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:33:25,528  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:33:29,049  - INFO - Total number of parameters: 0.65 M[0m
[0;32m2025-05-16 11:33:29,052  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:33:29,052  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:33:29,052  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:33:29,052  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:33:29,052  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:33:29,059  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:33:29,060  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:33:29,060  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:33:29,063  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v4                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.65 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:33:34,596  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:33:38,043  - INFO - Total number of parameters: 0.97 M[0m
[0;32m2025-05-16 11:33:38,045  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:33:38,046  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:33:38,046  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:33:38,046  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:33:38,046  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:33:38,053  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:33:38,053  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:33:38,053  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:33:38,057  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ ResUNetBaseline_S_SLK_v4                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.97 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:34:12,474  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:34:15,815  - INFO - Total number of parameters: 0.60 M[0m
[0;32m2025-05-16 11:34:15,818  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:34:15,818  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:34:15,818  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:34:15,818  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:34:15,818  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:34:15,825  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:34:15,825  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:34:15,825  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:34:15,829  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v4                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.60 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:34:21,755  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:34:25,125  - INFO - Total number of parameters: 0.93 M[0m
[0;32m2025-05-16 11:34:25,127  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:34:25,127  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:34:25,127  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:34:25,128  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:34:25,128  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:34:25,135  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:34:25,135  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:34:25,135  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:34:25,139  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ ResUNetBaseline_S_SLK_v4                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.93 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:34:25,374  - INFO - 
model: ResUNetBaseline_S_SLK_v4
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:34:25,374  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:35:01,005  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:35:01,006  - INFO - - Train mean loss: 0.7696
- ET loss: 0.7296
- TC loss: 0.6670
- WT loss: 0.9123
- Cost time: 0.59mins ⏱️
[0m
[0;32m2025-05-16 11:35:01,006  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:35:09,832  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLK_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.8249s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.412 │ 0.518 │ 0.624 │ 0.093 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.308 │ 0.379 │ 0.495 │ 0.05  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.388 │ 0.475 │ 0.638 │ 0.05  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.8   │ 0.714 │ 0.721 │ 0.964 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5937, ET: 0.4895, TC: 0.3848, WT: 0.9067
[0m
[0;32m2025-05-16 11:35:09,876  - INFO - ✨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLK_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.5937_dice0.4117_20250516113509.pth;             Size 11.30 MB[0m
[0;32m2025-05-16 11:35:09,877  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:35:44,807  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:35:44,807  - INFO - - Train mean loss: 0.6537
- ET loss: 0.5538
- TC loss: 0.5003
- WT loss: 0.9070
- Cost time: 0.58mins ⏱️
[0m
[0;32m2025-05-16 11:35:44,807  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:35:53,009  - INFO - === [Epoch 2/10] ===
- Model:    ResUNetBaseline_S_SLK_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:8.1992s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.449 │ 0.59  │ 0.66  │ 0.098 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.351 │ 0.459 │ 0.543 │ 0.053 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.492 │ 0.627 │ 0.795 │ 0.053 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.76  │ 0.662 │ 0.638 │ 0.98  │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.5529, ET: 0.4134, TC: 0.3436, WT: 0.9017
[0m
[0;32m2025-05-16 11:35:53,044  - INFO - ✨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLK_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.5529_dice0.4494_20250516113553.pth;             Size 11.30 MB[0m
[0;32m2025-05-16 11:35:53,045  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:36:27,493  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:36:30,996  - INFO - Total number of parameters: 2.38 M[0m
[0;32m2025-05-16 11:36:31,000  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:36:31,000  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:36:31,000  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:36:31,000  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:36:31,000  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:36:31,009  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:36:31,010  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:36:31,010  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:36:31,016  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v4                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 2.38 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:37:22,950  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:37:26,421  - INFO - Total number of parameters: 2.38 M[0m
[0;32m2025-05-16 11:37:26,424  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:37:26,424  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:37:26,424  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:37:26,424  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:37:26,424  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:37:26,431  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:37:26,431  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:37:26,431  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:37:26,435  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v4                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 2.38 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:37:31,596  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:42:04,276  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:42:07,713  - INFO - Total number of parameters: 0.74 M[0m
[0;32m2025-05-16 11:42:07,716  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:42:07,716  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:42:07,716  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:42:07,716  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:42:07,716  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:42:07,724  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:42:07,724  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:42:07,724  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:42:07,728  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ DCLA_UNet_v4                                                    │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.74 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:42:08,045  - INFO - 
model: DCLA_UNet_v4
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:42:08,046  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:43:09,883  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:43:09,883  - INFO - - Train mean loss: 0.6467
- ET loss: 0.6624
- TC loss: 0.6496
- WT loss: 0.6280
- Cost time: 1.03mins ⏱️
[0m
[0;32m2025-05-16 11:43:09,883  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:43:19,501  - INFO - === [Epoch 1/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:9.6160s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.656 │ 0.581 │ 0.632 │ 0.753 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.527 │ 0.442 │ 0.505 │ 0.635 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.643 │ 0.515 │ 0.639 │ 0.777 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.751 │ 0.769 │ 0.72  │ 0.763 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3691, ET: 0.4413, TC: 0.3912, WT: 0.2748
[0m
[0;32m2025-05-16 11:43:19,565  - INFO - ✨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.3691_dice0.6556_20250516114319.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:43:19,566  - INFO - === Training on [Epoch 2/10] ===:[0m
[0;33m2025-05-16 11:44:20,068  - WARNING - lr reduce to 9.991120277927223e-05[0m
[0;32m2025-05-16 11:44:20,069  - INFO - - Train mean loss: 0.4557
- ET loss: 0.5208
- TC loss: 0.4954
- WT loss: 0.3511
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:44:20,069  - INFO - === Validating on [Epoch 2/10] ===:[0m
[0;32m2025-05-16 11:44:30,216  - INFO - === [Epoch 2/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.991120277927223e-05
- val_cost_time:10.1457s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.704 │ 0.665 │ 0.662 │ 0.786 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.588 │ 0.54  │ 0.544 │ 0.679 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.75  │ 0.655 │ 0.757 │ 0.838 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.72  │ 0.741 │ 0.652 │ 0.765 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3134, ET: 0.3544, TC: 0.3542, WT: 0.2316
[0m
[0;32m2025-05-16 11:44:30,292  - INFO - ✨ Saved checkpoint (epoch 2) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch2_loss0.3134_dice0.7041_20250516114430.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:44:30,292  - INFO - === Training on [Epoch 3/10] ===:[0m
[0;33m2025-05-16 11:45:31,111  - WARNING - lr reduce to 9.980028840713861e-05[0m
[0;32m2025-05-16 11:45:31,112  - INFO - - Train mean loss: 0.4137
- ET loss: 0.4662
- TC loss: 0.4601
- WT loss: 0.3149
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:45:31,112  - INFO - === Validating on [Epoch 3/10] ===:[0m
[0;32m2025-05-16 11:45:41,029  - INFO - === [Epoch 3/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.980028840713861e-05
- val_cost_time:9.9152s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.712 │ 0.669 │ 0.683 │ 0.785 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.597 │ 0.544 │ 0.567 │ 0.679 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.764 │ 0.646 │ 0.762 │ 0.884 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.727 │ 0.765 │ 0.684 │ 0.732 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.3013, ET: 0.3468, TC: 0.3316, WT: 0.2255
[0m
[1;31m2025-05-16 11:45:41,030  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.3134_dice0.7041_20250516114430.pth[0m
[0;32m2025-05-16 11:45:41,102  - INFO - ✨ Saved checkpoint (epoch 3) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch3_loss0.3013_dice0.7122_20250516114541.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:45:41,103  - INFO - === Training on [Epoch 4/10] ===:[0m
[0;33m2025-05-16 11:46:42,161  - WARNING - lr reduce to 9.964516155915153e-05[0m
[0;32m2025-05-16 11:46:42,162  - INFO - - Train mean loss: 0.4002
- ET loss: 0.4480
- TC loss: 0.4497
- WT loss: 0.3030
- Cost time: 1.02mins ⏱️
[0m
[0;32m2025-05-16 11:46:42,162  - INFO - === Validating on [Epoch 4/10] ===:[0m
[0;32m2025-05-16 11:46:52,004  - INFO - === [Epoch 4/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.964516155915153e-05
- val_cost_time:9.8415s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.73  │ 0.696 │ 0.693 │ 0.802 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.615 │ 0.575 │ 0.577 │ 0.694 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.742 │ 0.665 │ 0.767 │ 0.794 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.77  │ 0.788 │ 0.69  │ 0.833 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2847, ET: 0.3196, TC: 0.3198, WT: 0.2147
[0m
[1;31m2025-05-16 11:46:52,006  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch3_loss0.3013_dice0.7122_20250516114541.pth[0m
[0;32m2025-05-16 11:46:52,085  - INFO - ✨ Saved checkpoint (epoch 4) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch4_loss0.2847_dice0.7302_20250516114652.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:46:52,086  - INFO - === Training on [Epoch 5/10] ===:[0m
[0;33m2025-05-16 11:47:52,978  - WARNING - lr reduce to 9.944597532678122e-05[0m
[0;32m2025-05-16 11:47:52,978  - INFO - - Train mean loss: 0.3805
- ET loss: 0.4289
- TC loss: 0.4338
- WT loss: 0.2789
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:47:52,978  - INFO - === Validating on [Epoch 5/10] ===:[0m
[0;32m2025-05-16 11:48:02,582  - INFO - === [Epoch 5/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.944597532678122e-05
- val_cost_time:9.6035s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.729 │ 0.67  │ 0.706 │ 0.81  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.613 │ 0.542 │ 0.591 │ 0.706 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.729 │ 0.606 │ 0.748 │ 0.833 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.791 │ 0.818 │ 0.745 │ 0.812 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2829, ET: 0.3416, TC: 0.3056, WT: 0.2015
[0m
[1;31m2025-05-16 11:48:02,584  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch4_loss0.2847_dice0.7302_20250516114652.pth[0m
[0;32m2025-05-16 11:48:02,647  - INFO - ✨ Saved checkpoint (epoch 5) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch5_loss0.2829_dice0.7285_20250516114802.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:48:02,648  - INFO - === Training on [Epoch 6/10] ===:[0m
[0;33m2025-05-16 11:49:03,367  - WARNING - lr reduce to 9.920292628279102e-05[0m
[0;32m2025-05-16 11:49:03,368  - INFO - - Train mean loss: 0.3568
- ET loss: 0.4017
- TC loss: 0.4044
- WT loss: 0.2642
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:49:03,368  - INFO - === Validating on [Epoch 6/10] ===:[0m
[0;32m2025-05-16 11:49:12,903  - INFO - === [Epoch 6/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.920292628279102e-05
- val_cost_time:9.5341s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.737 │ 0.717 │ 0.691 │ 0.803 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.629 │ 0.606 │ 0.579 │ 0.703 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.818 │ 0.735 │ 0.828 │ 0.892 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.716 │ 0.75  │ 0.64  │ 0.758 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2727, ET: 0.2958, TC: 0.3186, WT: 0.2037
[0m
[1;31m2025-05-16 11:49:12,904  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch5_loss0.2829_dice0.7285_20250516114802.pth[0m
[0;32m2025-05-16 11:49:13,208  - INFO - ✨ Saved checkpoint (epoch 6) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch6_loss0.2727_dice0.7372_20250516114912.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:49:13,209  - INFO - === Training on [Epoch 7/10] ===:[0m
[0;33m2025-05-16 11:50:13,977  - WARNING - lr reduce to 9.891625428724366e-05[0m
[0;32m2025-05-16 11:50:13,977  - INFO - - Train mean loss: 0.3843
- ET loss: 0.4268
- TC loss: 0.4448
- WT loss: 0.2814
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:50:13,977  - INFO - === Validating on [Epoch 7/10] ===:[0m
[0;32m2025-05-16 11:50:23,712  - INFO - === [Epoch 7/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.891625428724366e-05
- val_cost_time:9.7336s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.73  │ 0.664 │ 0.711 │ 0.817 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.613 │ 0.535 │ 0.594 │ 0.711 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.694 │ 0.571 │ 0.713 │ 0.798 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.832 │ 0.857 │ 0.783 │ 0.857 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2798, ET: 0.3452, TC: 0.2990, WT: 0.1953
[0m
[0;33m2025-05-16 11:50:23,712  - WARNING - 😢😢😢Early stopping counter: 1/5[0m
[0;32m2025-05-16 11:50:23,713  - INFO - === Training on [Epoch 8/10] ===:[0m
[0;33m2025-05-16 11:51:24,592  - WARNING - lr reduce to 9.858624225078842e-05[0m
[0;32m2025-05-16 11:51:24,593  - INFO - - Train mean loss: 0.3821
- ET loss: 0.4389
- TC loss: 0.4475
- WT loss: 0.2600
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:51:24,593  - INFO - === Validating on [Epoch 8/10] ===:[0m
[0;32m2025-05-16 11:51:34,130  - INFO - === [Epoch 8/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.858624225078842e-05
- val_cost_time:9.5361s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.742 │ 0.697 │ 0.718 │ 0.81  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.633 │ 0.578 │ 0.609 │ 0.712 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.788 │ 0.659 │ 0.801 │ 0.903 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.76  │ 0.8   │ 0.715 │ 0.763 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2658, ET: 0.3119, TC: 0.2909, WT: 0.1946
[0m
[1;31m2025-05-16 11:51:34,131  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch6_loss0.2727_dice0.7372_20250516114912.pth[0m
[0;32m2025-05-16 11:51:34,193  - INFO - ✨ Saved checkpoint (epoch 8) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch8_loss0.2658_dice0.7417_20250516115134.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:51:34,194  - INFO - === Training on [Epoch 9/10] ===:[0m
[0;33m2025-05-16 11:52:35,627  - WARNING - lr reduce to 9.821321585546247e-05[0m
[0;32m2025-05-16 11:52:35,627  - INFO - - Train mean loss: 0.3619
- ET loss: 0.4106
- TC loss: 0.4188
- WT loss: 0.2562
- Cost time: 1.02mins ⏱️
[0m
[0;32m2025-05-16 11:52:35,627  - INFO - === Validating on [Epoch 9/10] ===:[0m
[0;32m2025-05-16 11:52:44,699  - INFO - === [Epoch 9/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.821321585546247e-05
- val_cost_time:9.0711s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.747 │ 0.702 │ 0.724 │ 0.815 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.635 │ 0.584 │ 0.614 │ 0.708 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.724 │ 0.637 │ 0.762 │ 0.772 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.828 │ 0.847 │ 0.754 │ 0.883 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2631, ET: 0.3076, TC: 0.2861, WT: 0.1956
[0m
[1;31m2025-05-16 11:52:44,701  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch8_loss0.2658_dice0.7417_20250516115134.pth[0m
[0;32m2025-05-16 11:52:44,764  - INFO - ✨ Saved checkpoint (epoch 9) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch9_loss0.2631_dice0.7469_20250516115244.pth;             Size 9.36 MB[0m
[0;32m2025-05-16 11:52:44,764  - INFO - === Training on [Epoch 10/10] ===:[0m
[0;33m2025-05-16 11:53:45,272  - WARNING - lr reduce to 9.779754323328194e-05[0m
[0;32m2025-05-16 11:53:45,272  - INFO - - Train mean loss: 0.3358
- ET loss: 0.3764
- TC loss: 0.3896
- WT loss: 0.2413
- Cost time: 1.01mins ⏱️
[0m
[0;32m2025-05-16 11:53:45,272  - INFO - === Validating on [Epoch 10/10] ===:[0m
[0;32m2025-05-16 11:53:54,236  - INFO - === [Epoch 10/10] ===
- Model:    DCLA_UNet_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.779754323328194e-05
- val_cost_time:8.9628s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.756 │ 0.715 │ 0.726 │ 0.828 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.65  │ 0.602 │ 0.62  │ 0.727 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.761 │ 0.664 │ 0.796 │ 0.824 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.803 │ 0.827 │ 0.73  │ 0.852 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.2524, ET: 0.2932, TC: 0.2821, WT: 0.1819
[0m
[1;31m2025-05-16 11:53:54,238  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch9_loss0.2631_dice0.7469_20250516115244.pth[0m
[0;32m2025-05-16 11:53:54,299  - INFO - ✨ Saved checkpoint (epoch 10) to /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch10_loss0.2524_dice0.7565_20250516115354.pth;             Size 9.36 MB[0m
[1;31m2025-05-16 11:53:54,300  - CRITICAL - 🥳🎉🎊Train finished. Best val loss: 👉0.2524 at epoch 10[0m
[0;32m2025-05-16 11:53:54,300  - INFO - 🛠️ 准备保存最终模型.......[0m
[0;32m2025-05-16 11:53:54,305  - INFO - ✅ 最后一个权重文件已复制为 /root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/DCLA_UNet_v4_final_model.pth[0m
[1;31m2025-05-16 11:53:54,305  - CRITICAL - 🥳🎉🎊 最终模型已保存[0m
[0;32m2025-05-16 11:53:54,305  - INFO - 🛠️ 准备测试模型.......[0m
[1;31m2025-05-16 11:54:47,022  - CRITICAL - === [FINAL TEST METRIC] ===
╒═══════════════╤════════╤═══════╤═══════╤════════╕
│ Metric_Name   │   MEAN │    ET │    TC │     WT │
╞═══════════════╪════════╪═══════╪═══════╪════════╡
│ Dice          │  0.758 │ 0.72  │ 0.708 │  0.847 │
├───────────────┼────────┼───────┼───────┼────────┤
│ Jaccard       │  0.642 │ 0.594 │ 0.588 │  0.745 │
├───────────────┼────────┼───────┼───────┼────────┤
│ Precision     │  0.819 │ 0.693 │ 0.871 │  0.892 │
├───────────────┼────────┼───────┼───────┼────────┤
│ Recall        │  0.77  │ 0.812 │ 0.664 │  0.834 │
├───────────────┼────────┼───────┼───────┼────────┤
│ H95           │  9.966 │ 9.365 │ 9.544 │ 10.988 │
╘═══════════════╧════════╧═══════╧═══════╧════════╛
Mean Loss: 0.2501;ET: 0.2909;ET: 0.2909;TC: 0.2990;WT: 0.1603
[0m
[0;32m2025-05-16 11:54:47,022  - INFO - 🥳🎉🎊 模型测试已完成.......[0m
[0;32m2025-05-16 11:54:47,023  - INFO - 测试集的指标已保存至/root/autodl-tmp/DCLA-UNet/results/DCLA_UNet_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/logs/2025-05-16.log[0m
[0;32m2025-05-16 11:54:52,824  - INFO - 加载配置文件耗时: 0.00 s[0m
[0;32m2025-05-16 11:54:56,247  - INFO - Total number of parameters: 0.93 M[0m
[0;32m2025-05-16 11:54:56,250  - INFO - 数据集差异分析结果:
训练集样本数: 875
验证集样本数: 250
测试集样本数: 126
----------------------------------------[0m
[0;32m2025-05-16 11:54:56,250  - INFO - train_val_overlap: 无重叠[0m
[0;32m2025-05-16 11:54:56,250  - INFO - train_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:54:56,250  - INFO - val_test_overlap: 无重叠[0m
[0;32m2025-05-16 11:54:56,250  - INFO - all_overlap: 无重叠[0m
[0;33m2025-05-16 11:54:56,257  - WARNING - 训练集大小变成：210[0m
[0;33m2025-05-16 11:54:56,258  - WARNING - 验证集大小变成：60[0m
[0;33m2025-05-16 11:54:56,258  - WARNING - 测试大小变成：30[0m
[0;32m2025-05-16 11:54:56,261  - INFO - 🧠 项目名：lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100 
╒═════════════════════╤═════════════════════════════════════════════════════════════════╕
│ Parameter           │ Value                                                           │
╞═════════════════════╪═════════════════════════════════════════════════════════════════╡
│ data_root           │ /root/autodl-tmp/DCLA-UNet/data/brats21/BraTS2021_Training_Data │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ outputs_dir         │ /root/autodl-tmp/DCLA-UNet/outputs                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ results_dir         │ /root/autodl-tmp/DCLA-UNet/results                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ in_channel          │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ out_channel         │ 4                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ config              │ None                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ model_name          │ ResUNetBaseline_S_SLK_v4                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb_project         │ lr2e-4_wd1e-5_mlr1e-5_epochs200_T_max100                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ resume              │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ loss_type           │ diceloss                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ optimizer_type      │ adamw                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ epochs              │ 10                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ batch_size          │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ num_workers         │ 8                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ lr                  │ 0.0001                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ wd                  │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_eta_min      │ 1e-05                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ cosine_T_max        │ 100                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ early_stop_patience │ 5                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ scheduler_type      │ cosine                                                          │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ save_max            │ 2                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ interval            │ 1                                                               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ commit              │ Training                                                        │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ data_split          │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ local               │ True                                                            │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_length        │ 210                                                             │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_length          │ 60                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_length         │ 30                                                              │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ slb                 │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ tb                  │ False                                                           │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ train_csv_path      │ /root/autodl-tmp/DCLA-UNet/data/brats21/train.csv               │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ val_csv_path        │ /root/autodl-tmp/DCLA-UNet/data/brats21/val.csv                 │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ test_csv_path       │ /root/autodl-tmp/DCLA-UNet/data/brats21/test.csv                │
├─────────────────────┼─────────────────────────────────────────────────────────────────┤
│ total_parms         │ 0.93 M                                                          │
╘═════════════════════╧═════════════════════════════════════════════════════════════════╛[0m
[0;32m2025-05-16 11:54:56,488  - INFO - 
model: ResUNetBaseline_S_SLK_v4
optimizer: AdamW
scheduler: CosineAnnealingLR
loss_function: DiceLoss
initial_lr: 0.0001
batch_size: 2
num_epochs: 10
early_stopping: 5
[0m
[0;32m2025-05-16 11:54:56,488  - INFO - === Training on [Epoch 1/10] ===:[0m
[0;33m2025-05-16 11:55:33,078  - WARNING - lr reduce to 9.997779521645793e-05[0m
[0;32m2025-05-16 11:55:33,079  - INFO - - Train mean loss: 0.6166
- ET loss: 0.7464
- TC loss: 0.6563
- WT loss: 0.4471
- Cost time: 0.61mins ⏱️
[0m
[0;32m2025-05-16 11:55:33,079  - INFO - === Validating on [Epoch 1/10] ===:[0m
[0;32m2025-05-16 11:55:41,803  - INFO - === [Epoch 1/10] ===
- Model:    ResUNetBaseline_S_SLK_v4
- Optimizer:AdamW
- Scheduler:CosineAnnealingLR
- LossFunc: DiceLoss
- Lr:       9.997779521645793e-05
- val_cost_time:8.7223s ⏱️
- early_stopping: 5
╒═══════════════╤════════╤═══════╤═══════╤═══════╕
│ Metric_Name   │   MEAN │    ET │    TC │    WT │
╞═══════════════╪════════╪═══════╪═══════╪═══════╡
│ Dice          │  0.595 │ 0.47  │ 0.535 │ 0.78  │
├───────────────┼────────┼───────┼───────┼───────┤
│ Jaccard       │  0.466 │ 0.329 │ 0.393 │ 0.676 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Precision     │  0.566 │ 0.364 │ 0.479 │ 0.854 │
├───────────────┼────────┼───────┼───────┼───────┤
│ Recall        │  0.759 │ 0.782 │ 0.744 │ 0.752 │
╘═══════════════╧════════╧═══════╧═══════╧═══════╛
Mean Loss: 0.4187, ET: 0.5483, TC: 0.4843, WT: 0.2235
[0m
[1;31m2025-05-16 11:55:41,805  - CRITICAL - 🗑️ Due to reach the max save amount, Removed best_epoch2_loss0.5529_dice0.4494_20250516113553.pth[0m
[0;32m2025-05-16 11:55:41,845  - INFO - ✨ Saved checkpoint (epoch 1) to /root/autodl-tmp/DCLA-UNet/results/ResUNetBaseline_S_SLK_v4_2025-05-16_lr0.0001_mlr1e-05_Tmax100_10_5/checkpoints/best_epoch1_loss0.4187_dice0.5950_20250516115541.pth;             Size 11.30 MB[0m
[0;32m2025-05-16 11:55:41,845  - INFO - === Training on [Epoch 2/10] ===:[0m
